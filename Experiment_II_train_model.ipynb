{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Experiment_II_train_model.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"xZlaIJnq3nGD"},"source":["## Model Training (Done on Google Collab)\n","### VGG19 train & tune\n","### DenseNet train & tune\n","### Xception train & tune"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ejixluTATVDy","executionInfo":{"status":"ok","timestamp":1619177158932,"user_tz":240,"elapsed":21525,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"4c02b477-39a6-486b-d35b-557a7c5ec7b9"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"BN5T7AsM5iA0"},"source":["# 1.Package & Dependencies Setup"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pORElq4lpDpD","executionInfo":{"status":"ok","timestamp":1619177164661,"user_tz":240,"elapsed":7480,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"73572641-1e1e-4e8e-e297-b3e785c02049"},"source":["\"\"\"Install NSL package\"\"\"\n","!pip install --upgrade neural_structured_learning\n","!pip install tensorflow-addons"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting neural_structured_learning\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8a/23/179e6b7555000de51d9a317e9e47db84cda0180c941cfbf14775925af611/neural_structured_learning-1.3.1-py2.py3-none-any.whl (120kB)\n","\r\u001b[K     |██▊                             | 10kB 21.2MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 20kB 27.2MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 30kB 21.4MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 40kB 24.9MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 51kB 26.2MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 61kB 28.6MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 71kB 19.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 81kB 20.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 92kB 19.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 102kB 20.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 112kB 20.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 122kB 20.0MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.7/dist-packages (from neural_structured_learning) (1.15.0)\n","Requirement already satisfied, skipping upgrade: absl-py in /usr/local/lib/python3.7/dist-packages (from neural_structured_learning) (0.12.0)\n","Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.7/dist-packages (from neural_structured_learning) (1.4.1)\n","Requirement already satisfied, skipping upgrade: attrs in /usr/local/lib/python3.7/dist-packages (from neural_structured_learning) (20.3.0)\n","Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy->neural_structured_learning) (1.19.5)\n","Installing collected packages: neural-structured-learning\n","Successfully installed neural-structured-learning-1.3.1\n","Collecting tensorflow-addons\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/e3/56d2fe76f0bb7c88ed9b2a6a557e25e83e252aec08f13de34369cd850a0b/tensorflow_addons-0.12.1-cp37-cp37m-manylinux2010_x86_64.whl (703kB)\n","\u001b[K     |████████████████████████████████| 706kB 17.2MB/s \n","\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n","Installing collected packages: tensorflow-addons\n","Successfully installed tensorflow-addons-0.12.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0y7x5Ku4pHI5","executionInfo":{"status":"ok","timestamp":1619177167452,"user_tz":240,"elapsed":8535,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"74cfc736-66f0-4ab4-c9d8-2f42331c0aa7"},"source":["import numpy as np\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","from neural_structured_learning.tools import graph_utils\n","import neural_structured_learning as nsl\n","import tensorflow_addons as tfa\n","from copy import deepcopy\n","from sklearn.metrics import multilabel_confusion_matrix\n","import random\n","import os\n","import PIL\n","import time\n","import re\n","\n","tf.keras.backend.clear_session()\n","print(\"tensorflow version: \", tf.__version__)\n","print(\"keras version\", tf.keras.__version__)\n","print(\"Eager mode: \", tf.executing_eagerly())\n","print(\"GPU is\", \"available\" if tf.config.experimental.list_physical_devices('GPU') else \"NOT AVAILABLE\")"],"execution_count":3,"outputs":[{"output_type":"stream","text":["tensorflow version:  2.4.1\n","keras version 2.4.0\n","Eager mode:  True\n","GPU is available\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fIT8u-ur2-Tn","executionInfo":{"status":"ok","timestamp":1619177185961,"user_tz":240,"elapsed":409,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}}},"source":["from graph_data_processing import GraphDataProcess\n","from AAE_model import AAE\n","from Kmeans import KMeans, KMeansModels\n","from nsl_data_processing import GenerateTrainTestDict, NSLDataFormat\n","from AD_model_builder import AD_params, ADModelBuilder, AccEarlyStop"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"GX74Sd5dUCA6","executionInfo":{"status":"ok","timestamp":1619177186237,"user_tz":240,"elapsed":306,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}}},"source":["''' label definition: NonDemented - 0, VeryMildDemented - 1, MildDemented -2, ModerateDemented -3 '''\n","label_list = ['NonDemented', 'VeryMildDemented', 'MildDemented', 'ModerateDemented']\n","root_path = '/content/drive/MyDrive/AD Expriment II/graph_images/'\n","train_root_path = f'{root_path}train/'\n","test_root_path = f'{root_path}test/'\n","\n","train_path_list = [f'{train_root_path}{label}/' for label in label_list]\n","train_tfr_list = [f'{train_root_path}{label}.tfr' for label in label_list]\n","\n","test_path_list = [f'{test_root_path}{label}/' for label in label_list]\n","test_tfr_list = [f'{test_root_path}{label}.tfr' for label in label_list]\n","\n","tfr_rep_list = [f'{train_root_path}{label}_AAErep.tfr' for label in label_list]\n","\n","train_tfr_path = f'{train_root_path}train_data.tfr'"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"wZmCxER147rD"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yBqQepbk4729"},"source":["#2.VGG19 & VGG19-NSL Model Training"]},{"cell_type":"code","metadata":{"id":"I7z0hDGW4khr"},"source":["'''define hyper params'''\n","params = AD_params()\n","params.max_seed_nbr=5\n","params.batch_size=64\n","params.image_channels =3\n","params.image_size =(100,100)\n","params.ad_base_model_input_shape=(100,100,3)\n","params.train_tfr_path = train_tfr_path\n","\n","'''parse train_data.tfr to train image dataset with batch_size at 128'''\n","train_image_dataset = NSLDataFormat.parse_tfr_to_dataset(file_path_list=[params.train_tfr_path],\n","                                                         batch_size=params.batch_size,\n","                                                         max_neighbor_number=params.max_seed_nbr,\n","                                                         image_size=params.image_size,\n","                                                         image_channels=params.image_channels,\n","                                                         shuffle=True)\n","\n","'''load test data with batch_size at 128 '''\n","test_image_dataset = NSLDataFormat.generate_test_tfr_image_tensor(path_list=test_tfr_list, \n","                                                                  batch_size=params.batch_size, \n","                                                                  size=params.image_size,\n","                                                                  channels=params.image_channels,\n","                                                                  shuffle=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Nts7SfZMjVeQ"},"source":["## 2.1 VGG19 Base Model Training\n","### val_acc: 0.64, val_auc: 0.89, val_f1_score: 0.64"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A2Nx9izfXeoG","executionInfo":{"status":"ok","timestamp":1617716713672,"user_tz":240,"elapsed":1449,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"6390c1b4-8279-4340-9734-577a35a91d8a"},"source":["'''define params'''\n","params.learning_rate=0.001\n","params.checkpoint_path = '/content/drive/MyDrive/AD Expriment II/VGG19_model_checkpoints/vgg19_weights_base'\n","params.early_stop_base_line=0.90\n","params.train_epoch=50\n","\"\"\"build a base_model and restore weights from last training\"\"\"\n","base_model = ADModelBuilder(input_shape=params.ad_base_model_input_shape, base_model='vgg19').get_ADModel()\n","base_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=params.learning_rate), \n","                   loss=tf.losses.CategoricalCrossentropy(), \n","                   metrics=['accuracy', 'AUC',  tfa.metrics.F1Score(num_classes=4, average=\"micro\", threshold = 0.5)])\n","base_model.load_weights(params.checkpoint_path)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Note: default vgg19 not includes top and has imagenet weights. It is not a trainable model in ADModelBuilder. Setup specific trainable layers in setup_VGG19_by_layer_names or setup_VGG19 function based on the VGG19 layer name or layer number\n","Model: \"VGG19_ADModel\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","tensor (InputLayer)          [(None, 100, 100, 3)]     0         \n","_________________________________________________________________\n","vgg19 (Functional)           (None, 3, 3, 512)         20024384  \n","_________________________________________________________________\n","flatten_8 (Flatten)          (None, 4608)              0         \n","_________________________________________________________________\n","dense_16 (Dense)             (None, 32)                147488    \n","_________________________________________________________________\n","batch_normalization_8 (Batch (None, 32)                128       \n","_________________________________________________________________\n","leaky_re_lu_8 (LeakyReLU)    (None, 32)                0         \n","_________________________________________________________________\n","dropout_8 (Dropout)          (None, 32)                0         \n","_________________________________________________________________\n","dense_17 (Dense)             (None, 4)                 132       \n","=================================================================\n","Total params: 20,172,132\n","Trainable params: 147,684\n","Non-trainable params: 20,024,448\n","_________________________________________________________________\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f5e20f009d0>"]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2UaS25Lt4kqZ","executionInfo":{"status":"ok","timestamp":1617716687817,"user_tz":240,"elapsed":1456624,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"a4acf616-0a3d-4086-8472-b648775acf4a"},"source":["'''train base model'''\n","callback_checkpoints = tf.keras.callbacks.ModelCheckpoint(filepath=params.checkpoint_path, monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=True, \n","                                                          mode='max',save_freq='epoch',options=None)\n","\n","callback_earlystop = AccEarlyStop(val_acc_base=params.early_stop_base_line)\n","\n","history = base_model.fit(train_image_dataset,\n","                         validation_data= test_image_dataset,\n","                         callbacks = [callback_checkpoints, callback_earlystop],\n","                         epochs=params.train_epoch,\n","                         verbose=1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/50\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py:595: UserWarning: Input dict contained keys ['NL_nbr_0_id', 'NL_nbr_0_tensor', 'NL_nbr_0_weight', 'NL_nbr_1_id', 'NL_nbr_1_tensor', 'NL_nbr_1_weight', 'NL_nbr_2_id', 'NL_nbr_2_tensor', 'NL_nbr_2_weight', 'NL_nbr_3_id', 'NL_nbr_3_tensor', 'NL_nbr_3_weight', 'NL_nbr_4_id', 'NL_nbr_4_tensor', 'NL_nbr_4_weight', 'id'] which did not match any model input. They will be ignored by the model.\n","  [n for n in tensors.keys() if n not in ref_input_names])\n"],"name":"stderr"},{"output_type":"stream","text":["    160/Unknown - 28s 159ms/step - loss: 1.0112 - accuracy: 0.5801 - auc: 0.8262 - f1_score: 0.4933"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py:595: UserWarning: Input dict contained keys ['id'] which did not match any model input. They will be ignored by the model.\n","  [n for n in tensors.keys() if n not in ref_input_names])\n"],"name":"stderr"},{"output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r160/160 [==============================] - 31s 182ms/step - loss: 1.0101 - accuracy: 0.5805 - auc: 0.8265 - f1_score: 0.4937 - val_loss: 1.4173 - val_accuracy: 0.3753 - val_auc: 0.6352 - val_f1_score: 0.2414\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.37529, saving model to /content/drive/MyDrive/AD Expriment II/VGG19_model_checkpoints/vgg19_weights_base\n","Epoch 2/50\n","160/160 [==============================] - 30s 181ms/step - loss: 0.6073 - accuracy: 0.7445 - auc: 0.9359 - f1_score: 0.6846 - val_loss: 1.1158 - val_accuracy: 0.5465 - val_auc: 0.8065 - val_f1_score: 0.4966\n","\n","Epoch 00002: val_accuracy improved from 0.37529 to 0.54652, saving model to /content/drive/MyDrive/AD Expriment II/VGG19_model_checkpoints/vgg19_weights_base\n","Epoch 3/50\n","160/160 [==============================] - 30s 179ms/step - loss: 0.5309 - accuracy: 0.7771 - auc: 0.9508 - f1_score: 0.7323 - val_loss: 1.4043 - val_accuracy: 0.4934 - val_auc: 0.7588 - val_f1_score: 0.4842\n","\n","Epoch 00003: val_accuracy did not improve from 0.54652\n","Epoch 4/50\n","160/160 [==============================] - 29s 174ms/step - loss: 0.4637 - accuracy: 0.8051 - auc: 0.9621 - f1_score: 0.7666 - val_loss: 1.3021 - val_accuracy: 0.5426 - val_auc: 0.8100 - val_f1_score: 0.5196\n","\n","Epoch 00004: val_accuracy did not improve from 0.54652\n","Epoch 5/50\n","160/160 [==============================] - 29s 174ms/step - loss: 0.4286 - accuracy: 0.8203 - auc: 0.9677 - f1_score: 0.7931 - val_loss: 1.4733 - val_accuracy: 0.5371 - val_auc: 0.8033 - val_f1_score: 0.5295\n","\n","Epoch 00005: val_accuracy did not improve from 0.54652\n","Epoch 6/50\n","160/160 [==============================] - 29s 174ms/step - loss: 0.3707 - accuracy: 0.8537 - auc: 0.9761 - f1_score: 0.8242 - val_loss: 2.8030 - val_accuracy: 0.5012 - val_auc: 0.7529 - val_f1_score: 0.5008\n","\n","Epoch 00006: val_accuracy did not improve from 0.54652\n","Epoch 7/50\n","160/160 [==============================] - 29s 175ms/step - loss: 0.3618 - accuracy: 0.8497 - auc: 0.9767 - f1_score: 0.8321 - val_loss: 2.0773 - val_accuracy: 0.5012 - val_auc: 0.7349 - val_f1_score: 0.4986\n","\n","Epoch 00007: val_accuracy did not improve from 0.54652\n","Epoch 8/50\n","160/160 [==============================] - 29s 178ms/step - loss: 0.3519 - accuracy: 0.8548 - auc: 0.9778 - f1_score: 0.8366 - val_loss: 1.0411 - val_accuracy: 0.5966 - val_auc: 0.8484 - val_f1_score: 0.5396\n","\n","Epoch 00008: val_accuracy improved from 0.54652 to 0.59656, saving model to /content/drive/MyDrive/AD Expriment II/VGG19_model_checkpoints/vgg19_weights_base\n","Epoch 9/50\n","160/160 [==============================] - 30s 180ms/step - loss: 0.3104 - accuracy: 0.8758 - auc: 0.9829 - f1_score: 0.8619 - val_loss: 2.0243 - val_accuracy: 0.4691 - val_auc: 0.7404 - val_f1_score: 0.4690\n","\n","Epoch 00009: val_accuracy did not improve from 0.59656\n","Epoch 10/50\n","160/160 [==============================] - 29s 174ms/step - loss: 0.3284 - accuracy: 0.8633 - auc: 0.9804 - f1_score: 0.8514 - val_loss: 1.6579 - val_accuracy: 0.5442 - val_auc: 0.7994 - val_f1_score: 0.5328\n","\n","Epoch 00010: val_accuracy did not improve from 0.59656\n","Epoch 11/50\n","160/160 [==============================] - 29s 173ms/step - loss: 0.2944 - accuracy: 0.8852 - auc: 0.9844 - f1_score: 0.8714 - val_loss: 2.5107 - val_accuracy: 0.4363 - val_auc: 0.7575 - val_f1_score: 0.4222\n","\n","Epoch 00011: val_accuracy did not improve from 0.59656\n","Epoch 12/50\n","160/160 [==============================] - 29s 176ms/step - loss: 0.2960 - accuracy: 0.8802 - auc: 0.9839 - f1_score: 0.8687 - val_loss: 1.3722 - val_accuracy: 0.6013 - val_auc: 0.8475 - val_f1_score: 0.5872\n","\n","Epoch 00012: val_accuracy improved from 0.59656 to 0.60125, saving model to /content/drive/MyDrive/AD Expriment II/VGG19_model_checkpoints/vgg19_weights_base\n","Epoch 13/50\n","160/160 [==============================] - 30s 180ms/step - loss: 0.2695 - accuracy: 0.8963 - auc: 0.9866 - f1_score: 0.8810 - val_loss: 1.8227 - val_accuracy: 0.5434 - val_auc: 0.7900 - val_f1_score: 0.5336\n","\n","Epoch 00013: val_accuracy did not improve from 0.60125\n","Epoch 14/50\n","160/160 [==============================] - 29s 174ms/step - loss: 0.2442 - accuracy: 0.9024 - auc: 0.9893 - f1_score: 0.8933 - val_loss: 1.2758 - val_accuracy: 0.6036 - val_auc: 0.8274 - val_f1_score: 0.5752\n","\n","Epoch 00014: val_accuracy improved from 0.60125 to 0.60360, saving model to /content/drive/MyDrive/AD Expriment II/VGG19_model_checkpoints/vgg19_weights_base\n","Epoch 15/50\n","160/160 [==============================] - 29s 175ms/step - loss: 0.2627 - accuracy: 0.9005 - auc: 0.9873 - f1_score: 0.8872 - val_loss: 1.6509 - val_accuracy: 0.5145 - val_auc: 0.7805 - val_f1_score: 0.4890\n","\n","Epoch 00015: val_accuracy did not improve from 0.60360\n","Epoch 16/50\n","160/160 [==============================] - 29s 176ms/step - loss: 0.2422 - accuracy: 0.9043 - auc: 0.9892 - f1_score: 0.8975 - val_loss: 1.4873 - val_accuracy: 0.5364 - val_auc: 0.7994 - val_f1_score: 0.5138\n","\n","Epoch 00016: val_accuracy did not improve from 0.60360\n","Epoch 17/50\n","160/160 [==============================] - 29s 177ms/step - loss: 0.2233 - accuracy: 0.9081 - auc: 0.9908 - f1_score: 0.9005 - val_loss: 1.4856 - val_accuracy: 0.5934 - val_auc: 0.8299 - val_f1_score: 0.5815\n","\n","Epoch 00017: val_accuracy did not improve from 0.60360\n","Epoch 18/50\n","160/160 [==============================] - 28s 173ms/step - loss: 0.2381 - accuracy: 0.9033 - auc: 0.9892 - f1_score: 0.8972 - val_loss: 2.4064 - val_accuracy: 0.4629 - val_auc: 0.7405 - val_f1_score: 0.4499\n","\n","Epoch 00018: val_accuracy did not improve from 0.60360\n","Epoch 19/50\n","160/160 [==============================] - 29s 176ms/step - loss: 0.2209 - accuracy: 0.9128 - auc: 0.9907 - f1_score: 0.9052 - val_loss: 1.4362 - val_accuracy: 0.5520 - val_auc: 0.8066 - val_f1_score: 0.5183\n","\n","Epoch 00019: val_accuracy did not improve from 0.60360\n","Epoch 20/50\n","160/160 [==============================] - 29s 176ms/step - loss: 0.2169 - accuracy: 0.9133 - auc: 0.9911 - f1_score: 0.9089 - val_loss: 2.8384 - val_accuracy: 0.5481 - val_auc: 0.7513 - val_f1_score: 0.5449\n","\n","Epoch 00020: val_accuracy did not improve from 0.60360\n","Epoch 21/50\n","160/160 [==============================] - 29s 174ms/step - loss: 0.2083 - accuracy: 0.9188 - auc: 0.9918 - f1_score: 0.9136 - val_loss: 1.5050 - val_accuracy: 0.5708 - val_auc: 0.8038 - val_f1_score: 0.5380\n","\n","Epoch 00021: val_accuracy did not improve from 0.60360\n","Epoch 22/50\n","160/160 [==============================] - 28s 172ms/step - loss: 0.2012 - accuracy: 0.9211 - auc: 0.9923 - f1_score: 0.9156 - val_loss: 1.7340 - val_accuracy: 0.5489 - val_auc: 0.8014 - val_f1_score: 0.5220\n","\n","Epoch 00022: val_accuracy did not improve from 0.60360\n","Epoch 23/50\n","160/160 [==============================] - 28s 172ms/step - loss: 0.1877 - accuracy: 0.9254 - auc: 0.9934 - f1_score: 0.9214 - val_loss: 3.5733 - val_accuracy: 0.4027 - val_auc: 0.6858 - val_f1_score: 0.3910\n","\n","Epoch 00023: val_accuracy did not improve from 0.60360\n","Epoch 24/50\n","160/160 [==============================] - 29s 173ms/step - loss: 0.1904 - accuracy: 0.9250 - auc: 0.9931 - f1_score: 0.9200 - val_loss: 1.7248 - val_accuracy: 0.5966 - val_auc: 0.8263 - val_f1_score: 0.5892\n","\n","Epoch 00024: val_accuracy did not improve from 0.60360\n","Epoch 25/50\n","160/160 [==============================] - 28s 173ms/step - loss: 0.1913 - accuracy: 0.9264 - auc: 0.9929 - f1_score: 0.9213 - val_loss: 1.6498 - val_accuracy: 0.5676 - val_auc: 0.8117 - val_f1_score: 0.5509\n","\n","Epoch 00025: val_accuracy did not improve from 0.60360\n","Epoch 26/50\n","160/160 [==============================] - 28s 173ms/step - loss: 0.1835 - accuracy: 0.9306 - auc: 0.9936 - f1_score: 0.9249 - val_loss: 2.1964 - val_accuracy: 0.5536 - val_auc: 0.7881 - val_f1_score: 0.5451\n","\n","Epoch 00026: val_accuracy did not improve from 0.60360\n","Epoch 27/50\n","160/160 [==============================] - 28s 173ms/step - loss: 0.1833 - accuracy: 0.9275 - auc: 0.9935 - f1_score: 0.9239 - val_loss: 1.9755 - val_accuracy: 0.5833 - val_auc: 0.8199 - val_f1_score: 0.5773\n","\n","Epoch 00027: val_accuracy did not improve from 0.60360\n","Epoch 28/50\n","160/160 [==============================] - 29s 173ms/step - loss: 0.1732 - accuracy: 0.9325 - auc: 0.9940 - f1_score: 0.9287 - val_loss: 1.8168 - val_accuracy: 0.6044 - val_auc: 0.8251 - val_f1_score: 0.5927\n","\n","Epoch 00028: val_accuracy improved from 0.60360 to 0.60438, saving model to /content/drive/MyDrive/AD Expriment II/VGG19_model_checkpoints/vgg19_weights_base\n","Epoch 29/50\n","160/160 [==============================] - 29s 176ms/step - loss: 0.1704 - accuracy: 0.9333 - auc: 0.9943 - f1_score: 0.9295 - val_loss: 1.9750 - val_accuracy: 0.5324 - val_auc: 0.7856 - val_f1_score: 0.5077\n","\n","Epoch 00029: val_accuracy did not improve from 0.60438\n","Epoch 30/50\n","160/160 [==============================] - 29s 174ms/step - loss: 0.1788 - accuracy: 0.9309 - auc: 0.9937 - f1_score: 0.9258 - val_loss: 1.4785 - val_accuracy: 0.6372 - val_auc: 0.8520 - val_f1_score: 0.6280\n","\n","Epoch 00030: val_accuracy improved from 0.60438 to 0.63722, saving model to /content/drive/MyDrive/AD Expriment II/VGG19_model_checkpoints/vgg19_weights_base\n","Epoch 31/50\n","160/160 [==============================] - 29s 177ms/step - loss: 0.1652 - accuracy: 0.9333 - auc: 0.9948 - f1_score: 0.9311 - val_loss: 2.6618 - val_accuracy: 0.4699 - val_auc: 0.7220 - val_f1_score: 0.4551\n","\n","Epoch 00031: val_accuracy did not improve from 0.63722\n","Epoch 32/50\n","160/160 [==============================] - 29s 175ms/step - loss: 0.1759 - accuracy: 0.9331 - auc: 0.9941 - f1_score: 0.9279 - val_loss: 2.4301 - val_accuracy: 0.5324 - val_auc: 0.7823 - val_f1_score: 0.5164\n","\n","Epoch 00032: val_accuracy did not improve from 0.63722\n","Epoch 33/50\n","160/160 [==============================] - 29s 175ms/step - loss: 0.1636 - accuracy: 0.9354 - auc: 0.9948 - f1_score: 0.9322 - val_loss: 2.0971 - val_accuracy: 0.5512 - val_auc: 0.7942 - val_f1_score: 0.5439\n","\n","Epoch 00033: val_accuracy did not improve from 0.63722\n","Epoch 34/50\n","160/160 [==============================] - 29s 173ms/step - loss: 0.1544 - accuracy: 0.9402 - auc: 0.9953 - f1_score: 0.9370 - val_loss: 2.5889 - val_accuracy: 0.4777 - val_auc: 0.7247 - val_f1_score: 0.4767\n","\n","Epoch 00034: val_accuracy did not improve from 0.63722\n","Epoch 35/50\n","160/160 [==============================] - 28s 173ms/step - loss: 0.1494 - accuracy: 0.9435 - auc: 0.9956 - f1_score: 0.9400 - val_loss: 2.2309 - val_accuracy: 0.5661 - val_auc: 0.7969 - val_f1_score: 0.5628\n","\n","Epoch 00035: val_accuracy did not improve from 0.63722\n","Epoch 36/50\n","160/160 [==============================] - 28s 171ms/step - loss: 0.1527 - accuracy: 0.9438 - auc: 0.9952 - f1_score: 0.9410 - val_loss: 2.5139 - val_accuracy: 0.4722 - val_auc: 0.7380 - val_f1_score: 0.4570\n","\n","Epoch 00036: val_accuracy did not improve from 0.63722\n","Epoch 37/50\n","160/160 [==============================] - 28s 173ms/step - loss: 0.1420 - accuracy: 0.9461 - auc: 0.9961 - f1_score: 0.9408 - val_loss: 2.9417 - val_accuracy: 0.5942 - val_auc: 0.8060 - val_f1_score: 0.5897\n","\n","Epoch 00037: val_accuracy did not improve from 0.63722\n","Epoch 38/50\n","160/160 [==============================] - 28s 173ms/step - loss: 0.1399 - accuracy: 0.9477 - auc: 0.9962 - f1_score: 0.9427 - val_loss: 1.9932 - val_accuracy: 0.6044 - val_auc: 0.8282 - val_f1_score: 0.5921\n","\n","Epoch 00038: val_accuracy did not improve from 0.63722\n","Epoch 39/50\n","160/160 [==============================] - 28s 172ms/step - loss: 0.1488 - accuracy: 0.9437 - auc: 0.9954 - f1_score: 0.9416 - val_loss: 1.9766 - val_accuracy: 0.5794 - val_auc: 0.8160 - val_f1_score: 0.5657\n","\n","Epoch 00039: val_accuracy did not improve from 0.63722\n","Epoch 40/50\n","160/160 [==============================] - 29s 175ms/step - loss: 0.1495 - accuracy: 0.9413 - auc: 0.9957 - f1_score: 0.9372 - val_loss: 2.4554 - val_accuracy: 0.5074 - val_auc: 0.7457 - val_f1_score: 0.4908\n","\n","Epoch 00040: val_accuracy did not improve from 0.63722\n","Epoch 41/50\n","160/160 [==============================] - 29s 177ms/step - loss: 0.1454 - accuracy: 0.9438 - auc: 0.9958 - f1_score: 0.9386 - val_loss: 2.5013 - val_accuracy: 0.5027 - val_auc: 0.7383 - val_f1_score: 0.4842\n","\n","Epoch 00041: val_accuracy did not improve from 0.63722\n","Epoch 42/50\n","160/160 [==============================] - 29s 177ms/step - loss: 0.1225 - accuracy: 0.9550 - auc: 0.9971 - f1_score: 0.9519 - val_loss: 1.9526 - val_accuracy: 0.6145 - val_auc: 0.8224 - val_f1_score: 0.6025\n","\n","Epoch 00042: val_accuracy did not improve from 0.63722\n","Epoch 43/50\n","160/160 [==============================] - 29s 179ms/step - loss: 0.1330 - accuracy: 0.9516 - auc: 0.9962 - f1_score: 0.9493 - val_loss: 1.7322 - val_accuracy: 0.6169 - val_auc: 0.8356 - val_f1_score: 0.6059\n","\n","Epoch 00043: val_accuracy did not improve from 0.63722\n","Epoch 44/50\n","160/160 [==============================] - 29s 177ms/step - loss: 0.1318 - accuracy: 0.9500 - auc: 0.9965 - f1_score: 0.9472 - val_loss: 2.2116 - val_accuracy: 0.5895 - val_auc: 0.8169 - val_f1_score: 0.5862\n","\n","Epoch 00044: val_accuracy did not improve from 0.63722\n","Epoch 45/50\n","160/160 [==============================] - 29s 178ms/step - loss: 0.1233 - accuracy: 0.9540 - auc: 0.9969 - f1_score: 0.9521 - val_loss: 2.4948 - val_accuracy: 0.5504 - val_auc: 0.7981 - val_f1_score: 0.5459\n","\n","Epoch 00045: val_accuracy did not improve from 0.63722\n","Epoch 46/50\n","160/160 [==============================] - 29s 179ms/step - loss: 0.1402 - accuracy: 0.9454 - auc: 0.9959 - f1_score: 0.9446 - val_loss: 2.5069 - val_accuracy: 0.5825 - val_auc: 0.8063 - val_f1_score: 0.5730\n","\n","Epoch 00046: val_accuracy did not improve from 0.63722\n","Epoch 47/50\n","160/160 [==============================] - 29s 177ms/step - loss: 0.1205 - accuracy: 0.9519 - auc: 0.9972 - f1_score: 0.9505 - val_loss: 2.4071 - val_accuracy: 0.5950 - val_auc: 0.8016 - val_f1_score: 0.5826\n","\n","Epoch 00047: val_accuracy did not improve from 0.63722\n","Epoch 48/50\n","160/160 [==============================] - 29s 176ms/step - loss: 0.1256 - accuracy: 0.9506 - auc: 0.9968 - f1_score: 0.9487 - val_loss: 2.7537 - val_accuracy: 0.5082 - val_auc: 0.7559 - val_f1_score: 0.4961\n","\n","Epoch 00048: val_accuracy did not improve from 0.63722\n","Epoch 49/50\n","160/160 [==============================] - 29s 177ms/step - loss: 0.1271 - accuracy: 0.9534 - auc: 0.9965 - f1_score: 0.9512 - val_loss: 4.1697 - val_accuracy: 0.4300 - val_auc: 0.6638 - val_f1_score: 0.4215\n","\n","Epoch 00049: val_accuracy did not improve from 0.63722\n","Epoch 50/50\n","160/160 [==============================] - 29s 178ms/step - loss: 0.1262 - accuracy: 0.9504 - auc: 0.9967 - f1_score: 0.9487 - val_loss: 2.6211 - val_accuracy: 0.5301 - val_auc: 0.7727 - val_f1_score: 0.5300\n","\n","Epoch 00050: val_accuracy did not improve from 0.63722\n","Early stopping is not triggered, but best model is restored at epoch 30\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lVP_CDnTbGaF","executionInfo":{"status":"ok","timestamp":1617714875929,"user_tz":240,"elapsed":3748,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"c52d7bcc-e581-4865-b072-3c5170baeef7"},"source":["'''evaluate the base model'''\n","base_model.evaluate(test_image_dataset)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1/1 [==============================] - 3s 3s/step - loss: 1.4312 - accuracy: 0.6403 - auc: 0.8503 - f1_score: 0.6390\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[1.4311827421188354,\n"," 0.6403440237045288,\n"," 0.8503028750419617,\n"," 0.6390205025672913]"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"mZdKTQIbLIhz"},"source":["'''plot confusion mat & calc acc for each label'''\n","test_image_dataset = NSLDataFormat.generate_test_tfr_image_tensor(path_list=test_tfr_list, \n","                                                                  batch_size=4000, \n","                                                                  size=(100,100),\n","                                                                  channels=3,\n","                                                                  shuffle=True)\n","data, data_label = iter(test_image_dataset).get_next()\n","data = data[\"tensor\"]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GGee70DfXROB","executionInfo":{"status":"ok","timestamp":1617714876787,"user_tz":240,"elapsed":3777,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"4335fec9-b581-46b4-a9d9-3fe975548ae8"},"source":["len(data)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1279"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":396},"id":"RDbn8__LLIjv","executionInfo":{"status":"ok","timestamp":1617714880272,"user_tz":240,"elapsed":4986,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"7352c72f-32a1-4593-f68c-00c97d65529c"},"source":["ADModelBuilder.plot_confusion_mat(base_model, data, data_label, \"VGG19\")"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x432 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"YVlyP5V1LIm3"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TDkD2QMS6b-_"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mPorVq79jeYK"},"source":["## 2.2 VGG19-NSL Model Training\n","### val_acc: 0.63, val_auc: 0.82 , val_f1_score: 0.63 "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4FsrX9lrC1hY","executionInfo":{"status":"ok","timestamp":1617806149760,"user_tz":240,"elapsed":1137,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"63975f7d-e1ce-4a93-c84b-af55fc0a02a1"},"source":["'''define params'''\n","params.learning_rate=0.001\n","params.checkpoint_path ='/content/drive/MyDrive/AD Expriment II/VGG19_model_checkpoints/vgg19_weights_nsl'\n","params.early_stop_base_line=0.70\n","params.train_epoch=30\n","params.nsl_multiplier = 0.01\n","params.nsl_sum_over_axis = -1\n","params.nsl_distance_type = nsl.configs.DistanceType.COSINE\n","\n","\"\"\"build a base_model\"\"\"\n","base_model = ADModelBuilder(input_shape=params.ad_base_model_input_shape, base_model='vgg19').get_ADModel()\n","\n","\"\"\"build a NSL model on top of the base model and retore weights from last training\"\"\"\n","graph_reg_config = nsl.configs.make_graph_reg_config(neighbor_prefix=params.neighbor_prefix,\n","                                                     neighbor_weight_suffix=params.neighbor_weight_suffix,\n","                                                     max_neighbors= params.max_seed_nbr,\n","                                                     multiplier= params.nsl_multiplier,\n","                                                     distance_type= params.nsl_distance_type,\n","                                                     sum_over_axis= params.nsl_sum_over_axis)\n","\n","graph_reg_model = nsl.keras.GraphRegularization(base_model,graph_reg_config)\n","\n","graph_reg_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=params.learning_rate, amsgrad=True), \n","                        loss=tf.losses.CategoricalCrossentropy(), \n","                        metrics=[\"accuracy\",\"AUC\", tfa.metrics.F1Score(num_classes=4, average=\"micro\", threshold = 0.5)])\n","graph_reg_model.load_weights(params.checkpoint_path)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Note: default vgg19 not includes top and has imagenet weights. It is not a trainable model in ADModelBuilder. Setup specific trainable layers in setup_VGG19_by_layer_names or setup_VGG19 function based on the VGG19 layer name or layer number\n","Model: \"VGG19_ADModel\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","tensor (InputLayer)          [(None, 100, 100, 3)]     0         \n","_________________________________________________________________\n","vgg19 (Functional)           (None, 3, 3, 512)         20024384  \n","_________________________________________________________________\n","flatten_1 (Flatten)          (None, 4608)              0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 16)                73744     \n","_________________________________________________________________\n","batch_normalization_1 (Batch (None, 16)                64        \n","_________________________________________________________________\n","leaky_re_lu_1 (LeakyReLU)    (None, 16)                0         \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 16)                0         \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 4)                 68        \n","=================================================================\n","Total params: 20,098,260\n","Trainable params: 73,844\n","Non-trainable params: 20,024,416\n","_________________________________________________________________\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f1469cc8bd0>"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"84c5v3r04ktO","executionInfo":{"status":"ok","timestamp":1617808398264,"user_tz":240,"elapsed":2244825,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"0a92de43-52fd-4e51-c691-9d709dd29696"},"source":["''' setup early stoping and checkpoints '''\n","callback_checkpoints = tf.keras.callbacks.ModelCheckpoint(filepath=params.checkpoint_path, monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=True, mode='max',\n","                                                         save_freq='epoch',options=None)\n","\n","callback_earlystop = AccEarlyStop(val_acc_base=params.early_stop_base_line)\n","\n","'''NSL model training'''\n","graph_reg_history = graph_reg_model.fit(train_image_dataset, \n","                                        validation_data=test_image_dataset,\n","                                        callbacks = [callback_checkpoints, callback_earlystop],\n","                                        epochs=params.train_epoch,\n","                                        verbose=1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/30\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py:595: UserWarning: Input dict contained keys ['id'] which did not match any model input. They will be ignored by the model.\n","  [n for n in tensors.keys() if n not in ref_input_names])\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/GraphRegularization/graph_loss/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/GraphRegularization/graph_loss/Reshape:0\", shape=(None, 4), dtype=float32), dense_shape=Tensor(\"gradient_tape/GraphRegularization/graph_loss/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"shape. This may consume a large amount of memory.\" % value)\n"],"name":"stderr"},{"output_type":"stream","text":["160/160 [==============================] - 78s 474ms/step - loss: 0.1486 - accuracy: 0.9443 - auc: 0.9957 - f1_score: 0.9432 - scaled_graph_loss: 6.7404e-04 - val_loss: 1.9059 - val_accuracy: 0.6153 - val_auc: 0.8326 - val_f1_score: 0.9033\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.61532, saving model to /content/drive/MyDrive/AD Expriment II/VGG19_model_checkpoints/vgg19_weights_nsl\n","Epoch 2/30\n","160/160 [==============================] - 75s 463ms/step - loss: 0.1538 - accuracy: 0.9393 - auc: 0.9955 - f1_score: 0.9403 - scaled_graph_loss: 6.9551e-04 - val_loss: 2.6825 - val_accuracy: 0.5559 - val_auc: 0.7794 - val_f1_score: 0.5570\n","\n","Epoch 00002: val_accuracy did not improve from 0.61532\n","Epoch 3/30\n","160/160 [==============================] - 74s 461ms/step - loss: 0.1642 - accuracy: 0.9378 - auc: 0.9948 - f1_score: 0.9373 - scaled_graph_loss: 7.2718e-04 - val_loss: 3.1422 - val_accuracy: 0.5176 - val_auc: 0.7519 - val_f1_score: 0.5169\n","\n","Epoch 00003: val_accuracy did not improve from 0.61532\n","Epoch 4/30\n","160/160 [==============================] - 75s 463ms/step - loss: 0.1561 - accuracy: 0.9398 - auc: 0.9954 - f1_score: 0.9401 - scaled_graph_loss: 7.1583e-04 - val_loss: 2.8461 - val_accuracy: 0.5653 - val_auc: 0.7852 - val_f1_score: 0.5651\n","\n","Epoch 00004: val_accuracy did not improve from 0.61532\n","Epoch 5/30\n","160/160 [==============================] - 74s 461ms/step - loss: 0.1649 - accuracy: 0.9389 - auc: 0.9945 - f1_score: 0.9380 - scaled_graph_loss: 7.3458e-04 - val_loss: 2.1273 - val_accuracy: 0.5934 - val_auc: 0.8042 - val_f1_score: 0.5944\n","\n","Epoch 00005: val_accuracy did not improve from 0.61532\n","Epoch 6/30\n","160/160 [==============================] - 74s 462ms/step - loss: 0.1427 - accuracy: 0.9440 - auc: 0.9962 - f1_score: 0.9446 - scaled_graph_loss: 6.8978e-04 - val_loss: 2.2703 - val_accuracy: 0.6130 - val_auc: 0.8211 - val_f1_score: 0.6132\n","\n","Epoch 00006: val_accuracy did not improve from 0.61532\n","Epoch 7/30\n","160/160 [==============================] - 75s 463ms/step - loss: 0.1508 - accuracy: 0.9401 - auc: 0.9955 - f1_score: 0.9396 - scaled_graph_loss: 6.9532e-04 - val_loss: 3.9789 - val_accuracy: 0.4652 - val_auc: 0.6943 - val_f1_score: 0.4643\n","\n","Epoch 00007: val_accuracy did not improve from 0.61532\n","Epoch 8/30\n","160/160 [==============================] - 75s 463ms/step - loss: 0.1551 - accuracy: 0.9388 - auc: 0.9954 - f1_score: 0.9395 - scaled_graph_loss: 7.3255e-04 - val_loss: 2.8172 - val_accuracy: 0.5708 - val_auc: 0.7934 - val_f1_score: 0.5724\n","\n","Epoch 00008: val_accuracy did not improve from 0.61532\n","Epoch 9/30\n","160/160 [==============================] - 75s 463ms/step - loss: 0.1377 - accuracy: 0.9475 - auc: 0.9962 - f1_score: 0.9475 - scaled_graph_loss: 6.3493e-04 - val_loss: 2.7700 - val_accuracy: 0.6130 - val_auc: 0.8088 - val_f1_score: 0.6117\n","\n","Epoch 00009: val_accuracy did not improve from 0.61532\n","Epoch 10/30\n","160/160 [==============================] - 74s 462ms/step - loss: 0.1597 - accuracy: 0.9414 - auc: 0.9946 - f1_score: 0.9393 - scaled_graph_loss: 7.0284e-04 - val_loss: 2.6220 - val_accuracy: 0.5090 - val_auc: 0.7463 - val_f1_score: 0.5069\n","\n","Epoch 00010: val_accuracy did not improve from 0.61532\n","Epoch 11/30\n","160/160 [==============================] - 74s 461ms/step - loss: 0.1561 - accuracy: 0.9397 - auc: 0.9951 - f1_score: 0.9400 - scaled_graph_loss: 6.9458e-04 - val_loss: 2.1600 - val_accuracy: 0.6013 - val_auc: 0.8157 - val_f1_score: 0.5994\n","\n","Epoch 00011: val_accuracy did not improve from 0.61532\n","Epoch 12/30\n","160/160 [==============================] - 74s 461ms/step - loss: 0.1493 - accuracy: 0.9409 - auc: 0.9956 - f1_score: 0.9418 - scaled_graph_loss: 6.9180e-04 - val_loss: 2.6991 - val_accuracy: 0.5403 - val_auc: 0.7706 - val_f1_score: 0.5421\n","\n","Epoch 00012: val_accuracy did not improve from 0.61532\n","Epoch 13/30\n","160/160 [==============================] - 75s 463ms/step - loss: 0.1443 - accuracy: 0.9472 - auc: 0.9958 - f1_score: 0.9478 - scaled_graph_loss: 6.5213e-04 - val_loss: 3.7988 - val_accuracy: 0.5418 - val_auc: 0.7443 - val_f1_score: 0.5402\n","\n","Epoch 00013: val_accuracy did not improve from 0.61532\n","Epoch 14/30\n","160/160 [==============================] - 74s 460ms/step - loss: 0.1394 - accuracy: 0.9462 - auc: 0.9961 - f1_score: 0.9457 - scaled_graph_loss: 6.6456e-04 - val_loss: 2.2015 - val_accuracy: 0.5817 - val_auc: 0.8002 - val_f1_score: 0.5807\n","\n","Epoch 00014: val_accuracy did not improve from 0.61532\n","Epoch 15/30\n","160/160 [==============================] - 75s 462ms/step - loss: 0.1407 - accuracy: 0.9453 - auc: 0.9962 - f1_score: 0.9453 - scaled_graph_loss: 6.6013e-04 - val_loss: 2.5665 - val_accuracy: 0.6286 - val_auc: 0.8202 - val_f1_score: 0.6281\n","\n","Epoch 00015: val_accuracy improved from 0.61532 to 0.62862, saving model to /content/drive/MyDrive/AD Expriment II/VGG19_model_checkpoints/vgg19_weights_nsl\n","Epoch 16/30\n","160/160 [==============================] - 75s 463ms/step - loss: 0.1404 - accuracy: 0.9470 - auc: 0.9960 - f1_score: 0.9477 - scaled_graph_loss: 6.5473e-04 - val_loss: 2.3366 - val_accuracy: 0.6357 - val_auc: 0.8260 - val_f1_score: 0.6355\n","\n","Epoch 00016: val_accuracy improved from 0.62862 to 0.63565, saving model to /content/drive/MyDrive/AD Expriment II/VGG19_model_checkpoints/vgg19_weights_nsl\n","Epoch 17/30\n","160/160 [==============================] - 74s 461ms/step - loss: 0.1326 - accuracy: 0.9499 - auc: 0.9967 - f1_score: 0.9494 - scaled_graph_loss: 6.1778e-04 - val_loss: 2.4530 - val_accuracy: 0.6185 - val_auc: 0.8195 - val_f1_score: 0.6185\n","\n","Epoch 00017: val_accuracy did not improve from 0.63565\n","Epoch 18/30\n","160/160 [==============================] - 75s 462ms/step - loss: 0.1424 - accuracy: 0.9437 - auc: 0.9959 - f1_score: 0.9439 - scaled_graph_loss: 6.6127e-04 - val_loss: 2.7050 - val_accuracy: 0.6114 - val_auc: 0.7975 - val_f1_score: 0.6127\n","\n","Epoch 00018: val_accuracy did not improve from 0.63565\n","Epoch 19/30\n","160/160 [==============================] - 75s 462ms/step - loss: 0.1401 - accuracy: 0.9454 - auc: 0.9963 - f1_score: 0.9458 - scaled_graph_loss: 6.4539e-04 - val_loss: 3.5434 - val_accuracy: 0.4292 - val_auc: 0.6731 - val_f1_score: 0.4286\n","\n","Epoch 00019: val_accuracy did not improve from 0.63565\n","Epoch 20/30\n","160/160 [==============================] - 74s 462ms/step - loss: 0.1282 - accuracy: 0.9507 - auc: 0.9967 - f1_score: 0.9511 - scaled_graph_loss: 6.1321e-04 - val_loss: 2.2671 - val_accuracy: 0.5887 - val_auc: 0.8066 - val_f1_score: 0.5883\n","\n","Epoch 00020: val_accuracy did not improve from 0.63565\n","Epoch 21/30\n","160/160 [==============================] - 75s 463ms/step - loss: 0.1253 - accuracy: 0.9538 - auc: 0.9969 - f1_score: 0.9525 - scaled_graph_loss: 5.8181e-04 - val_loss: 2.7905 - val_accuracy: 0.5379 - val_auc: 0.7734 - val_f1_score: 0.5343\n","\n","Epoch 00021: val_accuracy did not improve from 0.63565\n","Epoch 22/30\n","160/160 [==============================] - 75s 462ms/step - loss: 0.1361 - accuracy: 0.9493 - auc: 0.9963 - f1_score: 0.9491 - scaled_graph_loss: 6.1968e-04 - val_loss: 2.6618 - val_accuracy: 0.5676 - val_auc: 0.7845 - val_f1_score: 0.5639\n","\n","Epoch 00022: val_accuracy did not improve from 0.63565\n","Epoch 23/30\n","160/160 [==============================] - 75s 463ms/step - loss: 0.1481 - accuracy: 0.9436 - auc: 0.9954 - f1_score: 0.9439 - scaled_graph_loss: 6.8202e-04 - val_loss: 3.0070 - val_accuracy: 0.5622 - val_auc: 0.7797 - val_f1_score: 0.5627\n","\n","Epoch 00023: val_accuracy did not improve from 0.63565\n","Epoch 24/30\n","160/160 [==============================] - 75s 462ms/step - loss: 0.1345 - accuracy: 0.9480 - auc: 0.9964 - f1_score: 0.9479 - scaled_graph_loss: 6.1657e-04 - val_loss: 3.1459 - val_accuracy: 0.5661 - val_auc: 0.7859 - val_f1_score: 0.5664\n","\n","Epoch 00024: val_accuracy did not improve from 0.63565\n","Epoch 25/30\n","160/160 [==============================] - 74s 460ms/step - loss: 0.1344 - accuracy: 0.9495 - auc: 0.9965 - f1_score: 0.9503 - scaled_graph_loss: 6.1468e-04 - val_loss: 2.7792 - val_accuracy: 0.5676 - val_auc: 0.7841 - val_f1_score: 0.5670\n","\n","Epoch 00025: val_accuracy did not improve from 0.63565\n","Epoch 26/30\n","160/160 [==============================] - 75s 463ms/step - loss: 0.1280 - accuracy: 0.9516 - auc: 0.9969 - f1_score: 0.9512 - scaled_graph_loss: 5.8868e-04 - val_loss: 2.7471 - val_accuracy: 0.6130 - val_auc: 0.8162 - val_f1_score: 0.6137\n","\n","Epoch 00026: val_accuracy did not improve from 0.63565\n","Epoch 27/30\n","160/160 [==============================] - 75s 463ms/step - loss: 0.1294 - accuracy: 0.9506 - auc: 0.9965 - f1_score: 0.9505 - scaled_graph_loss: 6.0041e-04 - val_loss: 2.2123 - val_accuracy: 0.6044 - val_auc: 0.8207 - val_f1_score: 0.6053\n","\n","Epoch 00027: val_accuracy did not improve from 0.63565\n","Epoch 28/30\n","160/160 [==============================] - 74s 460ms/step - loss: 0.1140 - accuracy: 0.9558 - auc: 0.9976 - f1_score: 0.9564 - scaled_graph_loss: 5.4767e-04 - val_loss: 2.3431 - val_accuracy: 0.6028 - val_auc: 0.8073 - val_f1_score: 0.6034\n","\n","Epoch 00028: val_accuracy did not improve from 0.63565\n","Epoch 29/30\n","160/160 [==============================] - 75s 463ms/step - loss: 0.1217 - accuracy: 0.9544 - auc: 0.9971 - f1_score: 0.9535 - scaled_graph_loss: 5.9051e-04 - val_loss: 2.8941 - val_accuracy: 0.5723 - val_auc: 0.7950 - val_f1_score: 0.5733\n","\n","Epoch 00029: val_accuracy did not improve from 0.63565\n","Epoch 30/30\n","160/160 [==============================] - 75s 463ms/step - loss: 0.1137 - accuracy: 0.9568 - auc: 0.9975 - f1_score: 0.9570 - scaled_graph_loss: 5.6349e-04 - val_loss: 2.2441 - val_accuracy: 0.6059 - val_auc: 0.8191 - val_f1_score: 0.6054\n","\n","Epoch 00030: val_accuracy did not improve from 0.63565\n","Early stopping is not triggered, but best model is restored at epoch 16\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"877FiZyAUJv7","executionInfo":{"status":"ok","timestamp":1617808415958,"user_tz":240,"elapsed":2259,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"e75a57a7-8278-4471-ebc5-4266a1a6439e"},"source":["graph_reg_model.evaluate(test_image_dataset)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["20/20 [==============================] - 2s 74ms/step - loss: 2.3366 - accuracy: 0.6357 - auc: 0.8260 - f1_score: 0.6355\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[2.3365843296051025, 0.6356528401374817, 0.8260239958763123, 0.635469913482666]"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"anut2b6BRl6N"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mqiZpSxMXYSO"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"y67bzIq5iebn"},"source":["## 2.3 VGG19-NSL Model tunning\n","### val_acc: 0.68, val_auc: 0.86, val_f1_score: 0.68"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xl0BgfDHXgus","executionInfo":{"status":"ok","timestamp":1617890526023,"user_tz":240,"elapsed":6783,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"9890ff2b-e370-47c7-9315-3e9c9c180647"},"source":["'''define params'''\n","params.learning_rate = 0.000005\n","params.checkpoint_restore_path = '/content/drive/MyDrive/AD Expriment II/VGG19_model_checkpoints/vgg19_weights_nsl'\n","params.checkpoint_path= '/content/drive/MyDrive/AD Expriment II/VGG19_model_checkpoints/vgg19_weights_nsl_tuning'\n","params.early_stop_base_line=0.70\n","params.train_epoch=50\n","params.nsl_multiplier = 0.005\n","params.nsl_sum_over_axis = -1\n","params.nsl_distance_type = nsl.configs.DistanceType.COSINE\n","'''build base model'''\n","base_model = ADModelBuilder(input_shape=params.ad_base_model_input_shape, base_model='vgg19').setup_VGG19_by_layer_names(trainable_layers=['block1_conv1', 'block3_conv4' ,'block5_conv4']).get_ADModel()\n","\n","\"\"\"restore NSL model from last training\"\"\"\n","graph_reg_config = nsl.configs.make_graph_reg_config(neighbor_prefix=params.neighbor_prefix,\n","                                                     neighbor_weight_suffix=params.neighbor_weight_suffix,\n","                                                     max_neighbors= params.max_seed_nbr,\n","                                                     multiplier= params.nsl_multiplier,\n","                                                     distance_type= params.nsl_distance_type, \n","                                                     sum_over_axis= params.nsl_sum_over_axis)\n","\n","graph_reg_model = nsl.keras.GraphRegularization(base_model,graph_reg_config)\n","\n","graph_reg_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=params.learning_rate, amsgrad=True), \n","                        loss=tf.losses.CategoricalCrossentropy(),\n","                        metrics=[\"accuracy\",\"AUC\",tfa.metrics.F1Score(num_classes=4, average=\"micro\", threshold = 0.5)])\n","\n","graph_reg_model.load_weights(params.checkpoint_path)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Note: default vgg19 not includes top and has imagenet weights. It is not a trainable model in ADModelBuilder. Setup specific trainable layers in setup_VGG19_by_layer_names or setup_VGG19 function based on the VGG19 layer name or layer number\n","trainable layer:  block1_conv1\n","trainable layer:  block3_conv4\n","trainable layer:  block5_conv4\n","Model: \"vgg19\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_5 (InputLayer)         [(None, 100, 100, 3)]     0         \n","_________________________________________________________________\n","block1_conv1 (Conv2D)        (None, 100, 100, 64)      1792      \n","_________________________________________________________________\n","block1_conv2 (Conv2D)        (None, 100, 100, 64)      36928     \n","_________________________________________________________________\n","block1_pool (MaxPooling2D)   (None, 50, 50, 64)        0         \n","_________________________________________________________________\n","block2_conv1 (Conv2D)        (None, 50, 50, 128)       73856     \n","_________________________________________________________________\n","block2_conv2 (Conv2D)        (None, 50, 50, 128)       147584    \n","_________________________________________________________________\n","block2_pool (MaxPooling2D)   (None, 25, 25, 128)       0         \n","_________________________________________________________________\n","block3_conv1 (Conv2D)        (None, 25, 25, 256)       295168    \n","_________________________________________________________________\n","block3_conv2 (Conv2D)        (None, 25, 25, 256)       590080    \n","_________________________________________________________________\n","block3_conv3 (Conv2D)        (None, 25, 25, 256)       590080    \n","_________________________________________________________________\n","block3_conv4 (Conv2D)        (None, 25, 25, 256)       590080    \n","_________________________________________________________________\n","block3_pool (MaxPooling2D)   (None, 12, 12, 256)       0         \n","_________________________________________________________________\n","block4_conv1 (Conv2D)        (None, 12, 12, 512)       1180160   \n","_________________________________________________________________\n","block4_conv2 (Conv2D)        (None, 12, 12, 512)       2359808   \n","_________________________________________________________________\n","block4_conv3 (Conv2D)        (None, 12, 12, 512)       2359808   \n","_________________________________________________________________\n","block4_conv4 (Conv2D)        (None, 12, 12, 512)       2359808   \n","_________________________________________________________________\n","block4_pool (MaxPooling2D)   (None, 6, 6, 512)         0         \n","_________________________________________________________________\n","block5_conv1 (Conv2D)        (None, 6, 6, 512)         2359808   \n","_________________________________________________________________\n","block5_conv2 (Conv2D)        (None, 6, 6, 512)         2359808   \n","_________________________________________________________________\n","block5_conv3 (Conv2D)        (None, 6, 6, 512)         2359808   \n","_________________________________________________________________\n","block5_conv4 (Conv2D)        (None, 6, 6, 512)         2359808   \n","_________________________________________________________________\n","block5_pool (MaxPooling2D)   (None, 3, 3, 512)         0         \n","=================================================================\n","Total params: 20,024,384\n","Trainable params: 2,359,808\n","Non-trainable params: 17,664,576\n","_________________________________________________________________\n","Model: \"VGG19_ADModel\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","tensor (InputLayer)          [(None, 100, 100, 3)]     0         \n","_________________________________________________________________\n","vgg19 (Functional)           (None, 3, 3, 512)         20024384  \n","_________________________________________________________________\n","flatten_4 (Flatten)          (None, 4608)              0         \n","_________________________________________________________________\n","dense_8 (Dense)              (None, 16)                73744     \n","_________________________________________________________________\n","batch_normalization_4 (Batch (None, 16)                64        \n","_________________________________________________________________\n","leaky_re_lu_4 (LeakyReLU)    (None, 16)                0         \n","_________________________________________________________________\n","dropout_4 (Dropout)          (None, 16)                0         \n","_________________________________________________________________\n","dense_9 (Dense)              (None, 4)                 68        \n","=================================================================\n","Total params: 20,098,260\n","Trainable params: 2,433,652\n","Non-trainable params: 17,664,608\n","_________________________________________________________________\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f7b1bd90590>"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"3Yr-yYkzbxel","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617894427986,"user_tz":240,"elapsed":3899772,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"2cd16266-bfb8-4c21-a81f-c8cb59fba7bf"},"source":["\"\"\"set up training checkpoint and earlystop callbacks\"\"\"\n","callback_checkpoints = tf.keras.callbacks.ModelCheckpoint(filepath=params.checkpoint_path, monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=True, mode='max', save_freq='epoch')\n","\n","callback_earlystop = AccEarlyStop(val_acc_base = params.early_stop_base_line)\n","\n","\"\"\"NSL model training\"\"\"\n","graph_reg_history = graph_reg_model.fit(train_image_dataset, \n","                                        validation_data=test_image_dataset,\n","                                        callbacks = [callback_checkpoints, callback_earlystop],\n","                                        epochs= params.train_epoch,\n","                                        verbose=1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/50\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py:595: UserWarning: Input dict contained keys ['id'] which did not match any model input. They will be ignored by the model.\n","  [n for n in tensors.keys() if n not in ref_input_names])\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/GraphRegularization/graph_loss/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/GraphRegularization/graph_loss/Reshape:0\", shape=(None, 4), dtype=float32), dense_shape=Tensor(\"gradient_tape/GraphRegularization/graph_loss/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"shape. This may consume a large amount of memory.\" % value)\n"],"name":"stderr"},{"output_type":"stream","text":["160/160 [==============================] - 71s 428ms/step - loss: 0.0342 - accuracy: 0.9904 - auc: 0.9999 - f1_score: 0.9901 - scaled_graph_loss: 7.0651e-05 - val_loss: 2.9772 - val_accuracy: 0.5942 - val_auc: 0.7943 - val_f1_score: 0.9461\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.59421, saving model to /content/drive/MyDrive/AD Expriment II/VGG19_model_checkpoints/vgg19_weights_nsl_tuning\n","Epoch 2/50\n","160/160 [==============================] - 73s 451ms/step - loss: 0.0340 - accuracy: 0.9903 - auc: 0.9998 - f1_score: 0.9904 - scaled_graph_loss: 7.8045e-05 - val_loss: 1.9575 - val_accuracy: 0.6873 - val_auc: 0.8606 - val_f1_score: 0.6872\n","\n","Epoch 00002: val_accuracy improved from 0.59421 to 0.68726, saving model to /content/drive/MyDrive/AD Expriment II/VGG19_model_checkpoints/vgg19_weights_nsl_tuning\n","Epoch 3/50\n","160/160 [==============================] - 76s 471ms/step - loss: 0.0370 - accuracy: 0.9896 - auc: 0.9996 - f1_score: 0.9895 - scaled_graph_loss: 8.0414e-05 - val_loss: 3.1772 - val_accuracy: 0.5997 - val_auc: 0.7912 - val_f1_score: 0.5969\n","\n","Epoch 00003: val_accuracy did not improve from 0.68726\n","Epoch 4/50\n","160/160 [==============================] - 78s 480ms/step - loss: 0.0362 - accuracy: 0.9886 - auc: 0.9998 - f1_score: 0.9888 - scaled_graph_loss: 8.1341e-05 - val_loss: 2.5117 - val_accuracy: 0.6263 - val_auc: 0.8162 - val_f1_score: 0.6278\n","\n","Epoch 00004: val_accuracy did not improve from 0.68726\n","Epoch 5/50\n","160/160 [==============================] - 77s 480ms/step - loss: 0.0260 - accuracy: 0.9933 - auc: 0.9999 - f1_score: 0.9934 - scaled_graph_loss: 5.7768e-05 - val_loss: 2.5874 - val_accuracy: 0.6349 - val_auc: 0.8306 - val_f1_score: 0.6353\n","\n","Epoch 00005: val_accuracy did not improve from 0.68726\n","Epoch 6/50\n","160/160 [==============================] - 78s 482ms/step - loss: 0.0267 - accuracy: 0.9933 - auc: 0.9999 - f1_score: 0.9936 - scaled_graph_loss: 5.5954e-05 - val_loss: 2.4050 - val_accuracy: 0.6489 - val_auc: 0.8269 - val_f1_score: 0.6491\n","\n","Epoch 00006: val_accuracy did not improve from 0.68726\n","Epoch 7/50\n","160/160 [==============================] - 78s 481ms/step - loss: 0.0299 - accuracy: 0.9915 - auc: 0.9999 - f1_score: 0.9915 - scaled_graph_loss: 6.1604e-05 - val_loss: 2.0872 - val_accuracy: 0.6833 - val_auc: 0.8496 - val_f1_score: 0.6819\n","\n","Epoch 00007: val_accuracy did not improve from 0.68726\n","Epoch 8/50\n","160/160 [==============================] - 78s 482ms/step - loss: 0.0224 - accuracy: 0.9939 - auc: 1.0000 - f1_score: 0.9939 - scaled_graph_loss: 4.8494e-05 - val_loss: 2.6960 - val_accuracy: 0.6403 - val_auc: 0.8211 - val_f1_score: 0.6386\n","\n","Epoch 00008: val_accuracy did not improve from 0.68726\n","Epoch 9/50\n","160/160 [==============================] - 78s 482ms/step - loss: 0.0202 - accuracy: 0.9950 - auc: 1.0000 - f1_score: 0.9947 - scaled_graph_loss: 4.4582e-05 - val_loss: 3.3979 - val_accuracy: 0.5864 - val_auc: 0.7912 - val_f1_score: 0.5869\n","\n","Epoch 00009: val_accuracy did not improve from 0.68726\n","Epoch 10/50\n","160/160 [==============================] - 78s 481ms/step - loss: 0.0256 - accuracy: 0.9933 - auc: 0.9998 - f1_score: 0.9932 - scaled_graph_loss: 5.9098e-05 - val_loss: 2.5353 - val_accuracy: 0.6372 - val_auc: 0.8325 - val_f1_score: 0.6392\n","\n","Epoch 00010: val_accuracy did not improve from 0.68726\n","Epoch 11/50\n","160/160 [==============================] - 78s 482ms/step - loss: 0.0215 - accuracy: 0.9959 - auc: 0.9999 - f1_score: 0.9956 - scaled_graph_loss: 4.7420e-05 - val_loss: 2.3514 - val_accuracy: 0.6638 - val_auc: 0.8407 - val_f1_score: 0.6630\n","\n","Epoch 00011: val_accuracy did not improve from 0.68726\n","Epoch 12/50\n","160/160 [==============================] - 78s 483ms/step - loss: 0.0195 - accuracy: 0.9950 - auc: 0.9999 - f1_score: 0.9951 - scaled_graph_loss: 4.3061e-05 - val_loss: 2.8871 - val_accuracy: 0.6701 - val_auc: 0.8364 - val_f1_score: 0.6711\n","\n","Epoch 00012: val_accuracy did not improve from 0.68726\n","Epoch 13/50\n","160/160 [==============================] - 78s 482ms/step - loss: 0.0342 - accuracy: 0.9902 - auc: 0.9996 - f1_score: 0.9901 - scaled_graph_loss: 7.0735e-05 - val_loss: 2.4687 - val_accuracy: 0.6294 - val_auc: 0.8238 - val_f1_score: 0.6267\n","\n","Epoch 00013: val_accuracy did not improve from 0.68726\n","Epoch 14/50\n","160/160 [==============================] - 78s 482ms/step - loss: 0.0425 - accuracy: 0.9858 - auc: 0.9997 - f1_score: 0.9859 - scaled_graph_loss: 1.0354e-04 - val_loss: 4.2911 - val_accuracy: 0.5192 - val_auc: 0.7346 - val_f1_score: 0.5191\n","\n","Epoch 00014: val_accuracy did not improve from 0.68726\n","Epoch 15/50\n","160/160 [==============================] - 77s 480ms/step - loss: 0.0333 - accuracy: 0.9909 - auc: 0.9998 - f1_score: 0.9909 - scaled_graph_loss: 7.3374e-05 - val_loss: 2.3635 - val_accuracy: 0.6482 - val_auc: 0.8265 - val_f1_score: 0.6464\n","\n","Epoch 00015: val_accuracy did not improve from 0.68726\n","Epoch 16/50\n","160/160 [==============================] - 78s 482ms/step - loss: 0.0579 - accuracy: 0.9803 - auc: 0.9989 - f1_score: 0.9799 - scaled_graph_loss: 1.2221e-04 - val_loss: 2.1124 - val_accuracy: 0.6607 - val_auc: 0.8497 - val_f1_score: 0.6598\n","\n","Epoch 00016: val_accuracy did not improve from 0.68726\n","Epoch 17/50\n","160/160 [==============================] - 78s 481ms/step - loss: 0.0293 - accuracy: 0.9908 - auc: 0.9999 - f1_score: 0.9909 - scaled_graph_loss: 6.5131e-05 - val_loss: 2.0243 - val_accuracy: 0.6771 - val_auc: 0.8582 - val_f1_score: 0.6769\n","\n","Epoch 00017: val_accuracy did not improve from 0.68726\n","Epoch 18/50\n","160/160 [==============================] - 78s 482ms/step - loss: 0.0229 - accuracy: 0.9948 - auc: 0.9999 - f1_score: 0.9948 - scaled_graph_loss: 4.9767e-05 - val_loss: 2.9828 - val_accuracy: 0.6216 - val_auc: 0.8105 - val_f1_score: 0.6185\n","\n","Epoch 00018: val_accuracy did not improve from 0.68726\n","Epoch 19/50\n","160/160 [==============================] - 78s 480ms/step - loss: 0.0219 - accuracy: 0.9938 - auc: 0.9999 - f1_score: 0.9939 - scaled_graph_loss: 4.9504e-05 - val_loss: 2.7055 - val_accuracy: 0.6591 - val_auc: 0.8310 - val_f1_score: 0.6612\n","\n","Epoch 00019: val_accuracy did not improve from 0.68726\n","Epoch 20/50\n","160/160 [==============================] - 78s 482ms/step - loss: 0.0187 - accuracy: 0.9946 - auc: 1.0000 - f1_score: 0.9948 - scaled_graph_loss: 4.5109e-05 - val_loss: 4.6125 - val_accuracy: 0.5731 - val_auc: 0.7571 - val_f1_score: 0.5730\n","\n","Epoch 00020: val_accuracy did not improve from 0.68726\n","Epoch 21/50\n","160/160 [==============================] - 78s 481ms/step - loss: 0.0262 - accuracy: 0.9929 - auc: 0.9999 - f1_score: 0.9929 - scaled_graph_loss: 5.8313e-05 - val_loss: 3.7432 - val_accuracy: 0.5043 - val_auc: 0.7278 - val_f1_score: 0.5043\n","\n","Epoch 00021: val_accuracy did not improve from 0.68726\n","Epoch 22/50\n","160/160 [==============================] - 78s 482ms/step - loss: 0.0249 - accuracy: 0.9940 - auc: 0.9999 - f1_score: 0.9944 - scaled_graph_loss: 5.5840e-05 - val_loss: 7.0298 - val_accuracy: 0.4722 - val_auc: 0.6764 - val_f1_score: 0.4706\n","\n","Epoch 00022: val_accuracy did not improve from 0.68726\n","Epoch 23/50\n","160/160 [==============================] - 78s 482ms/step - loss: 0.0449 - accuracy: 0.9867 - auc: 0.9992 - f1_score: 0.9867 - scaled_graph_loss: 9.4326e-05 - val_loss: 2.5420 - val_accuracy: 0.6364 - val_auc: 0.8235 - val_f1_score: 0.6356\n","\n","Epoch 00023: val_accuracy did not improve from 0.68726\n","Epoch 24/50\n","160/160 [==============================] - 78s 482ms/step - loss: 0.0193 - accuracy: 0.9951 - auc: 1.0000 - f1_score: 0.9948 - scaled_graph_loss: 4.2203e-05 - val_loss: 2.8533 - val_accuracy: 0.6372 - val_auc: 0.8081 - val_f1_score: 0.6369\n","\n","Epoch 00024: val_accuracy did not improve from 0.68726\n","Epoch 25/50\n","160/160 [==============================] - 78s 482ms/step - loss: 0.0180 - accuracy: 0.9960 - auc: 1.0000 - f1_score: 0.9959 - scaled_graph_loss: 4.0155e-05 - val_loss: 2.8136 - val_accuracy: 0.6529 - val_auc: 0.8179 - val_f1_score: 0.6523\n","\n","Epoch 00025: val_accuracy did not improve from 0.68726\n","Epoch 26/50\n","160/160 [==============================] - 78s 482ms/step - loss: 0.0240 - accuracy: 0.9938 - auc: 0.9999 - f1_score: 0.9939 - scaled_graph_loss: 5.2327e-05 - val_loss: 3.3947 - val_accuracy: 0.5981 - val_auc: 0.7919 - val_f1_score: 0.5964\n","\n","Epoch 00026: val_accuracy did not improve from 0.68726\n","Epoch 27/50\n","160/160 [==============================] - 78s 483ms/step - loss: 0.0245 - accuracy: 0.9938 - auc: 0.9999 - f1_score: 0.9939 - scaled_graph_loss: 5.6450e-05 - val_loss: 2.9124 - val_accuracy: 0.6310 - val_auc: 0.8233 - val_f1_score: 0.6314\n","\n","Epoch 00027: val_accuracy did not improve from 0.68726\n","Epoch 28/50\n","160/160 [==============================] - 78s 482ms/step - loss: 0.0303 - accuracy: 0.9922 - auc: 0.9998 - f1_score: 0.9921 - scaled_graph_loss: 6.7786e-05 - val_loss: 2.8957 - val_accuracy: 0.6357 - val_auc: 0.8142 - val_f1_score: 0.6325\n","\n","Epoch 00028: val_accuracy did not improve from 0.68726\n","Epoch 29/50\n","160/160 [==============================] - 78s 483ms/step - loss: 0.0256 - accuracy: 0.9921 - auc: 0.9999 - f1_score: 0.9922 - scaled_graph_loss: 5.7630e-05 - val_loss: 2.5818 - val_accuracy: 0.6458 - val_auc: 0.8241 - val_f1_score: 0.6465\n","\n","Epoch 00029: val_accuracy did not improve from 0.68726\n","Epoch 30/50\n","160/160 [==============================] - 78s 482ms/step - loss: 0.0263 - accuracy: 0.9927 - auc: 0.9999 - f1_score: 0.9926 - scaled_graph_loss: 6.3728e-05 - val_loss: 3.0643 - val_accuracy: 0.6364 - val_auc: 0.8218 - val_f1_score: 0.6364\n","\n","Epoch 00030: val_accuracy did not improve from 0.68726\n","Epoch 31/50\n","160/160 [==============================] - 78s 482ms/step - loss: 0.0249 - accuracy: 0.9928 - auc: 0.9999 - f1_score: 0.9930 - scaled_graph_loss: 5.7294e-05 - val_loss: 4.0492 - val_accuracy: 0.5442 - val_auc: 0.7553 - val_f1_score: 0.5406\n","\n","Epoch 00031: val_accuracy did not improve from 0.68726\n","Epoch 32/50\n","160/160 [==============================] - 78s 483ms/step - loss: 0.0206 - accuracy: 0.9942 - auc: 1.0000 - f1_score: 0.9939 - scaled_graph_loss: 4.7313e-05 - val_loss: 2.5129 - val_accuracy: 0.6810 - val_auc: 0.8473 - val_f1_score: 0.6789\n","\n","Epoch 00032: val_accuracy did not improve from 0.68726\n","Epoch 33/50\n","160/160 [==============================] - 78s 482ms/step - loss: 0.0154 - accuracy: 0.9964 - auc: 1.0000 - f1_score: 0.9963 - scaled_graph_loss: 3.5752e-05 - val_loss: 2.6153 - val_accuracy: 0.6763 - val_auc: 0.8392 - val_f1_score: 0.6761\n","\n","Epoch 00033: val_accuracy did not improve from 0.68726\n","Epoch 34/50\n","160/160 [==============================] - 78s 483ms/step - loss: 0.0162 - accuracy: 0.9955 - auc: 1.0000 - f1_score: 0.9958 - scaled_graph_loss: 3.6727e-05 - val_loss: 3.3808 - val_accuracy: 0.5637 - val_auc: 0.7754 - val_f1_score: 0.5639\n","\n","Epoch 00034: val_accuracy did not improve from 0.68726\n","Epoch 35/50\n","160/160 [==============================] - 78s 482ms/step - loss: 0.0134 - accuracy: 0.9966 - auc: 1.0000 - f1_score: 0.9967 - scaled_graph_loss: 3.1232e-05 - val_loss: 3.3558 - val_accuracy: 0.6263 - val_auc: 0.8117 - val_f1_score: 0.6250\n","\n","Epoch 00035: val_accuracy did not improve from 0.68726\n","Epoch 36/50\n","160/160 [==============================] - 78s 482ms/step - loss: 0.0156 - accuracy: 0.9965 - auc: 1.0000 - f1_score: 0.9963 - scaled_graph_loss: 3.3853e-05 - val_loss: 3.1721 - val_accuracy: 0.6403 - val_auc: 0.8173 - val_f1_score: 0.6386\n","\n","Epoch 00036: val_accuracy did not improve from 0.68726\n","Epoch 37/50\n","160/160 [==============================] - 78s 482ms/step - loss: 0.0154 - accuracy: 0.9960 - auc: 1.0000 - f1_score: 0.9962 - scaled_graph_loss: 3.1824e-05 - val_loss: 3.0936 - val_accuracy: 0.6403 - val_auc: 0.8127 - val_f1_score: 0.6374\n","\n","Epoch 00037: val_accuracy did not improve from 0.68726\n","Epoch 38/50\n","160/160 [==============================] - 78s 482ms/step - loss: 0.0135 - accuracy: 0.9967 - auc: 1.0000 - f1_score: 0.9966 - scaled_graph_loss: 3.2395e-05 - val_loss: 2.6368 - val_accuracy: 0.6833 - val_auc: 0.8428 - val_f1_score: 0.6813\n","\n","Epoch 00038: val_accuracy did not improve from 0.68726\n","Epoch 39/50\n","160/160 [==============================] - 78s 481ms/step - loss: 0.0123 - accuracy: 0.9969 - auc: 1.0000 - f1_score: 0.9970 - scaled_graph_loss: 2.5569e-05 - val_loss: 2.5061 - val_accuracy: 0.6685 - val_auc: 0.8423 - val_f1_score: 0.6682\n","\n","Epoch 00039: val_accuracy did not improve from 0.68726\n","Epoch 40/50\n","160/160 [==============================] - 78s 482ms/step - loss: 0.0134 - accuracy: 0.9964 - auc: 1.0000 - f1_score: 0.9964 - scaled_graph_loss: 2.9713e-05 - val_loss: 2.8052 - val_accuracy: 0.6497 - val_auc: 0.8283 - val_f1_score: 0.6514\n","\n","Epoch 00040: val_accuracy did not improve from 0.68726\n","Epoch 41/50\n","160/160 [==============================] - 78s 483ms/step - loss: 0.0149 - accuracy: 0.9971 - auc: 0.9999 - f1_score: 0.9968 - scaled_graph_loss: 3.2979e-05 - val_loss: 4.6948 - val_accuracy: 0.5645 - val_auc: 0.7556 - val_f1_score: 0.5637\n","\n","Epoch 00041: val_accuracy did not improve from 0.68726\n","Epoch 42/50\n","160/160 [==============================] - 78s 482ms/step - loss: 0.0133 - accuracy: 0.9968 - auc: 1.0000 - f1_score: 0.9969 - scaled_graph_loss: 2.7393e-05 - val_loss: 2.5559 - val_accuracy: 0.6575 - val_auc: 0.8403 - val_f1_score: 0.6585\n","\n","Epoch 00042: val_accuracy did not improve from 0.68726\n","Epoch 43/50\n","160/160 [==============================] - 78s 481ms/step - loss: 0.0124 - accuracy: 0.9968 - auc: 1.0000 - f1_score: 0.9969 - scaled_graph_loss: 2.7805e-05 - val_loss: 3.6461 - val_accuracy: 0.5973 - val_auc: 0.7886 - val_f1_score: 0.5985\n","\n","Epoch 00043: val_accuracy did not improve from 0.68726\n","Epoch 44/50\n","160/160 [==============================] - 78s 482ms/step - loss: 0.0258 - accuracy: 0.9923 - auc: 0.9998 - f1_score: 0.9920 - scaled_graph_loss: 5.9304e-05 - val_loss: 3.8508 - val_accuracy: 0.6302 - val_auc: 0.7977 - val_f1_score: 0.6293\n","\n","Epoch 00044: val_accuracy did not improve from 0.68726\n","Epoch 45/50\n","160/160 [==============================] - 78s 482ms/step - loss: 0.0411 - accuracy: 0.9861 - auc: 0.9995 - f1_score: 0.9860 - scaled_graph_loss: 9.4467e-05 - val_loss: 2.4148 - val_accuracy: 0.6716 - val_auc: 0.8533 - val_f1_score: 0.6703\n","\n","Epoch 00045: val_accuracy did not improve from 0.68726\n","Epoch 46/50\n","160/160 [==============================] - 78s 483ms/step - loss: 0.0186 - accuracy: 0.9939 - auc: 1.0000 - f1_score: 0.9939 - scaled_graph_loss: 4.2677e-05 - val_loss: 3.6436 - val_accuracy: 0.5895 - val_auc: 0.7800 - val_f1_score: 0.5899\n","\n","Epoch 00046: val_accuracy did not improve from 0.68726\n","Epoch 47/50\n","160/160 [==============================] - 78s 483ms/step - loss: 0.0133 - accuracy: 0.9967 - auc: 1.0000 - f1_score: 0.9968 - scaled_graph_loss: 2.9554e-05 - val_loss: 4.1330 - val_accuracy: 0.5801 - val_auc: 0.7742 - val_f1_score: 0.5796\n","\n","Epoch 00047: val_accuracy did not improve from 0.68726\n","Epoch 48/50\n","160/160 [==============================] - 86s 486ms/step - loss: 0.0137 - accuracy: 0.9967 - auc: 1.0000 - f1_score: 0.9967 - scaled_graph_loss: 2.9468e-05 - val_loss: 2.6348 - val_accuracy: 0.6669 - val_auc: 0.8391 - val_f1_score: 0.6638\n","\n","Epoch 00048: val_accuracy did not improve from 0.68726\n","Epoch 49/50\n","160/160 [==============================] - 78s 482ms/step - loss: 0.0252 - accuracy: 0.9923 - auc: 0.9998 - f1_score: 0.9925 - scaled_graph_loss: 5.2909e-05 - val_loss: 3.1094 - val_accuracy: 0.6231 - val_auc: 0.8114 - val_f1_score: 0.6216\n","\n","Epoch 00049: val_accuracy did not improve from 0.68726\n","Epoch 50/50\n","160/160 [==============================] - 84s 486ms/step - loss: 0.0193 - accuracy: 0.9955 - auc: 0.9999 - f1_score: 0.9950 - scaled_graph_loss: 4.4492e-05 - val_loss: 2.9534 - val_accuracy: 0.6474 - val_auc: 0.8270 - val_f1_score: 0.6486\n","\n","Epoch 00050: val_accuracy did not improve from 0.68726\n","Early stopping is not triggered, but best model is restored at epoch 2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UhIlqMFhgbcK","executionInfo":{"status":"ok","timestamp":1617894437379,"user_tz":240,"elapsed":2448,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"f22c999d-a92d-43b9-a7ed-e4fb5df7805e"},"source":["\"\"\"evaluate tuned model\"\"\"\n","graph_reg_model.evaluate(test_image_dataset)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1/1 [==============================] - 2s 2s/step - loss: 1.9575 - accuracy: 0.6873 - auc: 0.8606 - f1_score: 0.6872\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[1.9574897289276123,\n"," 0.6872556805610657,\n"," 0.8606342077255249,\n"," 0.6871552467346191]"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"fuf0qJfrMNz6"},"source":["'''plot confusion mat & calc acc for each label'''\n","test_image_dataset = NSLDataFormat.generate_test_tfr_image_tensor(path_list=test_tfr_list, \n","                                                                  batch_size=4000, \n","                                                                  size=(100,100),\n","                                                                  channels=3,\n","                                                                  shuffle=True)\n","data, data_label = iter(test_image_dataset).get_next()\n","data = data[\"tensor\"]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":396},"id":"aHTNVO-oMN3O","executionInfo":{"status":"ok","timestamp":1617894439681,"user_tz":240,"elapsed":2686,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"62fc9797-b8e4-415e-86fa-6eb207ff65a2"},"source":["ADModelBuilder.plot_confusion_mat(graph_reg_model, data, data_label, \"VGG19_NSL\")"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x432 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"SZbyx6tgMeCw"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_fE_9cNM7AS9"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YRSBTOx_ZQ2Y"},"source":["# 3.DenseNet121 & DenseNet121-NSL Model Training"]},{"cell_type":"code","metadata":{"id":"KBPizJFmjEvJ"},"source":["'''define hyper params'''\n","params = AD_params()\n","params.max_seed_nbr=5\n","params.batch_size=128\n","params.image_channels =3\n","params.image_size =(100,100)\n","params.ad_base_model_input_shape=(100,100,3)\n","params.train_tfr_path = train_tfr_path\n","\n","'''parse train_data.tfr to train image dataset with batch_size at 64'''\n","train_image_dataset = NSLDataFormat.parse_tfr_to_dataset(file_path_list=[params.train_tfr_path],\n","                                                         batch_size=params.batch_size,\n","                                                         max_neighbor_number=params.max_seed_nbr,\n","                                                         image_size=params.image_size,\n","                                                         image_channels=params.image_channels,\n","                                                         shuffle=True)\n","\n","'''load test data with batch_size at 64 '''\n","test_image_dataset = NSLDataFormat.generate_test_tfr_image_tensor(path_list=test_tfr_list, \n","                                                                  batch_size=params.batch_size, \n","                                                                  size=params.image_size,\n","                                                                  channels=params.image_channels,\n","                                                                  shuffle=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"980I6MuXjAix"},"source":["## 3.1 DenseNet Base Model Training\n","### val_acc: 0.61, val_auc: 0.85, val_f1_score: 0.60 "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2xyvZj1bcueJ","executionInfo":{"status":"ok","timestamp":1618572362724,"user_tz":240,"elapsed":3904,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"fdd37215-e7cc-4e36-fa86-e239b20611fd"},"source":["'''define params'''\n","params.learning_rate=0.005\n","params.checkpoint_restore_path='/content/drive/MyDrive/AD Expriment II/DenseNet_model_checkpoints/densenet_weights'\n","params.checkpoint_path='/content/drive/MyDrive/AD Expriment II/DenseNet_model_checkpoints/densenet_weights'\n","params.early_stop_base_line=0.70\n","params.train_epoch=50\n","\n","'''build base_model and restore from the last training'''\n","base_model = ADModelBuilder(input_shape=params.ad_base_model_input_shape, base_model='densenet121').get_ADModel()\n","\n","base_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=params.learning_rate, amsgrad=True), \n","                   loss=tf.losses.CategoricalCrossentropy(), \n","                   metrics=['accuracy', 'AUC',tfa.metrics.F1Score(num_classes=4, average=\"micro\", threshold = 0.5)])\n","\n","# base_model.load_weights(params.checkpoint_restore_path)\n","\n","'''set up check point & early stopping'''\n","callback_checkpints = tf.keras.callbacks.ModelCheckpoint(filepath= params.checkpoint_path, monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=True, mode='max',\n","                                                         save_freq='epoch',options=None)\n","\n","callback_earlystop = AccEarlyStop(val_acc_base=params.early_stop_base_line)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Note: default DenseNet121 not includes top and has imagenet weights. It is not a trainable model in ADModelBuilder. Please setup trainable layers in setup_DenseNet121 function based on the \"Layer Number\"\n","Model: \"DenseNet121_ADModel\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","tensor (InputLayer)          [(None, 100, 100, 3)]     0         \n","_________________________________________________________________\n","densenet121 (Functional)     (None, 3, 3, 1024)        7037504   \n","_________________________________________________________________\n","flatten_3 (Flatten)          (None, 9216)              0         \n","_________________________________________________________________\n","dropout_6 (Dropout)          (None, 9216)              0         \n","_________________________________________________________________\n","dense_6 (Dense)              (None, 32)                294944    \n","_________________________________________________________________\n","batch_normalization_3 (Batch (None, 32)                128       \n","_________________________________________________________________\n","leaky_re_lu_3 (LeakyReLU)    (None, 32)                0         \n","_________________________________________________________________\n","dropout_7 (Dropout)          (None, 32)                0         \n","_________________________________________________________________\n","dense_7 (Dense)              (None, 4)                 132       \n","=================================================================\n","Total params: 7,332,708\n","Trainable params: 295,140\n","Non-trainable params: 7,037,568\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tpy7INugZP2P","executionInfo":{"status":"ok","timestamp":1618573367274,"user_tz":240,"elapsed":1001783,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"ef057faa-c15a-4c25-af37-7ea87d8f702f"},"source":["'''train base model'''\n","history = base_model.fit(train_image_dataset,\n","                         validation_data= test_image_dataset,\n","                         callbacks = [callback_checkpints, callback_earlystop],\n","                         epochs=params.train_epoch,\n","                         verbose=1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/50\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py:595: UserWarning: Input dict contained keys ['NL_nbr_0_id', 'NL_nbr_0_tensor', 'NL_nbr_0_weight', 'NL_nbr_1_id', 'NL_nbr_1_tensor', 'NL_nbr_1_weight', 'NL_nbr_2_id', 'NL_nbr_2_tensor', 'NL_nbr_2_weight', 'NL_nbr_3_id', 'NL_nbr_3_tensor', 'NL_nbr_3_weight', 'NL_nbr_4_id', 'NL_nbr_4_tensor', 'NL_nbr_4_weight', 'id'] which did not match any model input. They will be ignored by the model.\n","  [n for n in tensors.keys() if n not in ref_input_names])\n"],"name":"stderr"},{"output_type":"stream","text":["     80/Unknown - 26s 240ms/step - loss: 1.0793 - accuracy: 0.5513 - auc: 0.8067 - f1_score: 0.5097"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py:595: UserWarning: Input dict contained keys ['id'] which did not match any model input. They will be ignored by the model.\n","  [n for n in tensors.keys() if n not in ref_input_names])\n"],"name":"stderr"},{"output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r80/80 [==============================] - 29s 279ms/step - loss: 1.0771 - accuracy: 0.5519 - auc: 0.8073 - f1_score: 0.5103 - val_loss: 1.1650 - val_accuracy: 0.5113 - val_auc: 0.8189 - val_f1_score: 0.5029\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.51134, saving model to /content/drive/MyDrive/AD Expriment II/DenseNet_model_checkpoints/densenet_weights\n","Epoch 2/50\n","80/80 [==============================] - 20s 240ms/step - loss: 0.6907 - accuracy: 0.6897 - auc: 0.9137 - f1_score: 0.6640 - val_loss: 1.0876 - val_accuracy: 0.5199 - val_auc: 0.8202 - val_f1_score: 0.5060\n","\n","Epoch 00002: val_accuracy improved from 0.51134 to 0.51994, saving model to /content/drive/MyDrive/AD Expriment II/DenseNet_model_checkpoints/densenet_weights\n","Epoch 3/50\n","80/80 [==============================] - 20s 238ms/step - loss: 0.6191 - accuracy: 0.7267 - auc: 0.9305 - f1_score: 0.7107 - val_loss: 0.9327 - val_accuracy: 0.5614 - val_auc: 0.8416 - val_f1_score: 0.5304\n","\n","Epoch 00003: val_accuracy improved from 0.51994 to 0.56138, saving model to /content/drive/MyDrive/AD Expriment II/DenseNet_model_checkpoints/densenet_weights\n","Epoch 4/50\n","80/80 [==============================] - 20s 241ms/step - loss: 0.5851 - accuracy: 0.7388 - auc: 0.9368 - f1_score: 0.7262 - val_loss: 1.0732 - val_accuracy: 0.5590 - val_auc: 0.8328 - val_f1_score: 0.5416\n","\n","Epoch 00004: val_accuracy did not improve from 0.56138\n","Epoch 5/50\n","80/80 [==============================] - 20s 237ms/step - loss: 0.5634 - accuracy: 0.7446 - auc: 0.9417 - f1_score: 0.7405 - val_loss: 0.9974 - val_accuracy: 0.5637 - val_auc: 0.8404 - val_f1_score: 0.5470\n","\n","Epoch 00005: val_accuracy improved from 0.56138 to 0.56372, saving model to /content/drive/MyDrive/AD Expriment II/DenseNet_model_checkpoints/densenet_weights\n","Epoch 6/50\n","80/80 [==============================] - 20s 239ms/step - loss: 0.5246 - accuracy: 0.7702 - auc: 0.9495 - f1_score: 0.7605 - val_loss: 1.1080 - val_accuracy: 0.5582 - val_auc: 0.8317 - val_f1_score: 0.5503\n","\n","Epoch 00006: val_accuracy did not improve from 0.56372\n","Epoch 7/50\n","80/80 [==============================] - 19s 236ms/step - loss: 0.5124 - accuracy: 0.7771 - auc: 0.9520 - f1_score: 0.7691 - val_loss: 1.1980 - val_accuracy: 0.5645 - val_auc: 0.8309 - val_f1_score: 0.5529\n","\n","Epoch 00007: val_accuracy improved from 0.56372 to 0.56450, saving model to /content/drive/MyDrive/AD Expriment II/DenseNet_model_checkpoints/densenet_weights\n","Epoch 8/50\n","80/80 [==============================] - 20s 239ms/step - loss: 0.5064 - accuracy: 0.7747 - auc: 0.9524 - f1_score: 0.7698 - val_loss: 1.0088 - val_accuracy: 0.5450 - val_auc: 0.8351 - val_f1_score: 0.5320\n","\n","Epoch 00008: val_accuracy did not improve from 0.56450\n","Epoch 9/50\n","80/80 [==============================] - 19s 235ms/step - loss: 0.5004 - accuracy: 0.7778 - auc: 0.9535 - f1_score: 0.7680 - val_loss: 1.0023 - val_accuracy: 0.5801 - val_auc: 0.8417 - val_f1_score: 0.5611\n","\n","Epoch 00009: val_accuracy improved from 0.56450 to 0.58014, saving model to /content/drive/MyDrive/AD Expriment II/DenseNet_model_checkpoints/densenet_weights\n","Epoch 10/50\n","80/80 [==============================] - 20s 236ms/step - loss: 0.4809 - accuracy: 0.7893 - auc: 0.9575 - f1_score: 0.7862 - val_loss: 1.1044 - val_accuracy: 0.5293 - val_auc: 0.8221 - val_f1_score: 0.5255\n","\n","Epoch 00010: val_accuracy did not improve from 0.58014\n","Epoch 11/50\n","80/80 [==============================] - 19s 236ms/step - loss: 0.4690 - accuracy: 0.7939 - auc: 0.9591 - f1_score: 0.7872 - val_loss: 0.9995 - val_accuracy: 0.5747 - val_auc: 0.8390 - val_f1_score: 0.5552\n","\n","Epoch 00011: val_accuracy did not improve from 0.58014\n","Epoch 12/50\n","80/80 [==============================] - 19s 236ms/step - loss: 0.4595 - accuracy: 0.8015 - auc: 0.9611 - f1_score: 0.7968 - val_loss: 1.1117 - val_accuracy: 0.5747 - val_auc: 0.8401 - val_f1_score: 0.5675\n","\n","Epoch 00012: val_accuracy did not improve from 0.58014\n","Epoch 13/50\n","80/80 [==============================] - 20s 237ms/step - loss: 0.4689 - accuracy: 0.7894 - auc: 0.9590 - f1_score: 0.7850 - val_loss: 1.0213 - val_accuracy: 0.5622 - val_auc: 0.8405 - val_f1_score: 0.5498\n","\n","Epoch 00013: val_accuracy did not improve from 0.58014\n","Epoch 14/50\n","80/80 [==============================] - 20s 237ms/step - loss: 0.4518 - accuracy: 0.8001 - auc: 0.9622 - f1_score: 0.7990 - val_loss: 1.1541 - val_accuracy: 0.5770 - val_auc: 0.8406 - val_f1_score: 0.5651\n","\n","Epoch 00014: val_accuracy did not improve from 0.58014\n","Epoch 15/50\n","80/80 [==============================] - 19s 236ms/step - loss: 0.4460 - accuracy: 0.8070 - auc: 0.9631 - f1_score: 0.8023 - val_loss: 1.1428 - val_accuracy: 0.5887 - val_auc: 0.8404 - val_f1_score: 0.5853\n","\n","Epoch 00015: val_accuracy improved from 0.58014 to 0.58874, saving model to /content/drive/MyDrive/AD Expriment II/DenseNet_model_checkpoints/densenet_weights\n","Epoch 16/50\n","80/80 [==============================] - 20s 237ms/step - loss: 0.4414 - accuracy: 0.8043 - auc: 0.9636 - f1_score: 0.8024 - val_loss: 1.0559 - val_accuracy: 0.5676 - val_auc: 0.8380 - val_f1_score: 0.5504\n","\n","Epoch 00016: val_accuracy did not improve from 0.58874\n","Epoch 17/50\n","80/80 [==============================] - 19s 236ms/step - loss: 0.4360 - accuracy: 0.8137 - auc: 0.9650 - f1_score: 0.8114 - val_loss: 1.0675 - val_accuracy: 0.5786 - val_auc: 0.8401 - val_f1_score: 0.5680\n","\n","Epoch 00017: val_accuracy did not improve from 0.58874\n","Epoch 18/50\n","80/80 [==============================] - 19s 235ms/step - loss: 0.4381 - accuracy: 0.8124 - auc: 0.9646 - f1_score: 0.8088 - val_loss: 1.0232 - val_accuracy: 0.5848 - val_auc: 0.8476 - val_f1_score: 0.5802\n","\n","Epoch 00018: val_accuracy did not improve from 0.58874\n","Epoch 19/50\n","80/80 [==============================] - 19s 235ms/step - loss: 0.4232 - accuracy: 0.8187 - auc: 0.9668 - f1_score: 0.8169 - val_loss: 1.0355 - val_accuracy: 0.5794 - val_auc: 0.8401 - val_f1_score: 0.5657\n","\n","Epoch 00019: val_accuracy did not improve from 0.58874\n","Epoch 20/50\n","80/80 [==============================] - 19s 236ms/step - loss: 0.4363 - accuracy: 0.8072 - auc: 0.9650 - f1_score: 0.8054 - val_loss: 1.2271 - val_accuracy: 0.5723 - val_auc: 0.8362 - val_f1_score: 0.5609\n","\n","Epoch 00020: val_accuracy did not improve from 0.58874\n","Epoch 21/50\n","80/80 [==============================] - 19s 236ms/step - loss: 0.4489 - accuracy: 0.8013 - auc: 0.9624 - f1_score: 0.8010 - val_loss: 1.1370 - val_accuracy: 0.5942 - val_auc: 0.8432 - val_f1_score: 0.5837\n","\n","Epoch 00021: val_accuracy improved from 0.58874 to 0.59421, saving model to /content/drive/MyDrive/AD Expriment II/DenseNet_model_checkpoints/densenet_weights\n","Epoch 22/50\n","80/80 [==============================] - 20s 238ms/step - loss: 0.4123 - accuracy: 0.8202 - auc: 0.9683 - f1_score: 0.8183 - val_loss: 1.1872 - val_accuracy: 0.5887 - val_auc: 0.8406 - val_f1_score: 0.5815\n","\n","Epoch 00022: val_accuracy did not improve from 0.59421\n","Epoch 23/50\n","80/80 [==============================] - 19s 236ms/step - loss: 0.4046 - accuracy: 0.8270 - auc: 0.9697 - f1_score: 0.8240 - val_loss: 1.0830 - val_accuracy: 0.5911 - val_auc: 0.8463 - val_f1_score: 0.5809\n","\n","Epoch 00023: val_accuracy did not improve from 0.59421\n","Epoch 24/50\n","80/80 [==============================] - 19s 236ms/step - loss: 0.4239 - accuracy: 0.8182 - auc: 0.9666 - f1_score: 0.8141 - val_loss: 1.0741 - val_accuracy: 0.5864 - val_auc: 0.8453 - val_f1_score: 0.5794\n","\n","Epoch 00024: val_accuracy did not improve from 0.59421\n","Epoch 25/50\n","80/80 [==============================] - 19s 236ms/step - loss: 0.4136 - accuracy: 0.8186 - auc: 0.9681 - f1_score: 0.8148 - val_loss: 1.2256 - val_accuracy: 0.5903 - val_auc: 0.8412 - val_f1_score: 0.5851\n","\n","Epoch 00025: val_accuracy did not improve from 0.59421\n","Epoch 26/50\n","80/80 [==============================] - 19s 236ms/step - loss: 0.3989 - accuracy: 0.8279 - auc: 0.9703 - f1_score: 0.8246 - val_loss: 1.1275 - val_accuracy: 0.5887 - val_auc: 0.8433 - val_f1_score: 0.5797\n","\n","Epoch 00026: val_accuracy did not improve from 0.59421\n","Epoch 27/50\n","80/80 [==============================] - 19s 236ms/step - loss: 0.3919 - accuracy: 0.8323 - auc: 0.9716 - f1_score: 0.8315 - val_loss: 1.0760 - val_accuracy: 0.5895 - val_auc: 0.8435 - val_f1_score: 0.5864\n","\n","Epoch 00027: val_accuracy did not improve from 0.59421\n","Epoch 28/50\n","80/80 [==============================] - 20s 238ms/step - loss: 0.3897 - accuracy: 0.8364 - auc: 0.9718 - f1_score: 0.8337 - val_loss: 1.2020 - val_accuracy: 0.5801 - val_auc: 0.8380 - val_f1_score: 0.5693\n","\n","Epoch 00028: val_accuracy did not improve from 0.59421\n","Epoch 29/50\n","80/80 [==============================] - 19s 237ms/step - loss: 0.3927 - accuracy: 0.8329 - auc: 0.9712 - f1_score: 0.8305 - val_loss: 1.1084 - val_accuracy: 0.5958 - val_auc: 0.8453 - val_f1_score: 0.5887\n","\n","Epoch 00029: val_accuracy improved from 0.59421 to 0.59578, saving model to /content/drive/MyDrive/AD Expriment II/DenseNet_model_checkpoints/densenet_weights\n","Epoch 30/50\n","80/80 [==============================] - 20s 238ms/step - loss: 0.3831 - accuracy: 0.8401 - auc: 0.9726 - f1_score: 0.8369 - val_loss: 1.1415 - val_accuracy: 0.5598 - val_auc: 0.8369 - val_f1_score: 0.5560\n","\n","Epoch 00030: val_accuracy did not improve from 0.59578\n","Epoch 31/50\n","80/80 [==============================] - 19s 236ms/step - loss: 0.3896 - accuracy: 0.8319 - auc: 0.9718 - f1_score: 0.8301 - val_loss: 1.2393 - val_accuracy: 0.5747 - val_auc: 0.8403 - val_f1_score: 0.5707\n","\n","Epoch 00031: val_accuracy did not improve from 0.59578\n","Epoch 32/50\n","80/80 [==============================] - 20s 237ms/step - loss: 0.3968 - accuracy: 0.8294 - auc: 0.9707 - f1_score: 0.8279 - val_loss: 1.0810 - val_accuracy: 0.5911 - val_auc: 0.8482 - val_f1_score: 0.5830\n","\n","Epoch 00032: val_accuracy did not improve from 0.59578\n","Epoch 33/50\n","80/80 [==============================] - 20s 237ms/step - loss: 0.3838 - accuracy: 0.8404 - auc: 0.9726 - f1_score: 0.8370 - val_loss: 1.0879 - val_accuracy: 0.6028 - val_auc: 0.8497 - val_f1_score: 0.5903\n","\n","Epoch 00033: val_accuracy improved from 0.59578 to 0.60281, saving model to /content/drive/MyDrive/AD Expriment II/DenseNet_model_checkpoints/densenet_weights\n","Epoch 34/50\n","80/80 [==============================] - 20s 238ms/step - loss: 0.3851 - accuracy: 0.8333 - auc: 0.9724 - f1_score: 0.8326 - val_loss: 1.3948 - val_accuracy: 0.5700 - val_auc: 0.8298 - val_f1_score: 0.5614\n","\n","Epoch 00034: val_accuracy did not improve from 0.60281\n","Epoch 35/50\n","80/80 [==============================] - 19s 236ms/step - loss: 0.3815 - accuracy: 0.8410 - auc: 0.9729 - f1_score: 0.8397 - val_loss: 1.2103 - val_accuracy: 0.5942 - val_auc: 0.8440 - val_f1_score: 0.5885\n","\n","Epoch 00035: val_accuracy did not improve from 0.60281\n","Epoch 36/50\n","80/80 [==============================] - 20s 237ms/step - loss: 0.3647 - accuracy: 0.8462 - auc: 0.9752 - f1_score: 0.8459 - val_loss: 1.2784 - val_accuracy: 0.5817 - val_auc: 0.8389 - val_f1_score: 0.5826\n","\n","Epoch 00036: val_accuracy did not improve from 0.60281\n","Epoch 37/50\n","80/80 [==============================] - 20s 240ms/step - loss: 0.3899 - accuracy: 0.8372 - auc: 0.9718 - f1_score: 0.8356 - val_loss: 1.2409 - val_accuracy: 0.5973 - val_auc: 0.8431 - val_f1_score: 0.5841\n","\n","Epoch 00037: val_accuracy did not improve from 0.60281\n","Epoch 38/50\n","80/80 [==============================] - 19s 235ms/step - loss: 0.3749 - accuracy: 0.8390 - auc: 0.9738 - f1_score: 0.8395 - val_loss: 1.1457 - val_accuracy: 0.6013 - val_auc: 0.8476 - val_f1_score: 0.5923\n","\n","Epoch 00038: val_accuracy did not improve from 0.60281\n","Epoch 39/50\n","80/80 [==============================] - 19s 236ms/step - loss: 0.3592 - accuracy: 0.8526 - auc: 0.9759 - f1_score: 0.8476 - val_loss: 1.2206 - val_accuracy: 0.5379 - val_auc: 0.8241 - val_f1_score: 0.5344\n","\n","Epoch 00039: val_accuracy did not improve from 0.60281\n","Epoch 40/50\n","80/80 [==============================] - 20s 238ms/step - loss: 0.3667 - accuracy: 0.8411 - auc: 0.9749 - f1_score: 0.8417 - val_loss: 1.0602 - val_accuracy: 0.6013 - val_auc: 0.8510 - val_f1_score: 0.5937\n","\n","Epoch 00040: val_accuracy did not improve from 0.60281\n","Epoch 41/50\n","80/80 [==============================] - 19s 235ms/step - loss: 0.3675 - accuracy: 0.8446 - auc: 0.9747 - f1_score: 0.8406 - val_loss: 1.2212 - val_accuracy: 0.5958 - val_auc: 0.8463 - val_f1_score: 0.5896\n","\n","Epoch 00041: val_accuracy did not improve from 0.60281\n","Epoch 42/50\n","80/80 [==============================] - 20s 237ms/step - loss: 0.3628 - accuracy: 0.8482 - auc: 0.9754 - f1_score: 0.8460 - val_loss: 1.3262 - val_accuracy: 0.5809 - val_auc: 0.8388 - val_f1_score: 0.5789\n","\n","Epoch 00042: val_accuracy did not improve from 0.60281\n","Epoch 43/50\n","80/80 [==============================] - 20s 238ms/step - loss: 0.3680 - accuracy: 0.8415 - auc: 0.9748 - f1_score: 0.8413 - val_loss: 1.1639 - val_accuracy: 0.6083 - val_auc: 0.8471 - val_f1_score: 0.6018\n","\n","Epoch 00043: val_accuracy improved from 0.60281 to 0.60829, saving model to /content/drive/MyDrive/AD Expriment II/DenseNet_model_checkpoints/densenet_weights\n","Epoch 44/50\n","80/80 [==============================] - 20s 240ms/step - loss: 0.3610 - accuracy: 0.8452 - auc: 0.9757 - f1_score: 0.8432 - val_loss: 1.2098 - val_accuracy: 0.5934 - val_auc: 0.8423 - val_f1_score: 0.5836\n","\n","Epoch 00044: val_accuracy did not improve from 0.60829\n","Epoch 45/50\n","80/80 [==============================] - 20s 237ms/step - loss: 0.3634 - accuracy: 0.8472 - auc: 0.9755 - f1_score: 0.8460 - val_loss: 1.1322 - val_accuracy: 0.6020 - val_auc: 0.8492 - val_f1_score: 0.5973\n","\n","Epoch 00045: val_accuracy did not improve from 0.60829\n","Epoch 46/50\n","80/80 [==============================] - 20s 238ms/step - loss: 0.3452 - accuracy: 0.8506 - auc: 0.9778 - f1_score: 0.8505 - val_loss: 1.1089 - val_accuracy: 0.6106 - val_auc: 0.8511 - val_f1_score: 0.5994\n","\n","Epoch 00046: val_accuracy improved from 0.60829 to 0.61063, saving model to /content/drive/MyDrive/AD Expriment II/DenseNet_model_checkpoints/densenet_weights\n","Epoch 47/50\n","80/80 [==============================] - 20s 237ms/step - loss: 0.3481 - accuracy: 0.8512 - auc: 0.9774 - f1_score: 0.8504 - val_loss: 1.1098 - val_accuracy: 0.5989 - val_auc: 0.8490 - val_f1_score: 0.5848\n","\n","Epoch 00047: val_accuracy did not improve from 0.61063\n","Epoch 48/50\n","80/80 [==============================] - 20s 237ms/step - loss: 0.3648 - accuracy: 0.8440 - auc: 0.9748 - f1_score: 0.8436 - val_loss: 1.1981 - val_accuracy: 0.6091 - val_auc: 0.8502 - val_f1_score: 0.6048\n","\n","Epoch 00048: val_accuracy did not improve from 0.61063\n","Epoch 49/50\n","80/80 [==============================] - 19s 236ms/step - loss: 0.3569 - accuracy: 0.8485 - auc: 0.9763 - f1_score: 0.8489 - val_loss: 1.1528 - val_accuracy: 0.6036 - val_auc: 0.8480 - val_f1_score: 0.5980\n","\n","Epoch 00049: val_accuracy did not improve from 0.61063\n","Epoch 50/50\n","80/80 [==============================] - 20s 237ms/step - loss: 0.3402 - accuracy: 0.8534 - auc: 0.9784 - f1_score: 0.8532 - val_loss: 1.1750 - val_accuracy: 0.5973 - val_auc: 0.8462 - val_f1_score: 0.5906\n","\n","Epoch 00050: val_accuracy did not improve from 0.61063\n","Early stopping is not triggered, but best model is restored at epoch 46\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wyzcCFeOZP1r","executionInfo":{"status":"ok","timestamp":1618573379979,"user_tz":240,"elapsed":1828,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"316dcda6-6495-45ef-8410-a3660910ec52"},"source":["'''evaluate base model'''\n","base_model.evaluate(test_image_dataset)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1/1 [==============================] - 1s 1s/step - loss: 1.1089 - accuracy: 0.6106 - auc: 0.8511 - f1_score: 0.5994\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[1.1089028120040894,\n"," 0.6106333136558533,\n"," 0.8510772585868835,\n"," 0.5994260311126709]"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"6nBD2RQWKJto"},"source":["'''plot confusion mat & calc acc for each label'''\n","test_image_dataset = NSLDataFormat.generate_test_tfr_image_tensor(path_list=test_tfr_list, \n","                                                                  batch_size=4000, \n","                                                                  size=(100,100),\n","                                                                  channels=3,\n","                                                                  shuffle=True)\n","data, data_label = iter(test_image_dataset).get_next()\n","data = data[\"tensor\"]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":396},"id":"yz9TqB3XKJv_","executionInfo":{"status":"ok","timestamp":1618573392801,"user_tz":240,"elapsed":1566,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"b2989197-5983-433d-d6fd-34d29be1a447"},"source":["ADModelBuilder.plot_confusion_mat(base_model, data, data_label, \"DenseNet121\")"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x432 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"8BFz2NxAKJyD"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Jd0LKKAc5NLM"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aAfKfwGX5x9Y"},"source":["## 3.2 DenseNet_NSL Model Training\n","### val_acc: 0.60, val_auc: 0.85, val_f1_score: 0.59\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BY2jbBjQZP1C","executionInfo":{"status":"ok","timestamp":1618573548552,"user_tz":240,"elapsed":3943,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"4086f598-b0c0-4607-b902-990d63ecf6f3"},"source":["'''define params'''\n","params.learning_rate=0.005\n","params.restore_path = '/content/drive/MyDrive/AD Expriment II/DenseNet_model_checkpoints/densenet_nsl_weights'\n","params.checkpoint_path = '/content/drive/MyDrive/AD Expriment II/DenseNet_model_checkpoints/densenet_nsl_weights'\n","params.early_stop_base_line=0.65\n","params.train_epoch=50\n","params.nsl_multiplier = 0.005\n","params.nsl_sum_over_axis = -1\n","params.nsl_distance_type = nsl.configs.DistanceType.COSINE\n","\n","'''build base_model and restore from the last training'''\n","base_model = ADModelBuilder(input_shape=params.ad_base_model_input_shape, base_model='densenet121').get_ADModel()\n","\n","'''build NSL model on top of base model'''\n","graph_reg_config = nsl.configs.make_graph_reg_config(neighbor_prefix=params.neighbor_prefix,\n","                                                     neighbor_weight_suffix=params.neighbor_weight_suffix,\n","                                                     max_neighbors= params.max_seed_nbr,\n","                                                     multiplier= params.nsl_multiplier,\n","                                                     distance_type= params.nsl_distance_type,\n","                                                     sum_over_axis=params.nsl_sum_over_axis)\n","graph_reg_model = nsl.keras.GraphRegularization(base_model,graph_reg_config)\n","graph_reg_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=params.learning_rate, amsgrad=True),\n","                        loss=tf.losses.CategoricalCrossentropy(),\n","                        metrics=[\"accuracy\",\"AUC\",tfa.metrics.F1Score(num_classes=4, average=\"micro\", threshold = 0.5)])\n","\n","# graph_reg_model.load_weights(params.restore_path)\n","'''set up check point & early stopping'''\n","callback_checkpoints = tf.keras.callbacks.ModelCheckpoint(filepath= params.checkpoint_path, monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=True, mode='max', save_freq='epoch',options=None)\n","callback_earlystop = AccEarlyStop(val_acc_base=params.early_stop_base_line)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Note: default DenseNet121 not includes top and has imagenet weights. It is not a trainable model in ADModelBuilder. Please setup trainable layers in setup_DenseNet121 function based on the \"Layer Number\"\n","Model: \"DenseNet121_ADModel\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","tensor (InputLayer)          [(None, 100, 100, 3)]     0         \n","_________________________________________________________________\n","densenet121 (Functional)     (None, 3, 3, 1024)        7037504   \n","_________________________________________________________________\n","flatten_6 (Flatten)          (None, 9216)              0         \n","_________________________________________________________________\n","dropout_12 (Dropout)         (None, 9216)              0         \n","_________________________________________________________________\n","dense_12 (Dense)             (None, 32)                294944    \n","_________________________________________________________________\n","batch_normalization_6 (Batch (None, 32)                128       \n","_________________________________________________________________\n","leaky_re_lu_6 (LeakyReLU)    (None, 32)                0         \n","_________________________________________________________________\n","dropout_13 (Dropout)         (None, 32)                0         \n","_________________________________________________________________\n","dense_13 (Dense)             (None, 4)                 132       \n","=================================================================\n","Total params: 7,332,708\n","Trainable params: 295,140\n","Non-trainable params: 7,037,568\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zfVdJD-ff1BO","executionInfo":{"status":"ok","timestamp":1618575723514,"user_tz":240,"elapsed":2171249,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"d23cba9d-699f-4ab1-e412-b42cf5a87761"},"source":["'''train the nsl model'''\n","graph_reg_history = graph_reg_model.fit(train_image_dataset, \n","                                        validation_data=test_image_dataset,\n","                                        callbacks = [callback_checkpoints, callback_earlystop],\n","                                        epochs=params.train_epoch,\n","                                        verbose=1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/50\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py:595: UserWarning: Input dict contained keys ['id'] which did not match any model input. They will be ignored by the model.\n","  [n for n in tensors.keys() if n not in ref_input_names])\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/GraphRegularization/graph_loss/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/GraphRegularization/graph_loss/Reshape:0\", shape=(None, 4), dtype=float32), dense_shape=Tensor(\"gradient_tape/GraphRegularization/graph_loss/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"shape. This may consume a large amount of memory.\" % value)\n"],"name":"stderr"},{"output_type":"stream","text":["80/80 [==============================] - 69s 633ms/step - loss: 0.9899 - accuracy: 0.5700 - auc: 0.8274 - f1_score: 0.5272 - scaled_graph_loss: 7.1967e-04 - val_loss: 0.9882 - val_accuracy: 0.5403 - val_auc: 0.8239 - val_f1_score: 0.5757\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.54027, saving model to /content/drive/MyDrive/AD Expriment II/DenseNet_model_checkpoints/densenet_nsl_weights\n","Epoch 2/50\n","80/80 [==============================] - 43s 527ms/step - loss: 0.6759 - accuracy: 0.7045 - auc: 0.9178 - f1_score: 0.6812 - scaled_graph_loss: 5.7534e-04 - val_loss: 1.0293 - val_accuracy: 0.5426 - val_auc: 0.8313 - val_f1_score: 0.5348\n","\n","Epoch 00002: val_accuracy improved from 0.54027 to 0.54261, saving model to /content/drive/MyDrive/AD Expriment II/DenseNet_model_checkpoints/densenet_nsl_weights\n","Epoch 3/50\n","80/80 [==============================] - 42s 517ms/step - loss: 0.5909 - accuracy: 0.7378 - auc: 0.9366 - f1_score: 0.7239 - scaled_graph_loss: 5.7662e-04 - val_loss: 1.0261 - val_accuracy: 0.5645 - val_auc: 0.8362 - val_f1_score: 0.5496\n","\n","Epoch 00003: val_accuracy improved from 0.54261 to 0.56450, saving model to /content/drive/MyDrive/AD Expriment II/DenseNet_model_checkpoints/densenet_nsl_weights\n","Epoch 4/50\n","80/80 [==============================] - 43s 523ms/step - loss: 0.5660 - accuracy: 0.7469 - auc: 0.9416 - f1_score: 0.7316 - scaled_graph_loss: 5.6979e-04 - val_loss: 1.1417 - val_accuracy: 0.4824 - val_auc: 0.7768 - val_f1_score: 0.4561\n","\n","Epoch 00004: val_accuracy did not improve from 0.56450\n","Epoch 5/50\n","80/80 [==============================] - 42s 522ms/step - loss: 0.5487 - accuracy: 0.7571 - auc: 0.9447 - f1_score: 0.7472 - scaled_graph_loss: 5.8539e-04 - val_loss: 1.2228 - val_accuracy: 0.5481 - val_auc: 0.8281 - val_f1_score: 0.5402\n","\n","Epoch 00005: val_accuracy did not improve from 0.56450\n","Epoch 6/50\n","80/80 [==============================] - 42s 518ms/step - loss: 0.5352 - accuracy: 0.7638 - auc: 0.9472 - f1_score: 0.7550 - scaled_graph_loss: 6.0343e-04 - val_loss: 0.9828 - val_accuracy: 0.5801 - val_auc: 0.8468 - val_f1_score: 0.5605\n","\n","Epoch 00006: val_accuracy improved from 0.56450 to 0.58014, saving model to /content/drive/MyDrive/AD Expriment II/DenseNet_model_checkpoints/densenet_nsl_weights\n","Epoch 7/50\n","80/80 [==============================] - 42s 521ms/step - loss: 0.5057 - accuracy: 0.7730 - auc: 0.9532 - f1_score: 0.7692 - scaled_graph_loss: 6.1452e-04 - val_loss: 0.9944 - val_accuracy: 0.5442 - val_auc: 0.8341 - val_f1_score: 0.5289\n","\n","Epoch 00007: val_accuracy did not improve from 0.58014\n","Epoch 8/50\n","80/80 [==============================] - 43s 523ms/step - loss: 0.5110 - accuracy: 0.7775 - auc: 0.9518 - f1_score: 0.7698 - scaled_graph_loss: 6.1293e-04 - val_loss: 1.0226 - val_accuracy: 0.5285 - val_auc: 0.8308 - val_f1_score: 0.5215\n","\n","Epoch 00008: val_accuracy did not improve from 0.58014\n","Epoch 9/50\n","80/80 [==============================] - 42s 520ms/step - loss: 0.4840 - accuracy: 0.7892 - auc: 0.9568 - f1_score: 0.7817 - scaled_graph_loss: 6.2694e-04 - val_loss: 1.0709 - val_accuracy: 0.5747 - val_auc: 0.8438 - val_f1_score: 0.5699\n","\n","Epoch 00009: val_accuracy did not improve from 0.58014\n","Epoch 10/50\n","80/80 [==============================] - 43s 530ms/step - loss: 0.4899 - accuracy: 0.7844 - auc: 0.9558 - f1_score: 0.7784 - scaled_graph_loss: 6.2956e-04 - val_loss: 1.0551 - val_accuracy: 0.5747 - val_auc: 0.8384 - val_f1_score: 0.5601\n","\n","Epoch 00010: val_accuracy did not improve from 0.58014\n","Epoch 11/50\n","80/80 [==============================] - 43s 529ms/step - loss: 0.4627 - accuracy: 0.7997 - auc: 0.9605 - f1_score: 0.7947 - scaled_graph_loss: 6.1198e-04 - val_loss: 0.9992 - val_accuracy: 0.5676 - val_auc: 0.8446 - val_f1_score: 0.5611\n","\n","Epoch 00011: val_accuracy did not improve from 0.58014\n","Epoch 12/50\n","80/80 [==============================] - 43s 523ms/step - loss: 0.4581 - accuracy: 0.7978 - auc: 0.9615 - f1_score: 0.7953 - scaled_graph_loss: 6.0220e-04 - val_loss: 1.0080 - val_accuracy: 0.5551 - val_auc: 0.8441 - val_f1_score: 0.5490\n","\n","Epoch 00012: val_accuracy did not improve from 0.58014\n","Epoch 13/50\n","80/80 [==============================] - 43s 528ms/step - loss: 0.4470 - accuracy: 0.8083 - auc: 0.9633 - f1_score: 0.8025 - scaled_graph_loss: 6.1303e-04 - val_loss: 1.1667 - val_accuracy: 0.5786 - val_auc: 0.8398 - val_f1_score: 0.5693\n","\n","Epoch 00013: val_accuracy did not improve from 0.58014\n","Epoch 14/50\n","80/80 [==============================] - 43s 529ms/step - loss: 0.4312 - accuracy: 0.8085 - auc: 0.9658 - f1_score: 0.8095 - scaled_graph_loss: 6.0114e-04 - val_loss: 1.0820 - val_accuracy: 0.5809 - val_auc: 0.8436 - val_f1_score: 0.5713\n","\n","Epoch 00014: val_accuracy improved from 0.58014 to 0.58092, saving model to /content/drive/MyDrive/AD Expriment II/DenseNet_model_checkpoints/densenet_nsl_weights\n","Epoch 15/50\n","80/80 [==============================] - 43s 524ms/step - loss: 0.4364 - accuracy: 0.8121 - auc: 0.9649 - f1_score: 0.8097 - scaled_graph_loss: 6.3167e-04 - val_loss: 1.1055 - val_accuracy: 0.5676 - val_auc: 0.8419 - val_f1_score: 0.5573\n","\n","Epoch 00015: val_accuracy did not improve from 0.58092\n","Epoch 16/50\n","80/80 [==============================] - 42s 519ms/step - loss: 0.4353 - accuracy: 0.8119 - auc: 0.9650 - f1_score: 0.8089 - scaled_graph_loss: 6.3298e-04 - val_loss: 1.1482 - val_accuracy: 0.5903 - val_auc: 0.8428 - val_f1_score: 0.5837\n","\n","Epoch 00016: val_accuracy improved from 0.58092 to 0.59030, saving model to /content/drive/MyDrive/AD Expriment II/DenseNet_model_checkpoints/densenet_nsl_weights\n","Epoch 17/50\n","80/80 [==============================] - 42s 514ms/step - loss: 0.4267 - accuracy: 0.8173 - auc: 0.9667 - f1_score: 0.8162 - scaled_graph_loss: 6.5195e-04 - val_loss: 1.1876 - val_accuracy: 0.5770 - val_auc: 0.8425 - val_f1_score: 0.5694\n","\n","Epoch 00017: val_accuracy did not improve from 0.59030\n","Epoch 18/50\n","80/80 [==============================] - 43s 527ms/step - loss: 0.4310 - accuracy: 0.8119 - auc: 0.9658 - f1_score: 0.8102 - scaled_graph_loss: 6.2209e-04 - val_loss: 1.1125 - val_accuracy: 0.5895 - val_auc: 0.8479 - val_f1_score: 0.5801\n","\n","Epoch 00018: val_accuracy did not improve from 0.59030\n","Epoch 19/50\n","80/80 [==============================] - 41s 503ms/step - loss: 0.4221 - accuracy: 0.8198 - auc: 0.9673 - f1_score: 0.8176 - scaled_graph_loss: 6.3820e-04 - val_loss: 1.0739 - val_accuracy: 0.5880 - val_auc: 0.8483 - val_f1_score: 0.5815\n","\n","Epoch 00019: val_accuracy did not improve from 0.59030\n","Epoch 20/50\n","80/80 [==============================] - 43s 525ms/step - loss: 0.4264 - accuracy: 0.8172 - auc: 0.9667 - f1_score: 0.8152 - scaled_graph_loss: 6.2387e-04 - val_loss: 1.1268 - val_accuracy: 0.5911 - val_auc: 0.8475 - val_f1_score: 0.5855\n","\n","Epoch 00020: val_accuracy improved from 0.59030 to 0.59109, saving model to /content/drive/MyDrive/AD Expriment II/DenseNet_model_checkpoints/densenet_nsl_weights\n","Epoch 21/50\n","80/80 [==============================] - 42s 519ms/step - loss: 0.4057 - accuracy: 0.8226 - auc: 0.9695 - f1_score: 0.8209 - scaled_graph_loss: 6.4510e-04 - val_loss: 1.0698 - val_accuracy: 0.5958 - val_auc: 0.8505 - val_f1_score: 0.5901\n","\n","Epoch 00021: val_accuracy improved from 0.59109 to 0.59578, saving model to /content/drive/MyDrive/AD Expriment II/DenseNet_model_checkpoints/densenet_nsl_weights\n","Epoch 22/50\n","80/80 [==============================] - 42s 522ms/step - loss: 0.3995 - accuracy: 0.8327 - auc: 0.9707 - f1_score: 0.8297 - scaled_graph_loss: 6.3470e-04 - val_loss: 1.0913 - val_accuracy: 0.5786 - val_auc: 0.8447 - val_f1_score: 0.5704\n","\n","Epoch 00022: val_accuracy did not improve from 0.59578\n","Epoch 23/50\n","80/80 [==============================] - 43s 526ms/step - loss: 0.4061 - accuracy: 0.8192 - auc: 0.9693 - f1_score: 0.8194 - scaled_graph_loss: 6.2501e-04 - val_loss: 1.0396 - val_accuracy: 0.5825 - val_auc: 0.8519 - val_f1_score: 0.5740\n","\n","Epoch 00023: val_accuracy did not improve from 0.59578\n","Epoch 24/50\n","80/80 [==============================] - 43s 526ms/step - loss: 0.3933 - accuracy: 0.8310 - auc: 0.9713 - f1_score: 0.8298 - scaled_graph_loss: 6.3982e-04 - val_loss: 1.0724 - val_accuracy: 0.6083 - val_auc: 0.8544 - val_f1_score: 0.6005\n","\n","Epoch 00024: val_accuracy improved from 0.59578 to 0.60829, saving model to /content/drive/MyDrive/AD Expriment II/DenseNet_model_checkpoints/densenet_nsl_weights\n","Epoch 25/50\n","80/80 [==============================] - 43s 523ms/step - loss: 0.4010 - accuracy: 0.8279 - auc: 0.9702 - f1_score: 0.8274 - scaled_graph_loss: 6.4393e-04 - val_loss: 1.0180 - val_accuracy: 0.6044 - val_auc: 0.8556 - val_f1_score: 0.5979\n","\n","Epoch 00025: val_accuracy did not improve from 0.60829\n","Epoch 26/50\n","80/80 [==============================] - 41s 505ms/step - loss: 0.3915 - accuracy: 0.8319 - auc: 0.9718 - f1_score: 0.8295 - scaled_graph_loss: 6.0671e-04 - val_loss: 1.0883 - val_accuracy: 0.5848 - val_auc: 0.8467 - val_f1_score: 0.5798\n","\n","Epoch 00026: val_accuracy did not improve from 0.60829\n","Epoch 27/50\n","80/80 [==============================] - 43s 527ms/step - loss: 0.3861 - accuracy: 0.8363 - auc: 0.9727 - f1_score: 0.8336 - scaled_graph_loss: 6.2600e-04 - val_loss: 0.9869 - val_accuracy: 0.5934 - val_auc: 0.8526 - val_f1_score: 0.5830\n","\n","Epoch 00027: val_accuracy did not improve from 0.60829\n","Epoch 28/50\n","80/80 [==============================] - 43s 526ms/step - loss: 0.4039 - accuracy: 0.8292 - auc: 0.9698 - f1_score: 0.8255 - scaled_graph_loss: 6.3584e-04 - val_loss: 1.1874 - val_accuracy: 0.5778 - val_auc: 0.8430 - val_f1_score: 0.5707\n","\n","Epoch 00028: val_accuracy did not improve from 0.60829\n","Epoch 29/50\n","80/80 [==============================] - 42s 521ms/step - loss: 0.3824 - accuracy: 0.8379 - auc: 0.9731 - f1_score: 0.8378 - scaled_graph_loss: 6.1321e-04 - val_loss: 1.1359 - val_accuracy: 0.5997 - val_auc: 0.8487 - val_f1_score: 0.5860\n","\n","Epoch 00029: val_accuracy did not improve from 0.60829\n","Epoch 30/50\n","80/80 [==============================] - 43s 524ms/step - loss: 0.3840 - accuracy: 0.8353 - auc: 0.9727 - f1_score: 0.8345 - scaled_graph_loss: 6.3345e-04 - val_loss: 1.1485 - val_accuracy: 0.5739 - val_auc: 0.8443 - val_f1_score: 0.5681\n","\n","Epoch 00030: val_accuracy did not improve from 0.60829\n","Epoch 31/50\n","80/80 [==============================] - 43s 525ms/step - loss: 0.3806 - accuracy: 0.8401 - auc: 0.9731 - f1_score: 0.8358 - scaled_graph_loss: 6.3459e-04 - val_loss: 1.1451 - val_accuracy: 0.5942 - val_auc: 0.8467 - val_f1_score: 0.5855\n","\n","Epoch 00031: val_accuracy did not improve from 0.60829\n","Epoch 32/50\n","80/80 [==============================] - 43s 525ms/step - loss: 0.3945 - accuracy: 0.8289 - auc: 0.9708 - f1_score: 0.8263 - scaled_graph_loss: 6.3569e-04 - val_loss: 1.2410 - val_accuracy: 0.5880 - val_auc: 0.8430 - val_f1_score: 0.5803\n","\n","Epoch 00032: val_accuracy did not improve from 0.60829\n","Epoch 33/50\n","80/80 [==============================] - 43s 528ms/step - loss: 0.3744 - accuracy: 0.8412 - auc: 0.9740 - f1_score: 0.8390 - scaled_graph_loss: 6.3768e-04 - val_loss: 1.1965 - val_accuracy: 0.5903 - val_auc: 0.8457 - val_f1_score: 0.5872\n","\n","Epoch 00033: val_accuracy did not improve from 0.60829\n","Epoch 34/50\n","80/80 [==============================] - 42s 522ms/step - loss: 0.3708 - accuracy: 0.8465 - auc: 0.9745 - f1_score: 0.8439 - scaled_graph_loss: 6.2675e-04 - val_loss: 1.2382 - val_accuracy: 0.5825 - val_auc: 0.8398 - val_f1_score: 0.5799\n","\n","Epoch 00034: val_accuracy did not improve from 0.60829\n","Epoch 35/50\n","80/80 [==============================] - 43s 527ms/step - loss: 0.3807 - accuracy: 0.8360 - auc: 0.9731 - f1_score: 0.8350 - scaled_graph_loss: 6.5571e-04 - val_loss: 1.1910 - val_accuracy: 0.5880 - val_auc: 0.8421 - val_f1_score: 0.5714\n","\n","Epoch 00035: val_accuracy did not improve from 0.60829\n","Epoch 36/50\n","80/80 [==============================] - 43s 526ms/step - loss: 0.3734 - accuracy: 0.8412 - auc: 0.9742 - f1_score: 0.8362 - scaled_graph_loss: 6.1182e-04 - val_loss: 1.1423 - val_accuracy: 0.5997 - val_auc: 0.8528 - val_f1_score: 0.5998\n","\n","Epoch 00036: val_accuracy did not improve from 0.60829\n","Epoch 37/50\n","80/80 [==============================] - 43s 524ms/step - loss: 0.3644 - accuracy: 0.8470 - auc: 0.9755 - f1_score: 0.8445 - scaled_graph_loss: 6.2522e-04 - val_loss: 1.2276 - val_accuracy: 0.5895 - val_auc: 0.8426 - val_f1_score: 0.5818\n","\n","Epoch 00037: val_accuracy did not improve from 0.60829\n","Epoch 38/50\n","80/80 [==============================] - 42s 522ms/step - loss: 0.3574 - accuracy: 0.8489 - auc: 0.9764 - f1_score: 0.8472 - scaled_graph_loss: 6.2071e-04 - val_loss: 1.1661 - val_accuracy: 0.6044 - val_auc: 0.8489 - val_f1_score: 0.5969\n","\n","Epoch 00038: val_accuracy did not improve from 0.60829\n","Epoch 39/50\n","80/80 [==============================] - 42s 521ms/step - loss: 0.3676 - accuracy: 0.8375 - auc: 0.9747 - f1_score: 0.8370 - scaled_graph_loss: 6.4497e-04 - val_loss: 1.0826 - val_accuracy: 0.5934 - val_auc: 0.8535 - val_f1_score: 0.5855\n","\n","Epoch 00039: val_accuracy did not improve from 0.60829\n","Epoch 40/50\n","80/80 [==============================] - 42s 523ms/step - loss: 0.3606 - accuracy: 0.8510 - auc: 0.9759 - f1_score: 0.8505 - scaled_graph_loss: 6.2783e-04 - val_loss: 1.2041 - val_accuracy: 0.5919 - val_auc: 0.8497 - val_f1_score: 0.5884\n","\n","Epoch 00040: val_accuracy did not improve from 0.60829\n","Epoch 41/50\n","80/80 [==============================] - 43s 534ms/step - loss: 0.3547 - accuracy: 0.8481 - auc: 0.9765 - f1_score: 0.8464 - scaled_graph_loss: 6.2021e-04 - val_loss: 1.1623 - val_accuracy: 0.5895 - val_auc: 0.8472 - val_f1_score: 0.5833\n","\n","Epoch 00041: val_accuracy did not improve from 0.60829\n","Epoch 42/50\n","80/80 [==============================] - 43s 525ms/step - loss: 0.3525 - accuracy: 0.8477 - auc: 0.9768 - f1_score: 0.8445 - scaled_graph_loss: 6.3143e-04 - val_loss: 1.1064 - val_accuracy: 0.6067 - val_auc: 0.8511 - val_f1_score: 0.5998\n","\n","Epoch 00042: val_accuracy did not improve from 0.60829\n","Epoch 43/50\n","80/80 [==============================] - 43s 525ms/step - loss: 0.3546 - accuracy: 0.8516 - auc: 0.9766 - f1_score: 0.8495 - scaled_graph_loss: 6.3154e-04 - val_loss: 1.1878 - val_accuracy: 0.5934 - val_auc: 0.8482 - val_f1_score: 0.5892\n","\n","Epoch 00043: val_accuracy did not improve from 0.60829\n","Epoch 44/50\n","80/80 [==============================] - 43s 529ms/step - loss: 0.3634 - accuracy: 0.8456 - auc: 0.9755 - f1_score: 0.8435 - scaled_graph_loss: 6.2116e-04 - val_loss: 1.2152 - val_accuracy: 0.5661 - val_auc: 0.8414 - val_f1_score: 0.5621\n","\n","Epoch 00044: val_accuracy did not improve from 0.60829\n","Epoch 45/50\n","80/80 [==============================] - 43s 533ms/step - loss: 0.3747 - accuracy: 0.8442 - auc: 0.9741 - f1_score: 0.8438 - scaled_graph_loss: 6.4915e-04 - val_loss: 1.1309 - val_accuracy: 0.6036 - val_auc: 0.8527 - val_f1_score: 0.5986\n","\n","Epoch 00045: val_accuracy did not improve from 0.60829\n","Epoch 46/50\n","80/80 [==============================] - 43s 530ms/step - loss: 0.3583 - accuracy: 0.8494 - auc: 0.9762 - f1_score: 0.8473 - scaled_graph_loss: 6.2199e-04 - val_loss: 1.0458 - val_accuracy: 0.6005 - val_auc: 0.8536 - val_f1_score: 0.5966\n","\n","Epoch 00046: val_accuracy did not improve from 0.60829\n","Epoch 47/50\n","80/80 [==============================] - 43s 533ms/step - loss: 0.3538 - accuracy: 0.8481 - auc: 0.9767 - f1_score: 0.8472 - scaled_graph_loss: 6.2467e-04 - val_loss: 1.0697 - val_accuracy: 0.6059 - val_auc: 0.8558 - val_f1_score: 0.5996\n","\n","Epoch 00047: val_accuracy did not improve from 0.60829\n","Epoch 48/50\n","80/80 [==============================] - 43s 525ms/step - loss: 0.3379 - accuracy: 0.8603 - auc: 0.9789 - f1_score: 0.8588 - scaled_graph_loss: 6.0366e-04 - val_loss: 1.2255 - val_accuracy: 0.5895 - val_auc: 0.8453 - val_f1_score: 0.5846\n","\n","Epoch 00048: val_accuracy did not improve from 0.60829\n","Epoch 49/50\n","80/80 [==============================] - 43s 527ms/step - loss: 0.3488 - accuracy: 0.8515 - auc: 0.9772 - f1_score: 0.8498 - scaled_graph_loss: 6.3529e-04 - val_loss: 1.1292 - val_accuracy: 0.5856 - val_auc: 0.8493 - val_f1_score: 0.5847\n","\n","Epoch 00049: val_accuracy did not improve from 0.60829\n","Epoch 50/50\n","80/80 [==============================] - 43s 525ms/step - loss: 0.3520 - accuracy: 0.8504 - auc: 0.9770 - f1_score: 0.8486 - scaled_graph_loss: 6.3182e-04 - val_loss: 1.1792 - val_accuracy: 0.5801 - val_auc: 0.8444 - val_f1_score: 0.5795\n","\n","Epoch 00050: val_accuracy did not improve from 0.60829\n","Early stopping is not triggered, but best model is restored at epoch 24\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KEo0rokAZPzs","executionInfo":{"status":"ok","timestamp":1618575724803,"user_tz":240,"elapsed":2170862,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"2d9c7c9c-8ce1-4b3c-8661-9df432500f95"},"source":["graph_reg_model.evaluate(test_image_dataset)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1/1 [==============================] - 1s 1s/step - loss: 1.0724 - accuracy: 0.6083 - auc: 0.8544 - f1_score: 0.6005\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[1.0724372863769531,\n"," 0.6082877516746521,\n"," 0.8544427752494812,\n"," 0.6004882454872131]"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"code","metadata":{"id":"SeIDeU8uf5cG"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0XAmOO5ZgGcj"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dg3vzxBShRRh"},"source":["## 3.3 DenseNet_NSL top 20 layers and bottom 20 laysers tuning\n","### val_acc: 0.73, val_auc: 0.89, val_f1_score: 0.73"]},{"cell_type":"code","metadata":{"id":"K5IOkuPWirui"},"source":["'''redefine hyper params'''\n","params = AD_params()\n","params.max_seed_nbr=5\n","params.batch_size=64\n","params.image_channels =3\n","params.image_size =(100,100)\n","params.ad_base_model_input_shape=(100,100,3)\n","params.train_tfr_path = train_tfr_path\n","\n","'''parse train_data.tfr to train image dataset with batch_size at 64'''\n","train_image_dataset = NSLDataFormat.parse_tfr_to_dataset(file_path_list=[params.train_tfr_path],\n","                                                         batch_size=params.batch_size,\n","                                                         max_neighbor_number=params.max_seed_nbr,\n","                                                         image_size=params.image_size,\n","                                                         image_channels=params.image_channels,\n","                                                         shuffle=True)\n","\n","'''load test data with batch_size at 64 '''\n","test_image_dataset = NSLDataFormat.generate_test_tfr_image_tensor(path_list=test_tfr_list, \n","                                                                  batch_size=params.batch_size, \n","                                                                  size=params.image_size,\n","                                                                  channels=params.image_channels,\n","                                                                  shuffle=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0EWDr4Po5vgq","executionInfo":{"status":"ok","timestamp":1618838669106,"user_tz":240,"elapsed":22548,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"552b8ae8-0008-4023-d1c1-5b04c661c2ed"},"source":["params.learning_rate=0.0001\n","params.restore_path= '/content/drive/MyDrive/AD Expriment II/DenseNet_model_checkpoints/densenet_nsl_weights'\n","params.checkpoint_path = '/content/drive/MyDrive/AD Expriment II/DenseNet_model_checkpoints/densenet_nsl_weights'\n","params.early_stop_base_line=0.80\n","params.train_epoch=50\n","params.nsl_multiplier = 0.0005\n","params.nsl_sum_over_axis = -1\n","params.nsl_distance_type = nsl.configs.DistanceType.COSINE\n","\n","'''build a base model with selected trainable layer'''\n","admodel = ADModelBuilder(input_shape=params.ad_base_model_input_shape, base_model='densenet121').setup_DenseNet121(top_layers=20, middle_layers=None, bottom_layers=30).get_ADModel()\n","\n","'''build NSL model on top of base model'''\n","graph_reg_config = nsl.configs.make_graph_reg_config(neighbor_prefix=params.neighbor_prefix,\n","                                                     neighbor_weight_suffix=params.neighbor_weight_suffix,\n","                                                     max_neighbors= params.max_seed_nbr,\n","                                                     multiplier= params.nsl_multiplier,\n","                                                     distance_type= params.nsl_distance_type,\n","                                                     sum_over_axis= params.nsl_sum_over_axis)\n","graph_reg_model = nsl.keras.GraphRegularization(admodel,graph_reg_config)\n","graph_reg_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=params.learning_rate, amsgrad=True), \n","                        loss=tf.losses.CategoricalCrossentropy(), \n","                        metrics=[\"accuracy\",\"AUC\", tfa.metrics.F1Score(num_classes=4, average=\"micro\", threshold = 0.5)])\n","\n","'''restore the model from last training'''\n","graph_reg_model.load_weights(params.restore_path)\n","\n","''' NSL model training '''\n","callback_checkpoints = tf.keras.callbacks.ModelCheckpoint(filepath=params.checkpoint_path, monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=True, mode='max',\n","                                                          save_freq='epoch',options=None)\n","callback_earlystop = AccEarlyStop(val_acc_base=params.early_stop_base_line)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Note: default DenseNet121 not includes top and has imagenet weights. It is not a trainable model in ADModelBuilder. Please setup trainable layers in setup_DenseNet121 function based on the \"Layer Number\"\n","Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n","29089792/29084464 [==============================] - 1s 0us/step\n","Model: \"densenet121\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 100, 100, 3) 0                                            \n","__________________________________________________________________________________________________\n","zero_padding2d (ZeroPadding2D)  (None, 106, 106, 3)  0           input_1[0][0]                    \n","__________________________________________________________________________________________________\n","conv1/conv (Conv2D)             (None, 50, 50, 64)   9408        zero_padding2d[0][0]             \n","__________________________________________________________________________________________________\n","conv1/bn (BatchNormalization)   (None, 50, 50, 64)   256         conv1/conv[0][0]                 \n","__________________________________________________________________________________________________\n","conv1/relu (Activation)         (None, 50, 50, 64)   0           conv1/bn[0][0]                   \n","__________________________________________________________________________________________________\n","zero_padding2d_1 (ZeroPadding2D (None, 52, 52, 64)   0           conv1/relu[0][0]                 \n","__________________________________________________________________________________________________\n","pool1 (MaxPooling2D)            (None, 25, 25, 64)   0           zero_padding2d_1[0][0]           \n","__________________________________________________________________________________________________\n","conv2_block1_0_bn (BatchNormali (None, 25, 25, 64)   256         pool1[0][0]                      \n","__________________________________________________________________________________________________\n","conv2_block1_0_relu (Activation (None, 25, 25, 64)   0           conv2_block1_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block1_1_conv (Conv2D)    (None, 25, 25, 128)  8192        conv2_block1_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_1_bn (BatchNormali (None, 25, 25, 128)  512         conv2_block1_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_1_relu (Activation (None, 25, 25, 128)  0           conv2_block1_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block1_2_conv (Conv2D)    (None, 25, 25, 32)   36864       conv2_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_concat (Concatenat (None, 25, 25, 96)   0           pool1[0][0]                      \n","                                                                 conv2_block1_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_0_bn (BatchNormali (None, 25, 25, 96)   384         conv2_block1_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_0_relu (Activation (None, 25, 25, 96)   0           conv2_block2_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block2_1_conv (Conv2D)    (None, 25, 25, 128)  12288       conv2_block2_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_1_bn (BatchNormali (None, 25, 25, 128)  512         conv2_block2_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_1_relu (Activation (None, 25, 25, 128)  0           conv2_block2_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block2_2_conv (Conv2D)    (None, 25, 25, 32)   36864       conv2_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_concat (Concatenat (None, 25, 25, 128)  0           conv2_block1_concat[0][0]        \n","                                                                 conv2_block2_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_0_bn (BatchNormali (None, 25, 25, 128)  512         conv2_block2_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_0_relu (Activation (None, 25, 25, 128)  0           conv2_block3_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block3_1_conv (Conv2D)    (None, 25, 25, 128)  16384       conv2_block3_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_1_bn (BatchNormali (None, 25, 25, 128)  512         conv2_block3_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_1_relu (Activation (None, 25, 25, 128)  0           conv2_block3_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block3_2_conv (Conv2D)    (None, 25, 25, 32)   36864       conv2_block3_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_concat (Concatenat (None, 25, 25, 160)  0           conv2_block2_concat[0][0]        \n","                                                                 conv2_block3_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block4_0_bn (BatchNormali (None, 25, 25, 160)  640         conv2_block3_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block4_0_relu (Activation (None, 25, 25, 160)  0           conv2_block4_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block4_1_conv (Conv2D)    (None, 25, 25, 128)  20480       conv2_block4_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block4_1_bn (BatchNormali (None, 25, 25, 128)  512         conv2_block4_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block4_1_relu (Activation (None, 25, 25, 128)  0           conv2_block4_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block4_2_conv (Conv2D)    (None, 25, 25, 32)   36864       conv2_block4_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block4_concat (Concatenat (None, 25, 25, 192)  0           conv2_block3_concat[0][0]        \n","                                                                 conv2_block4_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block5_0_bn (BatchNormali (None, 25, 25, 192)  768         conv2_block4_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block5_0_relu (Activation (None, 25, 25, 192)  0           conv2_block5_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block5_1_conv (Conv2D)    (None, 25, 25, 128)  24576       conv2_block5_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block5_1_bn (BatchNormali (None, 25, 25, 128)  512         conv2_block5_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block5_1_relu (Activation (None, 25, 25, 128)  0           conv2_block5_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block5_2_conv (Conv2D)    (None, 25, 25, 32)   36864       conv2_block5_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block5_concat (Concatenat (None, 25, 25, 224)  0           conv2_block4_concat[0][0]        \n","                                                                 conv2_block5_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block6_0_bn (BatchNormali (None, 25, 25, 224)  896         conv2_block5_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block6_0_relu (Activation (None, 25, 25, 224)  0           conv2_block6_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block6_1_conv (Conv2D)    (None, 25, 25, 128)  28672       conv2_block6_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block6_1_bn (BatchNormali (None, 25, 25, 128)  512         conv2_block6_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block6_1_relu (Activation (None, 25, 25, 128)  0           conv2_block6_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block6_2_conv (Conv2D)    (None, 25, 25, 32)   36864       conv2_block6_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block6_concat (Concatenat (None, 25, 25, 256)  0           conv2_block5_concat[0][0]        \n","                                                                 conv2_block6_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","pool2_bn (BatchNormalization)   (None, 25, 25, 256)  1024        conv2_block6_concat[0][0]        \n","__________________________________________________________________________________________________\n","pool2_relu (Activation)         (None, 25, 25, 256)  0           pool2_bn[0][0]                   \n","__________________________________________________________________________________________________\n","pool2_conv (Conv2D)             (None, 25, 25, 128)  32768       pool2_relu[0][0]                 \n","__________________________________________________________________________________________________\n","pool2_pool (AveragePooling2D)   (None, 12, 12, 128)  0           pool2_conv[0][0]                 \n","__________________________________________________________________________________________________\n","conv3_block1_0_bn (BatchNormali (None, 12, 12, 128)  512         pool2_pool[0][0]                 \n","__________________________________________________________________________________________________\n","conv3_block1_0_relu (Activation (None, 12, 12, 128)  0           conv3_block1_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block1_1_conv (Conv2D)    (None, 12, 12, 128)  16384       conv3_block1_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_1_bn (BatchNormali (None, 12, 12, 128)  512         conv3_block1_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_1_relu (Activation (None, 12, 12, 128)  0           conv3_block1_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block1_2_conv (Conv2D)    (None, 12, 12, 32)   36864       conv3_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_concat (Concatenat (None, 12, 12, 160)  0           pool2_pool[0][0]                 \n","                                                                 conv3_block1_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_0_bn (BatchNormali (None, 12, 12, 160)  640         conv3_block1_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_0_relu (Activation (None, 12, 12, 160)  0           conv3_block2_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block2_1_conv (Conv2D)    (None, 12, 12, 128)  20480       conv3_block2_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_1_bn (BatchNormali (None, 12, 12, 128)  512         conv3_block2_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_1_relu (Activation (None, 12, 12, 128)  0           conv3_block2_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block2_2_conv (Conv2D)    (None, 12, 12, 32)   36864       conv3_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_concat (Concatenat (None, 12, 12, 192)  0           conv3_block1_concat[0][0]        \n","                                                                 conv3_block2_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_0_bn (BatchNormali (None, 12, 12, 192)  768         conv3_block2_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_0_relu (Activation (None, 12, 12, 192)  0           conv3_block3_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block3_1_conv (Conv2D)    (None, 12, 12, 128)  24576       conv3_block3_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_1_bn (BatchNormali (None, 12, 12, 128)  512         conv3_block3_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_1_relu (Activation (None, 12, 12, 128)  0           conv3_block3_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block3_2_conv (Conv2D)    (None, 12, 12, 32)   36864       conv3_block3_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_concat (Concatenat (None, 12, 12, 224)  0           conv3_block2_concat[0][0]        \n","                                                                 conv3_block3_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_0_bn (BatchNormali (None, 12, 12, 224)  896         conv3_block3_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_0_relu (Activation (None, 12, 12, 224)  0           conv3_block4_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block4_1_conv (Conv2D)    (None, 12, 12, 128)  28672       conv3_block4_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_1_bn (BatchNormali (None, 12, 12, 128)  512         conv3_block4_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_1_relu (Activation (None, 12, 12, 128)  0           conv3_block4_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block4_2_conv (Conv2D)    (None, 12, 12, 32)   36864       conv3_block4_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_concat (Concatenat (None, 12, 12, 256)  0           conv3_block3_concat[0][0]        \n","                                                                 conv3_block4_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block5_0_bn (BatchNormali (None, 12, 12, 256)  1024        conv3_block4_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block5_0_relu (Activation (None, 12, 12, 256)  0           conv3_block5_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block5_1_conv (Conv2D)    (None, 12, 12, 128)  32768       conv3_block5_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block5_1_bn (BatchNormali (None, 12, 12, 128)  512         conv3_block5_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block5_1_relu (Activation (None, 12, 12, 128)  0           conv3_block5_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block5_2_conv (Conv2D)    (None, 12, 12, 32)   36864       conv3_block5_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block5_concat (Concatenat (None, 12, 12, 288)  0           conv3_block4_concat[0][0]        \n","                                                                 conv3_block5_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block6_0_bn (BatchNormali (None, 12, 12, 288)  1152        conv3_block5_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block6_0_relu (Activation (None, 12, 12, 288)  0           conv3_block6_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block6_1_conv (Conv2D)    (None, 12, 12, 128)  36864       conv3_block6_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block6_1_bn (BatchNormali (None, 12, 12, 128)  512         conv3_block6_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block6_1_relu (Activation (None, 12, 12, 128)  0           conv3_block6_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block6_2_conv (Conv2D)    (None, 12, 12, 32)   36864       conv3_block6_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block6_concat (Concatenat (None, 12, 12, 320)  0           conv3_block5_concat[0][0]        \n","                                                                 conv3_block6_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block7_0_bn (BatchNormali (None, 12, 12, 320)  1280        conv3_block6_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block7_0_relu (Activation (None, 12, 12, 320)  0           conv3_block7_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block7_1_conv (Conv2D)    (None, 12, 12, 128)  40960       conv3_block7_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block7_1_bn (BatchNormali (None, 12, 12, 128)  512         conv3_block7_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block7_1_relu (Activation (None, 12, 12, 128)  0           conv3_block7_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block7_2_conv (Conv2D)    (None, 12, 12, 32)   36864       conv3_block7_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block7_concat (Concatenat (None, 12, 12, 352)  0           conv3_block6_concat[0][0]        \n","                                                                 conv3_block7_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block8_0_bn (BatchNormali (None, 12, 12, 352)  1408        conv3_block7_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block8_0_relu (Activation (None, 12, 12, 352)  0           conv3_block8_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block8_1_conv (Conv2D)    (None, 12, 12, 128)  45056       conv3_block8_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block8_1_bn (BatchNormali (None, 12, 12, 128)  512         conv3_block8_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block8_1_relu (Activation (None, 12, 12, 128)  0           conv3_block8_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block8_2_conv (Conv2D)    (None, 12, 12, 32)   36864       conv3_block8_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block8_concat (Concatenat (None, 12, 12, 384)  0           conv3_block7_concat[0][0]        \n","                                                                 conv3_block8_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block9_0_bn (BatchNormali (None, 12, 12, 384)  1536        conv3_block8_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block9_0_relu (Activation (None, 12, 12, 384)  0           conv3_block9_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block9_1_conv (Conv2D)    (None, 12, 12, 128)  49152       conv3_block9_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block9_1_bn (BatchNormali (None, 12, 12, 128)  512         conv3_block9_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block9_1_relu (Activation (None, 12, 12, 128)  0           conv3_block9_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block9_2_conv (Conv2D)    (None, 12, 12, 32)   36864       conv3_block9_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block9_concat (Concatenat (None, 12, 12, 416)  0           conv3_block8_concat[0][0]        \n","                                                                 conv3_block9_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block10_0_bn (BatchNormal (None, 12, 12, 416)  1664        conv3_block9_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block10_0_relu (Activatio (None, 12, 12, 416)  0           conv3_block10_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv3_block10_1_conv (Conv2D)   (None, 12, 12, 128)  53248       conv3_block10_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv3_block10_1_bn (BatchNormal (None, 12, 12, 128)  512         conv3_block10_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv3_block10_1_relu (Activatio (None, 12, 12, 128)  0           conv3_block10_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv3_block10_2_conv (Conv2D)   (None, 12, 12, 32)   36864       conv3_block10_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv3_block10_concat (Concatena (None, 12, 12, 448)  0           conv3_block9_concat[0][0]        \n","                                                                 conv3_block10_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv3_block11_0_bn (BatchNormal (None, 12, 12, 448)  1792        conv3_block10_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv3_block11_0_relu (Activatio (None, 12, 12, 448)  0           conv3_block11_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv3_block11_1_conv (Conv2D)   (None, 12, 12, 128)  57344       conv3_block11_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv3_block11_1_bn (BatchNormal (None, 12, 12, 128)  512         conv3_block11_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv3_block11_1_relu (Activatio (None, 12, 12, 128)  0           conv3_block11_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv3_block11_2_conv (Conv2D)   (None, 12, 12, 32)   36864       conv3_block11_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv3_block11_concat (Concatena (None, 12, 12, 480)  0           conv3_block10_concat[0][0]       \n","                                                                 conv3_block11_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv3_block12_0_bn (BatchNormal (None, 12, 12, 480)  1920        conv3_block11_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv3_block12_0_relu (Activatio (None, 12, 12, 480)  0           conv3_block12_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv3_block12_1_conv (Conv2D)   (None, 12, 12, 128)  61440       conv3_block12_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv3_block12_1_bn (BatchNormal (None, 12, 12, 128)  512         conv3_block12_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv3_block12_1_relu (Activatio (None, 12, 12, 128)  0           conv3_block12_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv3_block12_2_conv (Conv2D)   (None, 12, 12, 32)   36864       conv3_block12_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv3_block12_concat (Concatena (None, 12, 12, 512)  0           conv3_block11_concat[0][0]       \n","                                                                 conv3_block12_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","pool3_bn (BatchNormalization)   (None, 12, 12, 512)  2048        conv3_block12_concat[0][0]       \n","__________________________________________________________________________________________________\n","pool3_relu (Activation)         (None, 12, 12, 512)  0           pool3_bn[0][0]                   \n","__________________________________________________________________________________________________\n","pool3_conv (Conv2D)             (None, 12, 12, 256)  131072      pool3_relu[0][0]                 \n","__________________________________________________________________________________________________\n","pool3_pool (AveragePooling2D)   (None, 6, 6, 256)    0           pool3_conv[0][0]                 \n","__________________________________________________________________________________________________\n","conv4_block1_0_bn (BatchNormali (None, 6, 6, 256)    1024        pool3_pool[0][0]                 \n","__________________________________________________________________________________________________\n","conv4_block1_0_relu (Activation (None, 6, 6, 256)    0           conv4_block1_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block1_1_conv (Conv2D)    (None, 6, 6, 128)    32768       conv4_block1_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_1_bn (BatchNormali (None, 6, 6, 128)    512         conv4_block1_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_1_relu (Activation (None, 6, 6, 128)    0           conv4_block1_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block1_2_conv (Conv2D)    (None, 6, 6, 32)     36864       conv4_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_concat (Concatenat (None, 6, 6, 288)    0           pool3_pool[0][0]                 \n","                                                                 conv4_block1_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_0_bn (BatchNormali (None, 6, 6, 288)    1152        conv4_block1_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_0_relu (Activation (None, 6, 6, 288)    0           conv4_block2_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block2_1_conv (Conv2D)    (None, 6, 6, 128)    36864       conv4_block2_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_1_bn (BatchNormali (None, 6, 6, 128)    512         conv4_block2_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_1_relu (Activation (None, 6, 6, 128)    0           conv4_block2_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block2_2_conv (Conv2D)    (None, 6, 6, 32)     36864       conv4_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_concat (Concatenat (None, 6, 6, 320)    0           conv4_block1_concat[0][0]        \n","                                                                 conv4_block2_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_0_bn (BatchNormali (None, 6, 6, 320)    1280        conv4_block2_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_0_relu (Activation (None, 6, 6, 320)    0           conv4_block3_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block3_1_conv (Conv2D)    (None, 6, 6, 128)    40960       conv4_block3_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_1_bn (BatchNormali (None, 6, 6, 128)    512         conv4_block3_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_1_relu (Activation (None, 6, 6, 128)    0           conv4_block3_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block3_2_conv (Conv2D)    (None, 6, 6, 32)     36864       conv4_block3_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_concat (Concatenat (None, 6, 6, 352)    0           conv4_block2_concat[0][0]        \n","                                                                 conv4_block3_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_0_bn (BatchNormali (None, 6, 6, 352)    1408        conv4_block3_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_0_relu (Activation (None, 6, 6, 352)    0           conv4_block4_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block4_1_conv (Conv2D)    (None, 6, 6, 128)    45056       conv4_block4_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_1_bn (BatchNormali (None, 6, 6, 128)    512         conv4_block4_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_1_relu (Activation (None, 6, 6, 128)    0           conv4_block4_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block4_2_conv (Conv2D)    (None, 6, 6, 32)     36864       conv4_block4_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_concat (Concatenat (None, 6, 6, 384)    0           conv4_block3_concat[0][0]        \n","                                                                 conv4_block4_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_0_bn (BatchNormali (None, 6, 6, 384)    1536        conv4_block4_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_0_relu (Activation (None, 6, 6, 384)    0           conv4_block5_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block5_1_conv (Conv2D)    (None, 6, 6, 128)    49152       conv4_block5_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_1_bn (BatchNormali (None, 6, 6, 128)    512         conv4_block5_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_1_relu (Activation (None, 6, 6, 128)    0           conv4_block5_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block5_2_conv (Conv2D)    (None, 6, 6, 32)     36864       conv4_block5_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_concat (Concatenat (None, 6, 6, 416)    0           conv4_block4_concat[0][0]        \n","                                                                 conv4_block5_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_0_bn (BatchNormali (None, 6, 6, 416)    1664        conv4_block5_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_0_relu (Activation (None, 6, 6, 416)    0           conv4_block6_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block6_1_conv (Conv2D)    (None, 6, 6, 128)    53248       conv4_block6_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_1_bn (BatchNormali (None, 6, 6, 128)    512         conv4_block6_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_1_relu (Activation (None, 6, 6, 128)    0           conv4_block6_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block6_2_conv (Conv2D)    (None, 6, 6, 32)     36864       conv4_block6_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_concat (Concatenat (None, 6, 6, 448)    0           conv4_block5_concat[0][0]        \n","                                                                 conv4_block6_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block7_0_bn (BatchNormali (None, 6, 6, 448)    1792        conv4_block6_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block7_0_relu (Activation (None, 6, 6, 448)    0           conv4_block7_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block7_1_conv (Conv2D)    (None, 6, 6, 128)    57344       conv4_block7_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block7_1_bn (BatchNormali (None, 6, 6, 128)    512         conv4_block7_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block7_1_relu (Activation (None, 6, 6, 128)    0           conv4_block7_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block7_2_conv (Conv2D)    (None, 6, 6, 32)     36864       conv4_block7_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block7_concat (Concatenat (None, 6, 6, 480)    0           conv4_block6_concat[0][0]        \n","                                                                 conv4_block7_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block8_0_bn (BatchNormali (None, 6, 6, 480)    1920        conv4_block7_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block8_0_relu (Activation (None, 6, 6, 480)    0           conv4_block8_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block8_1_conv (Conv2D)    (None, 6, 6, 128)    61440       conv4_block8_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block8_1_bn (BatchNormali (None, 6, 6, 128)    512         conv4_block8_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block8_1_relu (Activation (None, 6, 6, 128)    0           conv4_block8_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block8_2_conv (Conv2D)    (None, 6, 6, 32)     36864       conv4_block8_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block8_concat (Concatenat (None, 6, 6, 512)    0           conv4_block7_concat[0][0]        \n","                                                                 conv4_block8_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block9_0_bn (BatchNormali (None, 6, 6, 512)    2048        conv4_block8_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block9_0_relu (Activation (None, 6, 6, 512)    0           conv4_block9_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block9_1_conv (Conv2D)    (None, 6, 6, 128)    65536       conv4_block9_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block9_1_bn (BatchNormali (None, 6, 6, 128)    512         conv4_block9_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block9_1_relu (Activation (None, 6, 6, 128)    0           conv4_block9_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block9_2_conv (Conv2D)    (None, 6, 6, 32)     36864       conv4_block9_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block9_concat (Concatenat (None, 6, 6, 544)    0           conv4_block8_concat[0][0]        \n","                                                                 conv4_block9_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block10_0_bn (BatchNormal (None, 6, 6, 544)    2176        conv4_block9_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block10_0_relu (Activatio (None, 6, 6, 544)    0           conv4_block10_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block10_1_conv (Conv2D)   (None, 6, 6, 128)    69632       conv4_block10_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block10_1_bn (BatchNormal (None, 6, 6, 128)    512         conv4_block10_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block10_1_relu (Activatio (None, 6, 6, 128)    0           conv4_block10_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block10_2_conv (Conv2D)   (None, 6, 6, 32)     36864       conv4_block10_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block10_concat (Concatena (None, 6, 6, 576)    0           conv4_block9_concat[0][0]        \n","                                                                 conv4_block10_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block11_0_bn (BatchNormal (None, 6, 6, 576)    2304        conv4_block10_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block11_0_relu (Activatio (None, 6, 6, 576)    0           conv4_block11_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block11_1_conv (Conv2D)   (None, 6, 6, 128)    73728       conv4_block11_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block11_1_bn (BatchNormal (None, 6, 6, 128)    512         conv4_block11_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block11_1_relu (Activatio (None, 6, 6, 128)    0           conv4_block11_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block11_2_conv (Conv2D)   (None, 6, 6, 32)     36864       conv4_block11_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block11_concat (Concatena (None, 6, 6, 608)    0           conv4_block10_concat[0][0]       \n","                                                                 conv4_block11_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block12_0_bn (BatchNormal (None, 6, 6, 608)    2432        conv4_block11_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block12_0_relu (Activatio (None, 6, 6, 608)    0           conv4_block12_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block12_1_conv (Conv2D)   (None, 6, 6, 128)    77824       conv4_block12_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block12_1_bn (BatchNormal (None, 6, 6, 128)    512         conv4_block12_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block12_1_relu (Activatio (None, 6, 6, 128)    0           conv4_block12_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block12_2_conv (Conv2D)   (None, 6, 6, 32)     36864       conv4_block12_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block12_concat (Concatena (None, 6, 6, 640)    0           conv4_block11_concat[0][0]       \n","                                                                 conv4_block12_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block13_0_bn (BatchNormal (None, 6, 6, 640)    2560        conv4_block12_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block13_0_relu (Activatio (None, 6, 6, 640)    0           conv4_block13_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block13_1_conv (Conv2D)   (None, 6, 6, 128)    81920       conv4_block13_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block13_1_bn (BatchNormal (None, 6, 6, 128)    512         conv4_block13_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block13_1_relu (Activatio (None, 6, 6, 128)    0           conv4_block13_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block13_2_conv (Conv2D)   (None, 6, 6, 32)     36864       conv4_block13_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block13_concat (Concatena (None, 6, 6, 672)    0           conv4_block12_concat[0][0]       \n","                                                                 conv4_block13_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block14_0_bn (BatchNormal (None, 6, 6, 672)    2688        conv4_block13_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block14_0_relu (Activatio (None, 6, 6, 672)    0           conv4_block14_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block14_1_conv (Conv2D)   (None, 6, 6, 128)    86016       conv4_block14_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block14_1_bn (BatchNormal (None, 6, 6, 128)    512         conv4_block14_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block14_1_relu (Activatio (None, 6, 6, 128)    0           conv4_block14_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block14_2_conv (Conv2D)   (None, 6, 6, 32)     36864       conv4_block14_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block14_concat (Concatena (None, 6, 6, 704)    0           conv4_block13_concat[0][0]       \n","                                                                 conv4_block14_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block15_0_bn (BatchNormal (None, 6, 6, 704)    2816        conv4_block14_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block15_0_relu (Activatio (None, 6, 6, 704)    0           conv4_block15_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block15_1_conv (Conv2D)   (None, 6, 6, 128)    90112       conv4_block15_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block15_1_bn (BatchNormal (None, 6, 6, 128)    512         conv4_block15_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block15_1_relu (Activatio (None, 6, 6, 128)    0           conv4_block15_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block15_2_conv (Conv2D)   (None, 6, 6, 32)     36864       conv4_block15_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block15_concat (Concatena (None, 6, 6, 736)    0           conv4_block14_concat[0][0]       \n","                                                                 conv4_block15_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block16_0_bn (BatchNormal (None, 6, 6, 736)    2944        conv4_block15_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block16_0_relu (Activatio (None, 6, 6, 736)    0           conv4_block16_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block16_1_conv (Conv2D)   (None, 6, 6, 128)    94208       conv4_block16_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block16_1_bn (BatchNormal (None, 6, 6, 128)    512         conv4_block16_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block16_1_relu (Activatio (None, 6, 6, 128)    0           conv4_block16_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block16_2_conv (Conv2D)   (None, 6, 6, 32)     36864       conv4_block16_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block16_concat (Concatena (None, 6, 6, 768)    0           conv4_block15_concat[0][0]       \n","                                                                 conv4_block16_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block17_0_bn (BatchNormal (None, 6, 6, 768)    3072        conv4_block16_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block17_0_relu (Activatio (None, 6, 6, 768)    0           conv4_block17_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block17_1_conv (Conv2D)   (None, 6, 6, 128)    98304       conv4_block17_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block17_1_bn (BatchNormal (None, 6, 6, 128)    512         conv4_block17_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block17_1_relu (Activatio (None, 6, 6, 128)    0           conv4_block17_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block17_2_conv (Conv2D)   (None, 6, 6, 32)     36864       conv4_block17_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block17_concat (Concatena (None, 6, 6, 800)    0           conv4_block16_concat[0][0]       \n","                                                                 conv4_block17_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block18_0_bn (BatchNormal (None, 6, 6, 800)    3200        conv4_block17_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block18_0_relu (Activatio (None, 6, 6, 800)    0           conv4_block18_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block18_1_conv (Conv2D)   (None, 6, 6, 128)    102400      conv4_block18_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block18_1_bn (BatchNormal (None, 6, 6, 128)    512         conv4_block18_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block18_1_relu (Activatio (None, 6, 6, 128)    0           conv4_block18_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block18_2_conv (Conv2D)   (None, 6, 6, 32)     36864       conv4_block18_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block18_concat (Concatena (None, 6, 6, 832)    0           conv4_block17_concat[0][0]       \n","                                                                 conv4_block18_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block19_0_bn (BatchNormal (None, 6, 6, 832)    3328        conv4_block18_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block19_0_relu (Activatio (None, 6, 6, 832)    0           conv4_block19_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block19_1_conv (Conv2D)   (None, 6, 6, 128)    106496      conv4_block19_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block19_1_bn (BatchNormal (None, 6, 6, 128)    512         conv4_block19_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block19_1_relu (Activatio (None, 6, 6, 128)    0           conv4_block19_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block19_2_conv (Conv2D)   (None, 6, 6, 32)     36864       conv4_block19_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block19_concat (Concatena (None, 6, 6, 864)    0           conv4_block18_concat[0][0]       \n","                                                                 conv4_block19_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block20_0_bn (BatchNormal (None, 6, 6, 864)    3456        conv4_block19_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block20_0_relu (Activatio (None, 6, 6, 864)    0           conv4_block20_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block20_1_conv (Conv2D)   (None, 6, 6, 128)    110592      conv4_block20_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block20_1_bn (BatchNormal (None, 6, 6, 128)    512         conv4_block20_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block20_1_relu (Activatio (None, 6, 6, 128)    0           conv4_block20_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block20_2_conv (Conv2D)   (None, 6, 6, 32)     36864       conv4_block20_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block20_concat (Concatena (None, 6, 6, 896)    0           conv4_block19_concat[0][0]       \n","                                                                 conv4_block20_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block21_0_bn (BatchNormal (None, 6, 6, 896)    3584        conv4_block20_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block21_0_relu (Activatio (None, 6, 6, 896)    0           conv4_block21_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block21_1_conv (Conv2D)   (None, 6, 6, 128)    114688      conv4_block21_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block21_1_bn (BatchNormal (None, 6, 6, 128)    512         conv4_block21_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block21_1_relu (Activatio (None, 6, 6, 128)    0           conv4_block21_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block21_2_conv (Conv2D)   (None, 6, 6, 32)     36864       conv4_block21_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block21_concat (Concatena (None, 6, 6, 928)    0           conv4_block20_concat[0][0]       \n","                                                                 conv4_block21_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block22_0_bn (BatchNormal (None, 6, 6, 928)    3712        conv4_block21_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block22_0_relu (Activatio (None, 6, 6, 928)    0           conv4_block22_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block22_1_conv (Conv2D)   (None, 6, 6, 128)    118784      conv4_block22_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block22_1_bn (BatchNormal (None, 6, 6, 128)    512         conv4_block22_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block22_1_relu (Activatio (None, 6, 6, 128)    0           conv4_block22_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block22_2_conv (Conv2D)   (None, 6, 6, 32)     36864       conv4_block22_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block22_concat (Concatena (None, 6, 6, 960)    0           conv4_block21_concat[0][0]       \n","                                                                 conv4_block22_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block23_0_bn (BatchNormal (None, 6, 6, 960)    3840        conv4_block22_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block23_0_relu (Activatio (None, 6, 6, 960)    0           conv4_block23_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block23_1_conv (Conv2D)   (None, 6, 6, 128)    122880      conv4_block23_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block23_1_bn (BatchNormal (None, 6, 6, 128)    512         conv4_block23_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block23_1_relu (Activatio (None, 6, 6, 128)    0           conv4_block23_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block23_2_conv (Conv2D)   (None, 6, 6, 32)     36864       conv4_block23_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block23_concat (Concatena (None, 6, 6, 992)    0           conv4_block22_concat[0][0]       \n","                                                                 conv4_block23_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block24_0_bn (BatchNormal (None, 6, 6, 992)    3968        conv4_block23_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block24_0_relu (Activatio (None, 6, 6, 992)    0           conv4_block24_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block24_1_conv (Conv2D)   (None, 6, 6, 128)    126976      conv4_block24_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block24_1_bn (BatchNormal (None, 6, 6, 128)    512         conv4_block24_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block24_1_relu (Activatio (None, 6, 6, 128)    0           conv4_block24_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block24_2_conv (Conv2D)   (None, 6, 6, 32)     36864       conv4_block24_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block24_concat (Concatena (None, 6, 6, 1024)   0           conv4_block23_concat[0][0]       \n","                                                                 conv4_block24_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","pool4_bn (BatchNormalization)   (None, 6, 6, 1024)   4096        conv4_block24_concat[0][0]       \n","__________________________________________________________________________________________________\n","pool4_relu (Activation)         (None, 6, 6, 1024)   0           pool4_bn[0][0]                   \n","__________________________________________________________________________________________________\n","pool4_conv (Conv2D)             (None, 6, 6, 512)    524288      pool4_relu[0][0]                 \n","__________________________________________________________________________________________________\n","pool4_pool (AveragePooling2D)   (None, 3, 3, 512)    0           pool4_conv[0][0]                 \n","__________________________________________________________________________________________________\n","conv5_block1_0_bn (BatchNormali (None, 3, 3, 512)    2048        pool4_pool[0][0]                 \n","__________________________________________________________________________________________________\n","conv5_block1_0_relu (Activation (None, 3, 3, 512)    0           conv5_block1_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block1_1_conv (Conv2D)    (None, 3, 3, 128)    65536       conv5_block1_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block1_1_bn (BatchNormali (None, 3, 3, 128)    512         conv5_block1_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block1_1_relu (Activation (None, 3, 3, 128)    0           conv5_block1_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block1_2_conv (Conv2D)    (None, 3, 3, 32)     36864       conv5_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block1_concat (Concatenat (None, 3, 3, 544)    0           pool4_pool[0][0]                 \n","                                                                 conv5_block1_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block2_0_bn (BatchNormali (None, 3, 3, 544)    2176        conv5_block1_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block2_0_relu (Activation (None, 3, 3, 544)    0           conv5_block2_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block2_1_conv (Conv2D)    (None, 3, 3, 128)    69632       conv5_block2_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block2_1_bn (BatchNormali (None, 3, 3, 128)    512         conv5_block2_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block2_1_relu (Activation (None, 3, 3, 128)    0           conv5_block2_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block2_2_conv (Conv2D)    (None, 3, 3, 32)     36864       conv5_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block2_concat (Concatenat (None, 3, 3, 576)    0           conv5_block1_concat[0][0]        \n","                                                                 conv5_block2_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block3_0_bn (BatchNormali (None, 3, 3, 576)    2304        conv5_block2_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block3_0_relu (Activation (None, 3, 3, 576)    0           conv5_block3_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block3_1_conv (Conv2D)    (None, 3, 3, 128)    73728       conv5_block3_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block3_1_bn (BatchNormali (None, 3, 3, 128)    512         conv5_block3_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block3_1_relu (Activation (None, 3, 3, 128)    0           conv5_block3_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block3_2_conv (Conv2D)    (None, 3, 3, 32)     36864       conv5_block3_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block3_concat (Concatenat (None, 3, 3, 608)    0           conv5_block2_concat[0][0]        \n","                                                                 conv5_block3_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block4_0_bn (BatchNormali (None, 3, 3, 608)    2432        conv5_block3_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block4_0_relu (Activation (None, 3, 3, 608)    0           conv5_block4_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block4_1_conv (Conv2D)    (None, 3, 3, 128)    77824       conv5_block4_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block4_1_bn (BatchNormali (None, 3, 3, 128)    512         conv5_block4_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block4_1_relu (Activation (None, 3, 3, 128)    0           conv5_block4_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block4_2_conv (Conv2D)    (None, 3, 3, 32)     36864       conv5_block4_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block4_concat (Concatenat (None, 3, 3, 640)    0           conv5_block3_concat[0][0]        \n","                                                                 conv5_block4_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block5_0_bn (BatchNormali (None, 3, 3, 640)    2560        conv5_block4_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block5_0_relu (Activation (None, 3, 3, 640)    0           conv5_block5_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block5_1_conv (Conv2D)    (None, 3, 3, 128)    81920       conv5_block5_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block5_1_bn (BatchNormali (None, 3, 3, 128)    512         conv5_block5_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block5_1_relu (Activation (None, 3, 3, 128)    0           conv5_block5_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block5_2_conv (Conv2D)    (None, 3, 3, 32)     36864       conv5_block5_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block5_concat (Concatenat (None, 3, 3, 672)    0           conv5_block4_concat[0][0]        \n","                                                                 conv5_block5_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block6_0_bn (BatchNormali (None, 3, 3, 672)    2688        conv5_block5_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block6_0_relu (Activation (None, 3, 3, 672)    0           conv5_block6_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block6_1_conv (Conv2D)    (None, 3, 3, 128)    86016       conv5_block6_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block6_1_bn (BatchNormali (None, 3, 3, 128)    512         conv5_block6_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block6_1_relu (Activation (None, 3, 3, 128)    0           conv5_block6_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block6_2_conv (Conv2D)    (None, 3, 3, 32)     36864       conv5_block6_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block6_concat (Concatenat (None, 3, 3, 704)    0           conv5_block5_concat[0][0]        \n","                                                                 conv5_block6_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block7_0_bn (BatchNormali (None, 3, 3, 704)    2816        conv5_block6_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block7_0_relu (Activation (None, 3, 3, 704)    0           conv5_block7_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block7_1_conv (Conv2D)    (None, 3, 3, 128)    90112       conv5_block7_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block7_1_bn (BatchNormali (None, 3, 3, 128)    512         conv5_block7_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block7_1_relu (Activation (None, 3, 3, 128)    0           conv5_block7_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block7_2_conv (Conv2D)    (None, 3, 3, 32)     36864       conv5_block7_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block7_concat (Concatenat (None, 3, 3, 736)    0           conv5_block6_concat[0][0]        \n","                                                                 conv5_block7_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block8_0_bn (BatchNormali (None, 3, 3, 736)    2944        conv5_block7_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block8_0_relu (Activation (None, 3, 3, 736)    0           conv5_block8_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block8_1_conv (Conv2D)    (None, 3, 3, 128)    94208       conv5_block8_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block8_1_bn (BatchNormali (None, 3, 3, 128)    512         conv5_block8_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block8_1_relu (Activation (None, 3, 3, 128)    0           conv5_block8_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block8_2_conv (Conv2D)    (None, 3, 3, 32)     36864       conv5_block8_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block8_concat (Concatenat (None, 3, 3, 768)    0           conv5_block7_concat[0][0]        \n","                                                                 conv5_block8_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block9_0_bn (BatchNormali (None, 3, 3, 768)    3072        conv5_block8_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block9_0_relu (Activation (None, 3, 3, 768)    0           conv5_block9_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block9_1_conv (Conv2D)    (None, 3, 3, 128)    98304       conv5_block9_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block9_1_bn (BatchNormali (None, 3, 3, 128)    512         conv5_block9_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block9_1_relu (Activation (None, 3, 3, 128)    0           conv5_block9_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block9_2_conv (Conv2D)    (None, 3, 3, 32)     36864       conv5_block9_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block9_concat (Concatenat (None, 3, 3, 800)    0           conv5_block8_concat[0][0]        \n","                                                                 conv5_block9_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block10_0_bn (BatchNormal (None, 3, 3, 800)    3200        conv5_block9_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block10_0_relu (Activatio (None, 3, 3, 800)    0           conv5_block10_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv5_block10_1_conv (Conv2D)   (None, 3, 3, 128)    102400      conv5_block10_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block10_1_bn (BatchNormal (None, 3, 3, 128)    512         conv5_block10_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block10_1_relu (Activatio (None, 3, 3, 128)    0           conv5_block10_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv5_block10_2_conv (Conv2D)   (None, 3, 3, 32)     36864       conv5_block10_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block10_concat (Concatena (None, 3, 3, 832)    0           conv5_block9_concat[0][0]        \n","                                                                 conv5_block10_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block11_0_bn (BatchNormal (None, 3, 3, 832)    3328        conv5_block10_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block11_0_relu (Activatio (None, 3, 3, 832)    0           conv5_block11_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv5_block11_1_conv (Conv2D)   (None, 3, 3, 128)    106496      conv5_block11_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block11_1_bn (BatchNormal (None, 3, 3, 128)    512         conv5_block11_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block11_1_relu (Activatio (None, 3, 3, 128)    0           conv5_block11_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv5_block11_2_conv (Conv2D)   (None, 3, 3, 32)     36864       conv5_block11_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block11_concat (Concatena (None, 3, 3, 864)    0           conv5_block10_concat[0][0]       \n","                                                                 conv5_block11_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block12_0_bn (BatchNormal (None, 3, 3, 864)    3456        conv5_block11_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block12_0_relu (Activatio (None, 3, 3, 864)    0           conv5_block12_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv5_block12_1_conv (Conv2D)   (None, 3, 3, 128)    110592      conv5_block12_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block12_1_bn (BatchNormal (None, 3, 3, 128)    512         conv5_block12_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block12_1_relu (Activatio (None, 3, 3, 128)    0           conv5_block12_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv5_block12_2_conv (Conv2D)   (None, 3, 3, 32)     36864       conv5_block12_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block12_concat (Concatena (None, 3, 3, 896)    0           conv5_block11_concat[0][0]       \n","                                                                 conv5_block12_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block13_0_bn (BatchNormal (None, 3, 3, 896)    3584        conv5_block12_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block13_0_relu (Activatio (None, 3, 3, 896)    0           conv5_block13_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv5_block13_1_conv (Conv2D)   (None, 3, 3, 128)    114688      conv5_block13_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block13_1_bn (BatchNormal (None, 3, 3, 128)    512         conv5_block13_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block13_1_relu (Activatio (None, 3, 3, 128)    0           conv5_block13_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv5_block13_2_conv (Conv2D)   (None, 3, 3, 32)     36864       conv5_block13_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block13_concat (Concatena (None, 3, 3, 928)    0           conv5_block12_concat[0][0]       \n","                                                                 conv5_block13_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block14_0_bn (BatchNormal (None, 3, 3, 928)    3712        conv5_block13_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block14_0_relu (Activatio (None, 3, 3, 928)    0           conv5_block14_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv5_block14_1_conv (Conv2D)   (None, 3, 3, 128)    118784      conv5_block14_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block14_1_bn (BatchNormal (None, 3, 3, 128)    512         conv5_block14_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block14_1_relu (Activatio (None, 3, 3, 128)    0           conv5_block14_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv5_block14_2_conv (Conv2D)   (None, 3, 3, 32)     36864       conv5_block14_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block14_concat (Concatena (None, 3, 3, 960)    0           conv5_block13_concat[0][0]       \n","                                                                 conv5_block14_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block15_0_bn (BatchNormal (None, 3, 3, 960)    3840        conv5_block14_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block15_0_relu (Activatio (None, 3, 3, 960)    0           conv5_block15_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv5_block15_1_conv (Conv2D)   (None, 3, 3, 128)    122880      conv5_block15_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block15_1_bn (BatchNormal (None, 3, 3, 128)    512         conv5_block15_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block15_1_relu (Activatio (None, 3, 3, 128)    0           conv5_block15_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv5_block15_2_conv (Conv2D)   (None, 3, 3, 32)     36864       conv5_block15_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block15_concat (Concatena (None, 3, 3, 992)    0           conv5_block14_concat[0][0]       \n","                                                                 conv5_block15_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block16_0_bn (BatchNormal (None, 3, 3, 992)    3968        conv5_block15_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block16_0_relu (Activatio (None, 3, 3, 992)    0           conv5_block16_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv5_block16_1_conv (Conv2D)   (None, 3, 3, 128)    126976      conv5_block16_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block16_1_bn (BatchNormal (None, 3, 3, 128)    512         conv5_block16_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block16_1_relu (Activatio (None, 3, 3, 128)    0           conv5_block16_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv5_block16_2_conv (Conv2D)   (None, 3, 3, 32)     36864       conv5_block16_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block16_concat (Concatena (None, 3, 3, 1024)   0           conv5_block15_concat[0][0]       \n","                                                                 conv5_block16_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","bn (BatchNormalization)         (None, 3, 3, 1024)   4096        conv5_block16_concat[0][0]       \n","__________________________________________________________________________________________________\n","relu (Activation)               (None, 3, 3, 1024)   0           bn[0][0]                         \n","==================================================================================================\n","Total params: 7,037,504\n","Trainable params: 745,984\n","Non-trainable params: 6,291,520\n","__________________________________________________________________________________________________\n","Model: \"DenseNet121_ADModel\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","tensor (InputLayer)          [(None, 100, 100, 3)]     0         \n","_________________________________________________________________\n","densenet121 (Functional)     (None, 3, 3, 1024)        7037504   \n","_________________________________________________________________\n","flatten (Flatten)            (None, 9216)              0         \n","_________________________________________________________________\n","dropout (Dropout)            (None, 9216)              0         \n","_________________________________________________________________\n","dense (Dense)                (None, 32)                294944    \n","_________________________________________________________________\n","batch_normalization (BatchNo (None, 32)                128       \n","_________________________________________________________________\n","leaky_re_lu (LeakyReLU)      (None, 32)                0         \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 32)                0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 4)                 132       \n","=================================================================\n","Total params: 7,332,708\n","Trainable params: 1,041,124\n","Non-trainable params: 6,291,584\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MZ4jfdUCPsXW","executionInfo":{"status":"ok","timestamp":1618592092264,"user_tz":240,"elapsed":6808657,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"0c7e2bd3-1d71-4c45-cd7d-9bf0645fd7f9"},"source":["# train the model\n","graph_reg_history = graph_reg_model.fit(train_image_dataset, \n","                                        validation_data=test_image_dataset,\n","                                        callbacks = [callback_checkpoints, callback_earlystop],\n","                                        epochs=params.train_epoch,\n","                                        verbose=1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/50\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py:595: UserWarning: Input dict contained keys ['id'] which did not match any model input. They will be ignored by the model.\n","  [n for n in tensors.keys() if n not in ref_input_names])\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/GraphRegularization/graph_loss/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/GraphRegularization/graph_loss/Reshape:0\", shape=(None, 4), dtype=float32), dense_shape=Tensor(\"gradient_tape/GraphRegularization/graph_loss/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"shape. This may consume a large amount of memory.\" % value)\n"],"name":"stderr"},{"output_type":"stream","text":["160/160 [==============================] - 152s 855ms/step - loss: 0.0375 - accuracy: 0.9868 - auc: 0.9996 - f1_score: 0.9867 - scaled_graph_loss: 7.8527e-06 - val_loss: 1.7916 - val_accuracy: 0.6787 - val_auc: 0.8602 - val_f1_score: 0.9518\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.67866, saving model to /content/drive/MyDrive/AD Expriment II/DenseNet_model_checkpoints/densenet_nsl_weights\n","Epoch 2/50\n","160/160 [==============================] - 136s 843ms/step - loss: 0.0354 - accuracy: 0.9877 - auc: 0.9996 - f1_score: 0.9876 - scaled_graph_loss: 8.3765e-06 - val_loss: 2.1548 - val_accuracy: 0.6591 - val_auc: 0.8469 - val_f1_score: 0.6585\n","\n","Epoch 00002: val_accuracy did not improve from 0.67866\n","Epoch 3/50\n","160/160 [==============================] - 136s 843ms/step - loss: 0.0394 - accuracy: 0.9853 - auc: 0.9992 - f1_score: 0.9854 - scaled_graph_loss: 8.6871e-06 - val_loss: 1.9432 - val_accuracy: 0.6654 - val_auc: 0.8628 - val_f1_score: 0.6664\n","\n","Epoch 00003: val_accuracy did not improve from 0.67866\n","Epoch 4/50\n","160/160 [==============================] - 135s 843ms/step - loss: 0.0550 - accuracy: 0.9815 - auc: 0.9985 - f1_score: 0.9816 - scaled_graph_loss: 1.0712e-05 - val_loss: 1.8573 - val_accuracy: 0.6701 - val_auc: 0.8645 - val_f1_score: 0.6695\n","\n","Epoch 00004: val_accuracy did not improve from 0.67866\n","Epoch 5/50\n","160/160 [==============================] - 136s 843ms/step - loss: 0.0365 - accuracy: 0.9881 - auc: 0.9997 - f1_score: 0.9882 - scaled_graph_loss: 7.6446e-06 - val_loss: 2.0336 - val_accuracy: 0.6575 - val_auc: 0.8468 - val_f1_score: 0.6559\n","\n","Epoch 00005: val_accuracy did not improve from 0.67866\n","Epoch 6/50\n","160/160 [==============================] - 135s 843ms/step - loss: 0.0419 - accuracy: 0.9874 - auc: 0.9989 - f1_score: 0.9875 - scaled_graph_loss: 8.3417e-06 - val_loss: 1.9979 - val_accuracy: 0.6513 - val_auc: 0.8505 - val_f1_score: 0.6512\n","\n","Epoch 00006: val_accuracy did not improve from 0.67866\n","Epoch 7/50\n","160/160 [==============================] - 135s 843ms/step - loss: 0.0420 - accuracy: 0.9872 - auc: 0.9992 - f1_score: 0.9871 - scaled_graph_loss: 9.5421e-06 - val_loss: 2.4714 - val_accuracy: 0.6599 - val_auc: 0.8430 - val_f1_score: 0.6593\n","\n","Epoch 00007: val_accuracy did not improve from 0.67866\n","Epoch 8/50\n","160/160 [==============================] - 135s 842ms/step - loss: 0.0531 - accuracy: 0.9831 - auc: 0.9991 - f1_score: 0.9832 - scaled_graph_loss: 1.0583e-05 - val_loss: 4.4842 - val_accuracy: 0.4668 - val_auc: 0.6876 - val_f1_score: 0.4653\n","\n","Epoch 00008: val_accuracy did not improve from 0.67866\n","Epoch 9/50\n","160/160 [==============================] - 135s 842ms/step - loss: 0.0358 - accuracy: 0.9872 - auc: 0.9994 - f1_score: 0.9875 - scaled_graph_loss: 8.0613e-06 - val_loss: 2.4453 - val_accuracy: 0.5895 - val_auc: 0.8075 - val_f1_score: 0.5904\n","\n","Epoch 00009: val_accuracy did not improve from 0.67866\n","Epoch 10/50\n","160/160 [==============================] - 136s 844ms/step - loss: 0.0367 - accuracy: 0.9886 - auc: 0.9994 - f1_score: 0.9888 - scaled_graph_loss: 7.6077e-06 - val_loss: 1.7030 - val_accuracy: 0.6747 - val_auc: 0.8664 - val_f1_score: 0.6732\n","\n","Epoch 00010: val_accuracy did not improve from 0.67866\n","Epoch 11/50\n","160/160 [==============================] - 136s 844ms/step - loss: 0.0258 - accuracy: 0.9912 - auc: 0.9998 - f1_score: 0.9912 - scaled_graph_loss: 5.7446e-06 - val_loss: 2.6047 - val_accuracy: 0.6482 - val_auc: 0.8332 - val_f1_score: 0.6489\n","\n","Epoch 00011: val_accuracy did not improve from 0.67866\n","Epoch 12/50\n","160/160 [==============================] - 136s 844ms/step - loss: 0.0224 - accuracy: 0.9917 - auc: 0.9998 - f1_score: 0.9916 - scaled_graph_loss: 5.1262e-06 - val_loss: 5.1756 - val_accuracy: 0.4206 - val_auc: 0.6528 - val_f1_score: 0.4214\n","\n","Epoch 00012: val_accuracy did not improve from 0.67866\n","Epoch 13/50\n","160/160 [==============================] - 136s 844ms/step - loss: 0.0229 - accuracy: 0.9919 - auc: 0.9999 - f1_score: 0.9919 - scaled_graph_loss: 5.0381e-06 - val_loss: 1.8995 - val_accuracy: 0.6919 - val_auc: 0.8725 - val_f1_score: 0.6920\n","\n","Epoch 00013: val_accuracy improved from 0.67866 to 0.69195, saving model to /content/drive/MyDrive/AD Expriment II/DenseNet_model_checkpoints/densenet_nsl_weights\n","Epoch 14/50\n","160/160 [==============================] - 136s 844ms/step - loss: 0.0382 - accuracy: 0.9872 - auc: 0.9993 - f1_score: 0.9873 - scaled_graph_loss: 8.1346e-06 - val_loss: 2.0061 - val_accuracy: 0.6443 - val_auc: 0.8425 - val_f1_score: 0.6436\n","\n","Epoch 00014: val_accuracy did not improve from 0.69195\n","Epoch 15/50\n","160/160 [==============================] - 136s 844ms/step - loss: 0.0200 - accuracy: 0.9932 - auc: 0.9999 - f1_score: 0.9931 - scaled_graph_loss: 4.4804e-06 - val_loss: 2.5266 - val_accuracy: 0.6661 - val_auc: 0.8421 - val_f1_score: 0.6664\n","\n","Epoch 00015: val_accuracy did not improve from 0.69195\n","Epoch 16/50\n","160/160 [==============================] - 136s 843ms/step - loss: 0.0208 - accuracy: 0.9938 - auc: 0.9997 - f1_score: 0.9938 - scaled_graph_loss: 3.9676e-06 - val_loss: 3.9223 - val_accuracy: 0.5653 - val_auc: 0.7679 - val_f1_score: 0.5659\n","\n","Epoch 00016: val_accuracy did not improve from 0.69195\n","Epoch 17/50\n","160/160 [==============================] - 136s 844ms/step - loss: 0.0365 - accuracy: 0.9881 - auc: 0.9993 - f1_score: 0.9882 - scaled_graph_loss: 8.9564e-06 - val_loss: 1.7026 - val_accuracy: 0.7005 - val_auc: 0.8785 - val_f1_score: 0.7018\n","\n","Epoch 00017: val_accuracy improved from 0.69195 to 0.70055, saving model to /content/drive/MyDrive/AD Expriment II/DenseNet_model_checkpoints/densenet_nsl_weights\n","Epoch 18/50\n","160/160 [==============================] - 136s 843ms/step - loss: 0.0238 - accuracy: 0.9925 - auc: 0.9996 - f1_score: 0.9925 - scaled_graph_loss: 4.6742e-06 - val_loss: 1.6964 - val_accuracy: 0.6919 - val_auc: 0.8777 - val_f1_score: 0.6934\n","\n","Epoch 00018: val_accuracy did not improve from 0.70055\n","Epoch 19/50\n","160/160 [==============================] - 136s 844ms/step - loss: 0.0259 - accuracy: 0.9905 - auc: 0.9997 - f1_score: 0.9907 - scaled_graph_loss: 5.7367e-06 - val_loss: 2.2976 - val_accuracy: 0.6833 - val_auc: 0.8600 - val_f1_score: 0.6821\n","\n","Epoch 00019: val_accuracy did not improve from 0.70055\n","Epoch 20/50\n","160/160 [==============================] - 136s 844ms/step - loss: 0.0219 - accuracy: 0.9933 - auc: 0.9996 - f1_score: 0.9933 - scaled_graph_loss: 5.0357e-06 - val_loss: 3.5378 - val_accuracy: 0.5606 - val_auc: 0.7765 - val_f1_score: 0.5599\n","\n","Epoch 00020: val_accuracy did not improve from 0.70055\n","Epoch 21/50\n","160/160 [==============================] - 136s 844ms/step - loss: 0.0244 - accuracy: 0.9909 - auc: 0.9998 - f1_score: 0.9910 - scaled_graph_loss: 6.0378e-06 - val_loss: 3.8804 - val_accuracy: 0.4621 - val_auc: 0.6999 - val_f1_score: 0.4627\n","\n","Epoch 00021: val_accuracy did not improve from 0.70055\n","Epoch 22/50\n","160/160 [==============================] - 136s 844ms/step - loss: 0.0445 - accuracy: 0.9847 - auc: 0.9991 - f1_score: 0.9844 - scaled_graph_loss: 9.3943e-06 - val_loss: 3.0353 - val_accuracy: 0.5997 - val_auc: 0.8135 - val_f1_score: 0.6006\n","\n","Epoch 00022: val_accuracy did not improve from 0.70055\n","Epoch 23/50\n","160/160 [==============================] - 136s 844ms/step - loss: 0.0176 - accuracy: 0.9946 - auc: 0.9998 - f1_score: 0.9945 - scaled_graph_loss: 4.2005e-06 - val_loss: 2.0265 - val_accuracy: 0.6724 - val_auc: 0.8635 - val_f1_score: 0.6727\n","\n","Epoch 00023: val_accuracy did not improve from 0.70055\n","Epoch 24/50\n","160/160 [==============================] - 136s 844ms/step - loss: 0.0160 - accuracy: 0.9945 - auc: 0.9998 - f1_score: 0.9946 - scaled_graph_loss: 3.7837e-06 - val_loss: 5.6415 - val_accuracy: 0.5012 - val_auc: 0.6999 - val_f1_score: 0.4994\n","\n","Epoch 00024: val_accuracy did not improve from 0.70055\n","Epoch 25/50\n","160/160 [==============================] - 136s 844ms/step - loss: 0.0213 - accuracy: 0.9928 - auc: 0.9998 - f1_score: 0.9927 - scaled_graph_loss: 5.0975e-06 - val_loss: 3.1619 - val_accuracy: 0.6419 - val_auc: 0.8149 - val_f1_score: 0.6422\n","\n","Epoch 00025: val_accuracy did not improve from 0.70055\n","Epoch 26/50\n","160/160 [==============================] - 136s 843ms/step - loss: 0.0393 - accuracy: 0.9879 - auc: 0.9988 - f1_score: 0.9881 - scaled_graph_loss: 7.3741e-06 - val_loss: 2.4968 - val_accuracy: 0.6560 - val_auc: 0.8460 - val_f1_score: 0.6565\n","\n","Epoch 00026: val_accuracy did not improve from 0.70055\n","Epoch 27/50\n","160/160 [==============================] - 135s 843ms/step - loss: 0.0286 - accuracy: 0.9906 - auc: 0.9997 - f1_score: 0.9906 - scaled_graph_loss: 6.1659e-06 - val_loss: 2.8227 - val_accuracy: 0.6466 - val_auc: 0.8274 - val_f1_score: 0.6473\n","\n","Epoch 00027: val_accuracy did not improve from 0.70055\n","Epoch 28/50\n","160/160 [==============================] - 136s 844ms/step - loss: 0.0156 - accuracy: 0.9942 - auc: 0.9999 - f1_score: 0.9942 - scaled_graph_loss: 4.0055e-06 - val_loss: 3.0268 - val_accuracy: 0.6560 - val_auc: 0.8322 - val_f1_score: 0.6555\n","\n","Epoch 00028: val_accuracy did not improve from 0.70055\n","Epoch 29/50\n","160/160 [==============================] - 136s 844ms/step - loss: 0.0128 - accuracy: 0.9963 - auc: 0.9998 - f1_score: 0.9963 - scaled_graph_loss: 2.5728e-06 - val_loss: 2.1397 - val_accuracy: 0.6826 - val_auc: 0.8608 - val_f1_score: 0.6821\n","\n","Epoch 00029: val_accuracy did not improve from 0.70055\n","Epoch 30/50\n","160/160 [==============================] - 136s 844ms/step - loss: 0.0076 - accuracy: 0.9977 - auc: 1.0000 - f1_score: 0.9977 - scaled_graph_loss: 2.2545e-06 - val_loss: 2.0458 - val_accuracy: 0.6904 - val_auc: 0.8676 - val_f1_score: 0.6897\n","\n","Epoch 00030: val_accuracy did not improve from 0.70055\n","Epoch 31/50\n","160/160 [==============================] - 136s 844ms/step - loss: 0.0133 - accuracy: 0.9952 - auc: 0.9999 - f1_score: 0.9954 - scaled_graph_loss: 3.0761e-06 - val_loss: 2.3040 - val_accuracy: 0.6599 - val_auc: 0.8430 - val_f1_score: 0.6599\n","\n","Epoch 00031: val_accuracy did not improve from 0.70055\n","Epoch 32/50\n","160/160 [==============================] - 135s 843ms/step - loss: 0.0400 - accuracy: 0.9862 - auc: 0.9994 - f1_score: 0.9862 - scaled_graph_loss: 9.1672e-06 - val_loss: 2.4635 - val_accuracy: 0.6403 - val_auc: 0.8353 - val_f1_score: 0.6408\n","\n","Epoch 00032: val_accuracy did not improve from 0.70055\n","Epoch 33/50\n","160/160 [==============================] - 136s 843ms/step - loss: 0.0290 - accuracy: 0.9897 - auc: 0.9995 - f1_score: 0.9897 - scaled_graph_loss: 6.4769e-06 - val_loss: 2.1033 - val_accuracy: 0.6747 - val_auc: 0.8587 - val_f1_score: 0.6743\n","\n","Epoch 00033: val_accuracy did not improve from 0.70055\n","Epoch 34/50\n","160/160 [==============================] - 136s 843ms/step - loss: 0.0133 - accuracy: 0.9958 - auc: 1.0000 - f1_score: 0.9958 - scaled_graph_loss: 3.2524e-06 - val_loss: 2.1089 - val_accuracy: 0.6771 - val_auc: 0.8524 - val_f1_score: 0.6792\n","\n","Epoch 00034: val_accuracy did not improve from 0.70055\n","Epoch 35/50\n","160/160 [==============================] - 135s 843ms/step - loss: 0.0154 - accuracy: 0.9951 - auc: 0.9999 - f1_score: 0.9951 - scaled_graph_loss: 3.1643e-06 - val_loss: 2.9907 - val_accuracy: 0.5950 - val_auc: 0.7951 - val_f1_score: 0.5941\n","\n","Epoch 00035: val_accuracy did not improve from 0.70055\n","Epoch 36/50\n","160/160 [==============================] - 136s 843ms/step - loss: 0.0252 - accuracy: 0.9910 - auc: 0.9996 - f1_score: 0.9911 - scaled_graph_loss: 5.6026e-06 - val_loss: 3.9942 - val_accuracy: 0.5911 - val_auc: 0.7889 - val_f1_score: 0.5912\n","\n","Epoch 00036: val_accuracy did not improve from 0.70055\n","Epoch 37/50\n","160/160 [==============================] - 136s 844ms/step - loss: 0.0525 - accuracy: 0.9850 - auc: 0.9986 - f1_score: 0.9849 - scaled_graph_loss: 8.9702e-06 - val_loss: 3.0624 - val_accuracy: 0.6302 - val_auc: 0.8184 - val_f1_score: 0.6291\n","\n","Epoch 00037: val_accuracy did not improve from 0.70055\n","Epoch 38/50\n","160/160 [==============================] - 136s 844ms/step - loss: 0.0096 - accuracy: 0.9975 - auc: 1.0000 - f1_score: 0.9975 - scaled_graph_loss: 2.0821e-06 - val_loss: 1.6922 - val_accuracy: 0.7349 - val_auc: 0.8940 - val_f1_score: 0.7341\n","\n","Epoch 00038: val_accuracy improved from 0.70055 to 0.73495, saving model to /content/drive/MyDrive/AD Expriment II/DenseNet_model_checkpoints/densenet_nsl_weights\n","Epoch 39/50\n","160/160 [==============================] - 136s 844ms/step - loss: 0.0082 - accuracy: 0.9974 - auc: 1.0000 - f1_score: 0.9974 - scaled_graph_loss: 1.9283e-06 - val_loss: 3.0343 - val_accuracy: 0.5801 - val_auc: 0.7854 - val_f1_score: 0.5797\n","\n","Epoch 00039: val_accuracy did not improve from 0.73495\n","Epoch 40/50\n","160/160 [==============================] - 136s 843ms/step - loss: 0.0292 - accuracy: 0.9903 - auc: 0.9996 - f1_score: 0.9902 - scaled_graph_loss: 6.5459e-06 - val_loss: 2.3255 - val_accuracy: 0.6489 - val_auc: 0.8439 - val_f1_score: 0.6486\n","\n","Epoch 00040: val_accuracy did not improve from 0.73495\n","Epoch 41/50\n","160/160 [==============================] - 136s 844ms/step - loss: 0.0118 - accuracy: 0.9968 - auc: 0.9999 - f1_score: 0.9968 - scaled_graph_loss: 2.7580e-06 - val_loss: 2.3850 - val_accuracy: 0.6615 - val_auc: 0.8404 - val_f1_score: 0.6612\n","\n","Epoch 00041: val_accuracy did not improve from 0.73495\n","Epoch 42/50\n","160/160 [==============================] - 136s 844ms/step - loss: 0.0317 - accuracy: 0.9900 - auc: 0.9993 - f1_score: 0.9900 - scaled_graph_loss: 6.3021e-06 - val_loss: 2.6623 - val_accuracy: 0.6630 - val_auc: 0.8355 - val_f1_score: 0.6638\n","\n","Epoch 00042: val_accuracy did not improve from 0.73495\n","Epoch 43/50\n","160/160 [==============================] - 136s 844ms/step - loss: 0.0130 - accuracy: 0.9950 - auc: 1.0000 - f1_score: 0.9950 - scaled_graph_loss: 2.9010e-06 - val_loss: 2.0376 - val_accuracy: 0.6771 - val_auc: 0.8673 - val_f1_score: 0.6777\n","\n","Epoch 00043: val_accuracy did not improve from 0.73495\n","Epoch 44/50\n","160/160 [==============================] - 136s 843ms/step - loss: 0.0154 - accuracy: 0.9941 - auc: 0.9998 - f1_score: 0.9941 - scaled_graph_loss: 3.5064e-06 - val_loss: 3.1994 - val_accuracy: 0.5856 - val_auc: 0.7844 - val_f1_score: 0.5867\n","\n","Epoch 00044: val_accuracy did not improve from 0.73495\n","Epoch 45/50\n","160/160 [==============================] - 136s 843ms/step - loss: 0.0132 - accuracy: 0.9963 - auc: 0.9998 - f1_score: 0.9962 - scaled_graph_loss: 2.5483e-06 - val_loss: 1.8726 - val_accuracy: 0.7131 - val_auc: 0.8787 - val_f1_score: 0.7129\n","\n","Epoch 00045: val_accuracy did not improve from 0.73495\n","Epoch 46/50\n","160/160 [==============================] - 136s 844ms/step - loss: 0.0090 - accuracy: 0.9969 - auc: 1.0000 - f1_score: 0.9969 - scaled_graph_loss: 2.2684e-06 - val_loss: 3.2279 - val_accuracy: 0.6310 - val_auc: 0.8205 - val_f1_score: 0.6307\n","\n","Epoch 00046: val_accuracy did not improve from 0.73495\n","Epoch 47/50\n","160/160 [==============================] - 136s 843ms/step - loss: 0.0103 - accuracy: 0.9957 - auc: 1.0000 - f1_score: 0.9958 - scaled_graph_loss: 2.4637e-06 - val_loss: 2.2080 - val_accuracy: 0.7091 - val_auc: 0.8666 - val_f1_score: 0.7084\n","\n","Epoch 00047: val_accuracy did not improve from 0.73495\n","Epoch 48/50\n","160/160 [==============================] - 136s 844ms/step - loss: 0.0166 - accuracy: 0.9937 - auc: 0.9998 - f1_score: 0.9938 - scaled_graph_loss: 3.5880e-06 - val_loss: 3.2128 - val_accuracy: 0.6388 - val_auc: 0.8243 - val_f1_score: 0.6395\n","\n","Epoch 00048: val_accuracy did not improve from 0.73495\n","Epoch 49/50\n","160/160 [==============================] - 136s 844ms/step - loss: 0.0294 - accuracy: 0.9913 - auc: 0.9993 - f1_score: 0.9911 - scaled_graph_loss: 6.0812e-06 - val_loss: 3.0242 - val_accuracy: 0.6435 - val_auc: 0.8219 - val_f1_score: 0.6445\n","\n","Epoch 00049: val_accuracy did not improve from 0.73495\n","Epoch 50/50\n","160/160 [==============================] - 136s 843ms/step - loss: 0.0191 - accuracy: 0.9935 - auc: 0.9997 - f1_score: 0.9933 - scaled_graph_loss: 3.7100e-06 - val_loss: 2.3824 - val_accuracy: 0.6685 - val_auc: 0.8473 - val_f1_score: 0.6693\n","\n","Epoch 00050: val_accuracy did not improve from 0.73495\n","Early stopping is not triggered, but best model is restored at epoch 38\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CiySckZVg8GJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618838715816,"user_tz":240,"elapsed":40981,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"5a758e99-e12d-4251-a0cb-b5c4bcb5032b"},"source":["'''evalute the test model'''\n","graph_reg_model.evaluate(test_image_dataset)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py:595: UserWarning: Input dict contained keys ['id'] which did not match any model input. They will be ignored by the model.\n","  [n for n in tensors.keys() if n not in ref_input_names])\n"],"name":"stderr"},{"output_type":"stream","text":["20/20 [==============================] - 41s 171ms/step - loss: 1.6862 - accuracy: 0.7479 - auc: 0.8971 - f1_score: 0.7461\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[1.6922053098678589,\n"," 0.7349491715431213,\n"," 0.8940041661262512,\n"," 0.7341175675392151]"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"n1Kudc3XErB-"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pkkMlFWfBTFZ"},"source":["## 3.4 DenseNet_NSL top 10 layers, middle 20 layers and bottom 10 laysers tuning\n","### val_acc: 0.74, val_auc: 0.89, val_f1_score: 0.74"]},{"cell_type":"code","metadata":{"id":"MGAmz0zgZkZZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618853927874,"user_tz":240,"elapsed":9556,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"f00d57c6-c9f5-4604-ede2-7ce701ad5e93"},"source":["'''define params'''\n","params.learning_rate=0.000005\n","params.restore_path= '/content/drive/MyDrive/AD Expriment II/DenseNet_model_checkpoints/densenet_nsl_weights'\n","params.checkpoint_path = '/content/drive/MyDrive/AD Expriment II/DenseNet_model_checkpoints/densenet_nsl_weights'\n","params.early_stop_base_line=0.80\n","params.train_epoch=50\n","params.nsl_multiplier = 0.00005\n","params.nsl_sum_over_axis = -1\n","params.nsl_distance_type = nsl.configs.DistanceType.COSINE\n","\n","'''build a base model with selected trainable layer'''\n","admodel = ADModelBuilder(input_shape=params.ad_base_model_input_shape, base_model='densenet121').setup_DenseNet121(top_layers=10, middle_layers=[190, 210], bottom_layers=10).get_ADModel()\n","\n","'''build NSL model on top of base model'''\n","graph_reg_config = nsl.configs.make_graph_reg_config(neighbor_prefix=params.neighbor_prefix,\n","                                                     neighbor_weight_suffix=params.neighbor_weight_suffix,\n","                                                     max_neighbors= params.max_seed_nbr,\n","                                                     multiplier= params.nsl_multiplier,\n","                                                     distance_type= params.nsl_distance_type,\n","                                                     sum_over_axis= params.nsl_sum_over_axis)\n","graph_reg_model = nsl.keras.GraphRegularization(admodel,graph_reg_config)\n","graph_reg_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=params.learning_rate, amsgrad=True), \n","                        loss=tf.losses.CategoricalCrossentropy(), \n","                        metrics=[\"accuracy\",\"AUC\", tfa.metrics.F1Score(num_classes=4, average=\"micro\", threshold = 0.5)])\n","\n","'''restore the model from last training'''\n","graph_reg_model.load_weights(params.restore_path)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Note: default DenseNet121 not includes top and has imagenet weights. It is not a trainable model in ADModelBuilder. Please setup trainable layers in setup_DenseNet121 function based on the \"Layer Number\"\n","Model: \"densenet121\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 100, 100, 3) 0                                            \n","__________________________________________________________________________________________________\n","zero_padding2d (ZeroPadding2D)  (None, 106, 106, 3)  0           input_1[0][0]                    \n","__________________________________________________________________________________________________\n","conv1/conv (Conv2D)             (None, 50, 50, 64)   9408        zero_padding2d[0][0]             \n","__________________________________________________________________________________________________\n","conv1/bn (BatchNormalization)   (None, 50, 50, 64)   256         conv1/conv[0][0]                 \n","__________________________________________________________________________________________________\n","conv1/relu (Activation)         (None, 50, 50, 64)   0           conv1/bn[0][0]                   \n","__________________________________________________________________________________________________\n","zero_padding2d_1 (ZeroPadding2D (None, 52, 52, 64)   0           conv1/relu[0][0]                 \n","__________________________________________________________________________________________________\n","pool1 (MaxPooling2D)            (None, 25, 25, 64)   0           zero_padding2d_1[0][0]           \n","__________________________________________________________________________________________________\n","conv2_block1_0_bn (BatchNormali (None, 25, 25, 64)   256         pool1[0][0]                      \n","__________________________________________________________________________________________________\n","conv2_block1_0_relu (Activation (None, 25, 25, 64)   0           conv2_block1_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block1_1_conv (Conv2D)    (None, 25, 25, 128)  8192        conv2_block1_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_1_bn (BatchNormali (None, 25, 25, 128)  512         conv2_block1_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_1_relu (Activation (None, 25, 25, 128)  0           conv2_block1_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block1_2_conv (Conv2D)    (None, 25, 25, 32)   36864       conv2_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_concat (Concatenat (None, 25, 25, 96)   0           pool1[0][0]                      \n","                                                                 conv2_block1_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_0_bn (BatchNormali (None, 25, 25, 96)   384         conv2_block1_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_0_relu (Activation (None, 25, 25, 96)   0           conv2_block2_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block2_1_conv (Conv2D)    (None, 25, 25, 128)  12288       conv2_block2_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_1_bn (BatchNormali (None, 25, 25, 128)  512         conv2_block2_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_1_relu (Activation (None, 25, 25, 128)  0           conv2_block2_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block2_2_conv (Conv2D)    (None, 25, 25, 32)   36864       conv2_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_concat (Concatenat (None, 25, 25, 128)  0           conv2_block1_concat[0][0]        \n","                                                                 conv2_block2_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_0_bn (BatchNormali (None, 25, 25, 128)  512         conv2_block2_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_0_relu (Activation (None, 25, 25, 128)  0           conv2_block3_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block3_1_conv (Conv2D)    (None, 25, 25, 128)  16384       conv2_block3_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_1_bn (BatchNormali (None, 25, 25, 128)  512         conv2_block3_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_1_relu (Activation (None, 25, 25, 128)  0           conv2_block3_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block3_2_conv (Conv2D)    (None, 25, 25, 32)   36864       conv2_block3_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_concat (Concatenat (None, 25, 25, 160)  0           conv2_block2_concat[0][0]        \n","                                                                 conv2_block3_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block4_0_bn (BatchNormali (None, 25, 25, 160)  640         conv2_block3_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block4_0_relu (Activation (None, 25, 25, 160)  0           conv2_block4_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block4_1_conv (Conv2D)    (None, 25, 25, 128)  20480       conv2_block4_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block4_1_bn (BatchNormali (None, 25, 25, 128)  512         conv2_block4_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block4_1_relu (Activation (None, 25, 25, 128)  0           conv2_block4_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block4_2_conv (Conv2D)    (None, 25, 25, 32)   36864       conv2_block4_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block4_concat (Concatenat (None, 25, 25, 192)  0           conv2_block3_concat[0][0]        \n","                                                                 conv2_block4_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block5_0_bn (BatchNormali (None, 25, 25, 192)  768         conv2_block4_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block5_0_relu (Activation (None, 25, 25, 192)  0           conv2_block5_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block5_1_conv (Conv2D)    (None, 25, 25, 128)  24576       conv2_block5_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block5_1_bn (BatchNormali (None, 25, 25, 128)  512         conv2_block5_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block5_1_relu (Activation (None, 25, 25, 128)  0           conv2_block5_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block5_2_conv (Conv2D)    (None, 25, 25, 32)   36864       conv2_block5_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block5_concat (Concatenat (None, 25, 25, 224)  0           conv2_block4_concat[0][0]        \n","                                                                 conv2_block5_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block6_0_bn (BatchNormali (None, 25, 25, 224)  896         conv2_block5_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block6_0_relu (Activation (None, 25, 25, 224)  0           conv2_block6_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block6_1_conv (Conv2D)    (None, 25, 25, 128)  28672       conv2_block6_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block6_1_bn (BatchNormali (None, 25, 25, 128)  512         conv2_block6_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block6_1_relu (Activation (None, 25, 25, 128)  0           conv2_block6_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block6_2_conv (Conv2D)    (None, 25, 25, 32)   36864       conv2_block6_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block6_concat (Concatenat (None, 25, 25, 256)  0           conv2_block5_concat[0][0]        \n","                                                                 conv2_block6_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","pool2_bn (BatchNormalization)   (None, 25, 25, 256)  1024        conv2_block6_concat[0][0]        \n","__________________________________________________________________________________________________\n","pool2_relu (Activation)         (None, 25, 25, 256)  0           pool2_bn[0][0]                   \n","__________________________________________________________________________________________________\n","pool2_conv (Conv2D)             (None, 25, 25, 128)  32768       pool2_relu[0][0]                 \n","__________________________________________________________________________________________________\n","pool2_pool (AveragePooling2D)   (None, 12, 12, 128)  0           pool2_conv[0][0]                 \n","__________________________________________________________________________________________________\n","conv3_block1_0_bn (BatchNormali (None, 12, 12, 128)  512         pool2_pool[0][0]                 \n","__________________________________________________________________________________________________\n","conv3_block1_0_relu (Activation (None, 12, 12, 128)  0           conv3_block1_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block1_1_conv (Conv2D)    (None, 12, 12, 128)  16384       conv3_block1_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_1_bn (BatchNormali (None, 12, 12, 128)  512         conv3_block1_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_1_relu (Activation (None, 12, 12, 128)  0           conv3_block1_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block1_2_conv (Conv2D)    (None, 12, 12, 32)   36864       conv3_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_concat (Concatenat (None, 12, 12, 160)  0           pool2_pool[0][0]                 \n","                                                                 conv3_block1_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_0_bn (BatchNormali (None, 12, 12, 160)  640         conv3_block1_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_0_relu (Activation (None, 12, 12, 160)  0           conv3_block2_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block2_1_conv (Conv2D)    (None, 12, 12, 128)  20480       conv3_block2_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_1_bn (BatchNormali (None, 12, 12, 128)  512         conv3_block2_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_1_relu (Activation (None, 12, 12, 128)  0           conv3_block2_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block2_2_conv (Conv2D)    (None, 12, 12, 32)   36864       conv3_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_concat (Concatenat (None, 12, 12, 192)  0           conv3_block1_concat[0][0]        \n","                                                                 conv3_block2_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_0_bn (BatchNormali (None, 12, 12, 192)  768         conv3_block2_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_0_relu (Activation (None, 12, 12, 192)  0           conv3_block3_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block3_1_conv (Conv2D)    (None, 12, 12, 128)  24576       conv3_block3_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_1_bn (BatchNormali (None, 12, 12, 128)  512         conv3_block3_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_1_relu (Activation (None, 12, 12, 128)  0           conv3_block3_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block3_2_conv (Conv2D)    (None, 12, 12, 32)   36864       conv3_block3_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_concat (Concatenat (None, 12, 12, 224)  0           conv3_block2_concat[0][0]        \n","                                                                 conv3_block3_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_0_bn (BatchNormali (None, 12, 12, 224)  896         conv3_block3_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_0_relu (Activation (None, 12, 12, 224)  0           conv3_block4_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block4_1_conv (Conv2D)    (None, 12, 12, 128)  28672       conv3_block4_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_1_bn (BatchNormali (None, 12, 12, 128)  512         conv3_block4_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_1_relu (Activation (None, 12, 12, 128)  0           conv3_block4_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block4_2_conv (Conv2D)    (None, 12, 12, 32)   36864       conv3_block4_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_concat (Concatenat (None, 12, 12, 256)  0           conv3_block3_concat[0][0]        \n","                                                                 conv3_block4_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block5_0_bn (BatchNormali (None, 12, 12, 256)  1024        conv3_block4_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block5_0_relu (Activation (None, 12, 12, 256)  0           conv3_block5_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block5_1_conv (Conv2D)    (None, 12, 12, 128)  32768       conv3_block5_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block5_1_bn (BatchNormali (None, 12, 12, 128)  512         conv3_block5_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block5_1_relu (Activation (None, 12, 12, 128)  0           conv3_block5_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block5_2_conv (Conv2D)    (None, 12, 12, 32)   36864       conv3_block5_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block5_concat (Concatenat (None, 12, 12, 288)  0           conv3_block4_concat[0][0]        \n","                                                                 conv3_block5_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block6_0_bn (BatchNormali (None, 12, 12, 288)  1152        conv3_block5_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block6_0_relu (Activation (None, 12, 12, 288)  0           conv3_block6_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block6_1_conv (Conv2D)    (None, 12, 12, 128)  36864       conv3_block6_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block6_1_bn (BatchNormali (None, 12, 12, 128)  512         conv3_block6_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block6_1_relu (Activation (None, 12, 12, 128)  0           conv3_block6_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block6_2_conv (Conv2D)    (None, 12, 12, 32)   36864       conv3_block6_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block6_concat (Concatenat (None, 12, 12, 320)  0           conv3_block5_concat[0][0]        \n","                                                                 conv3_block6_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block7_0_bn (BatchNormali (None, 12, 12, 320)  1280        conv3_block6_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block7_0_relu (Activation (None, 12, 12, 320)  0           conv3_block7_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block7_1_conv (Conv2D)    (None, 12, 12, 128)  40960       conv3_block7_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block7_1_bn (BatchNormali (None, 12, 12, 128)  512         conv3_block7_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block7_1_relu (Activation (None, 12, 12, 128)  0           conv3_block7_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block7_2_conv (Conv2D)    (None, 12, 12, 32)   36864       conv3_block7_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block7_concat (Concatenat (None, 12, 12, 352)  0           conv3_block6_concat[0][0]        \n","                                                                 conv3_block7_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block8_0_bn (BatchNormali (None, 12, 12, 352)  1408        conv3_block7_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block8_0_relu (Activation (None, 12, 12, 352)  0           conv3_block8_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block8_1_conv (Conv2D)    (None, 12, 12, 128)  45056       conv3_block8_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block8_1_bn (BatchNormali (None, 12, 12, 128)  512         conv3_block8_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block8_1_relu (Activation (None, 12, 12, 128)  0           conv3_block8_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block8_2_conv (Conv2D)    (None, 12, 12, 32)   36864       conv3_block8_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block8_concat (Concatenat (None, 12, 12, 384)  0           conv3_block7_concat[0][0]        \n","                                                                 conv3_block8_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block9_0_bn (BatchNormali (None, 12, 12, 384)  1536        conv3_block8_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block9_0_relu (Activation (None, 12, 12, 384)  0           conv3_block9_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block9_1_conv (Conv2D)    (None, 12, 12, 128)  49152       conv3_block9_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block9_1_bn (BatchNormali (None, 12, 12, 128)  512         conv3_block9_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block9_1_relu (Activation (None, 12, 12, 128)  0           conv3_block9_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block9_2_conv (Conv2D)    (None, 12, 12, 32)   36864       conv3_block9_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block9_concat (Concatenat (None, 12, 12, 416)  0           conv3_block8_concat[0][0]        \n","                                                                 conv3_block9_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block10_0_bn (BatchNormal (None, 12, 12, 416)  1664        conv3_block9_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block10_0_relu (Activatio (None, 12, 12, 416)  0           conv3_block10_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv3_block10_1_conv (Conv2D)   (None, 12, 12, 128)  53248       conv3_block10_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv3_block10_1_bn (BatchNormal (None, 12, 12, 128)  512         conv3_block10_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv3_block10_1_relu (Activatio (None, 12, 12, 128)  0           conv3_block10_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv3_block10_2_conv (Conv2D)   (None, 12, 12, 32)   36864       conv3_block10_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv3_block10_concat (Concatena (None, 12, 12, 448)  0           conv3_block9_concat[0][0]        \n","                                                                 conv3_block10_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv3_block11_0_bn (BatchNormal (None, 12, 12, 448)  1792        conv3_block10_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv3_block11_0_relu (Activatio (None, 12, 12, 448)  0           conv3_block11_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv3_block11_1_conv (Conv2D)   (None, 12, 12, 128)  57344       conv3_block11_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv3_block11_1_bn (BatchNormal (None, 12, 12, 128)  512         conv3_block11_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv3_block11_1_relu (Activatio (None, 12, 12, 128)  0           conv3_block11_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv3_block11_2_conv (Conv2D)   (None, 12, 12, 32)   36864       conv3_block11_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv3_block11_concat (Concatena (None, 12, 12, 480)  0           conv3_block10_concat[0][0]       \n","                                                                 conv3_block11_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv3_block12_0_bn (BatchNormal (None, 12, 12, 480)  1920        conv3_block11_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv3_block12_0_relu (Activatio (None, 12, 12, 480)  0           conv3_block12_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv3_block12_1_conv (Conv2D)   (None, 12, 12, 128)  61440       conv3_block12_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv3_block12_1_bn (BatchNormal (None, 12, 12, 128)  512         conv3_block12_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv3_block12_1_relu (Activatio (None, 12, 12, 128)  0           conv3_block12_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv3_block12_2_conv (Conv2D)   (None, 12, 12, 32)   36864       conv3_block12_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv3_block12_concat (Concatena (None, 12, 12, 512)  0           conv3_block11_concat[0][0]       \n","                                                                 conv3_block12_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","pool3_bn (BatchNormalization)   (None, 12, 12, 512)  2048        conv3_block12_concat[0][0]       \n","__________________________________________________________________________________________________\n","pool3_relu (Activation)         (None, 12, 12, 512)  0           pool3_bn[0][0]                   \n","__________________________________________________________________________________________________\n","pool3_conv (Conv2D)             (None, 12, 12, 256)  131072      pool3_relu[0][0]                 \n","__________________________________________________________________________________________________\n","pool3_pool (AveragePooling2D)   (None, 6, 6, 256)    0           pool3_conv[0][0]                 \n","__________________________________________________________________________________________________\n","conv4_block1_0_bn (BatchNormali (None, 6, 6, 256)    1024        pool3_pool[0][0]                 \n","__________________________________________________________________________________________________\n","conv4_block1_0_relu (Activation (None, 6, 6, 256)    0           conv4_block1_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block1_1_conv (Conv2D)    (None, 6, 6, 128)    32768       conv4_block1_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_1_bn (BatchNormali (None, 6, 6, 128)    512         conv4_block1_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_1_relu (Activation (None, 6, 6, 128)    0           conv4_block1_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block1_2_conv (Conv2D)    (None, 6, 6, 32)     36864       conv4_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_concat (Concatenat (None, 6, 6, 288)    0           pool3_pool[0][0]                 \n","                                                                 conv4_block1_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_0_bn (BatchNormali (None, 6, 6, 288)    1152        conv4_block1_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_0_relu (Activation (None, 6, 6, 288)    0           conv4_block2_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block2_1_conv (Conv2D)    (None, 6, 6, 128)    36864       conv4_block2_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_1_bn (BatchNormali (None, 6, 6, 128)    512         conv4_block2_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_1_relu (Activation (None, 6, 6, 128)    0           conv4_block2_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block2_2_conv (Conv2D)    (None, 6, 6, 32)     36864       conv4_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_concat (Concatenat (None, 6, 6, 320)    0           conv4_block1_concat[0][0]        \n","                                                                 conv4_block2_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_0_bn (BatchNormali (None, 6, 6, 320)    1280        conv4_block2_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_0_relu (Activation (None, 6, 6, 320)    0           conv4_block3_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block3_1_conv (Conv2D)    (None, 6, 6, 128)    40960       conv4_block3_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_1_bn (BatchNormali (None, 6, 6, 128)    512         conv4_block3_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_1_relu (Activation (None, 6, 6, 128)    0           conv4_block3_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block3_2_conv (Conv2D)    (None, 6, 6, 32)     36864       conv4_block3_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_concat (Concatenat (None, 6, 6, 352)    0           conv4_block2_concat[0][0]        \n","                                                                 conv4_block3_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_0_bn (BatchNormali (None, 6, 6, 352)    1408        conv4_block3_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_0_relu (Activation (None, 6, 6, 352)    0           conv4_block4_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block4_1_conv (Conv2D)    (None, 6, 6, 128)    45056       conv4_block4_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_1_bn (BatchNormali (None, 6, 6, 128)    512         conv4_block4_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_1_relu (Activation (None, 6, 6, 128)    0           conv4_block4_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block4_2_conv (Conv2D)    (None, 6, 6, 32)     36864       conv4_block4_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_concat (Concatenat (None, 6, 6, 384)    0           conv4_block3_concat[0][0]        \n","                                                                 conv4_block4_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_0_bn (BatchNormali (None, 6, 6, 384)    1536        conv4_block4_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_0_relu (Activation (None, 6, 6, 384)    0           conv4_block5_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block5_1_conv (Conv2D)    (None, 6, 6, 128)    49152       conv4_block5_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_1_bn (BatchNormali (None, 6, 6, 128)    512         conv4_block5_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_1_relu (Activation (None, 6, 6, 128)    0           conv4_block5_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block5_2_conv (Conv2D)    (None, 6, 6, 32)     36864       conv4_block5_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_concat (Concatenat (None, 6, 6, 416)    0           conv4_block4_concat[0][0]        \n","                                                                 conv4_block5_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_0_bn (BatchNormali (None, 6, 6, 416)    1664        conv4_block5_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_0_relu (Activation (None, 6, 6, 416)    0           conv4_block6_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block6_1_conv (Conv2D)    (None, 6, 6, 128)    53248       conv4_block6_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_1_bn (BatchNormali (None, 6, 6, 128)    512         conv4_block6_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_1_relu (Activation (None, 6, 6, 128)    0           conv4_block6_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block6_2_conv (Conv2D)    (None, 6, 6, 32)     36864       conv4_block6_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_concat (Concatenat (None, 6, 6, 448)    0           conv4_block5_concat[0][0]        \n","                                                                 conv4_block6_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block7_0_bn (BatchNormali (None, 6, 6, 448)    1792        conv4_block6_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block7_0_relu (Activation (None, 6, 6, 448)    0           conv4_block7_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block7_1_conv (Conv2D)    (None, 6, 6, 128)    57344       conv4_block7_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block7_1_bn (BatchNormali (None, 6, 6, 128)    512         conv4_block7_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block7_1_relu (Activation (None, 6, 6, 128)    0           conv4_block7_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block7_2_conv (Conv2D)    (None, 6, 6, 32)     36864       conv4_block7_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block7_concat (Concatenat (None, 6, 6, 480)    0           conv4_block6_concat[0][0]        \n","                                                                 conv4_block7_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block8_0_bn (BatchNormali (None, 6, 6, 480)    1920        conv4_block7_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block8_0_relu (Activation (None, 6, 6, 480)    0           conv4_block8_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block8_1_conv (Conv2D)    (None, 6, 6, 128)    61440       conv4_block8_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block8_1_bn (BatchNormali (None, 6, 6, 128)    512         conv4_block8_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block8_1_relu (Activation (None, 6, 6, 128)    0           conv4_block8_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block8_2_conv (Conv2D)    (None, 6, 6, 32)     36864       conv4_block8_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block8_concat (Concatenat (None, 6, 6, 512)    0           conv4_block7_concat[0][0]        \n","                                                                 conv4_block8_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block9_0_bn (BatchNormali (None, 6, 6, 512)    2048        conv4_block8_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block9_0_relu (Activation (None, 6, 6, 512)    0           conv4_block9_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block9_1_conv (Conv2D)    (None, 6, 6, 128)    65536       conv4_block9_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block9_1_bn (BatchNormali (None, 6, 6, 128)    512         conv4_block9_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block9_1_relu (Activation (None, 6, 6, 128)    0           conv4_block9_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block9_2_conv (Conv2D)    (None, 6, 6, 32)     36864       conv4_block9_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block9_concat (Concatenat (None, 6, 6, 544)    0           conv4_block8_concat[0][0]        \n","                                                                 conv4_block9_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block10_0_bn (BatchNormal (None, 6, 6, 544)    2176        conv4_block9_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block10_0_relu (Activatio (None, 6, 6, 544)    0           conv4_block10_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block10_1_conv (Conv2D)   (None, 6, 6, 128)    69632       conv4_block10_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block10_1_bn (BatchNormal (None, 6, 6, 128)    512         conv4_block10_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block10_1_relu (Activatio (None, 6, 6, 128)    0           conv4_block10_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block10_2_conv (Conv2D)   (None, 6, 6, 32)     36864       conv4_block10_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block10_concat (Concatena (None, 6, 6, 576)    0           conv4_block9_concat[0][0]        \n","                                                                 conv4_block10_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block11_0_bn (BatchNormal (None, 6, 6, 576)    2304        conv4_block10_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block11_0_relu (Activatio (None, 6, 6, 576)    0           conv4_block11_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block11_1_conv (Conv2D)   (None, 6, 6, 128)    73728       conv4_block11_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block11_1_bn (BatchNormal (None, 6, 6, 128)    512         conv4_block11_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block11_1_relu (Activatio (None, 6, 6, 128)    0           conv4_block11_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block11_2_conv (Conv2D)   (None, 6, 6, 32)     36864       conv4_block11_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block11_concat (Concatena (None, 6, 6, 608)    0           conv4_block10_concat[0][0]       \n","                                                                 conv4_block11_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block12_0_bn (BatchNormal (None, 6, 6, 608)    2432        conv4_block11_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block12_0_relu (Activatio (None, 6, 6, 608)    0           conv4_block12_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block12_1_conv (Conv2D)   (None, 6, 6, 128)    77824       conv4_block12_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block12_1_bn (BatchNormal (None, 6, 6, 128)    512         conv4_block12_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block12_1_relu (Activatio (None, 6, 6, 128)    0           conv4_block12_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block12_2_conv (Conv2D)   (None, 6, 6, 32)     36864       conv4_block12_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block12_concat (Concatena (None, 6, 6, 640)    0           conv4_block11_concat[0][0]       \n","                                                                 conv4_block12_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block13_0_bn (BatchNormal (None, 6, 6, 640)    2560        conv4_block12_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block13_0_relu (Activatio (None, 6, 6, 640)    0           conv4_block13_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block13_1_conv (Conv2D)   (None, 6, 6, 128)    81920       conv4_block13_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block13_1_bn (BatchNormal (None, 6, 6, 128)    512         conv4_block13_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block13_1_relu (Activatio (None, 6, 6, 128)    0           conv4_block13_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block13_2_conv (Conv2D)   (None, 6, 6, 32)     36864       conv4_block13_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block13_concat (Concatena (None, 6, 6, 672)    0           conv4_block12_concat[0][0]       \n","                                                                 conv4_block13_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block14_0_bn (BatchNormal (None, 6, 6, 672)    2688        conv4_block13_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block14_0_relu (Activatio (None, 6, 6, 672)    0           conv4_block14_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block14_1_conv (Conv2D)   (None, 6, 6, 128)    86016       conv4_block14_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block14_1_bn (BatchNormal (None, 6, 6, 128)    512         conv4_block14_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block14_1_relu (Activatio (None, 6, 6, 128)    0           conv4_block14_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block14_2_conv (Conv2D)   (None, 6, 6, 32)     36864       conv4_block14_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block14_concat (Concatena (None, 6, 6, 704)    0           conv4_block13_concat[0][0]       \n","                                                                 conv4_block14_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block15_0_bn (BatchNormal (None, 6, 6, 704)    2816        conv4_block14_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block15_0_relu (Activatio (None, 6, 6, 704)    0           conv4_block15_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block15_1_conv (Conv2D)   (None, 6, 6, 128)    90112       conv4_block15_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block15_1_bn (BatchNormal (None, 6, 6, 128)    512         conv4_block15_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block15_1_relu (Activatio (None, 6, 6, 128)    0           conv4_block15_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block15_2_conv (Conv2D)   (None, 6, 6, 32)     36864       conv4_block15_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block15_concat (Concatena (None, 6, 6, 736)    0           conv4_block14_concat[0][0]       \n","                                                                 conv4_block15_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block16_0_bn (BatchNormal (None, 6, 6, 736)    2944        conv4_block15_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block16_0_relu (Activatio (None, 6, 6, 736)    0           conv4_block16_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block16_1_conv (Conv2D)   (None, 6, 6, 128)    94208       conv4_block16_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block16_1_bn (BatchNormal (None, 6, 6, 128)    512         conv4_block16_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block16_1_relu (Activatio (None, 6, 6, 128)    0           conv4_block16_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block16_2_conv (Conv2D)   (None, 6, 6, 32)     36864       conv4_block16_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block16_concat (Concatena (None, 6, 6, 768)    0           conv4_block15_concat[0][0]       \n","                                                                 conv4_block16_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block17_0_bn (BatchNormal (None, 6, 6, 768)    3072        conv4_block16_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block17_0_relu (Activatio (None, 6, 6, 768)    0           conv4_block17_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block17_1_conv (Conv2D)   (None, 6, 6, 128)    98304       conv4_block17_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block17_1_bn (BatchNormal (None, 6, 6, 128)    512         conv4_block17_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block17_1_relu (Activatio (None, 6, 6, 128)    0           conv4_block17_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block17_2_conv (Conv2D)   (None, 6, 6, 32)     36864       conv4_block17_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block17_concat (Concatena (None, 6, 6, 800)    0           conv4_block16_concat[0][0]       \n","                                                                 conv4_block17_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block18_0_bn (BatchNormal (None, 6, 6, 800)    3200        conv4_block17_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block18_0_relu (Activatio (None, 6, 6, 800)    0           conv4_block18_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block18_1_conv (Conv2D)   (None, 6, 6, 128)    102400      conv4_block18_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block18_1_bn (BatchNormal (None, 6, 6, 128)    512         conv4_block18_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block18_1_relu (Activatio (None, 6, 6, 128)    0           conv4_block18_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block18_2_conv (Conv2D)   (None, 6, 6, 32)     36864       conv4_block18_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block18_concat (Concatena (None, 6, 6, 832)    0           conv4_block17_concat[0][0]       \n","                                                                 conv4_block18_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block19_0_bn (BatchNormal (None, 6, 6, 832)    3328        conv4_block18_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block19_0_relu (Activatio (None, 6, 6, 832)    0           conv4_block19_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block19_1_conv (Conv2D)   (None, 6, 6, 128)    106496      conv4_block19_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block19_1_bn (BatchNormal (None, 6, 6, 128)    512         conv4_block19_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block19_1_relu (Activatio (None, 6, 6, 128)    0           conv4_block19_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block19_2_conv (Conv2D)   (None, 6, 6, 32)     36864       conv4_block19_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block19_concat (Concatena (None, 6, 6, 864)    0           conv4_block18_concat[0][0]       \n","                                                                 conv4_block19_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block20_0_bn (BatchNormal (None, 6, 6, 864)    3456        conv4_block19_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block20_0_relu (Activatio (None, 6, 6, 864)    0           conv4_block20_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block20_1_conv (Conv2D)   (None, 6, 6, 128)    110592      conv4_block20_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block20_1_bn (BatchNormal (None, 6, 6, 128)    512         conv4_block20_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block20_1_relu (Activatio (None, 6, 6, 128)    0           conv4_block20_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block20_2_conv (Conv2D)   (None, 6, 6, 32)     36864       conv4_block20_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block20_concat (Concatena (None, 6, 6, 896)    0           conv4_block19_concat[0][0]       \n","                                                                 conv4_block20_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block21_0_bn (BatchNormal (None, 6, 6, 896)    3584        conv4_block20_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block21_0_relu (Activatio (None, 6, 6, 896)    0           conv4_block21_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block21_1_conv (Conv2D)   (None, 6, 6, 128)    114688      conv4_block21_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block21_1_bn (BatchNormal (None, 6, 6, 128)    512         conv4_block21_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block21_1_relu (Activatio (None, 6, 6, 128)    0           conv4_block21_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block21_2_conv (Conv2D)   (None, 6, 6, 32)     36864       conv4_block21_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block21_concat (Concatena (None, 6, 6, 928)    0           conv4_block20_concat[0][0]       \n","                                                                 conv4_block21_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block22_0_bn (BatchNormal (None, 6, 6, 928)    3712        conv4_block21_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block22_0_relu (Activatio (None, 6, 6, 928)    0           conv4_block22_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block22_1_conv (Conv2D)   (None, 6, 6, 128)    118784      conv4_block22_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block22_1_bn (BatchNormal (None, 6, 6, 128)    512         conv4_block22_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block22_1_relu (Activatio (None, 6, 6, 128)    0           conv4_block22_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block22_2_conv (Conv2D)   (None, 6, 6, 32)     36864       conv4_block22_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block22_concat (Concatena (None, 6, 6, 960)    0           conv4_block21_concat[0][0]       \n","                                                                 conv4_block22_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block23_0_bn (BatchNormal (None, 6, 6, 960)    3840        conv4_block22_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block23_0_relu (Activatio (None, 6, 6, 960)    0           conv4_block23_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block23_1_conv (Conv2D)   (None, 6, 6, 128)    122880      conv4_block23_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block23_1_bn (BatchNormal (None, 6, 6, 128)    512         conv4_block23_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block23_1_relu (Activatio (None, 6, 6, 128)    0           conv4_block23_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block23_2_conv (Conv2D)   (None, 6, 6, 32)     36864       conv4_block23_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block23_concat (Concatena (None, 6, 6, 992)    0           conv4_block22_concat[0][0]       \n","                                                                 conv4_block23_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block24_0_bn (BatchNormal (None, 6, 6, 992)    3968        conv4_block23_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block24_0_relu (Activatio (None, 6, 6, 992)    0           conv4_block24_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block24_1_conv (Conv2D)   (None, 6, 6, 128)    126976      conv4_block24_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block24_1_bn (BatchNormal (None, 6, 6, 128)    512         conv4_block24_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block24_1_relu (Activatio (None, 6, 6, 128)    0           conv4_block24_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block24_2_conv (Conv2D)   (None, 6, 6, 32)     36864       conv4_block24_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block24_concat (Concatena (None, 6, 6, 1024)   0           conv4_block23_concat[0][0]       \n","                                                                 conv4_block24_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","pool4_bn (BatchNormalization)   (None, 6, 6, 1024)   4096        conv4_block24_concat[0][0]       \n","__________________________________________________________________________________________________\n","pool4_relu (Activation)         (None, 6, 6, 1024)   0           pool4_bn[0][0]                   \n","__________________________________________________________________________________________________\n","pool4_conv (Conv2D)             (None, 6, 6, 512)    524288      pool4_relu[0][0]                 \n","__________________________________________________________________________________________________\n","pool4_pool (AveragePooling2D)   (None, 3, 3, 512)    0           pool4_conv[0][0]                 \n","__________________________________________________________________________________________________\n","conv5_block1_0_bn (BatchNormali (None, 3, 3, 512)    2048        pool4_pool[0][0]                 \n","__________________________________________________________________________________________________\n","conv5_block1_0_relu (Activation (None, 3, 3, 512)    0           conv5_block1_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block1_1_conv (Conv2D)    (None, 3, 3, 128)    65536       conv5_block1_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block1_1_bn (BatchNormali (None, 3, 3, 128)    512         conv5_block1_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block1_1_relu (Activation (None, 3, 3, 128)    0           conv5_block1_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block1_2_conv (Conv2D)    (None, 3, 3, 32)     36864       conv5_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block1_concat (Concatenat (None, 3, 3, 544)    0           pool4_pool[0][0]                 \n","                                                                 conv5_block1_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block2_0_bn (BatchNormali (None, 3, 3, 544)    2176        conv5_block1_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block2_0_relu (Activation (None, 3, 3, 544)    0           conv5_block2_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block2_1_conv (Conv2D)    (None, 3, 3, 128)    69632       conv5_block2_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block2_1_bn (BatchNormali (None, 3, 3, 128)    512         conv5_block2_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block2_1_relu (Activation (None, 3, 3, 128)    0           conv5_block2_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block2_2_conv (Conv2D)    (None, 3, 3, 32)     36864       conv5_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block2_concat (Concatenat (None, 3, 3, 576)    0           conv5_block1_concat[0][0]        \n","                                                                 conv5_block2_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block3_0_bn (BatchNormali (None, 3, 3, 576)    2304        conv5_block2_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block3_0_relu (Activation (None, 3, 3, 576)    0           conv5_block3_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block3_1_conv (Conv2D)    (None, 3, 3, 128)    73728       conv5_block3_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block3_1_bn (BatchNormali (None, 3, 3, 128)    512         conv5_block3_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block3_1_relu (Activation (None, 3, 3, 128)    0           conv5_block3_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block3_2_conv (Conv2D)    (None, 3, 3, 32)     36864       conv5_block3_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block3_concat (Concatenat (None, 3, 3, 608)    0           conv5_block2_concat[0][0]        \n","                                                                 conv5_block3_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block4_0_bn (BatchNormali (None, 3, 3, 608)    2432        conv5_block3_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block4_0_relu (Activation (None, 3, 3, 608)    0           conv5_block4_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block4_1_conv (Conv2D)    (None, 3, 3, 128)    77824       conv5_block4_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block4_1_bn (BatchNormali (None, 3, 3, 128)    512         conv5_block4_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block4_1_relu (Activation (None, 3, 3, 128)    0           conv5_block4_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block4_2_conv (Conv2D)    (None, 3, 3, 32)     36864       conv5_block4_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block4_concat (Concatenat (None, 3, 3, 640)    0           conv5_block3_concat[0][0]        \n","                                                                 conv5_block4_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block5_0_bn (BatchNormali (None, 3, 3, 640)    2560        conv5_block4_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block5_0_relu (Activation (None, 3, 3, 640)    0           conv5_block5_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block5_1_conv (Conv2D)    (None, 3, 3, 128)    81920       conv5_block5_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block5_1_bn (BatchNormali (None, 3, 3, 128)    512         conv5_block5_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block5_1_relu (Activation (None, 3, 3, 128)    0           conv5_block5_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block5_2_conv (Conv2D)    (None, 3, 3, 32)     36864       conv5_block5_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block5_concat (Concatenat (None, 3, 3, 672)    0           conv5_block4_concat[0][0]        \n","                                                                 conv5_block5_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block6_0_bn (BatchNormali (None, 3, 3, 672)    2688        conv5_block5_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block6_0_relu (Activation (None, 3, 3, 672)    0           conv5_block6_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block6_1_conv (Conv2D)    (None, 3, 3, 128)    86016       conv5_block6_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block6_1_bn (BatchNormali (None, 3, 3, 128)    512         conv5_block6_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block6_1_relu (Activation (None, 3, 3, 128)    0           conv5_block6_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block6_2_conv (Conv2D)    (None, 3, 3, 32)     36864       conv5_block6_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block6_concat (Concatenat (None, 3, 3, 704)    0           conv5_block5_concat[0][0]        \n","                                                                 conv5_block6_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block7_0_bn (BatchNormali (None, 3, 3, 704)    2816        conv5_block6_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block7_0_relu (Activation (None, 3, 3, 704)    0           conv5_block7_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block7_1_conv (Conv2D)    (None, 3, 3, 128)    90112       conv5_block7_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block7_1_bn (BatchNormali (None, 3, 3, 128)    512         conv5_block7_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block7_1_relu (Activation (None, 3, 3, 128)    0           conv5_block7_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block7_2_conv (Conv2D)    (None, 3, 3, 32)     36864       conv5_block7_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block7_concat (Concatenat (None, 3, 3, 736)    0           conv5_block6_concat[0][0]        \n","                                                                 conv5_block7_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block8_0_bn (BatchNormali (None, 3, 3, 736)    2944        conv5_block7_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block8_0_relu (Activation (None, 3, 3, 736)    0           conv5_block8_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block8_1_conv (Conv2D)    (None, 3, 3, 128)    94208       conv5_block8_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block8_1_bn (BatchNormali (None, 3, 3, 128)    512         conv5_block8_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block8_1_relu (Activation (None, 3, 3, 128)    0           conv5_block8_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block8_2_conv (Conv2D)    (None, 3, 3, 32)     36864       conv5_block8_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block8_concat (Concatenat (None, 3, 3, 768)    0           conv5_block7_concat[0][0]        \n","                                                                 conv5_block8_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block9_0_bn (BatchNormali (None, 3, 3, 768)    3072        conv5_block8_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block9_0_relu (Activation (None, 3, 3, 768)    0           conv5_block9_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block9_1_conv (Conv2D)    (None, 3, 3, 128)    98304       conv5_block9_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block9_1_bn (BatchNormali (None, 3, 3, 128)    512         conv5_block9_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block9_1_relu (Activation (None, 3, 3, 128)    0           conv5_block9_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block9_2_conv (Conv2D)    (None, 3, 3, 32)     36864       conv5_block9_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block9_concat (Concatenat (None, 3, 3, 800)    0           conv5_block8_concat[0][0]        \n","                                                                 conv5_block9_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block10_0_bn (BatchNormal (None, 3, 3, 800)    3200        conv5_block9_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block10_0_relu (Activatio (None, 3, 3, 800)    0           conv5_block10_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv5_block10_1_conv (Conv2D)   (None, 3, 3, 128)    102400      conv5_block10_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block10_1_bn (BatchNormal (None, 3, 3, 128)    512         conv5_block10_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block10_1_relu (Activatio (None, 3, 3, 128)    0           conv5_block10_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv5_block10_2_conv (Conv2D)   (None, 3, 3, 32)     36864       conv5_block10_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block10_concat (Concatena (None, 3, 3, 832)    0           conv5_block9_concat[0][0]        \n","                                                                 conv5_block10_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block11_0_bn (BatchNormal (None, 3, 3, 832)    3328        conv5_block10_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block11_0_relu (Activatio (None, 3, 3, 832)    0           conv5_block11_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv5_block11_1_conv (Conv2D)   (None, 3, 3, 128)    106496      conv5_block11_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block11_1_bn (BatchNormal (None, 3, 3, 128)    512         conv5_block11_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block11_1_relu (Activatio (None, 3, 3, 128)    0           conv5_block11_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv5_block11_2_conv (Conv2D)   (None, 3, 3, 32)     36864       conv5_block11_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block11_concat (Concatena (None, 3, 3, 864)    0           conv5_block10_concat[0][0]       \n","                                                                 conv5_block11_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block12_0_bn (BatchNormal (None, 3, 3, 864)    3456        conv5_block11_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block12_0_relu (Activatio (None, 3, 3, 864)    0           conv5_block12_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv5_block12_1_conv (Conv2D)   (None, 3, 3, 128)    110592      conv5_block12_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block12_1_bn (BatchNormal (None, 3, 3, 128)    512         conv5_block12_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block12_1_relu (Activatio (None, 3, 3, 128)    0           conv5_block12_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv5_block12_2_conv (Conv2D)   (None, 3, 3, 32)     36864       conv5_block12_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block12_concat (Concatena (None, 3, 3, 896)    0           conv5_block11_concat[0][0]       \n","                                                                 conv5_block12_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block13_0_bn (BatchNormal (None, 3, 3, 896)    3584        conv5_block12_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block13_0_relu (Activatio (None, 3, 3, 896)    0           conv5_block13_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv5_block13_1_conv (Conv2D)   (None, 3, 3, 128)    114688      conv5_block13_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block13_1_bn (BatchNormal (None, 3, 3, 128)    512         conv5_block13_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block13_1_relu (Activatio (None, 3, 3, 128)    0           conv5_block13_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv5_block13_2_conv (Conv2D)   (None, 3, 3, 32)     36864       conv5_block13_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block13_concat (Concatena (None, 3, 3, 928)    0           conv5_block12_concat[0][0]       \n","                                                                 conv5_block13_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block14_0_bn (BatchNormal (None, 3, 3, 928)    3712        conv5_block13_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block14_0_relu (Activatio (None, 3, 3, 928)    0           conv5_block14_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv5_block14_1_conv (Conv2D)   (None, 3, 3, 128)    118784      conv5_block14_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block14_1_bn (BatchNormal (None, 3, 3, 128)    512         conv5_block14_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block14_1_relu (Activatio (None, 3, 3, 128)    0           conv5_block14_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv5_block14_2_conv (Conv2D)   (None, 3, 3, 32)     36864       conv5_block14_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block14_concat (Concatena (None, 3, 3, 960)    0           conv5_block13_concat[0][0]       \n","                                                                 conv5_block14_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block15_0_bn (BatchNormal (None, 3, 3, 960)    3840        conv5_block14_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block15_0_relu (Activatio (None, 3, 3, 960)    0           conv5_block15_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv5_block15_1_conv (Conv2D)   (None, 3, 3, 128)    122880      conv5_block15_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block15_1_bn (BatchNormal (None, 3, 3, 128)    512         conv5_block15_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block15_1_relu (Activatio (None, 3, 3, 128)    0           conv5_block15_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv5_block15_2_conv (Conv2D)   (None, 3, 3, 32)     36864       conv5_block15_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block15_concat (Concatena (None, 3, 3, 992)    0           conv5_block14_concat[0][0]       \n","                                                                 conv5_block15_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block16_0_bn (BatchNormal (None, 3, 3, 992)    3968        conv5_block15_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block16_0_relu (Activatio (None, 3, 3, 992)    0           conv5_block16_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv5_block16_1_conv (Conv2D)   (None, 3, 3, 128)    126976      conv5_block16_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block16_1_bn (BatchNormal (None, 3, 3, 128)    512         conv5_block16_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block16_1_relu (Activatio (None, 3, 3, 128)    0           conv5_block16_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv5_block16_2_conv (Conv2D)   (None, 3, 3, 32)     36864       conv5_block16_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block16_concat (Concatena (None, 3, 3, 1024)   0           conv5_block15_concat[0][0]       \n","                                                                 conv5_block16_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","bn (BatchNormalization)         (None, 3, 3, 1024)   4096        conv5_block16_concat[0][0]       \n","__________________________________________________________________________________________________\n","relu (Activation)               (None, 3, 3, 1024)   0           bn[0][0]                         \n","==================================================================================================\n","Total params: 7,037,504\n","Trainable params: 497,024\n","Non-trainable params: 6,540,480\n","__________________________________________________________________________________________________\n","Model: \"DenseNet121_ADModel\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","tensor (InputLayer)          [(None, 100, 100, 3)]     0         \n","_________________________________________________________________\n","densenet121 (Functional)     (None, 3, 3, 1024)        7037504   \n","_________________________________________________________________\n","flatten (Flatten)            (None, 9216)              0         \n","_________________________________________________________________\n","dropout (Dropout)            (None, 9216)              0         \n","_________________________________________________________________\n","dense (Dense)                (None, 32)                294944    \n","_________________________________________________________________\n","batch_normalization (BatchNo (None, 32)                128       \n","_________________________________________________________________\n","leaky_re_lu (LeakyReLU)      (None, 32)                0         \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 32)                0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 4)                 132       \n","=================================================================\n","Total params: 7,332,708\n","Trainable params: 792,164\n","Non-trainable params: 6,540,544\n","_________________________________________________________________\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fe96e133c50>"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yeQw5zEUg8Cw","outputId":"15764c25-a1a0-414b-dc3e-dcf4e7493b10"},"source":["''' NSL model training '''\n","callback_checkpoints = tf.keras.callbacks.ModelCheckpoint(filepath=params.checkpoint_path, monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=True, mode='max',\n","                                                          save_freq='epoch',options=None)\n","\n","callback_earlystop = AccEarlyStop(val_acc_base=params.early_stop_base_line)\n","graph_reg_history = graph_reg_model.fit(train_image_dataset, \n","                                        validation_data=test_image_dataset,\n","                                        callbacks = [callback_checkpoints, callback_earlystop],\n","                                        epochs=params.train_epoch,\n","                                        verbose=1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/50\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py:595: UserWarning: Input dict contained keys ['id'] which did not match any model input. They will be ignored by the model.\n","  [n for n in tensors.keys() if n not in ref_input_names])\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/GraphRegularization/graph_loss/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/GraphRegularization/graph_loss/Reshape:0\", shape=(None, 4), dtype=float32), dense_shape=Tensor(\"gradient_tape/GraphRegularization/graph_loss/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"shape. This may consume a large amount of memory.\" % value)\n"],"name":"stderr"},{"output_type":"stream","text":["160/160 [==============================] - 296s 2s/step - loss: 0.0068 - accuracy: 0.9980 - auc: 1.0000 - f1_score: 0.9980 - scaled_graph_loss: 1.6752e-07 - val_loss: 2.4455 - val_accuracy: 0.6904 - val_auc: 0.8527 - val_f1_score: 0.9642\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.69038, saving model to /content/drive/MyDrive/AD Expriment II/DenseNet_model_checkpoints/densenet_nsl_weights\n","Epoch 2/50\n","160/160 [==============================] - 252s 2s/step - loss: 0.0103 - accuracy: 0.9970 - auc: 0.9999 - f1_score: 0.9969 - scaled_graph_loss: 2.4588e-07 - val_loss: 2.0046 - val_accuracy: 0.7170 - val_auc: 0.8742 - val_f1_score: 0.7173\n","\n","Epoch 00002: val_accuracy improved from 0.69038 to 0.71697, saving model to /content/drive/MyDrive/AD Expriment II/DenseNet_model_checkpoints/densenet_nsl_weights\n","Epoch 3/50\n","160/160 [==============================] - 252s 2s/step - loss: 0.0112 - accuracy: 0.9967 - auc: 0.9998 - f1_score: 0.9967 - scaled_graph_loss: 2.3518e-07 - val_loss: 2.8941 - val_accuracy: 0.6466 - val_auc: 0.8271 - val_f1_score: 0.6474\n","\n","Epoch 00003: val_accuracy did not improve from 0.71697\n","Epoch 4/50\n","160/160 [==============================] - 252s 2s/step - loss: 0.0283 - accuracy: 0.9896 - auc: 0.9997 - f1_score: 0.9895 - scaled_graph_loss: 7.1620e-07 - val_loss: 1.9973 - val_accuracy: 0.7091 - val_auc: 0.8692 - val_f1_score: 0.7093\n","\n","Epoch 00004: val_accuracy did not improve from 0.71697\n","Epoch 5/50\n","160/160 [==============================] - 252s 2s/step - loss: 0.0163 - accuracy: 0.9946 - auc: 0.9999 - f1_score: 0.9948 - scaled_graph_loss: 3.5643e-07 - val_loss: 2.4048 - val_accuracy: 0.6951 - val_auc: 0.8533 - val_f1_score: 0.6946\n","\n","Epoch 00005: val_accuracy did not improve from 0.71697\n","Epoch 6/50\n","160/160 [==============================] - 252s 2s/step - loss: 0.0064 - accuracy: 0.9977 - auc: 1.0000 - f1_score: 0.9979 - scaled_graph_loss: 1.8525e-07 - val_loss: 2.5621 - val_accuracy: 0.7005 - val_auc: 0.8511 - val_f1_score: 0.7016\n","\n","Epoch 00006: val_accuracy did not improve from 0.71697\n","Epoch 7/50\n","160/160 [==============================] - 252s 2s/step - loss: 0.0079 - accuracy: 0.9972 - auc: 1.0000 - f1_score: 0.9974 - scaled_graph_loss: 1.8546e-07 - val_loss: 1.9843 - val_accuracy: 0.7232 - val_auc: 0.8770 - val_f1_score: 0.7218\n","\n","Epoch 00007: val_accuracy improved from 0.71697 to 0.72322, saving model to /content/drive/MyDrive/AD Expriment II/DenseNet_model_checkpoints/densenet_nsl_weights\n","Epoch 8/50\n","160/160 [==============================] - 252s 2s/step - loss: 0.0090 - accuracy: 0.9967 - auc: 1.0000 - f1_score: 0.9967 - scaled_graph_loss: 2.0750e-07 - val_loss: 3.2222 - val_accuracy: 0.6466 - val_auc: 0.8197 - val_f1_score: 0.6463\n","\n","Epoch 00008: val_accuracy did not improve from 0.72322\n","Epoch 9/50\n","160/160 [==============================] - 253s 2s/step - loss: 0.0078 - accuracy: 0.9973 - auc: 1.0000 - f1_score: 0.9973 - scaled_graph_loss: 2.1762e-07 - val_loss: 3.8934 - val_accuracy: 0.6005 - val_auc: 0.7854 - val_f1_score: 0.6002\n","\n","Epoch 00009: val_accuracy did not improve from 0.72322\n","Epoch 10/50\n","160/160 [==============================] - 252s 2s/step - loss: 0.0219 - accuracy: 0.9917 - auc: 0.9997 - f1_score: 0.9917 - scaled_graph_loss: 4.8710e-07 - val_loss: 2.5286 - val_accuracy: 0.6771 - val_auc: 0.8495 - val_f1_score: 0.6776\n","\n","Epoch 00010: val_accuracy did not improve from 0.72322\n","Epoch 11/50\n","160/160 [==============================] - 251s 2s/step - loss: 0.0113 - accuracy: 0.9956 - auc: 1.0000 - f1_score: 0.9954 - scaled_graph_loss: 2.7508e-07 - val_loss: 1.8409 - val_accuracy: 0.7076 - val_auc: 0.8778 - val_f1_score: 0.7067\n","\n","Epoch 00011: val_accuracy did not improve from 0.72322\n","Epoch 12/50\n","160/160 [==============================] - 250s 2s/step - loss: 0.0111 - accuracy: 0.9966 - auc: 0.9999 - f1_score: 0.9963 - scaled_graph_loss: 2.4966e-07 - val_loss: 2.3015 - val_accuracy: 0.6857 - val_auc: 0.8560 - val_f1_score: 0.6849\n","\n","Epoch 00012: val_accuracy did not improve from 0.72322\n","Epoch 13/50\n","160/160 [==============================] - 251s 2s/step - loss: 0.0233 - accuracy: 0.9919 - auc: 0.9997 - f1_score: 0.9919 - scaled_graph_loss: 5.6430e-07 - val_loss: 2.7023 - val_accuracy: 0.6654 - val_auc: 0.8374 - val_f1_score: 0.6638\n","\n","Epoch 00013: val_accuracy did not improve from 0.72322\n","Epoch 14/50\n","160/160 [==============================] - 251s 2s/step - loss: 0.0185 - accuracy: 0.9939 - auc: 0.9997 - f1_score: 0.9943 - scaled_graph_loss: 4.1453e-07 - val_loss: 2.0864 - val_accuracy: 0.7076 - val_auc: 0.8644 - val_f1_score: 0.7065\n","\n","Epoch 00014: val_accuracy did not improve from 0.72322\n","Epoch 15/50\n","160/160 [==============================] - 251s 2s/step - loss: 0.0111 - accuracy: 0.9968 - auc: 1.0000 - f1_score: 0.9968 - scaled_graph_loss: 2.6341e-07 - val_loss: 2.7121 - val_accuracy: 0.6458 - val_auc: 0.8411 - val_f1_score: 0.6432\n","\n","Epoch 00015: val_accuracy did not improve from 0.72322\n","Epoch 16/50\n","160/160 [==============================] - 251s 2s/step - loss: 0.0293 - accuracy: 0.9907 - auc: 0.9991 - f1_score: 0.9907 - scaled_graph_loss: 6.3656e-07 - val_loss: 3.1398 - val_accuracy: 0.5950 - val_auc: 0.7973 - val_f1_score: 0.5957\n","\n","Epoch 00016: val_accuracy did not improve from 0.72322\n","Epoch 17/50\n","160/160 [==============================] - 251s 2s/step - loss: 0.0175 - accuracy: 0.9938 - auc: 0.9998 - f1_score: 0.9937 - scaled_graph_loss: 3.7947e-07 - val_loss: 2.1039 - val_accuracy: 0.7029 - val_auc: 0.8704 - val_f1_score: 0.7019\n","\n","Epoch 00017: val_accuracy did not improve from 0.72322\n","Epoch 18/50\n","160/160 [==============================] - 251s 2s/step - loss: 0.0147 - accuracy: 0.9954 - auc: 0.9999 - f1_score: 0.9953 - scaled_graph_loss: 3.2141e-07 - val_loss: 2.8347 - val_accuracy: 0.6443 - val_auc: 0.8289 - val_f1_score: 0.6448\n","\n","Epoch 00018: val_accuracy did not improve from 0.72322\n","Epoch 19/50\n","160/160 [==============================] - 251s 2s/step - loss: 0.0069 - accuracy: 0.9978 - auc: 1.0000 - f1_score: 0.9978 - scaled_graph_loss: 2.0695e-07 - val_loss: 2.3198 - val_accuracy: 0.7115 - val_auc: 0.8592 - val_f1_score: 0.7109\n","\n","Epoch 00019: val_accuracy did not improve from 0.72322\n","Epoch 20/50\n","135/160 [========================>.....] - ETA: 38s - loss: 0.0038 - accuracy: 0.9988 - auc: 1.0000 - f1_score: 0.9989 - scaled_graph_loss: 8.4310e-08"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HqUg5ceng8E6","executionInfo":{"status":"ok","timestamp":1618851714725,"user_tz":240,"elapsed":3896,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"7f018f21-637e-4dff-e87c-a7726dde8c27"},"source":["'''evalute the test model'''\n","graph_reg_model.evaluate(test_image_dataset)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["20/20 [==============================] - 3s 111ms/step - loss: 1.8784 - accuracy: 0.7193 - auc: 0.8743 - f1_score: 0.7188\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[1.8783780336380005,\n"," 0.7193119525909424,\n"," 0.8742884993553162,\n"," 0.7188110947608948]"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"8IbO8pXDHuoS"},"source":["'''plot confusion mat & calc acc for each label'''\n","test_image_dataset = NSLDataFormat.generate_test_tfr_image_tensor(path_list=test_tfr_list, \n","                                                                  batch_size=4000, \n","                                                                  size=(100,100),\n","                                                                  channels=3,\n","                                                                  shuffle=True)\n","data, data_label = iter(test_image_dataset).get_next()\n","data = data[\"tensor\"]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":396},"id":"PYyy-pklHOzU","executionInfo":{"status":"ok","timestamp":1618851722869,"user_tz":240,"elapsed":12028,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"8e6470fc-dc1d-4497-a636-1a824336631f"},"source":["ADModelBuilder.plot_confusion_mat(graph_reg_model, data, data_label, title=\"DenseNet121_NSL\")"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x432 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"qQY3nmxy2Va6"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0GWdE1gQKqpF"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KLUpQmqlt3GW"},"source":["#4.Xception & Xception-NSL Model Training"]},{"cell_type":"code","metadata":{"id":"5axk1eIwD6qw","executionInfo":{"status":"ok","timestamp":1619177200504,"user_tz":240,"elapsed":5346,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}}},"source":["'''define hyper params'''\n","params = AD_params()\n","params.max_seed_nbr=5\n","params.batch_size=64\n","params.image_channels =3\n","params.image_size =(100,100)\n","params.ad_base_model_input_shape=(100,100,3)\n","params.train_tfr_path = train_tfr_path\n","\n","'''parse train_data.tfr to train image dataset with batch_size at 128'''\n","train_image_dataset = NSLDataFormat.parse_tfr_to_dataset(file_path_list=[params.train_tfr_path],\n","                                                         batch_size=params.batch_size,\n","                                                         max_neighbor_number=params.max_seed_nbr,\n","                                                         image_size=params.image_size,\n","                                                         image_channels=params.image_channels,\n","                                                         shuffle=True)\n","\n","'''load test data with batch_size at 128 '''\n","test_image_dataset = NSLDataFormat.generate_test_tfr_image_tensor(path_list=test_tfr_list, \n","                                                                  batch_size=params.batch_size, \n","                                                                  size=params.image_size,\n","                                                                  channels=params.image_channels,\n","                                                                  shuffle=True)"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VJqIRkiQ81qg"},"source":["##5.1 Xception Base Model Training\n","### val_acc: 0.51, val_auc: 0.81, val_f1_score: 0.51\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wj2Ei0L1Za0O","executionInfo":{"status":"ok","timestamp":1619050959963,"user_tz":240,"elapsed":2018,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"4d7d0df5-f8a8-4abd-8c77-e799d0df2d02"},"source":["'''define params'''\n","params.learning_rate=0.001\n","params.checkpoint_restore_path='/content/drive/MyDrive/AD Expriment II/Xception_model_checkpoints/Xception_weights'\n","params.checkpoint_path='/content/drive/MyDrive/AD Expriment II/Xception_model_checkpoints/Xception_model_weights'\n","params.early_stop_base_line=0.60\n","params.train_epoch=30\n","\n","'''build base_model and restore from the last training'''\n","base_model = ADModelBuilder(input_shape=params.ad_base_model_input_shape, base_model='xception').get_ADModel()\n","base_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=params.learning_rate, amsgrad=True), \n","                   loss=tf.losses.CategoricalCrossentropy(), \n","                   metrics=['accuracy', 'AUC',tfa.metrics.F1Score(num_classes=4, average=\"micro\", threshold = 0.5)])\n","# base_model.load_weights(params.checkpoint_restore_path)\n","\n","'''set up check point & early stopping'''\n","callback_checkpints = tf.keras.callbacks.ModelCheckpoint(filepath= params.checkpoint_path, monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=True, mode='max',\n","                                                         save_freq='epoch',options=None)\n","callback_earlystop = AccEarlyStop(val_acc_base=params.early_stop_base_line)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Note: default Xception not includes top and has imagenet weights. It is not a trainable model in ADModelBuilder. Please setup trainable layers in setup_Xception function based on the \"Layer Number\"\n","Model: \"Xception_ADModel\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","tensor (InputLayer)          [(None, 100, 100, 3)]     0         \n","_________________________________________________________________\n","xception (Functional)        (None, 3, 3, 2048)        20861480  \n","_________________________________________________________________\n","flatten_3 (Flatten)          (None, 18432)             0         \n","_________________________________________________________________\n","dropout_6 (Dropout)          (None, 18432)             0         \n","_________________________________________________________________\n","dense_6 (Dense)              (None, 32)                589856    \n","_________________________________________________________________\n","batch_normalization_19 (Batc (None, 32)                128       \n","_________________________________________________________________\n","leaky_re_lu_3 (LeakyReLU)    (None, 32)                0         \n","_________________________________________________________________\n","dropout_7 (Dropout)          (None, 32)                0         \n","_________________________________________________________________\n","dense_7 (Dense)              (None, 4)                 132       \n","=================================================================\n","Total params: 21,451,596\n","Trainable params: 590,052\n","Non-trainable params: 20,861,544\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jeuKRP8dCAAZ","executionInfo":{"status":"ok","timestamp":1619051652466,"user_tz":240,"elapsed":689806,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"296056e2-6511-41a7-83d7-6b5a0bc6fd8e"},"source":["'''train base model'''\n","history = base_model.fit(train_image_dataset,\n","                         validation_data= test_image_dataset,\n","                         callbacks = [callback_checkpints, callback_earlystop],\n","                         epochs=params.train_epoch,\n","                         verbose=1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/30\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py:595: UserWarning: Input dict contained keys ['NL_nbr_0_id', 'NL_nbr_0_tensor', 'NL_nbr_0_weight', 'NL_nbr_1_id', 'NL_nbr_1_tensor', 'NL_nbr_1_weight', 'NL_nbr_2_id', 'NL_nbr_2_tensor', 'NL_nbr_2_weight', 'NL_nbr_3_id', 'NL_nbr_3_tensor', 'NL_nbr_3_weight', 'NL_nbr_4_id', 'NL_nbr_4_tensor', 'NL_nbr_4_weight', 'id'] which did not match any model input. They will be ignored by the model.\n","  [n for n in tensors.keys() if n not in ref_input_names])\n"],"name":"stderr"},{"output_type":"stream","text":["    160/Unknown - 59s 124ms/step - loss: 1.1355 - accuracy: 0.5316 - auc: 0.7867 - f1_score: 0.4946"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py:595: UserWarning: Input dict contained keys ['id'] which did not match any model input. They will be ignored by the model.\n","  [n for n in tensors.keys() if n not in ref_input_names])\n"],"name":"stderr"},{"output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r160/160 [==============================] - 64s 156ms/step - loss: 1.1344 - accuracy: 0.5319 - auc: 0.7870 - f1_score: 0.4950 - val_loss: 1.1197 - val_accuracy: 0.4801 - val_auc: 0.7941 - val_f1_score: 0.4718\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.48006, saving model to /content/drive/MyDrive/AD Expriment II/Xception_model_checkpoints/Xception_model_weights\n","Epoch 2/30\n","160/160 [==============================] - 22s 129ms/step - loss: 0.7607 - accuracy: 0.6624 - auc: 0.8967 - f1_score: 0.6388 - val_loss: 1.1126 - val_accuracy: 0.5051 - val_auc: 0.7960 - val_f1_score: 0.4757\n","\n","Epoch 00002: val_accuracy improved from 0.48006 to 0.50508, saving model to /content/drive/MyDrive/AD Expriment II/Xception_model_checkpoints/Xception_model_weights\n","Epoch 3/30\n","160/160 [==============================] - 21s 130ms/step - loss: 0.6868 - accuracy: 0.7051 - auc: 0.9161 - f1_score: 0.6744 - val_loss: 0.9871 - val_accuracy: 0.5121 - val_auc: 0.8195 - val_f1_score: 0.4814\n","\n","Epoch 00003: val_accuracy improved from 0.50508 to 0.51212, saving model to /content/drive/MyDrive/AD Expriment II/Xception_model_checkpoints/Xception_model_weights\n","Epoch 4/30\n","160/160 [==============================] - 22s 131ms/step - loss: 0.6564 - accuracy: 0.7112 - auc: 0.9234 - f1_score: 0.6905 - val_loss: 0.9833 - val_accuracy: 0.5106 - val_auc: 0.8159 - val_f1_score: 0.4680\n","\n","Epoch 00004: val_accuracy did not improve from 0.51212\n","Epoch 5/30\n","160/160 [==============================] - 21s 129ms/step - loss: 0.6279 - accuracy: 0.7193 - auc: 0.9295 - f1_score: 0.7034 - val_loss: 1.1151 - val_accuracy: 0.5145 - val_auc: 0.8094 - val_f1_score: 0.4925\n","\n","Epoch 00005: val_accuracy improved from 0.51212 to 0.51446, saving model to /content/drive/MyDrive/AD Expriment II/Xception_model_checkpoints/Xception_model_weights\n","Epoch 6/30\n","160/160 [==============================] - 21s 131ms/step - loss: 0.6215 - accuracy: 0.7346 - auc: 0.9308 - f1_score: 0.7130 - val_loss: 1.0742 - val_accuracy: 0.5051 - val_auc: 0.8040 - val_f1_score: 0.4783\n","\n","Epoch 00006: val_accuracy did not improve from 0.51446\n","Epoch 7/30\n","160/160 [==============================] - 21s 129ms/step - loss: 0.6069 - accuracy: 0.7350 - auc: 0.9338 - f1_score: 0.7216 - val_loss: 1.1603 - val_accuracy: 0.5043 - val_auc: 0.8095 - val_f1_score: 0.4973\n","\n","Epoch 00007: val_accuracy did not improve from 0.51446\n","Epoch 8/30\n","160/160 [==============================] - 21s 128ms/step - loss: 0.5858 - accuracy: 0.7492 - auc: 0.9387 - f1_score: 0.7302 - val_loss: 1.0364 - val_accuracy: 0.5020 - val_auc: 0.8094 - val_f1_score: 0.4893\n","\n","Epoch 00008: val_accuracy did not improve from 0.51446\n","Epoch 9/30\n","160/160 [==============================] - 21s 130ms/step - loss: 0.5736 - accuracy: 0.7537 - auc: 0.9409 - f1_score: 0.7422 - val_loss: 1.0908 - val_accuracy: 0.4801 - val_auc: 0.7934 - val_f1_score: 0.4590\n","\n","Epoch 00009: val_accuracy did not improve from 0.51446\n","Epoch 10/30\n","160/160 [==============================] - 21s 129ms/step - loss: 0.5578 - accuracy: 0.7596 - auc: 0.9441 - f1_score: 0.7486 - val_loss: 1.0729 - val_accuracy: 0.4840 - val_auc: 0.7952 - val_f1_score: 0.4507\n","\n","Epoch 00010: val_accuracy did not improve from 0.51446\n","Epoch 11/30\n","160/160 [==============================] - 21s 129ms/step - loss: 0.5756 - accuracy: 0.7533 - auc: 0.9408 - f1_score: 0.7395 - val_loss: 1.0406 - val_accuracy: 0.4824 - val_auc: 0.8053 - val_f1_score: 0.4608\n","\n","Epoch 00011: val_accuracy did not improve from 0.51446\n","Epoch 12/30\n","160/160 [==============================] - 21s 130ms/step - loss: 0.5514 - accuracy: 0.7644 - auc: 0.9452 - f1_score: 0.7524 - val_loss: 1.1474 - val_accuracy: 0.4793 - val_auc: 0.7934 - val_f1_score: 0.4687\n","\n","Epoch 00012: val_accuracy did not improve from 0.51446\n","Epoch 13/30\n","160/160 [==============================] - 21s 130ms/step - loss: 0.5494 - accuracy: 0.7628 - auc: 0.9451 - f1_score: 0.7513 - val_loss: 1.0635 - val_accuracy: 0.4887 - val_auc: 0.8092 - val_f1_score: 0.4748\n","\n","Epoch 00013: val_accuracy did not improve from 0.51446\n","Epoch 14/30\n","160/160 [==============================] - 21s 130ms/step - loss: 0.5375 - accuracy: 0.7664 - auc: 0.9476 - f1_score: 0.7541 - val_loss: 1.0537 - val_accuracy: 0.4941 - val_auc: 0.8068 - val_f1_score: 0.4780\n","\n","Epoch 00014: val_accuracy did not improve from 0.51446\n","Epoch 15/30\n","160/160 [==============================] - 21s 129ms/step - loss: 0.5373 - accuracy: 0.7656 - auc: 0.9477 - f1_score: 0.7578 - val_loss: 1.0648 - val_accuracy: 0.4848 - val_auc: 0.8014 - val_f1_score: 0.4646\n","\n","Epoch 00015: val_accuracy did not improve from 0.51446\n","Epoch 16/30\n","160/160 [==============================] - 21s 130ms/step - loss: 0.5347 - accuracy: 0.7715 - auc: 0.9481 - f1_score: 0.7609 - val_loss: 1.1300 - val_accuracy: 0.5051 - val_auc: 0.8058 - val_f1_score: 0.4912\n","\n","Epoch 00016: val_accuracy did not improve from 0.51446\n","Epoch 17/30\n","160/160 [==============================] - 21s 130ms/step - loss: 0.5276 - accuracy: 0.7733 - auc: 0.9497 - f1_score: 0.7641 - val_loss: 1.0509 - val_accuracy: 0.5145 - val_auc: 0.8145 - val_f1_score: 0.4951\n","\n","Epoch 00017: val_accuracy did not improve from 0.51446\n","Epoch 18/30\n","160/160 [==============================] - 21s 129ms/step - loss: 0.5217 - accuracy: 0.7746 - auc: 0.9506 - f1_score: 0.7676 - val_loss: 1.1302 - val_accuracy: 0.5176 - val_auc: 0.8152 - val_f1_score: 0.5038\n","\n","Epoch 00018: val_accuracy improved from 0.51446 to 0.51759, saving model to /content/drive/MyDrive/AD Expriment II/Xception_model_checkpoints/Xception_model_weights\n","Epoch 19/30\n","160/160 [==============================] - 22s 131ms/step - loss: 0.5188 - accuracy: 0.7726 - auc: 0.9512 - f1_score: 0.7720 - val_loss: 1.1555 - val_accuracy: 0.4863 - val_auc: 0.7947 - val_f1_score: 0.4690\n","\n","Epoch 00019: val_accuracy did not improve from 0.51759\n","Epoch 20/30\n","160/160 [==============================] - 21s 129ms/step - loss: 0.5141 - accuracy: 0.7780 - auc: 0.9526 - f1_score: 0.7723 - val_loss: 1.1166 - val_accuracy: 0.5074 - val_auc: 0.8071 - val_f1_score: 0.5027\n","\n","Epoch 00020: val_accuracy did not improve from 0.51759\n","Epoch 21/30\n","160/160 [==============================] - 21s 128ms/step - loss: 0.5025 - accuracy: 0.7862 - auc: 0.9542 - f1_score: 0.7778 - val_loss: 1.1038 - val_accuracy: 0.4973 - val_auc: 0.8010 - val_f1_score: 0.4857\n","\n","Epoch 00021: val_accuracy did not improve from 0.51759\n","Epoch 22/30\n","160/160 [==============================] - 21s 129ms/step - loss: 0.5021 - accuracy: 0.7840 - auc: 0.9542 - f1_score: 0.7765 - val_loss: 1.0952 - val_accuracy: 0.4926 - val_auc: 0.8047 - val_f1_score: 0.4819\n","\n","Epoch 00022: val_accuracy did not improve from 0.51759\n","Epoch 23/30\n","160/160 [==============================] - 21s 130ms/step - loss: 0.5039 - accuracy: 0.7814 - auc: 0.9537 - f1_score: 0.7761 - val_loss: 1.1813 - val_accuracy: 0.5059 - val_auc: 0.7982 - val_f1_score: 0.4873\n","\n","Epoch 00023: val_accuracy did not improve from 0.51759\n","Epoch 24/30\n","160/160 [==============================] - 21s 129ms/step - loss: 0.4997 - accuracy: 0.7858 - auc: 0.9546 - f1_score: 0.7776 - val_loss: 1.1236 - val_accuracy: 0.5121 - val_auc: 0.8138 - val_f1_score: 0.5029\n","\n","Epoch 00024: val_accuracy did not improve from 0.51759\n","Epoch 25/30\n","160/160 [==============================] - 21s 129ms/step - loss: 0.5012 - accuracy: 0.7834 - auc: 0.9541 - f1_score: 0.7740 - val_loss: 1.1320 - val_accuracy: 0.4988 - val_auc: 0.8008 - val_f1_score: 0.4797\n","\n","Epoch 00025: val_accuracy did not improve from 0.51759\n","Epoch 26/30\n","160/160 [==============================] - 21s 130ms/step - loss: 0.5050 - accuracy: 0.7869 - auc: 0.9537 - f1_score: 0.7771 - val_loss: 1.1732 - val_accuracy: 0.5043 - val_auc: 0.8037 - val_f1_score: 0.4971\n","\n","Epoch 00026: val_accuracy did not improve from 0.51759\n","Epoch 27/30\n","160/160 [==============================] - 21s 129ms/step - loss: 0.5037 - accuracy: 0.7771 - auc: 0.9539 - f1_score: 0.7763 - val_loss: 1.1897 - val_accuracy: 0.4801 - val_auc: 0.7917 - val_f1_score: 0.4729\n","\n","Epoch 00027: val_accuracy did not improve from 0.51759\n","Epoch 28/30\n","160/160 [==============================] - 21s 130ms/step - loss: 0.4810 - accuracy: 0.7930 - auc: 0.9581 - f1_score: 0.7871 - val_loss: 1.1932 - val_accuracy: 0.4871 - val_auc: 0.7945 - val_f1_score: 0.4712\n","\n","Epoch 00028: val_accuracy did not improve from 0.51759\n","Epoch 29/30\n","160/160 [==============================] - 21s 129ms/step - loss: 0.4840 - accuracy: 0.7907 - auc: 0.9573 - f1_score: 0.7868 - val_loss: 1.1414 - val_accuracy: 0.5129 - val_auc: 0.8106 - val_f1_score: 0.5037\n","\n","Epoch 00029: val_accuracy did not improve from 0.51759\n","Epoch 30/30\n","160/160 [==============================] - 21s 129ms/step - loss: 0.4820 - accuracy: 0.7950 - auc: 0.9576 - f1_score: 0.7920 - val_loss: 1.2004 - val_accuracy: 0.4918 - val_auc: 0.8015 - val_f1_score: 0.4774\n","\n","Epoch 00030: val_accuracy did not improve from 0.51759\n","Early stopping is not triggered, but best model is restored at epoch 18\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fgKrbn5a9iHy","executionInfo":{"status":"ok","timestamp":1619051666460,"user_tz":240,"elapsed":1905,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"9eacca80-1fd5-447b-b698-3fa5237f9cfa"},"source":["\"\"\"evaluate base_model\"\"\"\n","base_model.evaluate(test_image_dataset)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["20/20 [==============================] - 2s 55ms/step - loss: 1.1302 - accuracy: 0.5176 - auc: 0.8152 - f1_score: 0.5038\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[1.1301771402359009, 0.5175918936729431, 0.8152245283126831, 0.503753125667572]"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"9gq88In5AIgl"},"source":["'''plot confusion mat & calc acc for each label'''\n","test_image_dataset = NSLDataFormat.generate_test_tfr_image_tensor(path_list=test_tfr_list, \n","                                                                  batch_size=4000, \n","                                                                  size=(100,100),\n","                                                                  channels=3,\n","                                                                  shuffle=True)\n","data, data_label = iter(test_image_dataset).get_next()\n","data = data[\"tensor\"]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":396},"id":"bxUfsjJTxVsb","executionInfo":{"status":"ok","timestamp":1619051747785,"user_tz":240,"elapsed":3191,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"fb6c6ae4-ffb1-4808-aa40-10ed99f643da"},"source":["ADModelBuilder.plot_confusion_mat(model=base_model, data=data, data_label=data_label, title=\"Xception\", figsize=(6,6))"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x432 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"JLKaHrGqGEFw"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rTkxi38f9Han"},"source":["##5.2 Xception_NSL Model Training\n","### val_acc: 0.954,val_auc: 0.990,val_f1_score:0.954"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H0aFX2Bp9Gnx","executionInfo":{"status":"ok","timestamp":1619052003242,"user_tz":240,"elapsed":2241,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"9e2e6a16-3386-4767-eaa1-4f1c97b591d1"},"source":["'''define params'''\n","params.learning_rate=0.00005\n","params.restore_path = '/content/drive/MyDrive/AD Expriment II/Xception_model_checkpoints/Xception_nsl_weights'\n","params.checkpoint_path = '/content/drive/MyDrive/AD Expriment II/Xception_model_checkpoints/Xception_nsl_weights'\n","params.early_stop_base_line=0.70\n","params.train_epoch=50\n","params.nsl_multiplier = 0.005\n","params.nsl_sum_over_axis = -1\n","params.nsl_distance_type = nsl.configs.DistanceType.COSINE\n","\n","'''build base_model and restore from the last training'''\n","base_model = ADModelBuilder(input_shape=params.ad_base_model_input_shape, base_model='xception').setup_Xception(top_layers=3, middle_layers=None, bottom_layers=3).get_ADModel()\n","\n","'''build NSL model on top of base model'''\n","graph_reg_config = nsl.configs.make_graph_reg_config(neighbor_prefix=params.neighbor_prefix,\n","                                                     neighbor_weight_suffix=params.neighbor_weight_suffix,\n","                                                     max_neighbors= params.max_seed_nbr,\n","                                                     multiplier= params.nsl_multiplier,\n","                                                     distance_type= params.nsl_distance_type,\n","                                                     sum_over_axis=params.nsl_sum_over_axis)\n","graph_reg_model = nsl.keras.GraphRegularization(base_model,graph_reg_config)\n","graph_reg_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=params.learning_rate, amsgrad=True),\n","                        loss=tf.losses.CategoricalCrossentropy(),\n","                        metrics=[\"accuracy\",\"AUC\",tfa.metrics.F1Score(num_classes=4, average=\"micro\", threshold = 0.5)])\n","# graph_reg_model.load_weights(params.restore_path)\n","\n","'''set up check point & early stopping'''\n","callback_checkpoints = tf.keras.callbacks.ModelCheckpoint(filepath= params.checkpoint_path, monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=True, mode='max',\n","                                                         save_freq='epoch',options=None)\n","callback_earlystop = AccEarlyStop(val_acc_base=params.early_stop_base_line)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Note: default Xception not includes top and has imagenet weights. It is not a trainable model in ADModelBuilder. Please setup trainable layers in setup_Xception function based on the \"Layer Number\"\n","Model: \"xception\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_16 (InputLayer)           [(None, 100, 100, 3) 0                                            \n","__________________________________________________________________________________________________\n","block1_conv1 (Conv2D)           (None, 49, 49, 32)   864         input_16[0][0]                   \n","__________________________________________________________________________________________________\n","block1_conv1_bn (BatchNormaliza (None, 49, 49, 32)   128         block1_conv1[0][0]               \n","__________________________________________________________________________________________________\n","block1_conv1_act (Activation)   (None, 49, 49, 32)   0           block1_conv1_bn[0][0]            \n","__________________________________________________________________________________________________\n","block1_conv2 (Conv2D)           (None, 47, 47, 64)   18432       block1_conv1_act[0][0]           \n","__________________________________________________________________________________________________\n","block1_conv2_bn (BatchNormaliza (None, 47, 47, 64)   256         block1_conv2[0][0]               \n","__________________________________________________________________________________________________\n","block1_conv2_act (Activation)   (None, 47, 47, 64)   0           block1_conv2_bn[0][0]            \n","__________________________________________________________________________________________________\n","block2_sepconv1 (SeparableConv2 (None, 47, 47, 128)  8768        block1_conv2_act[0][0]           \n","__________________________________________________________________________________________________\n","block2_sepconv1_bn (BatchNormal (None, 47, 47, 128)  512         block2_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block2_sepconv2_act (Activation (None, 47, 47, 128)  0           block2_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block2_sepconv2 (SeparableConv2 (None, 47, 47, 128)  17536       block2_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block2_sepconv2_bn (BatchNormal (None, 47, 47, 128)  512         block2_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","conv2d_60 (Conv2D)              (None, 24, 24, 128)  8192        block1_conv2_act[0][0]           \n","__________________________________________________________________________________________________\n","block2_pool (MaxPooling2D)      (None, 24, 24, 128)  0           block2_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","batch_normalization_75 (BatchNo (None, 24, 24, 128)  512         conv2d_60[0][0]                  \n","__________________________________________________________________________________________________\n","add_180 (Add)                   (None, 24, 24, 128)  0           block2_pool[0][0]                \n","                                                                 batch_normalization_75[0][0]     \n","__________________________________________________________________________________________________\n","block3_sepconv1_act (Activation (None, 24, 24, 128)  0           add_180[0][0]                    \n","__________________________________________________________________________________________________\n","block3_sepconv1 (SeparableConv2 (None, 24, 24, 256)  33920       block3_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block3_sepconv1_bn (BatchNormal (None, 24, 24, 256)  1024        block3_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block3_sepconv2_act (Activation (None, 24, 24, 256)  0           block3_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block3_sepconv2 (SeparableConv2 (None, 24, 24, 256)  67840       block3_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block3_sepconv2_bn (BatchNormal (None, 24, 24, 256)  1024        block3_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","conv2d_61 (Conv2D)              (None, 12, 12, 256)  32768       add_180[0][0]                    \n","__________________________________________________________________________________________________\n","block3_pool (MaxPooling2D)      (None, 12, 12, 256)  0           block3_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","batch_normalization_76 (BatchNo (None, 12, 12, 256)  1024        conv2d_61[0][0]                  \n","__________________________________________________________________________________________________\n","add_181 (Add)                   (None, 12, 12, 256)  0           block3_pool[0][0]                \n","                                                                 batch_normalization_76[0][0]     \n","__________________________________________________________________________________________________\n","block4_sepconv1_act (Activation (None, 12, 12, 256)  0           add_181[0][0]                    \n","__________________________________________________________________________________________________\n","block4_sepconv1 (SeparableConv2 (None, 12, 12, 728)  188672      block4_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block4_sepconv1_bn (BatchNormal (None, 12, 12, 728)  2912        block4_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block4_sepconv2_act (Activation (None, 12, 12, 728)  0           block4_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block4_sepconv2 (SeparableConv2 (None, 12, 12, 728)  536536      block4_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block4_sepconv2_bn (BatchNormal (None, 12, 12, 728)  2912        block4_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","conv2d_62 (Conv2D)              (None, 6, 6, 728)    186368      add_181[0][0]                    \n","__________________________________________________________________________________________________\n","block4_pool (MaxPooling2D)      (None, 6, 6, 728)    0           block4_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","batch_normalization_77 (BatchNo (None, 6, 6, 728)    2912        conv2d_62[0][0]                  \n","__________________________________________________________________________________________________\n","add_182 (Add)                   (None, 6, 6, 728)    0           block4_pool[0][0]                \n","                                                                 batch_normalization_77[0][0]     \n","__________________________________________________________________________________________________\n","block5_sepconv1_act (Activation (None, 6, 6, 728)    0           add_182[0][0]                    \n","__________________________________________________________________________________________________\n","block5_sepconv1 (SeparableConv2 (None, 6, 6, 728)    536536      block5_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block5_sepconv1_bn (BatchNormal (None, 6, 6, 728)    2912        block5_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block5_sepconv2_act (Activation (None, 6, 6, 728)    0           block5_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block5_sepconv2 (SeparableConv2 (None, 6, 6, 728)    536536      block5_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block5_sepconv2_bn (BatchNormal (None, 6, 6, 728)    2912        block5_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","block5_sepconv3_act (Activation (None, 6, 6, 728)    0           block5_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","block5_sepconv3 (SeparableConv2 (None, 6, 6, 728)    536536      block5_sepconv3_act[0][0]        \n","__________________________________________________________________________________________________\n","block5_sepconv3_bn (BatchNormal (None, 6, 6, 728)    2912        block5_sepconv3[0][0]            \n","__________________________________________________________________________________________________\n","add_183 (Add)                   (None, 6, 6, 728)    0           block5_sepconv3_bn[0][0]         \n","                                                                 add_182[0][0]                    \n","__________________________________________________________________________________________________\n","block6_sepconv1_act (Activation (None, 6, 6, 728)    0           add_183[0][0]                    \n","__________________________________________________________________________________________________\n","block6_sepconv1 (SeparableConv2 (None, 6, 6, 728)    536536      block6_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block6_sepconv1_bn (BatchNormal (None, 6, 6, 728)    2912        block6_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block6_sepconv2_act (Activation (None, 6, 6, 728)    0           block6_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block6_sepconv2 (SeparableConv2 (None, 6, 6, 728)    536536      block6_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block6_sepconv2_bn (BatchNormal (None, 6, 6, 728)    2912        block6_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","block6_sepconv3_act (Activation (None, 6, 6, 728)    0           block6_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","block6_sepconv3 (SeparableConv2 (None, 6, 6, 728)    536536      block6_sepconv3_act[0][0]        \n","__________________________________________________________________________________________________\n","block6_sepconv3_bn (BatchNormal (None, 6, 6, 728)    2912        block6_sepconv3[0][0]            \n","__________________________________________________________________________________________________\n","add_184 (Add)                   (None, 6, 6, 728)    0           block6_sepconv3_bn[0][0]         \n","                                                                 add_183[0][0]                    \n","__________________________________________________________________________________________________\n","block7_sepconv1_act (Activation (None, 6, 6, 728)    0           add_184[0][0]                    \n","__________________________________________________________________________________________________\n","block7_sepconv1 (SeparableConv2 (None, 6, 6, 728)    536536      block7_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block7_sepconv1_bn (BatchNormal (None, 6, 6, 728)    2912        block7_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block7_sepconv2_act (Activation (None, 6, 6, 728)    0           block7_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block7_sepconv2 (SeparableConv2 (None, 6, 6, 728)    536536      block7_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block7_sepconv2_bn (BatchNormal (None, 6, 6, 728)    2912        block7_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","block7_sepconv3_act (Activation (None, 6, 6, 728)    0           block7_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","block7_sepconv3 (SeparableConv2 (None, 6, 6, 728)    536536      block7_sepconv3_act[0][0]        \n","__________________________________________________________________________________________________\n","block7_sepconv3_bn (BatchNormal (None, 6, 6, 728)    2912        block7_sepconv3[0][0]            \n","__________________________________________________________________________________________________\n","add_185 (Add)                   (None, 6, 6, 728)    0           block7_sepconv3_bn[0][0]         \n","                                                                 add_184[0][0]                    \n","__________________________________________________________________________________________________\n","block8_sepconv1_act (Activation (None, 6, 6, 728)    0           add_185[0][0]                    \n","__________________________________________________________________________________________________\n","block8_sepconv1 (SeparableConv2 (None, 6, 6, 728)    536536      block8_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block8_sepconv1_bn (BatchNormal (None, 6, 6, 728)    2912        block8_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block8_sepconv2_act (Activation (None, 6, 6, 728)    0           block8_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block8_sepconv2 (SeparableConv2 (None, 6, 6, 728)    536536      block8_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block8_sepconv2_bn (BatchNormal (None, 6, 6, 728)    2912        block8_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","block8_sepconv3_act (Activation (None, 6, 6, 728)    0           block8_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","block8_sepconv3 (SeparableConv2 (None, 6, 6, 728)    536536      block8_sepconv3_act[0][0]        \n","__________________________________________________________________________________________________\n","block8_sepconv3_bn (BatchNormal (None, 6, 6, 728)    2912        block8_sepconv3[0][0]            \n","__________________________________________________________________________________________________\n","add_186 (Add)                   (None, 6, 6, 728)    0           block8_sepconv3_bn[0][0]         \n","                                                                 add_185[0][0]                    \n","__________________________________________________________________________________________________\n","block9_sepconv1_act (Activation (None, 6, 6, 728)    0           add_186[0][0]                    \n","__________________________________________________________________________________________________\n","block9_sepconv1 (SeparableConv2 (None, 6, 6, 728)    536536      block9_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block9_sepconv1_bn (BatchNormal (None, 6, 6, 728)    2912        block9_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block9_sepconv2_act (Activation (None, 6, 6, 728)    0           block9_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block9_sepconv2 (SeparableConv2 (None, 6, 6, 728)    536536      block9_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block9_sepconv2_bn (BatchNormal (None, 6, 6, 728)    2912        block9_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","block9_sepconv3_act (Activation (None, 6, 6, 728)    0           block9_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","block9_sepconv3 (SeparableConv2 (None, 6, 6, 728)    536536      block9_sepconv3_act[0][0]        \n","__________________________________________________________________________________________________\n","block9_sepconv3_bn (BatchNormal (None, 6, 6, 728)    2912        block9_sepconv3[0][0]            \n","__________________________________________________________________________________________________\n","add_187 (Add)                   (None, 6, 6, 728)    0           block9_sepconv3_bn[0][0]         \n","                                                                 add_186[0][0]                    \n","__________________________________________________________________________________________________\n","block10_sepconv1_act (Activatio (None, 6, 6, 728)    0           add_187[0][0]                    \n","__________________________________________________________________________________________________\n","block10_sepconv1 (SeparableConv (None, 6, 6, 728)    536536      block10_sepconv1_act[0][0]       \n","__________________________________________________________________________________________________\n","block10_sepconv1_bn (BatchNorma (None, 6, 6, 728)    2912        block10_sepconv1[0][0]           \n","__________________________________________________________________________________________________\n","block10_sepconv2_act (Activatio (None, 6, 6, 728)    0           block10_sepconv1_bn[0][0]        \n","__________________________________________________________________________________________________\n","block10_sepconv2 (SeparableConv (None, 6, 6, 728)    536536      block10_sepconv2_act[0][0]       \n","__________________________________________________________________________________________________\n","block10_sepconv2_bn (BatchNorma (None, 6, 6, 728)    2912        block10_sepconv2[0][0]           \n","__________________________________________________________________________________________________\n","block10_sepconv3_act (Activatio (None, 6, 6, 728)    0           block10_sepconv2_bn[0][0]        \n","__________________________________________________________________________________________________\n","block10_sepconv3 (SeparableConv (None, 6, 6, 728)    536536      block10_sepconv3_act[0][0]       \n","__________________________________________________________________________________________________\n","block10_sepconv3_bn (BatchNorma (None, 6, 6, 728)    2912        block10_sepconv3[0][0]           \n","__________________________________________________________________________________________________\n","add_188 (Add)                   (None, 6, 6, 728)    0           block10_sepconv3_bn[0][0]        \n","                                                                 add_187[0][0]                    \n","__________________________________________________________________________________________________\n","block11_sepconv1_act (Activatio (None, 6, 6, 728)    0           add_188[0][0]                    \n","__________________________________________________________________________________________________\n","block11_sepconv1 (SeparableConv (None, 6, 6, 728)    536536      block11_sepconv1_act[0][0]       \n","__________________________________________________________________________________________________\n","block11_sepconv1_bn (BatchNorma (None, 6, 6, 728)    2912        block11_sepconv1[0][0]           \n","__________________________________________________________________________________________________\n","block11_sepconv2_act (Activatio (None, 6, 6, 728)    0           block11_sepconv1_bn[0][0]        \n","__________________________________________________________________________________________________\n","block11_sepconv2 (SeparableConv (None, 6, 6, 728)    536536      block11_sepconv2_act[0][0]       \n","__________________________________________________________________________________________________\n","block11_sepconv2_bn (BatchNorma (None, 6, 6, 728)    2912        block11_sepconv2[0][0]           \n","__________________________________________________________________________________________________\n","block11_sepconv3_act (Activatio (None, 6, 6, 728)    0           block11_sepconv2_bn[0][0]        \n","__________________________________________________________________________________________________\n","block11_sepconv3 (SeparableConv (None, 6, 6, 728)    536536      block11_sepconv3_act[0][0]       \n","__________________________________________________________________________________________________\n","block11_sepconv3_bn (BatchNorma (None, 6, 6, 728)    2912        block11_sepconv3[0][0]           \n","__________________________________________________________________________________________________\n","add_189 (Add)                   (None, 6, 6, 728)    0           block11_sepconv3_bn[0][0]        \n","                                                                 add_188[0][0]                    \n","__________________________________________________________________________________________________\n","block12_sepconv1_act (Activatio (None, 6, 6, 728)    0           add_189[0][0]                    \n","__________________________________________________________________________________________________\n","block12_sepconv1 (SeparableConv (None, 6, 6, 728)    536536      block12_sepconv1_act[0][0]       \n","__________________________________________________________________________________________________\n","block12_sepconv1_bn (BatchNorma (None, 6, 6, 728)    2912        block12_sepconv1[0][0]           \n","__________________________________________________________________________________________________\n","block12_sepconv2_act (Activatio (None, 6, 6, 728)    0           block12_sepconv1_bn[0][0]        \n","__________________________________________________________________________________________________\n","block12_sepconv2 (SeparableConv (None, 6, 6, 728)    536536      block12_sepconv2_act[0][0]       \n","__________________________________________________________________________________________________\n","block12_sepconv2_bn (BatchNorma (None, 6, 6, 728)    2912        block12_sepconv2[0][0]           \n","__________________________________________________________________________________________________\n","block12_sepconv3_act (Activatio (None, 6, 6, 728)    0           block12_sepconv2_bn[0][0]        \n","__________________________________________________________________________________________________\n","block12_sepconv3 (SeparableConv (None, 6, 6, 728)    536536      block12_sepconv3_act[0][0]       \n","__________________________________________________________________________________________________\n","block12_sepconv3_bn (BatchNorma (None, 6, 6, 728)    2912        block12_sepconv3[0][0]           \n","__________________________________________________________________________________________________\n","add_190 (Add)                   (None, 6, 6, 728)    0           block12_sepconv3_bn[0][0]        \n","                                                                 add_189[0][0]                    \n","__________________________________________________________________________________________________\n","block13_sepconv1_act (Activatio (None, 6, 6, 728)    0           add_190[0][0]                    \n","__________________________________________________________________________________________________\n","block13_sepconv1 (SeparableConv (None, 6, 6, 728)    536536      block13_sepconv1_act[0][0]       \n","__________________________________________________________________________________________________\n","block13_sepconv1_bn (BatchNorma (None, 6, 6, 728)    2912        block13_sepconv1[0][0]           \n","__________________________________________________________________________________________________\n","block13_sepconv2_act (Activatio (None, 6, 6, 728)    0           block13_sepconv1_bn[0][0]        \n","__________________________________________________________________________________________________\n","block13_sepconv2 (SeparableConv (None, 6, 6, 1024)   752024      block13_sepconv2_act[0][0]       \n","__________________________________________________________________________________________________\n","block13_sepconv2_bn (BatchNorma (None, 6, 6, 1024)   4096        block13_sepconv2[0][0]           \n","__________________________________________________________________________________________________\n","conv2d_63 (Conv2D)              (None, 3, 3, 1024)   745472      add_190[0][0]                    \n","__________________________________________________________________________________________________\n","block13_pool (MaxPooling2D)     (None, 3, 3, 1024)   0           block13_sepconv2_bn[0][0]        \n","__________________________________________________________________________________________________\n","batch_normalization_78 (BatchNo (None, 3, 3, 1024)   4096        conv2d_63[0][0]                  \n","__________________________________________________________________________________________________\n","add_191 (Add)                   (None, 3, 3, 1024)   0           block13_pool[0][0]               \n","                                                                 batch_normalization_78[0][0]     \n","__________________________________________________________________________________________________\n","block14_sepconv1 (SeparableConv (None, 3, 3, 1536)   1582080     add_191[0][0]                    \n","__________________________________________________________________________________________________\n","block14_sepconv1_bn (BatchNorma (None, 3, 3, 1536)   6144        block14_sepconv1[0][0]           \n","__________________________________________________________________________________________________\n","block14_sepconv1_act (Activatio (None, 3, 3, 1536)   0           block14_sepconv1_bn[0][0]        \n","__________________________________________________________________________________________________\n","block14_sepconv2 (SeparableConv (None, 3, 3, 2048)   3159552     block14_sepconv1_act[0][0]       \n","__________________________________________________________________________________________________\n","block14_sepconv2_bn (BatchNorma (None, 3, 3, 2048)   8192        block14_sepconv2[0][0]           \n","__________________________________________________________________________________________________\n","block14_sepconv2_act (Activatio (None, 3, 3, 2048)   0           block14_sepconv2_bn[0][0]        \n","==================================================================================================\n","Total params: 20,861,480\n","Trainable params: 3,164,576\n","Non-trainable params: 17,696,904\n","__________________________________________________________________________________________________\n","Model: \"Xception_ADModel\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","tensor (InputLayer)          [(None, 100, 100, 3)]     0         \n","_________________________________________________________________\n","xception (Functional)        (None, 3, 3, 2048)        20861480  \n","_________________________________________________________________\n","flatten_15 (Flatten)         (None, 18432)             0         \n","_________________________________________________________________\n","dropout_30 (Dropout)         (None, 18432)             0         \n","_________________________________________________________________\n","dense_30 (Dense)             (None, 32)                589856    \n","_________________________________________________________________\n","batch_normalization_79 (Batc (None, 32)                128       \n","_________________________________________________________________\n","leaky_re_lu_15 (LeakyReLU)   (None, 32)                0         \n","_________________________________________________________________\n","dropout_31 (Dropout)         (None, 32)                0         \n","_________________________________________________________________\n","dense_31 (Dense)             (None, 4)                 132       \n","=================================================================\n","Total params: 21,451,596\n","Trainable params: 3,754,628\n","Non-trainable params: 17,696,968\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZixNdkut9Gpr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619059116363,"user_tz":240,"elapsed":7105445,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"8c0bd2cc-a601-438e-c8ce-896a64e6e7eb"},"source":["'''train the nsl model'''\n","graph_reg_history = graph_reg_model.fit(train_image_dataset, \n","                                        validation_data=test_image_dataset,\n","                                        callbacks = [callback_checkpoints, callback_earlystop],\n","                                        epochs=params.train_epoch,\n","                                        verbose=1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/50\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py:595: UserWarning: Input dict contained keys ['id'] which did not match any model input. They will be ignored by the model.\n","  [n for n in tensors.keys() if n not in ref_input_names])\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/GraphRegularization/graph_loss/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/GraphRegularization/graph_loss/Reshape:0\", shape=(None, 4), dtype=float32), dense_shape=Tensor(\"gradient_tape/GraphRegularization/graph_loss/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"shape. This may consume a large amount of memory.\" % value)\n"],"name":"stderr"},{"output_type":"stream","text":["160/160 [==============================] - 168s 971ms/step - loss: 1.4634 - accuracy: 0.4121 - auc: 0.6750 - f1_score: 0.3626 - scaled_graph_loss: 0.0015 - val_loss: 1.0589 - val_accuracy: 0.5004 - val_auc: 0.7897 - val_f1_score: 0.4334\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.50039, saving model to /content/drive/MyDrive/AD Expriment II/Xception_model_checkpoints/Xception_nsl_weights\n","Epoch 2/50\n","160/160 [==============================] - 141s 875ms/step - loss: 0.9879 - accuracy: 0.5918 - auc: 0.8337 - f1_score: 0.5533 - scaled_graph_loss: 0.0011 - val_loss: 1.0661 - val_accuracy: 0.5012 - val_auc: 0.8020 - val_f1_score: 0.4663\n","\n","Epoch 00002: val_accuracy improved from 0.50039 to 0.50117, saving model to /content/drive/MyDrive/AD Expriment II/Xception_model_checkpoints/Xception_nsl_weights\n","Epoch 3/50\n","160/160 [==============================] - 141s 877ms/step - loss: 0.8619 - accuracy: 0.6412 - auc: 0.8714 - f1_score: 0.6066 - scaled_graph_loss: 9.6428e-04 - val_loss: 1.0264 - val_accuracy: 0.5137 - val_auc: 0.8091 - val_f1_score: 0.4601\n","\n","Epoch 00003: val_accuracy improved from 0.50117 to 0.51368, saving model to /content/drive/MyDrive/AD Expriment II/Xception_model_checkpoints/Xception_nsl_weights\n","Epoch 4/50\n","160/160 [==============================] - 141s 875ms/step - loss: 0.7695 - accuracy: 0.6761 - auc: 0.8979 - f1_score: 0.6508 - scaled_graph_loss: 8.9362e-04 - val_loss: 0.9739 - val_accuracy: 0.5332 - val_auc: 0.8262 - val_f1_score: 0.4811\n","\n","Epoch 00004: val_accuracy improved from 0.51368 to 0.53323, saving model to /content/drive/MyDrive/AD Expriment II/Xception_model_checkpoints/Xception_nsl_weights\n","Epoch 5/50\n","160/160 [==============================] - 141s 877ms/step - loss: 0.7073 - accuracy: 0.7140 - auc: 0.9144 - f1_score: 0.6848 - scaled_graph_loss: 8.3649e-04 - val_loss: 0.9782 - val_accuracy: 0.5450 - val_auc: 0.8284 - val_f1_score: 0.5023\n","\n","Epoch 00005: val_accuracy improved from 0.53323 to 0.54496, saving model to /content/drive/MyDrive/AD Expriment II/Xception_model_checkpoints/Xception_nsl_weights\n","Epoch 6/50\n","160/160 [==============================] - 141s 878ms/step - loss: 0.6589 - accuracy: 0.7343 - auc: 0.9261 - f1_score: 0.7082 - scaled_graph_loss: 7.9607e-04 - val_loss: 0.9882 - val_accuracy: 0.5481 - val_auc: 0.8290 - val_f1_score: 0.5103\n","\n","Epoch 00006: val_accuracy improved from 0.54496 to 0.54808, saving model to /content/drive/MyDrive/AD Expriment II/Xception_model_checkpoints/Xception_nsl_weights\n","Epoch 7/50\n","160/160 [==============================] - 141s 877ms/step - loss: 0.6142 - accuracy: 0.7509 - auc: 0.9359 - f1_score: 0.7294 - scaled_graph_loss: 7.6319e-04 - val_loss: 1.0209 - val_accuracy: 0.5442 - val_auc: 0.8267 - val_f1_score: 0.5166\n","\n","Epoch 00007: val_accuracy did not improve from 0.54808\n","Epoch 8/50\n","160/160 [==============================] - 141s 878ms/step - loss: 0.5621 - accuracy: 0.7778 - auc: 0.9472 - f1_score: 0.7572 - scaled_graph_loss: 7.2783e-04 - val_loss: 0.9672 - val_accuracy: 0.5668 - val_auc: 0.8348 - val_f1_score: 0.5155\n","\n","Epoch 00008: val_accuracy improved from 0.54808 to 0.56685, saving model to /content/drive/MyDrive/AD Expriment II/Xception_model_checkpoints/Xception_nsl_weights\n","Epoch 9/50\n","160/160 [==============================] - 141s 877ms/step - loss: 0.5497 - accuracy: 0.7828 - auc: 0.9491 - f1_score: 0.7665 - scaled_graph_loss: 7.1611e-04 - val_loss: 0.9538 - val_accuracy: 0.5653 - val_auc: 0.8397 - val_f1_score: 0.5355\n","\n","Epoch 00009: val_accuracy did not improve from 0.56685\n","Epoch 10/50\n","160/160 [==============================] - 141s 880ms/step - loss: 0.4906 - accuracy: 0.8129 - auc: 0.9608 - f1_score: 0.7990 - scaled_graph_loss: 6.6411e-04 - val_loss: 1.0067 - val_accuracy: 0.5700 - val_auc: 0.8311 - val_f1_score: 0.5398\n","\n","Epoch 00010: val_accuracy improved from 0.56685 to 0.56998, saving model to /content/drive/MyDrive/AD Expriment II/Xception_model_checkpoints/Xception_nsl_weights\n","Epoch 11/50\n","160/160 [==============================] - 141s 878ms/step - loss: 0.4570 - accuracy: 0.8294 - auc: 0.9668 - f1_score: 0.8172 - scaled_graph_loss: 6.4552e-04 - val_loss: 1.1561 - val_accuracy: 0.5473 - val_auc: 0.8187 - val_f1_score: 0.5260\n","\n","Epoch 00011: val_accuracy did not improve from 0.56998\n","Epoch 12/50\n","160/160 [==============================] - 141s 877ms/step - loss: 0.4377 - accuracy: 0.8356 - auc: 0.9694 - f1_score: 0.8261 - scaled_graph_loss: 6.1958e-04 - val_loss: 1.1113 - val_accuracy: 0.5637 - val_auc: 0.8239 - val_f1_score: 0.5371\n","\n","Epoch 00012: val_accuracy did not improve from 0.56998\n","Epoch 13/50\n","160/160 [==============================] - 141s 878ms/step - loss: 0.4013 - accuracy: 0.8573 - auc: 0.9749 - f1_score: 0.8438 - scaled_graph_loss: 5.9139e-04 - val_loss: 1.0840 - val_accuracy: 0.5794 - val_auc: 0.8237 - val_f1_score: 0.5565\n","\n","Epoch 00013: val_accuracy improved from 0.56998 to 0.57936, saving model to /content/drive/MyDrive/AD Expriment II/Xception_model_checkpoints/Xception_nsl_weights\n","Epoch 14/50\n","160/160 [==============================] - 141s 877ms/step - loss: 0.3790 - accuracy: 0.8619 - auc: 0.9783 - f1_score: 0.8565 - scaled_graph_loss: 5.7066e-04 - val_loss: 1.1406 - val_accuracy: 0.5700 - val_auc: 0.8256 - val_f1_score: 0.5567\n","\n","Epoch 00014: val_accuracy did not improve from 0.57936\n","Epoch 15/50\n","160/160 [==============================] - 141s 879ms/step - loss: 0.3513 - accuracy: 0.8794 - auc: 0.9815 - f1_score: 0.8688 - scaled_graph_loss: 5.4345e-04 - val_loss: 1.1307 - val_accuracy: 0.5754 - val_auc: 0.8236 - val_f1_score: 0.5619\n","\n","Epoch 00015: val_accuracy did not improve from 0.57936\n","Epoch 16/50\n","160/160 [==============================] - 141s 877ms/step - loss: 0.3245 - accuracy: 0.8949 - auc: 0.9850 - f1_score: 0.8867 - scaled_graph_loss: 5.0930e-04 - val_loss: 1.1096 - val_accuracy: 0.5723 - val_auc: 0.8330 - val_f1_score: 0.5660\n","\n","Epoch 00016: val_accuracy did not improve from 0.57936\n","Epoch 17/50\n","160/160 [==============================] - 141s 879ms/step - loss: 0.3103 - accuracy: 0.9010 - auc: 0.9865 - f1_score: 0.8914 - scaled_graph_loss: 4.9261e-04 - val_loss: 1.1866 - val_accuracy: 0.5754 - val_auc: 0.8224 - val_f1_score: 0.5697\n","\n","Epoch 00017: val_accuracy did not improve from 0.57936\n","Epoch 18/50\n","160/160 [==============================] - 141s 879ms/step - loss: 0.2781 - accuracy: 0.9154 - auc: 0.9898 - f1_score: 0.9075 - scaled_graph_loss: 4.4833e-04 - val_loss: 1.2080 - val_accuracy: 0.5895 - val_auc: 0.8239 - val_f1_score: 0.5791\n","\n","Epoch 00018: val_accuracy improved from 0.57936 to 0.58952, saving model to /content/drive/MyDrive/AD Expriment II/Xception_model_checkpoints/Xception_nsl_weights\n","Epoch 19/50\n","160/160 [==============================] - 141s 879ms/step - loss: 0.2693 - accuracy: 0.9187 - auc: 0.9906 - f1_score: 0.9108 - scaled_graph_loss: 4.3839e-04 - val_loss: 1.2167 - val_accuracy: 0.5833 - val_auc: 0.8229 - val_f1_score: 0.5735\n","\n","Epoch 00019: val_accuracy did not improve from 0.58952\n","Epoch 20/50\n","160/160 [==============================] - 141s 880ms/step - loss: 0.2590 - accuracy: 0.9222 - auc: 0.9914 - f1_score: 0.9161 - scaled_graph_loss: 4.1882e-04 - val_loss: 1.2298 - val_accuracy: 0.5794 - val_auc: 0.8281 - val_f1_score: 0.5697\n","\n","Epoch 00020: val_accuracy did not improve from 0.58952\n","Epoch 21/50\n","160/160 [==============================] - 141s 879ms/step - loss: 0.2415 - accuracy: 0.9284 - auc: 0.9928 - f1_score: 0.9231 - scaled_graph_loss: 3.8886e-04 - val_loss: 1.2368 - val_accuracy: 0.5801 - val_auc: 0.8221 - val_f1_score: 0.5693\n","\n","Epoch 00021: val_accuracy did not improve from 0.58952\n","Epoch 22/50\n","160/160 [==============================] - 141s 879ms/step - loss: 0.2185 - accuracy: 0.9372 - auc: 0.9947 - f1_score: 0.9328 - scaled_graph_loss: 3.7599e-04 - val_loss: 1.1762 - val_accuracy: 0.5911 - val_auc: 0.8280 - val_f1_score: 0.5732\n","\n","Epoch 00022: val_accuracy improved from 0.58952 to 0.59109, saving model to /content/drive/MyDrive/AD Expriment II/Xception_model_checkpoints/Xception_nsl_weights\n","Epoch 23/50\n","160/160 [==============================] - 141s 879ms/step - loss: 0.2064 - accuracy: 0.9461 - auc: 0.9953 - f1_score: 0.9398 - scaled_graph_loss: 3.4460e-04 - val_loss: 1.2672 - val_accuracy: 0.5880 - val_auc: 0.8249 - val_f1_score: 0.5805\n","\n","Epoch 00023: val_accuracy did not improve from 0.59109\n","Epoch 24/50\n","160/160 [==============================] - 141s 880ms/step - loss: 0.1926 - accuracy: 0.9515 - auc: 0.9958 - f1_score: 0.9474 - scaled_graph_loss: 3.2350e-04 - val_loss: 1.3513 - val_accuracy: 0.5833 - val_auc: 0.8142 - val_f1_score: 0.5802\n","\n","Epoch 00024: val_accuracy did not improve from 0.59109\n","Epoch 25/50\n","160/160 [==============================] - 141s 878ms/step - loss: 0.1768 - accuracy: 0.9565 - auc: 0.9971 - f1_score: 0.9520 - scaled_graph_loss: 2.9356e-04 - val_loss: 1.3422 - val_accuracy: 0.5958 - val_auc: 0.8203 - val_f1_score: 0.5791\n","\n","Epoch 00025: val_accuracy improved from 0.59109 to 0.59578, saving model to /content/drive/MyDrive/AD Expriment II/Xception_model_checkpoints/Xception_nsl_weights\n","Epoch 26/50\n","160/160 [==============================] - 141s 879ms/step - loss: 0.1771 - accuracy: 0.9555 - auc: 0.9967 - f1_score: 0.9519 - scaled_graph_loss: 2.8776e-04 - val_loss: 1.2291 - val_accuracy: 0.5934 - val_auc: 0.8315 - val_f1_score: 0.5893\n","\n","Epoch 00026: val_accuracy did not improve from 0.59578\n","Epoch 27/50\n","160/160 [==============================] - 141s 877ms/step - loss: 0.1593 - accuracy: 0.9615 - auc: 0.9977 - f1_score: 0.9590 - scaled_graph_loss: 2.6439e-04 - val_loss: 1.3709 - val_accuracy: 0.5911 - val_auc: 0.8246 - val_f1_score: 0.5835\n","\n","Epoch 00027: val_accuracy did not improve from 0.59578\n","Epoch 28/50\n","160/160 [==============================] - 141s 877ms/step - loss: 0.1524 - accuracy: 0.9671 - auc: 0.9979 - f1_score: 0.9629 - scaled_graph_loss: 2.5117e-04 - val_loss: 1.3777 - val_accuracy: 0.5942 - val_auc: 0.8191 - val_f1_score: 0.5890\n","\n","Epoch 00028: val_accuracy did not improve from 0.59578\n","Epoch 29/50\n","160/160 [==============================] - 141s 879ms/step - loss: 0.1419 - accuracy: 0.9694 - auc: 0.9986 - f1_score: 0.9661 - scaled_graph_loss: 2.2606e-04 - val_loss: 1.3453 - val_accuracy: 0.6091 - val_auc: 0.8217 - val_f1_score: 0.5997\n","\n","Epoch 00029: val_accuracy improved from 0.59578 to 0.60907, saving model to /content/drive/MyDrive/AD Expriment II/Xception_model_checkpoints/Xception_nsl_weights\n","Epoch 30/50\n","160/160 [==============================] - 141s 876ms/step - loss: 0.1428 - accuracy: 0.9694 - auc: 0.9981 - f1_score: 0.9663 - scaled_graph_loss: 2.2761e-04 - val_loss: 1.3108 - val_accuracy: 0.6028 - val_auc: 0.8268 - val_f1_score: 0.5952\n","\n","Epoch 00030: val_accuracy did not improve from 0.60907\n","Epoch 31/50\n","160/160 [==============================] - 141s 878ms/step - loss: 0.1353 - accuracy: 0.9696 - auc: 0.9985 - f1_score: 0.9674 - scaled_graph_loss: 2.1900e-04 - val_loss: 1.3639 - val_accuracy: 0.5997 - val_auc: 0.8246 - val_f1_score: 0.5973\n","\n","Epoch 00031: val_accuracy did not improve from 0.60907\n","Epoch 32/50\n","160/160 [==============================] - 141s 877ms/step - loss: 0.1289 - accuracy: 0.9751 - auc: 0.9985 - f1_score: 0.9726 - scaled_graph_loss: 2.0439e-04 - val_loss: 1.3946 - val_accuracy: 0.5973 - val_auc: 0.8203 - val_f1_score: 0.5936\n","\n","Epoch 00032: val_accuracy did not improve from 0.60907\n","Epoch 33/50\n","160/160 [==============================] - 141s 879ms/step - loss: 0.1234 - accuracy: 0.9751 - auc: 0.9987 - f1_score: 0.9722 - scaled_graph_loss: 1.8513e-04 - val_loss: 1.4695 - val_accuracy: 0.6059 - val_auc: 0.8151 - val_f1_score: 0.5918\n","\n","Epoch 00033: val_accuracy did not improve from 0.60907\n","Epoch 34/50\n","160/160 [==============================] - 141s 880ms/step - loss: 0.1201 - accuracy: 0.9740 - auc: 0.9989 - f1_score: 0.9726 - scaled_graph_loss: 1.8723e-04 - val_loss: 1.4127 - val_accuracy: 0.5973 - val_auc: 0.8168 - val_f1_score: 0.5917\n","\n","Epoch 00034: val_accuracy did not improve from 0.60907\n","Epoch 35/50\n","160/160 [==============================] - 141s 879ms/step - loss: 0.1113 - accuracy: 0.9815 - auc: 0.9993 - f1_score: 0.9801 - scaled_graph_loss: 1.6876e-04 - val_loss: 1.5292 - val_accuracy: 0.6075 - val_auc: 0.8153 - val_f1_score: 0.5988\n","\n","Epoch 00035: val_accuracy did not improve from 0.60907\n","Epoch 36/50\n","160/160 [==============================] - 141s 879ms/step - loss: 0.1074 - accuracy: 0.9781 - auc: 0.9989 - f1_score: 0.9772 - scaled_graph_loss: 1.6189e-04 - val_loss: 1.4242 - val_accuracy: 0.6153 - val_auc: 0.8221 - val_f1_score: 0.6111\n","\n","Epoch 00036: val_accuracy improved from 0.60907 to 0.61532, saving model to /content/drive/MyDrive/AD Expriment II/Xception_model_checkpoints/Xception_nsl_weights\n","Epoch 37/50\n","160/160 [==============================] - 141s 877ms/step - loss: 0.0993 - accuracy: 0.9831 - auc: 0.9995 - f1_score: 0.9808 - scaled_graph_loss: 1.5028e-04 - val_loss: 1.4335 - val_accuracy: 0.5981 - val_auc: 0.8170 - val_f1_score: 0.5968\n","\n","Epoch 00037: val_accuracy did not improve from 0.61532\n","Epoch 38/50\n","160/160 [==============================] - 141s 877ms/step - loss: 0.0946 - accuracy: 0.9847 - auc: 0.9996 - f1_score: 0.9833 - scaled_graph_loss: 1.4025e-04 - val_loss: 1.3888 - val_accuracy: 0.5981 - val_auc: 0.8239 - val_f1_score: 0.5962\n","\n","Epoch 00038: val_accuracy did not improve from 0.61532\n","Epoch 39/50\n","160/160 [==============================] - 141s 879ms/step - loss: 0.0925 - accuracy: 0.9830 - auc: 0.9995 - f1_score: 0.9821 - scaled_graph_loss: 1.3993e-04 - val_loss: 1.4400 - val_accuracy: 0.6091 - val_auc: 0.8240 - val_f1_score: 0.6038\n","\n","Epoch 00039: val_accuracy did not improve from 0.61532\n","Epoch 40/50\n","160/160 [==============================] - 141s 880ms/step - loss: 0.0922 - accuracy: 0.9829 - auc: 0.9994 - f1_score: 0.9819 - scaled_graph_loss: 1.3738e-04 - val_loss: 1.4568 - val_accuracy: 0.6138 - val_auc: 0.8277 - val_f1_score: 0.6070\n","\n","Epoch 00040: val_accuracy did not improve from 0.61532\n","Epoch 41/50\n","160/160 [==============================] - 141s 880ms/step - loss: 0.0839 - accuracy: 0.9856 - auc: 0.9996 - f1_score: 0.9844 - scaled_graph_loss: 1.2289e-04 - val_loss: 1.4380 - val_accuracy: 0.6169 - val_auc: 0.8265 - val_f1_score: 0.6151\n","\n","Epoch 00041: val_accuracy improved from 0.61532 to 0.61689, saving model to /content/drive/MyDrive/AD Expriment II/Xception_model_checkpoints/Xception_nsl_weights\n","Epoch 42/50\n","160/160 [==============================] - 141s 880ms/step - loss: 0.0793 - accuracy: 0.9876 - auc: 0.9997 - f1_score: 0.9865 - scaled_graph_loss: 1.1642e-04 - val_loss: 1.4873 - val_accuracy: 0.5934 - val_auc: 0.8178 - val_f1_score: 0.5895\n","\n","Epoch 00042: val_accuracy did not improve from 0.61689\n","Epoch 43/50\n","160/160 [==============================] - 141s 880ms/step - loss: 0.0784 - accuracy: 0.9881 - auc: 0.9998 - f1_score: 0.9871 - scaled_graph_loss: 1.0787e-04 - val_loss: 1.5329 - val_accuracy: 0.5981 - val_auc: 0.8186 - val_f1_score: 0.5985\n","\n","Epoch 00043: val_accuracy did not improve from 0.61689\n","Epoch 44/50\n","160/160 [==============================] - 141s 880ms/step - loss: 0.0730 - accuracy: 0.9911 - auc: 0.9998 - f1_score: 0.9891 - scaled_graph_loss: 9.9067e-05 - val_loss: 1.4969 - val_accuracy: 0.6036 - val_auc: 0.8214 - val_f1_score: 0.6006\n","\n","Epoch 00044: val_accuracy did not improve from 0.61689\n","Epoch 45/50\n","160/160 [==============================] - 141s 878ms/step - loss: 0.0726 - accuracy: 0.9901 - auc: 0.9997 - f1_score: 0.9890 - scaled_graph_loss: 9.9525e-05 - val_loss: 1.5150 - val_accuracy: 0.6169 - val_auc: 0.8213 - val_f1_score: 0.6078\n","\n","Epoch 00045: val_accuracy did not improve from 0.61689\n","Epoch 46/50\n","160/160 [==============================] - 141s 879ms/step - loss: 0.0726 - accuracy: 0.9885 - auc: 0.9997 - f1_score: 0.9872 - scaled_graph_loss: 1.0410e-04 - val_loss: 1.4851 - val_accuracy: 0.6028 - val_auc: 0.8206 - val_f1_score: 0.6005\n","\n","Epoch 00046: val_accuracy did not improve from 0.61689\n","Epoch 47/50\n","160/160 [==============================] - 141s 880ms/step - loss: 0.0705 - accuracy: 0.9900 - auc: 0.9998 - f1_score: 0.9880 - scaled_graph_loss: 9.7563e-05 - val_loss: 1.4929 - val_accuracy: 0.6099 - val_auc: 0.8225 - val_f1_score: 0.6047\n","\n","Epoch 00047: val_accuracy did not improve from 0.61689\n","Epoch 48/50\n","160/160 [==============================] - 141s 879ms/step - loss: 0.0633 - accuracy: 0.9930 - auc: 0.9999 - f1_score: 0.9919 - scaled_graph_loss: 8.4820e-05 - val_loss: 1.5579 - val_accuracy: 0.6052 - val_auc: 0.8165 - val_f1_score: 0.6036\n","\n","Epoch 00048: val_accuracy did not improve from 0.61689\n","Epoch 49/50\n","160/160 [==============================] - 141s 878ms/step - loss: 0.0668 - accuracy: 0.9897 - auc: 0.9998 - f1_score: 0.9889 - scaled_graph_loss: 9.2208e-05 - val_loss: 1.5332 - val_accuracy: 0.6083 - val_auc: 0.8193 - val_f1_score: 0.6018\n","\n","Epoch 00049: val_accuracy did not improve from 0.61689\n","Epoch 50/50\n","160/160 [==============================] - 141s 878ms/step - loss: 0.0634 - accuracy: 0.9899 - auc: 0.9998 - f1_score: 0.9898 - scaled_graph_loss: 8.7171e-05 - val_loss: 1.6266 - val_accuracy: 0.6091 - val_auc: 0.8157 - val_f1_score: 0.6061\n","\n","Epoch 00050: val_accuracy did not improve from 0.61689\n","Early stopping is not triggered, but best model is restored at epoch 41\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ANAJY8pCAk-_"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QBplEqmx1pm1"},"source":["##5.3 Xception_NSL Model top 10 and bottom 5 layers tunning\n","### val_acc: 0.61, val_auc: 0.83, val_f1_score: 0.61\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qn_OeO8Pag-J","executionInfo":{"status":"ok","timestamp":1619177229570,"user_tz":240,"elapsed":8026,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"0dad2afd-1c7a-4d0d-9515-416c8cbddfa0"},"source":["'''define params'''\n","params.learning_rate=0.00001\n","params.restore_path = '/content/drive/MyDrive/AD Expriment II/Xception_model_checkpoints/Xception_nsl_weights'\n","params.checkpoint_path = '/content/drive/MyDrive/AD Expriment II/Xception_model_checkpoints/Xception_nsl_weights'\n","params.early_stop_base_line=0.80\n","params.train_epoch=50\n","params.nsl_multiplier = 0.0005\n","params.nsl_sum_over_axis = -1\n","params.nsl_distance_type = nsl.configs.DistanceType.COSINE\n","\n","'''build base_model and restore from the last training'''\n","base_model = ADModelBuilder(input_shape=params.ad_base_model_input_shape, base_model='xception').setup_Xception(top_layers=10, middle_layers=None, bottom_layers=5).get_ADModel()\n","\n","'''build NSL model on top of base model'''\n","graph_reg_config = nsl.configs.make_graph_reg_config(neighbor_prefix=params.neighbor_prefix,\n","                                                     neighbor_weight_suffix=params.neighbor_weight_suffix,\n","                                                     max_neighbors= params.max_seed_nbr,\n","                                                     multiplier= params.nsl_multiplier,\n","                                                     distance_type= params.nsl_distance_type,\n","                                                     sum_over_axis=params.nsl_sum_over_axis)\n","graph_reg_model = nsl.keras.GraphRegularization(base_model,graph_reg_config)\n","graph_reg_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=params.learning_rate, amsgrad=True),\n","                        loss=tf.losses.CategoricalCrossentropy(),\n","                        metrics=[\"accuracy\",\"AUC\",tfa.metrics.F1Score(num_classes=4, average=\"micro\", threshold = 0.5)])\n","graph_reg_model.load_weights(params.restore_path)\n","\n","'''set up check point & early stopping'''\n","callback_checkpoints = tf.keras.callbacks.ModelCheckpoint(filepath= params.checkpoint_path, monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=True, mode='max',\n","                                                         save_freq='epoch',options=None)\n","callback_earlystop = AccEarlyStop(val_acc_base=params.early_stop_base_line)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Note: default Xception not includes top and has imagenet weights. It is not a trainable model in ADModelBuilder. Please setup trainable layers in setup_Xception function based on the \"Layer Number\"\n","Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n","83689472/83683744 [==============================] - 0s 0us/step\n","Model: \"xception\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 100, 100, 3) 0                                            \n","__________________________________________________________________________________________________\n","block1_conv1 (Conv2D)           (None, 49, 49, 32)   864         input_1[0][0]                    \n","__________________________________________________________________________________________________\n","block1_conv1_bn (BatchNormaliza (None, 49, 49, 32)   128         block1_conv1[0][0]               \n","__________________________________________________________________________________________________\n","block1_conv1_act (Activation)   (None, 49, 49, 32)   0           block1_conv1_bn[0][0]            \n","__________________________________________________________________________________________________\n","block1_conv2 (Conv2D)           (None, 47, 47, 64)   18432       block1_conv1_act[0][0]           \n","__________________________________________________________________________________________________\n","block1_conv2_bn (BatchNormaliza (None, 47, 47, 64)   256         block1_conv2[0][0]               \n","__________________________________________________________________________________________________\n","block1_conv2_act (Activation)   (None, 47, 47, 64)   0           block1_conv2_bn[0][0]            \n","__________________________________________________________________________________________________\n","block2_sepconv1 (SeparableConv2 (None, 47, 47, 128)  8768        block1_conv2_act[0][0]           \n","__________________________________________________________________________________________________\n","block2_sepconv1_bn (BatchNormal (None, 47, 47, 128)  512         block2_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block2_sepconv2_act (Activation (None, 47, 47, 128)  0           block2_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block2_sepconv2 (SeparableConv2 (None, 47, 47, 128)  17536       block2_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block2_sepconv2_bn (BatchNormal (None, 47, 47, 128)  512         block2_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","conv2d (Conv2D)                 (None, 24, 24, 128)  8192        block1_conv2_act[0][0]           \n","__________________________________________________________________________________________________\n","block2_pool (MaxPooling2D)      (None, 24, 24, 128)  0           block2_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","batch_normalization (BatchNorma (None, 24, 24, 128)  512         conv2d[0][0]                     \n","__________________________________________________________________________________________________\n","add (Add)                       (None, 24, 24, 128)  0           block2_pool[0][0]                \n","                                                                 batch_normalization[0][0]        \n","__________________________________________________________________________________________________\n","block3_sepconv1_act (Activation (None, 24, 24, 128)  0           add[0][0]                        \n","__________________________________________________________________________________________________\n","block3_sepconv1 (SeparableConv2 (None, 24, 24, 256)  33920       block3_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block3_sepconv1_bn (BatchNormal (None, 24, 24, 256)  1024        block3_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block3_sepconv2_act (Activation (None, 24, 24, 256)  0           block3_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block3_sepconv2 (SeparableConv2 (None, 24, 24, 256)  67840       block3_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block3_sepconv2_bn (BatchNormal (None, 24, 24, 256)  1024        block3_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","conv2d_1 (Conv2D)               (None, 12, 12, 256)  32768       add[0][0]                        \n","__________________________________________________________________________________________________\n","block3_pool (MaxPooling2D)      (None, 12, 12, 256)  0           block3_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","batch_normalization_1 (BatchNor (None, 12, 12, 256)  1024        conv2d_1[0][0]                   \n","__________________________________________________________________________________________________\n","add_1 (Add)                     (None, 12, 12, 256)  0           block3_pool[0][0]                \n","                                                                 batch_normalization_1[0][0]      \n","__________________________________________________________________________________________________\n","block4_sepconv1_act (Activation (None, 12, 12, 256)  0           add_1[0][0]                      \n","__________________________________________________________________________________________________\n","block4_sepconv1 (SeparableConv2 (None, 12, 12, 728)  188672      block4_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block4_sepconv1_bn (BatchNormal (None, 12, 12, 728)  2912        block4_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block4_sepconv2_act (Activation (None, 12, 12, 728)  0           block4_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block4_sepconv2 (SeparableConv2 (None, 12, 12, 728)  536536      block4_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block4_sepconv2_bn (BatchNormal (None, 12, 12, 728)  2912        block4_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","conv2d_2 (Conv2D)               (None, 6, 6, 728)    186368      add_1[0][0]                      \n","__________________________________________________________________________________________________\n","block4_pool (MaxPooling2D)      (None, 6, 6, 728)    0           block4_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","batch_normalization_2 (BatchNor (None, 6, 6, 728)    2912        conv2d_2[0][0]                   \n","__________________________________________________________________________________________________\n","add_2 (Add)                     (None, 6, 6, 728)    0           block4_pool[0][0]                \n","                                                                 batch_normalization_2[0][0]      \n","__________________________________________________________________________________________________\n","block5_sepconv1_act (Activation (None, 6, 6, 728)    0           add_2[0][0]                      \n","__________________________________________________________________________________________________\n","block5_sepconv1 (SeparableConv2 (None, 6, 6, 728)    536536      block5_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block5_sepconv1_bn (BatchNormal (None, 6, 6, 728)    2912        block5_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block5_sepconv2_act (Activation (None, 6, 6, 728)    0           block5_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block5_sepconv2 (SeparableConv2 (None, 6, 6, 728)    536536      block5_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block5_sepconv2_bn (BatchNormal (None, 6, 6, 728)    2912        block5_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","block5_sepconv3_act (Activation (None, 6, 6, 728)    0           block5_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","block5_sepconv3 (SeparableConv2 (None, 6, 6, 728)    536536      block5_sepconv3_act[0][0]        \n","__________________________________________________________________________________________________\n","block5_sepconv3_bn (BatchNormal (None, 6, 6, 728)    2912        block5_sepconv3[0][0]            \n","__________________________________________________________________________________________________\n","add_3 (Add)                     (None, 6, 6, 728)    0           block5_sepconv3_bn[0][0]         \n","                                                                 add_2[0][0]                      \n","__________________________________________________________________________________________________\n","block6_sepconv1_act (Activation (None, 6, 6, 728)    0           add_3[0][0]                      \n","__________________________________________________________________________________________________\n","block6_sepconv1 (SeparableConv2 (None, 6, 6, 728)    536536      block6_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block6_sepconv1_bn (BatchNormal (None, 6, 6, 728)    2912        block6_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block6_sepconv2_act (Activation (None, 6, 6, 728)    0           block6_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block6_sepconv2 (SeparableConv2 (None, 6, 6, 728)    536536      block6_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block6_sepconv2_bn (BatchNormal (None, 6, 6, 728)    2912        block6_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","block6_sepconv3_act (Activation (None, 6, 6, 728)    0           block6_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","block6_sepconv3 (SeparableConv2 (None, 6, 6, 728)    536536      block6_sepconv3_act[0][0]        \n","__________________________________________________________________________________________________\n","block6_sepconv3_bn (BatchNormal (None, 6, 6, 728)    2912        block6_sepconv3[0][0]            \n","__________________________________________________________________________________________________\n","add_4 (Add)                     (None, 6, 6, 728)    0           block6_sepconv3_bn[0][0]         \n","                                                                 add_3[0][0]                      \n","__________________________________________________________________________________________________\n","block7_sepconv1_act (Activation (None, 6, 6, 728)    0           add_4[0][0]                      \n","__________________________________________________________________________________________________\n","block7_sepconv1 (SeparableConv2 (None, 6, 6, 728)    536536      block7_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block7_sepconv1_bn (BatchNormal (None, 6, 6, 728)    2912        block7_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block7_sepconv2_act (Activation (None, 6, 6, 728)    0           block7_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block7_sepconv2 (SeparableConv2 (None, 6, 6, 728)    536536      block7_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block7_sepconv2_bn (BatchNormal (None, 6, 6, 728)    2912        block7_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","block7_sepconv3_act (Activation (None, 6, 6, 728)    0           block7_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","block7_sepconv3 (SeparableConv2 (None, 6, 6, 728)    536536      block7_sepconv3_act[0][0]        \n","__________________________________________________________________________________________________\n","block7_sepconv3_bn (BatchNormal (None, 6, 6, 728)    2912        block7_sepconv3[0][0]            \n","__________________________________________________________________________________________________\n","add_5 (Add)                     (None, 6, 6, 728)    0           block7_sepconv3_bn[0][0]         \n","                                                                 add_4[0][0]                      \n","__________________________________________________________________________________________________\n","block8_sepconv1_act (Activation (None, 6, 6, 728)    0           add_5[0][0]                      \n","__________________________________________________________________________________________________\n","block8_sepconv1 (SeparableConv2 (None, 6, 6, 728)    536536      block8_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block8_sepconv1_bn (BatchNormal (None, 6, 6, 728)    2912        block8_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block8_sepconv2_act (Activation (None, 6, 6, 728)    0           block8_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block8_sepconv2 (SeparableConv2 (None, 6, 6, 728)    536536      block8_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block8_sepconv2_bn (BatchNormal (None, 6, 6, 728)    2912        block8_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","block8_sepconv3_act (Activation (None, 6, 6, 728)    0           block8_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","block8_sepconv3 (SeparableConv2 (None, 6, 6, 728)    536536      block8_sepconv3_act[0][0]        \n","__________________________________________________________________________________________________\n","block8_sepconv3_bn (BatchNormal (None, 6, 6, 728)    2912        block8_sepconv3[0][0]            \n","__________________________________________________________________________________________________\n","add_6 (Add)                     (None, 6, 6, 728)    0           block8_sepconv3_bn[0][0]         \n","                                                                 add_5[0][0]                      \n","__________________________________________________________________________________________________\n","block9_sepconv1_act (Activation (None, 6, 6, 728)    0           add_6[0][0]                      \n","__________________________________________________________________________________________________\n","block9_sepconv1 (SeparableConv2 (None, 6, 6, 728)    536536      block9_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block9_sepconv1_bn (BatchNormal (None, 6, 6, 728)    2912        block9_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block9_sepconv2_act (Activation (None, 6, 6, 728)    0           block9_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block9_sepconv2 (SeparableConv2 (None, 6, 6, 728)    536536      block9_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block9_sepconv2_bn (BatchNormal (None, 6, 6, 728)    2912        block9_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","block9_sepconv3_act (Activation (None, 6, 6, 728)    0           block9_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","block9_sepconv3 (SeparableConv2 (None, 6, 6, 728)    536536      block9_sepconv3_act[0][0]        \n","__________________________________________________________________________________________________\n","block9_sepconv3_bn (BatchNormal (None, 6, 6, 728)    2912        block9_sepconv3[0][0]            \n","__________________________________________________________________________________________________\n","add_7 (Add)                     (None, 6, 6, 728)    0           block9_sepconv3_bn[0][0]         \n","                                                                 add_6[0][0]                      \n","__________________________________________________________________________________________________\n","block10_sepconv1_act (Activatio (None, 6, 6, 728)    0           add_7[0][0]                      \n","__________________________________________________________________________________________________\n","block10_sepconv1 (SeparableConv (None, 6, 6, 728)    536536      block10_sepconv1_act[0][0]       \n","__________________________________________________________________________________________________\n","block10_sepconv1_bn (BatchNorma (None, 6, 6, 728)    2912        block10_sepconv1[0][0]           \n","__________________________________________________________________________________________________\n","block10_sepconv2_act (Activatio (None, 6, 6, 728)    0           block10_sepconv1_bn[0][0]        \n","__________________________________________________________________________________________________\n","block10_sepconv2 (SeparableConv (None, 6, 6, 728)    536536      block10_sepconv2_act[0][0]       \n","__________________________________________________________________________________________________\n","block10_sepconv2_bn (BatchNorma (None, 6, 6, 728)    2912        block10_sepconv2[0][0]           \n","__________________________________________________________________________________________________\n","block10_sepconv3_act (Activatio (None, 6, 6, 728)    0           block10_sepconv2_bn[0][0]        \n","__________________________________________________________________________________________________\n","block10_sepconv3 (SeparableConv (None, 6, 6, 728)    536536      block10_sepconv3_act[0][0]       \n","__________________________________________________________________________________________________\n","block10_sepconv3_bn (BatchNorma (None, 6, 6, 728)    2912        block10_sepconv3[0][0]           \n","__________________________________________________________________________________________________\n","add_8 (Add)                     (None, 6, 6, 728)    0           block10_sepconv3_bn[0][0]        \n","                                                                 add_7[0][0]                      \n","__________________________________________________________________________________________________\n","block11_sepconv1_act (Activatio (None, 6, 6, 728)    0           add_8[0][0]                      \n","__________________________________________________________________________________________________\n","block11_sepconv1 (SeparableConv (None, 6, 6, 728)    536536      block11_sepconv1_act[0][0]       \n","__________________________________________________________________________________________________\n","block11_sepconv1_bn (BatchNorma (None, 6, 6, 728)    2912        block11_sepconv1[0][0]           \n","__________________________________________________________________________________________________\n","block11_sepconv2_act (Activatio (None, 6, 6, 728)    0           block11_sepconv1_bn[0][0]        \n","__________________________________________________________________________________________________\n","block11_sepconv2 (SeparableConv (None, 6, 6, 728)    536536      block11_sepconv2_act[0][0]       \n","__________________________________________________________________________________________________\n","block11_sepconv2_bn (BatchNorma (None, 6, 6, 728)    2912        block11_sepconv2[0][0]           \n","__________________________________________________________________________________________________\n","block11_sepconv3_act (Activatio (None, 6, 6, 728)    0           block11_sepconv2_bn[0][0]        \n","__________________________________________________________________________________________________\n","block11_sepconv3 (SeparableConv (None, 6, 6, 728)    536536      block11_sepconv3_act[0][0]       \n","__________________________________________________________________________________________________\n","block11_sepconv3_bn (BatchNorma (None, 6, 6, 728)    2912        block11_sepconv3[0][0]           \n","__________________________________________________________________________________________________\n","add_9 (Add)                     (None, 6, 6, 728)    0           block11_sepconv3_bn[0][0]        \n","                                                                 add_8[0][0]                      \n","__________________________________________________________________________________________________\n","block12_sepconv1_act (Activatio (None, 6, 6, 728)    0           add_9[0][0]                      \n","__________________________________________________________________________________________________\n","block12_sepconv1 (SeparableConv (None, 6, 6, 728)    536536      block12_sepconv1_act[0][0]       \n","__________________________________________________________________________________________________\n","block12_sepconv1_bn (BatchNorma (None, 6, 6, 728)    2912        block12_sepconv1[0][0]           \n","__________________________________________________________________________________________________\n","block12_sepconv2_act (Activatio (None, 6, 6, 728)    0           block12_sepconv1_bn[0][0]        \n","__________________________________________________________________________________________________\n","block12_sepconv2 (SeparableConv (None, 6, 6, 728)    536536      block12_sepconv2_act[0][0]       \n","__________________________________________________________________________________________________\n","block12_sepconv2_bn (BatchNorma (None, 6, 6, 728)    2912        block12_sepconv2[0][0]           \n","__________________________________________________________________________________________________\n","block12_sepconv3_act (Activatio (None, 6, 6, 728)    0           block12_sepconv2_bn[0][0]        \n","__________________________________________________________________________________________________\n","block12_sepconv3 (SeparableConv (None, 6, 6, 728)    536536      block12_sepconv3_act[0][0]       \n","__________________________________________________________________________________________________\n","block12_sepconv3_bn (BatchNorma (None, 6, 6, 728)    2912        block12_sepconv3[0][0]           \n","__________________________________________________________________________________________________\n","add_10 (Add)                    (None, 6, 6, 728)    0           block12_sepconv3_bn[0][0]        \n","                                                                 add_9[0][0]                      \n","__________________________________________________________________________________________________\n","block13_sepconv1_act (Activatio (None, 6, 6, 728)    0           add_10[0][0]                     \n","__________________________________________________________________________________________________\n","block13_sepconv1 (SeparableConv (None, 6, 6, 728)    536536      block13_sepconv1_act[0][0]       \n","__________________________________________________________________________________________________\n","block13_sepconv1_bn (BatchNorma (None, 6, 6, 728)    2912        block13_sepconv1[0][0]           \n","__________________________________________________________________________________________________\n","block13_sepconv2_act (Activatio (None, 6, 6, 728)    0           block13_sepconv1_bn[0][0]        \n","__________________________________________________________________________________________________\n","block13_sepconv2 (SeparableConv (None, 6, 6, 1024)   752024      block13_sepconv2_act[0][0]       \n","__________________________________________________________________________________________________\n","block13_sepconv2_bn (BatchNorma (None, 6, 6, 1024)   4096        block13_sepconv2[0][0]           \n","__________________________________________________________________________________________________\n","conv2d_3 (Conv2D)               (None, 3, 3, 1024)   745472      add_10[0][0]                     \n","__________________________________________________________________________________________________\n","block13_pool (MaxPooling2D)     (None, 3, 3, 1024)   0           block13_sepconv2_bn[0][0]        \n","__________________________________________________________________________________________________\n","batch_normalization_3 (BatchNor (None, 3, 3, 1024)   4096        conv2d_3[0][0]                   \n","__________________________________________________________________________________________________\n","add_11 (Add)                    (None, 3, 3, 1024)   0           block13_pool[0][0]               \n","                                                                 batch_normalization_3[0][0]      \n","__________________________________________________________________________________________________\n","block14_sepconv1 (SeparableConv (None, 3, 3, 1536)   1582080     add_11[0][0]                     \n","__________________________________________________________________________________________________\n","block14_sepconv1_bn (BatchNorma (None, 3, 3, 1536)   6144        block14_sepconv1[0][0]           \n","__________________________________________________________________________________________________\n","block14_sepconv1_act (Activatio (None, 3, 3, 1536)   0           block14_sepconv1_bn[0][0]        \n","__________________________________________________________________________________________________\n","block14_sepconv2 (SeparableConv (None, 3, 3, 2048)   3159552     block14_sepconv1_act[0][0]       \n","__________________________________________________________________________________________________\n","block14_sepconv2_bn (BatchNorma (None, 3, 3, 2048)   8192        block14_sepconv2[0][0]           \n","__________________________________________________________________________________________________\n","block14_sepconv2_act (Activatio (None, 3, 3, 2048)   0           block14_sepconv2_bn[0][0]        \n","==================================================================================================\n","Total params: 20,861,480\n","Trainable params: 3,195,232\n","Non-trainable params: 17,666,248\n","__________________________________________________________________________________________________\n","Model: \"Xception_ADModel\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","tensor (InputLayer)          [(None, 100, 100, 3)]     0         \n","_________________________________________________________________\n","xception (Functional)        (None, 3, 3, 2048)        20861480  \n","_________________________________________________________________\n","flatten (Flatten)            (None, 18432)             0         \n","_________________________________________________________________\n","dropout (Dropout)            (None, 18432)             0         \n","_________________________________________________________________\n","dense (Dense)                (None, 32)                589856    \n","_________________________________________________________________\n","batch_normalization_4 (Batch (None, 32)                128       \n","_________________________________________________________________\n","leaky_re_lu (LeakyReLU)      (None, 32)                0         \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 32)                0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 4)                 132       \n","=================================================================\n","Total params: 21,451,596\n","Trainable params: 3,785,284\n","Non-trainable params: 17,666,312\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TVbtWj9t1oqo","executionInfo":{"status":"ok","timestamp":1619185002662,"user_tz":240,"elapsed":7768997,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"d49b8841-a159-4483-bd5b-ea28019561d7"},"source":["'''train the nsl model'''\n","graph_reg_history = graph_reg_model.fit(train_image_dataset, \n","                                        validation_data=test_image_dataset,\n","                                        callbacks = [callback_checkpoints, callback_earlystop],\n","                                        epochs=params.train_epoch,\n","                                        verbose=1)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Epoch 1/50\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py:595: UserWarning: Input dict contained keys ['id'] which did not match any model input. They will be ignored by the model.\n","  [n for n in tensors.keys() if n not in ref_input_names])\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/GraphRegularization/graph_loss/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/GraphRegularization/graph_loss/Reshape:0\", shape=(None, 4), dtype=float32), dense_shape=Tensor(\"gradient_tape/GraphRegularization/graph_loss/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"shape. This may consume a large amount of memory.\" % value)\n"],"name":"stderr"},{"output_type":"stream","text":["160/160 [==============================] - 213s 998ms/step - loss: 0.1510 - accuracy: 0.9601 - auc: 0.9966 - f1_score: 0.9561 - scaled_graph_loss: 2.6864e-05 - val_loss: 1.3546 - val_accuracy: 0.6067 - val_auc: 0.8324 - val_f1_score: 0.9201\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.60672, saving model to /content/drive/MyDrive/AD Expriment II/Xception_model_checkpoints/Xception_nsl_weights\n","Epoch 2/50\n","160/160 [==============================] - 154s 959ms/step - loss: 0.1339 - accuracy: 0.9676 - auc: 0.9979 - f1_score: 0.9653 - scaled_graph_loss: 2.3016e-05 - val_loss: 1.3802 - val_accuracy: 0.5958 - val_auc: 0.8324 - val_f1_score: 0.5945\n","\n","Epoch 00002: val_accuracy did not improve from 0.60672\n","Epoch 3/50\n","160/160 [==============================] - 154s 961ms/step - loss: 0.1138 - accuracy: 0.9721 - auc: 0.9987 - f1_score: 0.9701 - scaled_graph_loss: 2.0502e-05 - val_loss: 1.3697 - val_accuracy: 0.5950 - val_auc: 0.8311 - val_f1_score: 0.5992\n","\n","Epoch 00003: val_accuracy did not improve from 0.60672\n","Epoch 4/50\n","160/160 [==============================] - 154s 959ms/step - loss: 0.1112 - accuracy: 0.9730 - auc: 0.9985 - f1_score: 0.9712 - scaled_graph_loss: 1.8968e-05 - val_loss: 1.4439 - val_accuracy: 0.6020 - val_auc: 0.8315 - val_f1_score: 0.6006\n","\n","Epoch 00004: val_accuracy did not improve from 0.60672\n","Epoch 5/50\n","160/160 [==============================] - 154s 959ms/step - loss: 0.1092 - accuracy: 0.9724 - auc: 0.9985 - f1_score: 0.9707 - scaled_graph_loss: 1.8353e-05 - val_loss: 1.3753 - val_accuracy: 0.6067 - val_auc: 0.8362 - val_f1_score: 0.6103\n","\n","Epoch 00005: val_accuracy did not improve from 0.60672\n","Epoch 6/50\n","160/160 [==============================] - 154s 957ms/step - loss: 0.0995 - accuracy: 0.9767 - auc: 0.9990 - f1_score: 0.9749 - scaled_graph_loss: 1.6293e-05 - val_loss: 1.4781 - val_accuracy: 0.6013 - val_auc: 0.8315 - val_f1_score: 0.6012\n","\n","Epoch 00006: val_accuracy did not improve from 0.60672\n","Epoch 7/50\n","160/160 [==============================] - 154s 957ms/step - loss: 0.0877 - accuracy: 0.9824 - auc: 0.9995 - f1_score: 0.9831 - scaled_graph_loss: 1.4082e-05 - val_loss: 1.4435 - val_accuracy: 0.6013 - val_auc: 0.8350 - val_f1_score: 0.6039\n","\n","Epoch 00007: val_accuracy did not improve from 0.60672\n","Epoch 8/50\n","160/160 [==============================] - 154s 961ms/step - loss: 0.0830 - accuracy: 0.9847 - auc: 0.9994 - f1_score: 0.9835 - scaled_graph_loss: 1.2581e-05 - val_loss: 1.4129 - val_accuracy: 0.6122 - val_auc: 0.8346 - val_f1_score: 0.6068\n","\n","Epoch 00008: val_accuracy improved from 0.60672 to 0.61220, saving model to /content/drive/MyDrive/AD Expriment II/Xception_model_checkpoints/Xception_nsl_weights\n","Epoch 9/50\n","160/160 [==============================] - 154s 956ms/step - loss: 0.0822 - accuracy: 0.9842 - auc: 0.9994 - f1_score: 0.9840 - scaled_graph_loss: 1.2497e-05 - val_loss: 1.4711 - val_accuracy: 0.6099 - val_auc: 0.8332 - val_f1_score: 0.6083\n","\n","Epoch 00009: val_accuracy did not improve from 0.61220\n","Epoch 10/50\n","160/160 [==============================] - 155s 962ms/step - loss: 0.0747 - accuracy: 0.9855 - auc: 0.9996 - f1_score: 0.9847 - scaled_graph_loss: 1.1670e-05 - val_loss: 1.4303 - val_accuracy: 0.6130 - val_auc: 0.8341 - val_f1_score: 0.6110\n","\n","Epoch 00010: val_accuracy improved from 0.61220 to 0.61298, saving model to /content/drive/MyDrive/AD Expriment II/Xception_model_checkpoints/Xception_nsl_weights\n","Epoch 11/50\n","160/160 [==============================] - 154s 957ms/step - loss: 0.0751 - accuracy: 0.9852 - auc: 0.9996 - f1_score: 0.9847 - scaled_graph_loss: 1.1474e-05 - val_loss: 1.4408 - val_accuracy: 0.6153 - val_auc: 0.8337 - val_f1_score: 0.6125\n","\n","Epoch 00011: val_accuracy improved from 0.61298 to 0.61532, saving model to /content/drive/MyDrive/AD Expriment II/Xception_model_checkpoints/Xception_nsl_weights\n","Epoch 12/50\n","160/160 [==============================] - 154s 957ms/step - loss: 0.0714 - accuracy: 0.9860 - auc: 0.9997 - f1_score: 0.9853 - scaled_graph_loss: 1.0441e-05 - val_loss: 1.4699 - val_accuracy: 0.6052 - val_auc: 0.8318 - val_f1_score: 0.6036\n","\n","Epoch 00012: val_accuracy did not improve from 0.61532\n","Epoch 13/50\n","160/160 [==============================] - 154s 958ms/step - loss: 0.0629 - accuracy: 0.9893 - auc: 0.9997 - f1_score: 0.9885 - scaled_graph_loss: 9.0081e-06 - val_loss: 1.3722 - val_accuracy: 0.6145 - val_auc: 0.8399 - val_f1_score: 0.6142\n","\n","Epoch 00013: val_accuracy did not improve from 0.61532\n","Epoch 14/50\n","160/160 [==============================] - 154s 956ms/step - loss: 0.0648 - accuracy: 0.9905 - auc: 0.9997 - f1_score: 0.9893 - scaled_graph_loss: 9.2442e-06 - val_loss: 1.4197 - val_accuracy: 0.6052 - val_auc: 0.8347 - val_f1_score: 0.6076\n","\n","Epoch 00014: val_accuracy did not improve from 0.61532\n","Epoch 15/50\n","160/160 [==============================] - 154s 957ms/step - loss: 0.0624 - accuracy: 0.9878 - auc: 0.9997 - f1_score: 0.9875 - scaled_graph_loss: 9.1610e-06 - val_loss: 1.4379 - val_accuracy: 0.6052 - val_auc: 0.8379 - val_f1_score: 0.6045\n","\n","Epoch 00015: val_accuracy did not improve from 0.61532\n","Epoch 16/50\n","160/160 [==============================] - 154s 956ms/step - loss: 0.0614 - accuracy: 0.9905 - auc: 0.9997 - f1_score: 0.9896 - scaled_graph_loss: 8.3893e-06 - val_loss: 1.4110 - val_accuracy: 0.6106 - val_auc: 0.8395 - val_f1_score: 0.6121\n","\n","Epoch 00016: val_accuracy did not improve from 0.61532\n","Epoch 17/50\n","160/160 [==============================] - 154s 957ms/step - loss: 0.0622 - accuracy: 0.9875 - auc: 0.9997 - f1_score: 0.9865 - scaled_graph_loss: 8.5934e-06 - val_loss: 1.4175 - val_accuracy: 0.5989 - val_auc: 0.8375 - val_f1_score: 0.6025\n","\n","Epoch 00017: val_accuracy did not improve from 0.61532\n","Epoch 18/50\n","160/160 [==============================] - 154s 958ms/step - loss: 0.0552 - accuracy: 0.9933 - auc: 0.9998 - f1_score: 0.9926 - scaled_graph_loss: 7.0414e-06 - val_loss: 1.4990 - val_accuracy: 0.6036 - val_auc: 0.8320 - val_f1_score: 0.6071\n","\n","Epoch 00018: val_accuracy did not improve from 0.61532\n","Epoch 19/50\n","160/160 [==============================] - 154s 957ms/step - loss: 0.0527 - accuracy: 0.9926 - auc: 0.9999 - f1_score: 0.9918 - scaled_graph_loss: 7.0697e-06 - val_loss: 1.4763 - val_accuracy: 0.6067 - val_auc: 0.8356 - val_f1_score: 0.6085\n","\n","Epoch 00019: val_accuracy did not improve from 0.61532\n","Epoch 20/50\n","160/160 [==============================] - 154s 957ms/step - loss: 0.0492 - accuracy: 0.9931 - auc: 0.9999 - f1_score: 0.9926 - scaled_graph_loss: 6.5153e-06 - val_loss: 1.4261 - val_accuracy: 0.6036 - val_auc: 0.8394 - val_f1_score: 0.6038\n","\n","Epoch 00020: val_accuracy did not improve from 0.61532\n","Epoch 21/50\n","160/160 [==============================] - 154s 958ms/step - loss: 0.0463 - accuracy: 0.9953 - auc: 0.9999 - f1_score: 0.9951 - scaled_graph_loss: 5.6123e-06 - val_loss: 1.5086 - val_accuracy: 0.6020 - val_auc: 0.8372 - val_f1_score: 0.6059\n","\n","Epoch 00021: val_accuracy did not improve from 0.61532\n","Epoch 22/50\n","160/160 [==============================] - 154s 956ms/step - loss: 0.0471 - accuracy: 0.9943 - auc: 0.9999 - f1_score: 0.9932 - scaled_graph_loss: 5.9186e-06 - val_loss: 1.5191 - val_accuracy: 0.6059 - val_auc: 0.8369 - val_f1_score: 0.6079\n","\n","Epoch 00022: val_accuracy did not improve from 0.61532\n","Epoch 23/50\n","160/160 [==============================] - 154s 958ms/step - loss: 0.0472 - accuracy: 0.9941 - auc: 0.9999 - f1_score: 0.9939 - scaled_graph_loss: 5.7337e-06 - val_loss: 1.5228 - val_accuracy: 0.6075 - val_auc: 0.8373 - val_f1_score: 0.6047\n","\n","Epoch 00023: val_accuracy did not improve from 0.61532\n","Epoch 24/50\n","160/160 [==============================] - 154s 958ms/step - loss: 0.0448 - accuracy: 0.9953 - auc: 0.9999 - f1_score: 0.9953 - scaled_graph_loss: 5.3292e-06 - val_loss: 1.6223 - val_accuracy: 0.6075 - val_auc: 0.8284 - val_f1_score: 0.6070\n","\n","Epoch 00024: val_accuracy did not improve from 0.61532\n","Epoch 25/50\n","160/160 [==============================] - 154s 957ms/step - loss: 0.0459 - accuracy: 0.9932 - auc: 0.9997 - f1_score: 0.9931 - scaled_graph_loss: 5.5499e-06 - val_loss: 1.5220 - val_accuracy: 0.6099 - val_auc: 0.8362 - val_f1_score: 0.6117\n","\n","Epoch 00025: val_accuracy did not improve from 0.61532\n","Epoch 26/50\n","160/160 [==============================] - 154s 957ms/step - loss: 0.0397 - accuracy: 0.9965 - auc: 0.9999 - f1_score: 0.9953 - scaled_graph_loss: 4.8538e-06 - val_loss: 1.5569 - val_accuracy: 0.6005 - val_auc: 0.8337 - val_f1_score: 0.6021\n","\n","Epoch 00026: val_accuracy did not improve from 0.61532\n","Epoch 27/50\n","160/160 [==============================] - 154s 959ms/step - loss: 0.0457 - accuracy: 0.9935 - auc: 0.9999 - f1_score: 0.9936 - scaled_graph_loss: 5.7839e-06 - val_loss: 1.5237 - val_accuracy: 0.6059 - val_auc: 0.8344 - val_f1_score: 0.6056\n","\n","Epoch 00027: val_accuracy did not improve from 0.61532\n","Epoch 28/50\n","160/160 [==============================] - 154s 958ms/step - loss: 0.0398 - accuracy: 0.9957 - auc: 0.9999 - f1_score: 0.9952 - scaled_graph_loss: 4.7612e-06 - val_loss: 1.5226 - val_accuracy: 0.6059 - val_auc: 0.8341 - val_f1_score: 0.6056\n","\n","Epoch 00028: val_accuracy did not improve from 0.61532\n","Epoch 29/50\n","160/160 [==============================] - 154s 959ms/step - loss: 0.0391 - accuracy: 0.9960 - auc: 0.9999 - f1_score: 0.9959 - scaled_graph_loss: 4.5027e-06 - val_loss: 1.5792 - val_accuracy: 0.6059 - val_auc: 0.8322 - val_f1_score: 0.6065\n","\n","Epoch 00029: val_accuracy did not improve from 0.61532\n","Epoch 30/50\n","160/160 [==============================] - 154s 958ms/step - loss: 0.0381 - accuracy: 0.9958 - auc: 0.9999 - f1_score: 0.9957 - scaled_graph_loss: 4.2961e-06 - val_loss: 1.6276 - val_accuracy: 0.6052 - val_auc: 0.8305 - val_f1_score: 0.6041\n","\n","Epoch 00030: val_accuracy did not improve from 0.61532\n","Epoch 31/50\n","160/160 [==============================] - 154s 957ms/step - loss: 0.0390 - accuracy: 0.9953 - auc: 0.9999 - f1_score: 0.9948 - scaled_graph_loss: 4.5837e-06 - val_loss: 1.6110 - val_accuracy: 0.6036 - val_auc: 0.8320 - val_f1_score: 0.6030\n","\n","Epoch 00031: val_accuracy did not improve from 0.61532\n","Epoch 32/50\n","160/160 [==============================] - 154s 957ms/step - loss: 0.0358 - accuracy: 0.9951 - auc: 1.0000 - f1_score: 0.9951 - scaled_graph_loss: 4.1893e-06 - val_loss: 1.6535 - val_accuracy: 0.5958 - val_auc: 0.8283 - val_f1_score: 0.5957\n","\n","Epoch 00032: val_accuracy did not improve from 0.61532\n","Epoch 33/50\n","160/160 [==============================] - 154s 956ms/step - loss: 0.0341 - accuracy: 0.9965 - auc: 1.0000 - f1_score: 0.9961 - scaled_graph_loss: 3.6500e-06 - val_loss: 1.6059 - val_accuracy: 0.6005 - val_auc: 0.8322 - val_f1_score: 0.5995\n","\n","Epoch 00033: val_accuracy did not improve from 0.61532\n","Epoch 34/50\n","160/160 [==============================] - 154s 957ms/step - loss: 0.0347 - accuracy: 0.9955 - auc: 1.0000 - f1_score: 0.9956 - scaled_graph_loss: 3.8465e-06 - val_loss: 1.5691 - val_accuracy: 0.6044 - val_auc: 0.8361 - val_f1_score: 0.6067\n","\n","Epoch 00034: val_accuracy did not improve from 0.61532\n","Epoch 35/50\n","160/160 [==============================] - 154s 958ms/step - loss: 0.0328 - accuracy: 0.9970 - auc: 1.0000 - f1_score: 0.9964 - scaled_graph_loss: 3.5662e-06 - val_loss: 1.6216 - val_accuracy: 0.6052 - val_auc: 0.8310 - val_f1_score: 0.6075\n","\n","Epoch 00035: val_accuracy did not improve from 0.61532\n","Epoch 36/50\n","160/160 [==============================] - 154s 960ms/step - loss: 0.0321 - accuracy: 0.9971 - auc: 1.0000 - f1_score: 0.9967 - scaled_graph_loss: 3.4434e-06 - val_loss: 1.5765 - val_accuracy: 0.6052 - val_auc: 0.8321 - val_f1_score: 0.6037\n","\n","Epoch 00036: val_accuracy did not improve from 0.61532\n","Epoch 37/50\n","160/160 [==============================] - 154s 959ms/step - loss: 0.0321 - accuracy: 0.9976 - auc: 1.0000 - f1_score: 0.9975 - scaled_graph_loss: 3.2144e-06 - val_loss: 1.5842 - val_accuracy: 0.6122 - val_auc: 0.8324 - val_f1_score: 0.6126\n","\n","Epoch 00037: val_accuracy did not improve from 0.61532\n","Epoch 38/50\n","160/160 [==============================] - 154s 961ms/step - loss: 0.0326 - accuracy: 0.9963 - auc: 0.9999 - f1_score: 0.9961 - scaled_graph_loss: 3.6527e-06 - val_loss: 1.6257 - val_accuracy: 0.6020 - val_auc: 0.8317 - val_f1_score: 0.6028\n","\n","Epoch 00038: val_accuracy did not improve from 0.61532\n","Epoch 39/50\n","160/160 [==============================] - 154s 958ms/step - loss: 0.0322 - accuracy: 0.9967 - auc: 1.0000 - f1_score: 0.9963 - scaled_graph_loss: 3.5076e-06 - val_loss: 1.7440 - val_accuracy: 0.5958 - val_auc: 0.8231 - val_f1_score: 0.5939\n","\n","Epoch 00039: val_accuracy did not improve from 0.61532\n","Epoch 40/50\n","160/160 [==============================] - 154s 961ms/step - loss: 0.0307 - accuracy: 0.9966 - auc: 1.0000 - f1_score: 0.9963 - scaled_graph_loss: 3.2556e-06 - val_loss: 1.6159 - val_accuracy: 0.6052 - val_auc: 0.8340 - val_f1_score: 0.6023\n","\n","Epoch 00040: val_accuracy did not improve from 0.61532\n","Epoch 41/50\n","160/160 [==============================] - 154s 958ms/step - loss: 0.0297 - accuracy: 0.9971 - auc: 1.0000 - f1_score: 0.9968 - scaled_graph_loss: 3.1234e-06 - val_loss: 1.6474 - val_accuracy: 0.6036 - val_auc: 0.8318 - val_f1_score: 0.6036\n","\n","Epoch 00041: val_accuracy did not improve from 0.61532\n","Epoch 42/50\n","160/160 [==============================] - 154s 959ms/step - loss: 0.0278 - accuracy: 0.9974 - auc: 1.0000 - f1_score: 0.9973 - scaled_graph_loss: 2.9979e-06 - val_loss: 1.5656 - val_accuracy: 0.6114 - val_auc: 0.8333 - val_f1_score: 0.6104\n","\n","Epoch 00042: val_accuracy did not improve from 0.61532\n","Epoch 43/50\n","160/160 [==============================] - 155s 962ms/step - loss: 0.0275 - accuracy: 0.9972 - auc: 1.0000 - f1_score: 0.9972 - scaled_graph_loss: 2.9722e-06 - val_loss: 1.6193 - val_accuracy: 0.6075 - val_auc: 0.8336 - val_f1_score: 0.6072\n","\n","Epoch 00043: val_accuracy did not improve from 0.61532\n","Epoch 44/50\n","160/160 [==============================] - 154s 958ms/step - loss: 0.0281 - accuracy: 0.9974 - auc: 1.0000 - f1_score: 0.9975 - scaled_graph_loss: 2.7472e-06 - val_loss: 1.6548 - val_accuracy: 0.5989 - val_auc: 0.8301 - val_f1_score: 0.5996\n","\n","Epoch 00044: val_accuracy did not improve from 0.61532\n","Epoch 45/50\n","160/160 [==============================] - 154s 958ms/step - loss: 0.0281 - accuracy: 0.9964 - auc: 1.0000 - f1_score: 0.9962 - scaled_graph_loss: 3.0228e-06 - val_loss: 1.6429 - val_accuracy: 0.6020 - val_auc: 0.8317 - val_f1_score: 0.6034\n","\n","Epoch 00045: val_accuracy did not improve from 0.61532\n","Epoch 46/50\n","160/160 [==============================] - 154s 959ms/step - loss: 0.0270 - accuracy: 0.9977 - auc: 1.0000 - f1_score: 0.9980 - scaled_graph_loss: 2.7333e-06 - val_loss: 1.6802 - val_accuracy: 0.6044 - val_auc: 0.8307 - val_f1_score: 0.6007\n","\n","Epoch 00046: val_accuracy did not improve from 0.61532\n","Epoch 47/50\n","160/160 [==============================] - 154s 959ms/step - loss: 0.0282 - accuracy: 0.9959 - auc: 1.0000 - f1_score: 0.9958 - scaled_graph_loss: 3.1641e-06 - val_loss: 1.6483 - val_accuracy: 0.6028 - val_auc: 0.8307 - val_f1_score: 0.6003\n","\n","Epoch 00047: val_accuracy did not improve from 0.61532\n","Epoch 48/50\n","160/160 [==============================] - 154s 961ms/step - loss: 0.0263 - accuracy: 0.9970 - auc: 1.0000 - f1_score: 0.9968 - scaled_graph_loss: 2.7640e-06 - val_loss: 1.6301 - val_accuracy: 0.6036 - val_auc: 0.8316 - val_f1_score: 0.6031\n","\n","Epoch 00048: val_accuracy did not improve from 0.61532\n","Epoch 49/50\n","160/160 [==============================] - 154s 961ms/step - loss: 0.0298 - accuracy: 0.9954 - auc: 1.0000 - f1_score: 0.9955 - scaled_graph_loss: 3.5037e-06 - val_loss: 1.6171 - val_accuracy: 0.6028 - val_auc: 0.8289 - val_f1_score: 0.6033\n","\n","Epoch 00049: val_accuracy did not improve from 0.61532\n","Epoch 50/50\n","160/160 [==============================] - 154s 957ms/step - loss: 0.0258 - accuracy: 0.9980 - auc: 1.0000 - f1_score: 0.9979 - scaled_graph_loss: 2.5475e-06 - val_loss: 1.6129 - val_accuracy: 0.6106 - val_auc: 0.8326 - val_f1_score: 0.6100\n","\n","Epoch 00050: val_accuracy did not improve from 0.61532\n","Early stopping is not triggered, but best model is restored at epoch 11\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oy7GjSCq9Gtw","executionInfo":{"status":"ok","timestamp":1619185017243,"user_tz":240,"elapsed":1913,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"ef61a62a-f535-459f-f668-53f030c697a3"},"source":["'''evaluate the model'''\n","graph_reg_model.evaluate(test_image_dataset)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["20/20 [==============================] - 2s 55ms/step - loss: 1.4408 - accuracy: 0.6153 - auc: 0.8337 - f1_score: 0.6125\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[1.4408372640609741,\n"," 0.6153244972229004,\n"," 0.8336685299873352,\n"," 0.6125050187110901]"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"HYv6Ly9Y9GwB","executionInfo":{"status":"ok","timestamp":1619185025892,"user_tz":240,"elapsed":1377,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}}},"source":["'''plot confusion mat & calc acc for each label'''\n","test_image_dataset = NSLDataFormat.generate_test_tfr_image_tensor(path_list=test_tfr_list, \n","                                                                  batch_size=4000, \n","                                                                  size=(100,100),\n","                                                                  channels=3,\n","                                                                  shuffle=True)\n","data, data_label = iter(test_image_dataset).get_next()\n","data = data[\"tensor\"]"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":396},"id":"i82NDBcl9GyF","executionInfo":{"status":"ok","timestamp":1619185032077,"user_tz":240,"elapsed":3107,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"597e8b14-41c2-4f80-f7c5-64bfd006bfff"},"source":["ADModelBuilder.plot_confusion_mat(model=graph_reg_model, data=data, data_label=data_label, title=\"Xception_NSL\", figsize=(6,6))"],"execution_count":12,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x432 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"vdqXEIl89G4K"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eZvjZITyuaMt"},"source":[""],"execution_count":null,"outputs":[]}]}