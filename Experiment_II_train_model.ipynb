{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Experiment_II_train_model.ipynb","provenance":[],"collapsed_sections":["BN5T7AsM5iA0","y67bzIq5iebn","YRSBTOx_ZQ2Y","aAfKfwGX5x9Y","dg3vzxBShRRh","KLUpQmqlt3GW","rTkxi38f9Han"]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"xZlaIJnq3nGD"},"source":["## Model Training (Done on Google Collab)\n","### VGG19 train & tune\n","### DenseNet train & tune\n","### Xception train & tune"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ejixluTATVDy","executionInfo":{"status":"ok","timestamp":1617710468389,"user_tz":240,"elapsed":23318,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"f8430075-07b8-42f5-dd90-bd292e2954d4"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"BN5T7AsM5iA0"},"source":["# 1.Package & Dependencies Setup"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pORElq4lpDpD","executionInfo":{"status":"ok","timestamp":1617710478173,"user_tz":240,"elapsed":8041,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"2e26812f-c7d1-4b09-d16c-4d7252c0d0bc"},"source":["\"\"\"Install NSL package\"\"\"\n","!pip install --upgrade neural_structured_learning\n","!pip install tensorflow-addons"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting neural_structured_learning\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8a/23/179e6b7555000de51d9a317e9e47db84cda0180c941cfbf14775925af611/neural_structured_learning-1.3.1-py2.py3-none-any.whl (120kB)\n","\r\u001b[K     |██▊                             | 10kB 15.9MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 20kB 16.9MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 30kB 14.4MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 40kB 13.4MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 51kB 11.5MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 61kB 13.1MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 71kB 11.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 81kB 11.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 92kB 11.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 102kB 11.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 112kB 11.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 122kB 11.1MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.7/dist-packages (from neural_structured_learning) (1.15.0)\n","Requirement already satisfied, skipping upgrade: absl-py in /usr/local/lib/python3.7/dist-packages (from neural_structured_learning) (0.12.0)\n","Requirement already satisfied, skipping upgrade: attrs in /usr/local/lib/python3.7/dist-packages (from neural_structured_learning) (20.3.0)\n","Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.7/dist-packages (from neural_structured_learning) (1.4.1)\n","Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy->neural_structured_learning) (1.19.5)\n","Installing collected packages: neural-structured-learning\n","Successfully installed neural-structured-learning-1.3.1\n","Collecting tensorflow-addons\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/e3/56d2fe76f0bb7c88ed9b2a6a557e25e83e252aec08f13de34369cd850a0b/tensorflow_addons-0.12.1-cp37-cp37m-manylinux2010_x86_64.whl (703kB)\n","\u001b[K     |████████████████████████████████| 706kB 12.2MB/s \n","\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n","Installing collected packages: tensorflow-addons\n","Successfully installed tensorflow-addons-0.12.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0y7x5Ku4pHI5","executionInfo":{"status":"ok","timestamp":1617710497222,"user_tz":240,"elapsed":813,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"1cc8d6ea-a947-41e1-830b-043825e7fb22"},"source":["import numpy as np\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","from neural_structured_learning.tools import graph_utils\n","import neural_structured_learning as nsl\n","import tensorflow_addons as tfa\n","from copy import deepcopy\n","from sklearn.metrics import multilabel_confusion_matrix\n","import random\n","import os\n","import PIL\n","import time\n","import re\n","\n","tf.keras.backend.clear_session()\n","print(\"tensorflow version: \", tf.__version__)\n","print(\"keras version\", tf.keras.__version__)\n","print(\"Eager mode: \", tf.executing_eagerly())\n","print(\"GPU is\", \"available\" if tf.config.experimental.list_physical_devices('GPU') else \"NOT AVAILABLE\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tensorflow version:  2.4.1\n","keras version 2.4.0\n","Eager mode:  True\n","GPU is available\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fIT8u-ur2-Tn"},"source":["from graph_data_processing import GraphDataProcess\n","from AAE_model import AAE\n","from Kmeans import KMeans, KMeansModels\n","from nsl_data_processing import GenerateTrainTestDict, NSLDataFormat\n","from AD_model_builder import AD_params, ADModelBuilder, AccEarlyStop"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GX74Sd5dUCA6"},"source":["''' label definition: NonDemented - 0, VeryMildDemented - 1, MildDemented -2, ModerateDemented -3 '''\n","label_list = ['NonDemented', 'VeryMildDemented', 'MildDemented', 'ModerateDemented']\n","root_path = '/content/drive/MyDrive/AD Expriment II/graph_images/'\n","train_root_path = f'{root_path}train/'\n","test_root_path = f'{root_path}test/'\n","\n","train_path_list = [f'{train_root_path}{label}/' for label in label_list]\n","train_tfr_list = [f'{train_root_path}{label}.tfr' for label in label_list]\n","\n","test_path_list = [f'{test_root_path}{label}/' for label in label_list]\n","test_tfr_list = [f'{test_root_path}{label}.tfr' for label in label_list]\n","\n","tfr_rep_list = [f'{train_root_path}{label}_AAErep.tfr' for label in label_list]\n","\n","train_tfr_path = f'{train_root_path}train_data.tfr'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wZmCxER147rD"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yBqQepbk4729"},"source":["#2.VGG19 & VGG19-NSL Model Training"]},{"cell_type":"code","metadata":{"id":"I7z0hDGW4khr"},"source":["'''define hyper params'''\n","params = AD_params()\n","params.max_seed_nbr=5\n","params.batch_size=64\n","params.image_channels =3\n","params.image_size =(100,100)\n","params.ad_base_model_input_shape=(100,100,3)\n","params.train_tfr_path = train_tfr_path\n","\n","'''parse train_data.tfr to train image dataset with batch_size at 128'''\n","train_image_dataset = NSLDataFormat.parse_tfr_to_dataset(file_path_list=[params.train_tfr_path],\n","                                                         batch_size=params.batch_size,\n","                                                         max_neighbor_number=params.max_seed_nbr,\n","                                                         image_size=params.image_size,\n","                                                         image_channels=params.image_channels,\n","                                                         shuffle=True)\n","\n","'''load test data with batch_size at 128 '''\n","test_image_dataset = NSLDataFormat.generate_test_tfr_image_tensor(path_list=test_tfr_list, \n","                                                                  batch_size=params.batch_size, \n","                                                                  size=params.image_size,\n","                                                                  channels=params.image_channels,\n","                                                                  shuffle=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Nts7SfZMjVeQ"},"source":["## 2.1 VGG19 Base Model Training\n","### val_acc: 0.64, val_auc: 0.89, val_f1_score: 0.64"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A2Nx9izfXeoG","executionInfo":{"status":"ok","timestamp":1617716713672,"user_tz":240,"elapsed":1449,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"6390c1b4-8279-4340-9734-577a35a91d8a"},"source":["'''define params'''\n","params.learning_rate=0.001\n","params.checkpoint_path = '/content/drive/MyDrive/AD Expriment II/VGG19_model_checkpoints/vgg19_weights_base'\n","params.early_stop_base_line=0.90\n","params.train_epoch=50\n","\"\"\"build a base_model and restore weights from last training\"\"\"\n","base_model = ADModelBuilder(input_shape=params.ad_base_model_input_shape, base_model='vgg19').get_ADModel()\n","base_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=params.learning_rate), \n","                   loss=tf.losses.CategoricalCrossentropy(), \n","                   metrics=['accuracy', 'AUC',  tfa.metrics.F1Score(num_classes=4, average=\"micro\", threshold = 0.5)])\n","base_model.load_weights(params.checkpoint_path)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Note: default vgg19 not includes top and has imagenet weights. It is not a trainable model in ADModelBuilder. Setup specific trainable layers in setup_VGG19_by_layer_names or setup_VGG19 function based on the VGG19 layer name or layer number\n","Model: \"VGG19_ADModel\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","tensor (InputLayer)          [(None, 100, 100, 3)]     0         \n","_________________________________________________________________\n","vgg19 (Functional)           (None, 3, 3, 512)         20024384  \n","_________________________________________________________________\n","flatten_8 (Flatten)          (None, 4608)              0         \n","_________________________________________________________________\n","dense_16 (Dense)             (None, 32)                147488    \n","_________________________________________________________________\n","batch_normalization_8 (Batch (None, 32)                128       \n","_________________________________________________________________\n","leaky_re_lu_8 (LeakyReLU)    (None, 32)                0         \n","_________________________________________________________________\n","dropout_8 (Dropout)          (None, 32)                0         \n","_________________________________________________________________\n","dense_17 (Dense)             (None, 4)                 132       \n","=================================================================\n","Total params: 20,172,132\n","Trainable params: 147,684\n","Non-trainable params: 20,024,448\n","_________________________________________________________________\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f5e20f009d0>"]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2UaS25Lt4kqZ","executionInfo":{"status":"ok","timestamp":1617716687817,"user_tz":240,"elapsed":1456624,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"a4acf616-0a3d-4086-8472-b648775acf4a"},"source":["'''train base model'''\n","callback_checkpoints = tf.keras.callbacks.ModelCheckpoint(filepath=params.checkpoint_path, monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=True, \n","                                                          mode='max',save_freq='epoch',options=None)\n","\n","callback_earlystop = AccEarlyStop(val_acc_base=params.early_stop_base_line)\n","\n","history = base_model.fit(train_image_dataset,\n","                         validation_data= test_image_dataset,\n","                         callbacks = [callback_checkpoints, callback_earlystop],\n","                         epochs=params.train_epoch,\n","                         verbose=1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/50\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py:595: UserWarning: Input dict contained keys ['NL_nbr_0_id', 'NL_nbr_0_tensor', 'NL_nbr_0_weight', 'NL_nbr_1_id', 'NL_nbr_1_tensor', 'NL_nbr_1_weight', 'NL_nbr_2_id', 'NL_nbr_2_tensor', 'NL_nbr_2_weight', 'NL_nbr_3_id', 'NL_nbr_3_tensor', 'NL_nbr_3_weight', 'NL_nbr_4_id', 'NL_nbr_4_tensor', 'NL_nbr_4_weight', 'id'] which did not match any model input. They will be ignored by the model.\n","  [n for n in tensors.keys() if n not in ref_input_names])\n"],"name":"stderr"},{"output_type":"stream","text":["    160/Unknown - 28s 159ms/step - loss: 1.0112 - accuracy: 0.5801 - auc: 0.8262 - f1_score: 0.4933"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py:595: UserWarning: Input dict contained keys ['id'] which did not match any model input. They will be ignored by the model.\n","  [n for n in tensors.keys() if n not in ref_input_names])\n"],"name":"stderr"},{"output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r160/160 [==============================] - 31s 182ms/step - loss: 1.0101 - accuracy: 0.5805 - auc: 0.8265 - f1_score: 0.4937 - val_loss: 1.4173 - val_accuracy: 0.3753 - val_auc: 0.6352 - val_f1_score: 0.2414\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.37529, saving model to /content/drive/MyDrive/AD Expriment II/VGG19_model_checkpoints/vgg19_weights_base\n","Epoch 2/50\n","160/160 [==============================] - 30s 181ms/step - loss: 0.6073 - accuracy: 0.7445 - auc: 0.9359 - f1_score: 0.6846 - val_loss: 1.1158 - val_accuracy: 0.5465 - val_auc: 0.8065 - val_f1_score: 0.4966\n","\n","Epoch 00002: val_accuracy improved from 0.37529 to 0.54652, saving model to /content/drive/MyDrive/AD Expriment II/VGG19_model_checkpoints/vgg19_weights_base\n","Epoch 3/50\n","160/160 [==============================] - 30s 179ms/step - loss: 0.5309 - accuracy: 0.7771 - auc: 0.9508 - f1_score: 0.7323 - val_loss: 1.4043 - val_accuracy: 0.4934 - val_auc: 0.7588 - val_f1_score: 0.4842\n","\n","Epoch 00003: val_accuracy did not improve from 0.54652\n","Epoch 4/50\n","160/160 [==============================] - 29s 174ms/step - loss: 0.4637 - accuracy: 0.8051 - auc: 0.9621 - f1_score: 0.7666 - val_loss: 1.3021 - val_accuracy: 0.5426 - val_auc: 0.8100 - val_f1_score: 0.5196\n","\n","Epoch 00004: val_accuracy did not improve from 0.54652\n","Epoch 5/50\n","160/160 [==============================] - 29s 174ms/step - loss: 0.4286 - accuracy: 0.8203 - auc: 0.9677 - f1_score: 0.7931 - val_loss: 1.4733 - val_accuracy: 0.5371 - val_auc: 0.8033 - val_f1_score: 0.5295\n","\n","Epoch 00005: val_accuracy did not improve from 0.54652\n","Epoch 6/50\n","160/160 [==============================] - 29s 174ms/step - loss: 0.3707 - accuracy: 0.8537 - auc: 0.9761 - f1_score: 0.8242 - val_loss: 2.8030 - val_accuracy: 0.5012 - val_auc: 0.7529 - val_f1_score: 0.5008\n","\n","Epoch 00006: val_accuracy did not improve from 0.54652\n","Epoch 7/50\n","160/160 [==============================] - 29s 175ms/step - loss: 0.3618 - accuracy: 0.8497 - auc: 0.9767 - f1_score: 0.8321 - val_loss: 2.0773 - val_accuracy: 0.5012 - val_auc: 0.7349 - val_f1_score: 0.4986\n","\n","Epoch 00007: val_accuracy did not improve from 0.54652\n","Epoch 8/50\n","160/160 [==============================] - 29s 178ms/step - loss: 0.3519 - accuracy: 0.8548 - auc: 0.9778 - f1_score: 0.8366 - val_loss: 1.0411 - val_accuracy: 0.5966 - val_auc: 0.8484 - val_f1_score: 0.5396\n","\n","Epoch 00008: val_accuracy improved from 0.54652 to 0.59656, saving model to /content/drive/MyDrive/AD Expriment II/VGG19_model_checkpoints/vgg19_weights_base\n","Epoch 9/50\n","160/160 [==============================] - 30s 180ms/step - loss: 0.3104 - accuracy: 0.8758 - auc: 0.9829 - f1_score: 0.8619 - val_loss: 2.0243 - val_accuracy: 0.4691 - val_auc: 0.7404 - val_f1_score: 0.4690\n","\n","Epoch 00009: val_accuracy did not improve from 0.59656\n","Epoch 10/50\n","160/160 [==============================] - 29s 174ms/step - loss: 0.3284 - accuracy: 0.8633 - auc: 0.9804 - f1_score: 0.8514 - val_loss: 1.6579 - val_accuracy: 0.5442 - val_auc: 0.7994 - val_f1_score: 0.5328\n","\n","Epoch 00010: val_accuracy did not improve from 0.59656\n","Epoch 11/50\n","160/160 [==============================] - 29s 173ms/step - loss: 0.2944 - accuracy: 0.8852 - auc: 0.9844 - f1_score: 0.8714 - val_loss: 2.5107 - val_accuracy: 0.4363 - val_auc: 0.7575 - val_f1_score: 0.4222\n","\n","Epoch 00011: val_accuracy did not improve from 0.59656\n","Epoch 12/50\n","160/160 [==============================] - 29s 176ms/step - loss: 0.2960 - accuracy: 0.8802 - auc: 0.9839 - f1_score: 0.8687 - val_loss: 1.3722 - val_accuracy: 0.6013 - val_auc: 0.8475 - val_f1_score: 0.5872\n","\n","Epoch 00012: val_accuracy improved from 0.59656 to 0.60125, saving model to /content/drive/MyDrive/AD Expriment II/VGG19_model_checkpoints/vgg19_weights_base\n","Epoch 13/50\n","160/160 [==============================] - 30s 180ms/step - loss: 0.2695 - accuracy: 0.8963 - auc: 0.9866 - f1_score: 0.8810 - val_loss: 1.8227 - val_accuracy: 0.5434 - val_auc: 0.7900 - val_f1_score: 0.5336\n","\n","Epoch 00013: val_accuracy did not improve from 0.60125\n","Epoch 14/50\n","160/160 [==============================] - 29s 174ms/step - loss: 0.2442 - accuracy: 0.9024 - auc: 0.9893 - f1_score: 0.8933 - val_loss: 1.2758 - val_accuracy: 0.6036 - val_auc: 0.8274 - val_f1_score: 0.5752\n","\n","Epoch 00014: val_accuracy improved from 0.60125 to 0.60360, saving model to /content/drive/MyDrive/AD Expriment II/VGG19_model_checkpoints/vgg19_weights_base\n","Epoch 15/50\n","160/160 [==============================] - 29s 175ms/step - loss: 0.2627 - accuracy: 0.9005 - auc: 0.9873 - f1_score: 0.8872 - val_loss: 1.6509 - val_accuracy: 0.5145 - val_auc: 0.7805 - val_f1_score: 0.4890\n","\n","Epoch 00015: val_accuracy did not improve from 0.60360\n","Epoch 16/50\n","160/160 [==============================] - 29s 176ms/step - loss: 0.2422 - accuracy: 0.9043 - auc: 0.9892 - f1_score: 0.8975 - val_loss: 1.4873 - val_accuracy: 0.5364 - val_auc: 0.7994 - val_f1_score: 0.5138\n","\n","Epoch 00016: val_accuracy did not improve from 0.60360\n","Epoch 17/50\n","160/160 [==============================] - 29s 177ms/step - loss: 0.2233 - accuracy: 0.9081 - auc: 0.9908 - f1_score: 0.9005 - val_loss: 1.4856 - val_accuracy: 0.5934 - val_auc: 0.8299 - val_f1_score: 0.5815\n","\n","Epoch 00017: val_accuracy did not improve from 0.60360\n","Epoch 18/50\n","160/160 [==============================] - 28s 173ms/step - loss: 0.2381 - accuracy: 0.9033 - auc: 0.9892 - f1_score: 0.8972 - val_loss: 2.4064 - val_accuracy: 0.4629 - val_auc: 0.7405 - val_f1_score: 0.4499\n","\n","Epoch 00018: val_accuracy did not improve from 0.60360\n","Epoch 19/50\n","160/160 [==============================] - 29s 176ms/step - loss: 0.2209 - accuracy: 0.9128 - auc: 0.9907 - f1_score: 0.9052 - val_loss: 1.4362 - val_accuracy: 0.5520 - val_auc: 0.8066 - val_f1_score: 0.5183\n","\n","Epoch 00019: val_accuracy did not improve from 0.60360\n","Epoch 20/50\n","160/160 [==============================] - 29s 176ms/step - loss: 0.2169 - accuracy: 0.9133 - auc: 0.9911 - f1_score: 0.9089 - val_loss: 2.8384 - val_accuracy: 0.5481 - val_auc: 0.7513 - val_f1_score: 0.5449\n","\n","Epoch 00020: val_accuracy did not improve from 0.60360\n","Epoch 21/50\n","160/160 [==============================] - 29s 174ms/step - loss: 0.2083 - accuracy: 0.9188 - auc: 0.9918 - f1_score: 0.9136 - val_loss: 1.5050 - val_accuracy: 0.5708 - val_auc: 0.8038 - val_f1_score: 0.5380\n","\n","Epoch 00021: val_accuracy did not improve from 0.60360\n","Epoch 22/50\n","160/160 [==============================] - 28s 172ms/step - loss: 0.2012 - accuracy: 0.9211 - auc: 0.9923 - f1_score: 0.9156 - val_loss: 1.7340 - val_accuracy: 0.5489 - val_auc: 0.8014 - val_f1_score: 0.5220\n","\n","Epoch 00022: val_accuracy did not improve from 0.60360\n","Epoch 23/50\n","160/160 [==============================] - 28s 172ms/step - loss: 0.1877 - accuracy: 0.9254 - auc: 0.9934 - f1_score: 0.9214 - val_loss: 3.5733 - val_accuracy: 0.4027 - val_auc: 0.6858 - val_f1_score: 0.3910\n","\n","Epoch 00023: val_accuracy did not improve from 0.60360\n","Epoch 24/50\n","160/160 [==============================] - 29s 173ms/step - loss: 0.1904 - accuracy: 0.9250 - auc: 0.9931 - f1_score: 0.9200 - val_loss: 1.7248 - val_accuracy: 0.5966 - val_auc: 0.8263 - val_f1_score: 0.5892\n","\n","Epoch 00024: val_accuracy did not improve from 0.60360\n","Epoch 25/50\n","160/160 [==============================] - 28s 173ms/step - loss: 0.1913 - accuracy: 0.9264 - auc: 0.9929 - f1_score: 0.9213 - val_loss: 1.6498 - val_accuracy: 0.5676 - val_auc: 0.8117 - val_f1_score: 0.5509\n","\n","Epoch 00025: val_accuracy did not improve from 0.60360\n","Epoch 26/50\n","160/160 [==============================] - 28s 173ms/step - loss: 0.1835 - accuracy: 0.9306 - auc: 0.9936 - f1_score: 0.9249 - val_loss: 2.1964 - val_accuracy: 0.5536 - val_auc: 0.7881 - val_f1_score: 0.5451\n","\n","Epoch 00026: val_accuracy did not improve from 0.60360\n","Epoch 27/50\n","160/160 [==============================] - 28s 173ms/step - loss: 0.1833 - accuracy: 0.9275 - auc: 0.9935 - f1_score: 0.9239 - val_loss: 1.9755 - val_accuracy: 0.5833 - val_auc: 0.8199 - val_f1_score: 0.5773\n","\n","Epoch 00027: val_accuracy did not improve from 0.60360\n","Epoch 28/50\n","160/160 [==============================] - 29s 173ms/step - loss: 0.1732 - accuracy: 0.9325 - auc: 0.9940 - f1_score: 0.9287 - val_loss: 1.8168 - val_accuracy: 0.6044 - val_auc: 0.8251 - val_f1_score: 0.5927\n","\n","Epoch 00028: val_accuracy improved from 0.60360 to 0.60438, saving model to /content/drive/MyDrive/AD Expriment II/VGG19_model_checkpoints/vgg19_weights_base\n","Epoch 29/50\n","160/160 [==============================] - 29s 176ms/step - loss: 0.1704 - accuracy: 0.9333 - auc: 0.9943 - f1_score: 0.9295 - val_loss: 1.9750 - val_accuracy: 0.5324 - val_auc: 0.7856 - val_f1_score: 0.5077\n","\n","Epoch 00029: val_accuracy did not improve from 0.60438\n","Epoch 30/50\n","160/160 [==============================] - 29s 174ms/step - loss: 0.1788 - accuracy: 0.9309 - auc: 0.9937 - f1_score: 0.9258 - val_loss: 1.4785 - val_accuracy: 0.6372 - val_auc: 0.8520 - val_f1_score: 0.6280\n","\n","Epoch 00030: val_accuracy improved from 0.60438 to 0.63722, saving model to /content/drive/MyDrive/AD Expriment II/VGG19_model_checkpoints/vgg19_weights_base\n","Epoch 31/50\n","160/160 [==============================] - 29s 177ms/step - loss: 0.1652 - accuracy: 0.9333 - auc: 0.9948 - f1_score: 0.9311 - val_loss: 2.6618 - val_accuracy: 0.4699 - val_auc: 0.7220 - val_f1_score: 0.4551\n","\n","Epoch 00031: val_accuracy did not improve from 0.63722\n","Epoch 32/50\n","160/160 [==============================] - 29s 175ms/step - loss: 0.1759 - accuracy: 0.9331 - auc: 0.9941 - f1_score: 0.9279 - val_loss: 2.4301 - val_accuracy: 0.5324 - val_auc: 0.7823 - val_f1_score: 0.5164\n","\n","Epoch 00032: val_accuracy did not improve from 0.63722\n","Epoch 33/50\n","160/160 [==============================] - 29s 175ms/step - loss: 0.1636 - accuracy: 0.9354 - auc: 0.9948 - f1_score: 0.9322 - val_loss: 2.0971 - val_accuracy: 0.5512 - val_auc: 0.7942 - val_f1_score: 0.5439\n","\n","Epoch 00033: val_accuracy did not improve from 0.63722\n","Epoch 34/50\n","160/160 [==============================] - 29s 173ms/step - loss: 0.1544 - accuracy: 0.9402 - auc: 0.9953 - f1_score: 0.9370 - val_loss: 2.5889 - val_accuracy: 0.4777 - val_auc: 0.7247 - val_f1_score: 0.4767\n","\n","Epoch 00034: val_accuracy did not improve from 0.63722\n","Epoch 35/50\n","160/160 [==============================] - 28s 173ms/step - loss: 0.1494 - accuracy: 0.9435 - auc: 0.9956 - f1_score: 0.9400 - val_loss: 2.2309 - val_accuracy: 0.5661 - val_auc: 0.7969 - val_f1_score: 0.5628\n","\n","Epoch 00035: val_accuracy did not improve from 0.63722\n","Epoch 36/50\n","160/160 [==============================] - 28s 171ms/step - loss: 0.1527 - accuracy: 0.9438 - auc: 0.9952 - f1_score: 0.9410 - val_loss: 2.5139 - val_accuracy: 0.4722 - val_auc: 0.7380 - val_f1_score: 0.4570\n","\n","Epoch 00036: val_accuracy did not improve from 0.63722\n","Epoch 37/50\n","160/160 [==============================] - 28s 173ms/step - loss: 0.1420 - accuracy: 0.9461 - auc: 0.9961 - f1_score: 0.9408 - val_loss: 2.9417 - val_accuracy: 0.5942 - val_auc: 0.8060 - val_f1_score: 0.5897\n","\n","Epoch 00037: val_accuracy did not improve from 0.63722\n","Epoch 38/50\n","160/160 [==============================] - 28s 173ms/step - loss: 0.1399 - accuracy: 0.9477 - auc: 0.9962 - f1_score: 0.9427 - val_loss: 1.9932 - val_accuracy: 0.6044 - val_auc: 0.8282 - val_f1_score: 0.5921\n","\n","Epoch 00038: val_accuracy did not improve from 0.63722\n","Epoch 39/50\n","160/160 [==============================] - 28s 172ms/step - loss: 0.1488 - accuracy: 0.9437 - auc: 0.9954 - f1_score: 0.9416 - val_loss: 1.9766 - val_accuracy: 0.5794 - val_auc: 0.8160 - val_f1_score: 0.5657\n","\n","Epoch 00039: val_accuracy did not improve from 0.63722\n","Epoch 40/50\n","160/160 [==============================] - 29s 175ms/step - loss: 0.1495 - accuracy: 0.9413 - auc: 0.9957 - f1_score: 0.9372 - val_loss: 2.4554 - val_accuracy: 0.5074 - val_auc: 0.7457 - val_f1_score: 0.4908\n","\n","Epoch 00040: val_accuracy did not improve from 0.63722\n","Epoch 41/50\n","160/160 [==============================] - 29s 177ms/step - loss: 0.1454 - accuracy: 0.9438 - auc: 0.9958 - f1_score: 0.9386 - val_loss: 2.5013 - val_accuracy: 0.5027 - val_auc: 0.7383 - val_f1_score: 0.4842\n","\n","Epoch 00041: val_accuracy did not improve from 0.63722\n","Epoch 42/50\n","160/160 [==============================] - 29s 177ms/step - loss: 0.1225 - accuracy: 0.9550 - auc: 0.9971 - f1_score: 0.9519 - val_loss: 1.9526 - val_accuracy: 0.6145 - val_auc: 0.8224 - val_f1_score: 0.6025\n","\n","Epoch 00042: val_accuracy did not improve from 0.63722\n","Epoch 43/50\n","160/160 [==============================] - 29s 179ms/step - loss: 0.1330 - accuracy: 0.9516 - auc: 0.9962 - f1_score: 0.9493 - val_loss: 1.7322 - val_accuracy: 0.6169 - val_auc: 0.8356 - val_f1_score: 0.6059\n","\n","Epoch 00043: val_accuracy did not improve from 0.63722\n","Epoch 44/50\n","160/160 [==============================] - 29s 177ms/step - loss: 0.1318 - accuracy: 0.9500 - auc: 0.9965 - f1_score: 0.9472 - val_loss: 2.2116 - val_accuracy: 0.5895 - val_auc: 0.8169 - val_f1_score: 0.5862\n","\n","Epoch 00044: val_accuracy did not improve from 0.63722\n","Epoch 45/50\n","160/160 [==============================] - 29s 178ms/step - loss: 0.1233 - accuracy: 0.9540 - auc: 0.9969 - f1_score: 0.9521 - val_loss: 2.4948 - val_accuracy: 0.5504 - val_auc: 0.7981 - val_f1_score: 0.5459\n","\n","Epoch 00045: val_accuracy did not improve from 0.63722\n","Epoch 46/50\n","160/160 [==============================] - 29s 179ms/step - loss: 0.1402 - accuracy: 0.9454 - auc: 0.9959 - f1_score: 0.9446 - val_loss: 2.5069 - val_accuracy: 0.5825 - val_auc: 0.8063 - val_f1_score: 0.5730\n","\n","Epoch 00046: val_accuracy did not improve from 0.63722\n","Epoch 47/50\n","160/160 [==============================] - 29s 177ms/step - loss: 0.1205 - accuracy: 0.9519 - auc: 0.9972 - f1_score: 0.9505 - val_loss: 2.4071 - val_accuracy: 0.5950 - val_auc: 0.8016 - val_f1_score: 0.5826\n","\n","Epoch 00047: val_accuracy did not improve from 0.63722\n","Epoch 48/50\n","160/160 [==============================] - 29s 176ms/step - loss: 0.1256 - accuracy: 0.9506 - auc: 0.9968 - f1_score: 0.9487 - val_loss: 2.7537 - val_accuracy: 0.5082 - val_auc: 0.7559 - val_f1_score: 0.4961\n","\n","Epoch 00048: val_accuracy did not improve from 0.63722\n","Epoch 49/50\n","160/160 [==============================] - 29s 177ms/step - loss: 0.1271 - accuracy: 0.9534 - auc: 0.9965 - f1_score: 0.9512 - val_loss: 4.1697 - val_accuracy: 0.4300 - val_auc: 0.6638 - val_f1_score: 0.4215\n","\n","Epoch 00049: val_accuracy did not improve from 0.63722\n","Epoch 50/50\n","160/160 [==============================] - 29s 178ms/step - loss: 0.1262 - accuracy: 0.9504 - auc: 0.9967 - f1_score: 0.9487 - val_loss: 2.6211 - val_accuracy: 0.5301 - val_auc: 0.7727 - val_f1_score: 0.5300\n","\n","Epoch 00050: val_accuracy did not improve from 0.63722\n","Early stopping is not triggered, but best model is restored at epoch 30\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lVP_CDnTbGaF","executionInfo":{"status":"ok","timestamp":1617714875929,"user_tz":240,"elapsed":3748,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"c52d7bcc-e581-4865-b072-3c5170baeef7"},"source":["'''evaluate the base model'''\n","base_model.evaluate(test_image_dataset)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1/1 [==============================] - 3s 3s/step - loss: 1.4312 - accuracy: 0.6403 - auc: 0.8503 - f1_score: 0.6390\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[1.4311827421188354,\n"," 0.6403440237045288,\n"," 0.8503028750419617,\n"," 0.6390205025672913]"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"mZdKTQIbLIhz"},"source":["'''plot confusion mat & calc acc for each label'''\n","test_image_dataset = NSLDataFormat.generate_test_tfr_image_tensor(path_list=test_tfr_list, \n","                                                                  batch_size=4000, \n","                                                                  size=(100,100),\n","                                                                  channels=3,\n","                                                                  shuffle=True)\n","data, data_label = iter(test_image_dataset).get_next()\n","data = data[\"tensor\"]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GGee70DfXROB","executionInfo":{"status":"ok","timestamp":1617714876787,"user_tz":240,"elapsed":3777,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"4335fec9-b581-46b4-a9d9-3fe975548ae8"},"source":["len(data)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1279"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":396},"id":"RDbn8__LLIjv","executionInfo":{"status":"ok","timestamp":1617714880272,"user_tz":240,"elapsed":4986,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"7352c72f-32a1-4593-f68c-00c97d65529c"},"source":["ADModelBuilder.plot_confusion_mat(base_model, data, data_label, \"VGG19\")"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x432 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YVlyP5V1LIm3","executionInfo":{"status":"ok","timestamp":1606257036228,"user_tz":300,"elapsed":4908,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"0b41531a-3ad0-47d1-d810-9fd5e2d3cefc"},"source":["ADModelBuilder.calc_confu_mat_for_each_label(base_model,data, data_label)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["TN: [2809 2680 2795 2863]\n","TP: [838 859 876 918]\n","FN: [153  79  58  47]\n","FP: [ 28 210  99   0]\n","Acc: [0.95271682 0.92450366 0.95898642 0.98772205]\n","ER(Error rate): [0.04728318 0.07549634 0.04101358 0.01227795]\n","Recall(TP rate): [0.84561049 0.91577825 0.9379015  0.95129534]\n","Specialty(TN rate): [0.99013042 0.92733564 0.96579129 1.        ]\n","Fall Out(FP rate): [0.00986958 0.07266436 0.03420871 0.        ]\n","Miss Rate(FN rate): [0.15438951 0.08422175 0.0620985  0.04870466]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"TDkD2QMS6b-_"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mPorVq79jeYK"},"source":["## 2.2 VGG19-NSL Model Training\n","### val_acc: ???, val_auc: ???, val_f1_score: ???"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4FsrX9lrC1hY","executionInfo":{"status":"ok","timestamp":1617716774112,"user_tz":240,"elapsed":1169,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"c7acf02a-58d1-4a8d-eb4e-89a14480da07"},"source":["'''define params'''\n","params.learning_rate=0.001\n","params.checkpoint_path ='/content/drive/MyDrive/AD Expriment II/VGG19_model_checkpoints/vgg19_weights_nsl'\n","params.early_stop_base_line=0.70\n","params.train_epoch=100\n","params.nsl_multiplier = 0.8\n","params.nsl_sum_over_axis = -1\n","params.nsl_distance_type = nsl.configs.DistanceType.COSINE\n","\"\"\"build a base_model\"\"\"\n","base_model = ADModelBuilder(input_shape=params.ad_base_model_input_shape, base_model='vgg19').get_ADModel()\n","\"\"\"build a NSL model on top of the base model and retore weights from last training\"\"\"\n","graph_reg_config = nsl.configs.make_graph_reg_config(neighbor_prefix=params.neighbor_prefix,\n","                                                     neighbor_weight_suffix=params.neighbor_weight_suffix,\n","                                                     max_neighbors= params.max_seed_nbr,\n","                                                     multiplier= params.nsl_multiplier,\n","                                                     distance_type= params.nsl_distance_type,\n","                                                     sum_over_axis= params.nsl_sum_over_axis)\n","graph_reg_model = nsl.keras.GraphRegularization(base_model,graph_reg_config)\n","graph_reg_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=params.learning_rate, amsgrad=True), \n","                        loss=tf.losses.CategoricalCrossentropy(), \n","                        metrics=[\"accuracy\",\"AUC\", tfa.metrics.F1Score(num_classes=4, average=\"micro\", threshold = 0.5)])\n","# graph_reg_model.load_weights(params.checkpoint_path)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Note: default vgg19 not includes top and has imagenet weights. It is not a trainable model in ADModelBuilder. Setup specific trainable layers in setup_VGG19_by_layer_names or setup_VGG19 function based on the VGG19 layer name or layer number\n","Model: \"VGG19_ADModel\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","tensor (InputLayer)          [(None, 100, 100, 3)]     0         \n","_________________________________________________________________\n","vgg19 (Functional)           (None, 3, 3, 512)         20024384  \n","_________________________________________________________________\n","flatten_9 (Flatten)          (None, 4608)              0         \n","_________________________________________________________________\n","dense_18 (Dense)             (None, 32)                147488    \n","_________________________________________________________________\n","batch_normalization_9 (Batch (None, 32)                128       \n","_________________________________________________________________\n","leaky_re_lu_9 (LeakyReLU)    (None, 32)                0         \n","_________________________________________________________________\n","dropout_9 (Dropout)          (None, 32)                0         \n","_________________________________________________________________\n","dense_19 (Dense)             (None, 4)                 132       \n","=================================================================\n","Total params: 20,172,132\n","Trainable params: 147,684\n","Non-trainable params: 20,024,448\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"84c5v3r04ktO","executionInfo":{"status":"ok","timestamp":1617729491003,"user_tz":240,"elapsed":509157,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"869513ae-c2b6-43b5-dc9d-69544f7ca626"},"source":["''' setup early stoping and checkpoints '''\n","callback_checkpoints = tf.keras.callbacks.ModelCheckpoint(filepath=params.checkpoint_path, monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=True, mode='max',\n","                                                         save_freq='epoch',options=None)\n","\n","callback_earlystop = AccEarlyStop(val_acc_base=params.early_stop_base_line)\n","\n","'''NSL model training'''\n","graph_reg_history = graph_reg_model.fit(train_image_dataset, \n","                                        validation_data=test_image_dataset,\n","                                        callbacks = [callback_checkpoints, callback_earlystop],\n","                                        epochs=params.train_epoch,\n","                                        verbose=1)"],"execution_count":29,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py:595: UserWarning: Input dict contained keys ['id'] which did not match any model input. They will be ignored by the model.\n","  [n for n in tensors.keys() if n not in ref_input_names])\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/GraphRegularization/graph_loss/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/GraphRegularization/graph_loss/Reshape:0\", shape=(None, 4), dtype=float32), dense_shape=Tensor(\"gradient_tape/GraphRegularization/graph_loss/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"shape. This may consume a large amount of memory.\" % value)\n"],"name":"stderr"},{"output_type":"stream","text":["160/160 [==============================] - 162s 863ms/step - loss: 1.1171 - accuracy: 0.5694 - auc: 0.8186 - f1_score: 0.5377 - scaled_graph_loss: 0.0771 - val_loss: 1.1478 - val_accuracy: 0.5246 - val_auc: 0.7817 - val_f1_score: 0.5987\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.52463, saving model to /content/drive/MyDrive/AD Expriment II/VGG19_model_checkpoints/vgg19_weights_nsl\n","Epoch 2/100\n","160/160 [==============================] - 126s 781ms/step - loss: 0.6543 - accuracy: 0.7461 - auc: 0.9366 - f1_score: 0.7221 - scaled_graph_loss: 0.0486 - val_loss: 1.1522 - val_accuracy: 0.5285 - val_auc: 0.8211 - val_f1_score: 0.5217\n","\n","Epoch 00002: val_accuracy improved from 0.52463 to 0.52854, saving model to /content/drive/MyDrive/AD Expriment II/VGG19_model_checkpoints/vgg19_weights_nsl\n","Epoch 3/100\n","160/160 [==============================] - 126s 782ms/step - loss: 0.5596 - accuracy: 0.7798 - auc: 0.9535 - f1_score: 0.7666 - scaled_graph_loss: 0.0418 - val_loss: 1.0028 - val_accuracy: 0.5794 - val_auc: 0.8320 - val_f1_score: 0.5555\n","\n","Epoch 00003: val_accuracy improved from 0.52854 to 0.57936, saving model to /content/drive/MyDrive/AD Expriment II/VGG19_model_checkpoints/vgg19_weights_nsl\n","Epoch 4/100\n","160/160 [==============================] - 126s 782ms/step - loss: 0.5069 - accuracy: 0.8072 - auc: 0.9626 - f1_score: 0.8021 - scaled_graph_loss: 0.0417 - val_loss: 1.0525 - val_accuracy: 0.5590 - val_auc: 0.8267 - val_f1_score: 0.5432\n","\n","Epoch 00004: val_accuracy did not improve from 0.57936\n","Epoch 5/100\n","160/160 [==============================] - 126s 782ms/step - loss: 0.4618 - accuracy: 0.8328 - auc: 0.9702 - f1_score: 0.8223 - scaled_graph_loss: 0.0427 - val_loss: 0.8926 - val_accuracy: 0.6083 - val_auc: 0.8572 - val_f1_score: 0.5903\n","\n","Epoch 00005: val_accuracy improved from 0.57936 to 0.60829, saving model to /content/drive/MyDrive/AD Expriment II/VGG19_model_checkpoints/vgg19_weights_nsl\n","Epoch 6/100\n","160/160 [==============================] - 126s 781ms/step - loss: 0.4329 - accuracy: 0.8379 - auc: 0.9740 - f1_score: 0.8341 - scaled_graph_loss: 0.0432 - val_loss: 1.2605 - val_accuracy: 0.5426 - val_auc: 0.8416 - val_f1_score: 0.5357\n","\n","Epoch 00006: val_accuracy did not improve from 0.60829\n","Epoch 7/100\n","160/160 [==============================] - 126s 780ms/step - loss: 0.4043 - accuracy: 0.8570 - auc: 0.9778 - f1_score: 0.8509 - scaled_graph_loss: 0.0438 - val_loss: 1.1459 - val_accuracy: 0.5481 - val_auc: 0.8063 - val_f1_score: 0.5251\n","\n","Epoch 00007: val_accuracy did not improve from 0.60829\n","Epoch 8/100\n","160/160 [==============================] - 126s 781ms/step - loss: 0.3990 - accuracy: 0.8565 - auc: 0.9779 - f1_score: 0.8532 - scaled_graph_loss: 0.0445 - val_loss: 1.0341 - val_accuracy: 0.6255 - val_auc: 0.8630 - val_f1_score: 0.6251\n","\n","Epoch 00008: val_accuracy improved from 0.60829 to 0.62549, saving model to /content/drive/MyDrive/AD Expriment II/VGG19_model_checkpoints/vgg19_weights_nsl\n","Epoch 9/100\n","160/160 [==============================] - 126s 782ms/step - loss: 0.3628 - accuracy: 0.8685 - auc: 0.9821 - f1_score: 0.8692 - scaled_graph_loss: 0.0428 - val_loss: 1.1714 - val_accuracy: 0.6091 - val_auc: 0.8466 - val_f1_score: 0.6030\n","\n","Epoch 00009: val_accuracy did not improve from 0.62549\n","Epoch 10/100\n","160/160 [==============================] - 126s 782ms/step - loss: 0.3583 - accuracy: 0.8718 - auc: 0.9822 - f1_score: 0.8709 - scaled_graph_loss: 0.0427 - val_loss: 1.1211 - val_accuracy: 0.5989 - val_auc: 0.8492 - val_f1_score: 0.5941\n","\n","Epoch 00010: val_accuracy did not improve from 0.62549\n","Epoch 11/100\n","160/160 [==============================] - 126s 781ms/step - loss: 0.3398 - accuracy: 0.8831 - auc: 0.9841 - f1_score: 0.8824 - scaled_graph_loss: 0.0428 - val_loss: 1.7220 - val_accuracy: 0.5622 - val_auc: 0.8216 - val_f1_score: 0.5620\n","\n","Epoch 00011: val_accuracy did not improve from 0.62549\n","Epoch 12/100\n","160/160 [==============================] - 126s 782ms/step - loss: 0.3266 - accuracy: 0.8835 - auc: 0.9857 - f1_score: 0.8851 - scaled_graph_loss: 0.0428 - val_loss: 1.0693 - val_accuracy: 0.5973 - val_auc: 0.8448 - val_f1_score: 0.5880\n","\n","Epoch 00012: val_accuracy did not improve from 0.62549\n","Epoch 13/100\n","160/160 [==============================] - 126s 782ms/step - loss: 0.3149 - accuracy: 0.8927 - auc: 0.9866 - f1_score: 0.8918 - scaled_graph_loss: 0.0418 - val_loss: 1.7051 - val_accuracy: 0.5841 - val_auc: 0.8185 - val_f1_score: 0.5829\n","\n","Epoch 00013: val_accuracy did not improve from 0.62549\n","Epoch 14/100\n","160/160 [==============================] - 126s 782ms/step - loss: 0.2894 - accuracy: 0.8974 - auc: 0.9888 - f1_score: 0.8970 - scaled_graph_loss: 0.0394 - val_loss: 1.6429 - val_accuracy: 0.5801 - val_auc: 0.8350 - val_f1_score: 0.5799\n","\n","Epoch 00014: val_accuracy did not improve from 0.62549\n","Epoch 15/100\n","160/160 [==============================] - 126s 781ms/step - loss: 0.3036 - accuracy: 0.8916 - auc: 0.9874 - f1_score: 0.8908 - scaled_graph_loss: 0.0423 - val_loss: 1.2806 - val_accuracy: 0.6028 - val_auc: 0.8479 - val_f1_score: 0.6036\n","\n","Epoch 00015: val_accuracy did not improve from 0.62549\n","Epoch 16/100\n","160/160 [==============================] - 126s 781ms/step - loss: 0.2672 - accuracy: 0.9093 - auc: 0.9906 - f1_score: 0.9093 - scaled_graph_loss: 0.0389 - val_loss: 1.3408 - val_accuracy: 0.5708 - val_auc: 0.8091 - val_f1_score: 0.5603\n","\n","Epoch 00016: val_accuracy did not improve from 0.62549\n","Epoch 17/100\n","160/160 [==============================] - 126s 781ms/step - loss: 0.2656 - accuracy: 0.9098 - auc: 0.9907 - f1_score: 0.9112 - scaled_graph_loss: 0.0384 - val_loss: 1.3143 - val_accuracy: 0.5911 - val_auc: 0.8406 - val_f1_score: 0.5909\n","\n","Epoch 00017: val_accuracy did not improve from 0.62549\n","Epoch 18/100\n","160/160 [==============================] - 126s 780ms/step - loss: 0.2536 - accuracy: 0.9146 - auc: 0.9915 - f1_score: 0.9152 - scaled_graph_loss: 0.0364 - val_loss: 1.9602 - val_accuracy: 0.5676 - val_auc: 0.8200 - val_f1_score: 0.5662\n","\n","Epoch 00018: val_accuracy did not improve from 0.62549\n","Epoch 19/100\n","160/160 [==============================] - 126s 782ms/step - loss: 0.2564 - accuracy: 0.9132 - auc: 0.9912 - f1_score: 0.9121 - scaled_graph_loss: 0.0374 - val_loss: 1.2938 - val_accuracy: 0.6411 - val_auc: 0.8562 - val_f1_score: 0.6390\n","\n","Epoch 00019: val_accuracy improved from 0.62549 to 0.64113, saving model to /content/drive/MyDrive/AD Expriment II/VGG19_model_checkpoints/vgg19_weights_nsl\n","Epoch 20/100\n","160/160 [==============================] - 126s 783ms/step - loss: 0.2643 - accuracy: 0.9083 - auc: 0.9906 - f1_score: 0.9087 - scaled_graph_loss: 0.0389 - val_loss: 1.4153 - val_accuracy: 0.6075 - val_auc: 0.8480 - val_f1_score: 0.6066\n","\n","Epoch 00020: val_accuracy did not improve from 0.64113\n","Epoch 21/100\n","160/160 [==============================] - 126s 782ms/step - loss: 0.2510 - accuracy: 0.9139 - auc: 0.9916 - f1_score: 0.9140 - scaled_graph_loss: 0.0382 - val_loss: 1.8793 - val_accuracy: 0.5754 - val_auc: 0.8254 - val_f1_score: 0.5732\n","\n","Epoch 00021: val_accuracy did not improve from 0.64113\n","Epoch 22/100\n","160/160 [==============================] - 126s 783ms/step - loss: 0.2338 - accuracy: 0.9233 - auc: 0.9924 - f1_score: 0.9234 - scaled_graph_loss: 0.0349 - val_loss: 1.5436 - val_accuracy: 0.6028 - val_auc: 0.8383 - val_f1_score: 0.6032\n","\n","Epoch 00022: val_accuracy did not improve from 0.64113\n","Epoch 23/100\n","160/160 [==============================] - 126s 782ms/step - loss: 0.2147 - accuracy: 0.9288 - auc: 0.9940 - f1_score: 0.9301 - scaled_graph_loss: 0.0342 - val_loss: 1.6040 - val_accuracy: 0.6200 - val_auc: 0.8477 - val_f1_score: 0.6216\n","\n","Epoch 00023: val_accuracy did not improve from 0.64113\n","Epoch 24/100\n","160/160 [==============================] - 126s 784ms/step - loss: 0.2204 - accuracy: 0.9307 - auc: 0.9936 - f1_score: 0.9315 - scaled_graph_loss: 0.0351 - val_loss: 1.4503 - val_accuracy: 0.6411 - val_auc: 0.8542 - val_f1_score: 0.6403\n","\n","Epoch 00024: val_accuracy did not improve from 0.64113\n","Epoch 25/100\n","160/160 [==============================] - 127s 786ms/step - loss: 0.2053 - accuracy: 0.9344 - auc: 0.9944 - f1_score: 0.9348 - scaled_graph_loss: 0.0322 - val_loss: 1.2647 - val_accuracy: 0.6364 - val_auc: 0.8592 - val_f1_score: 0.6327\n","\n","Epoch 00025: val_accuracy did not improve from 0.64113\n","Epoch 26/100\n","160/160 [==============================] - 126s 784ms/step - loss: 0.2099 - accuracy: 0.9340 - auc: 0.9942 - f1_score: 0.9337 - scaled_graph_loss: 0.0340 - val_loss: 1.7998 - val_accuracy: 0.5973 - val_auc: 0.8294 - val_f1_score: 0.5988\n","\n","Epoch 00026: val_accuracy did not improve from 0.64113\n","Epoch 27/100\n","160/160 [==============================] - 127s 786ms/step - loss: 0.2006 - accuracy: 0.9365 - auc: 0.9947 - f1_score: 0.9362 - scaled_graph_loss: 0.0328 - val_loss: 1.5266 - val_accuracy: 0.5848 - val_auc: 0.8310 - val_f1_score: 0.5867\n","\n","Epoch 00027: val_accuracy did not improve from 0.64113\n","Epoch 28/100\n","160/160 [==============================] - 126s 782ms/step - loss: 0.2025 - accuracy: 0.9349 - auc: 0.9945 - f1_score: 0.9350 - scaled_graph_loss: 0.0328 - val_loss: 2.6980 - val_accuracy: 0.5074 - val_auc: 0.7713 - val_f1_score: 0.5067\n","\n","Epoch 00028: val_accuracy did not improve from 0.64113\n","Epoch 29/100\n","160/160 [==============================] - 126s 783ms/step - loss: 0.1894 - accuracy: 0.9379 - auc: 0.9954 - f1_score: 0.9387 - scaled_graph_loss: 0.0318 - val_loss: 2.7210 - val_accuracy: 0.4457 - val_auc: 0.7413 - val_f1_score: 0.4461\n","\n","Epoch 00029: val_accuracy did not improve from 0.64113\n","Epoch 30/100\n","160/160 [==============================] - 126s 783ms/step - loss: 0.1946 - accuracy: 0.9375 - auc: 0.9949 - f1_score: 0.9375 - scaled_graph_loss: 0.0325 - val_loss: 1.6303 - val_accuracy: 0.5989 - val_auc: 0.8295 - val_f1_score: 0.5972\n","\n","Epoch 00030: val_accuracy did not improve from 0.64113\n","Epoch 31/100\n","160/160 [==============================] - 126s 782ms/step - loss: 0.1811 - accuracy: 0.9416 - auc: 0.9957 - f1_score: 0.9422 - scaled_graph_loss: 0.0309 - val_loss: 2.5705 - val_accuracy: 0.5020 - val_auc: 0.7568 - val_f1_score: 0.5035\n","\n","Epoch 00031: val_accuracy did not improve from 0.64113\n","Epoch 32/100\n","160/160 [==============================] - 126s 783ms/step - loss: 0.1667 - accuracy: 0.9488 - auc: 0.9965 - f1_score: 0.9491 - scaled_graph_loss: 0.0288 - val_loss: 1.6914 - val_accuracy: 0.6239 - val_auc: 0.8416 - val_f1_score: 0.6233\n","\n","Epoch 00032: val_accuracy did not improve from 0.64113\n","Epoch 33/100\n","160/160 [==============================] - 126s 782ms/step - loss: 0.1576 - accuracy: 0.9505 - auc: 0.9968 - f1_score: 0.9500 - scaled_graph_loss: 0.0277 - val_loss: 1.7174 - val_accuracy: 0.6286 - val_auc: 0.8453 - val_f1_score: 0.6271\n","\n","Epoch 00033: val_accuracy did not improve from 0.64113\n","Epoch 34/100\n","160/160 [==============================] - 126s 782ms/step - loss: 0.1782 - accuracy: 0.9459 - auc: 0.9956 - f1_score: 0.9456 - scaled_graph_loss: 0.0296 - val_loss: 2.4954 - val_accuracy: 0.5520 - val_auc: 0.7976 - val_f1_score: 0.5525\n","\n","Epoch 00034: val_accuracy did not improve from 0.64113\n","Epoch 35/100\n","160/160 [==============================] - 126s 783ms/step - loss: 0.1648 - accuracy: 0.9464 - auc: 0.9965 - f1_score: 0.9459 - scaled_graph_loss: 0.0287 - val_loss: 1.6218 - val_accuracy: 0.6325 - val_auc: 0.8417 - val_f1_score: 0.6303\n","\n","Epoch 00035: val_accuracy did not improve from 0.64113\n","Epoch 36/100\n","160/160 [==============================] - 126s 782ms/step - loss: 0.1824 - accuracy: 0.9412 - auc: 0.9955 - f1_score: 0.9411 - scaled_graph_loss: 0.0308 - val_loss: 1.7209 - val_accuracy: 0.6036 - val_auc: 0.8306 - val_f1_score: 0.6028\n","\n","Epoch 00036: val_accuracy did not improve from 0.64113\n","Epoch 37/100\n","160/160 [==============================] - 126s 782ms/step - loss: 0.1566 - accuracy: 0.9534 - auc: 0.9967 - f1_score: 0.9532 - scaled_graph_loss: 0.0277 - val_loss: 1.8871 - val_accuracy: 0.5590 - val_auc: 0.7881 - val_f1_score: 0.5564\n","\n","Epoch 00037: val_accuracy did not improve from 0.64113\n","Epoch 38/100\n","160/160 [==============================] - 126s 782ms/step - loss: 0.1543 - accuracy: 0.9538 - auc: 0.9970 - f1_score: 0.9542 - scaled_graph_loss: 0.0269 - val_loss: 2.5855 - val_accuracy: 0.5199 - val_auc: 0.7775 - val_f1_score: 0.5188\n","\n","Epoch 00038: val_accuracy did not improve from 0.64113\n","Epoch 39/100\n","160/160 [==============================] - 126s 784ms/step - loss: 0.1604 - accuracy: 0.9475 - auc: 0.9967 - f1_score: 0.9482 - scaled_graph_loss: 0.0285 - val_loss: 1.9858 - val_accuracy: 0.5403 - val_auc: 0.7880 - val_f1_score: 0.5421\n","\n","Epoch 00039: val_accuracy did not improve from 0.64113\n","Epoch 40/100\n","160/160 [==============================] - 126s 785ms/step - loss: 0.1585 - accuracy: 0.9522 - auc: 0.9967 - f1_score: 0.9515 - scaled_graph_loss: 0.0279 - val_loss: 1.8214 - val_accuracy: 0.6028 - val_auc: 0.8266 - val_f1_score: 0.6022\n","\n","Epoch 00040: val_accuracy did not improve from 0.64113\n","Epoch 41/100\n","160/160 [==============================] - 126s 785ms/step - loss: 0.1539 - accuracy: 0.9527 - auc: 0.9968 - f1_score: 0.9529 - scaled_graph_loss: 0.0284 - val_loss: 2.0475 - val_accuracy: 0.5770 - val_auc: 0.8061 - val_f1_score: 0.5783\n","\n","Epoch 00041: val_accuracy did not improve from 0.64113\n","Epoch 42/100\n","160/160 [==============================] - 126s 785ms/step - loss: 0.1691 - accuracy: 0.9454 - auc: 0.9962 - f1_score: 0.9455 - scaled_graph_loss: 0.0290 - val_loss: 2.5954 - val_accuracy: 0.5450 - val_auc: 0.7870 - val_f1_score: 0.5451\n","\n","Epoch 00042: val_accuracy did not improve from 0.64113\n","Epoch 43/100\n","160/160 [==============================] - 126s 783ms/step - loss: 0.1507 - accuracy: 0.9548 - auc: 0.9967 - f1_score: 0.9544 - scaled_graph_loss: 0.0272 - val_loss: 2.3952 - val_accuracy: 0.5676 - val_auc: 0.8027 - val_f1_score: 0.5678\n","\n","Epoch 00043: val_accuracy did not improve from 0.64113\n","Epoch 44/100\n","160/160 [==============================] - 126s 784ms/step - loss: 0.1448 - accuracy: 0.9552 - auc: 0.9970 - f1_score: 0.9552 - scaled_graph_loss: 0.0263 - val_loss: 2.1533 - val_accuracy: 0.6114 - val_auc: 0.8278 - val_f1_score: 0.6121\n","\n","Epoch 00044: val_accuracy did not improve from 0.64113\n","Epoch 45/100\n","160/160 [==============================] - 126s 785ms/step - loss: 0.1572 - accuracy: 0.9510 - auc: 0.9967 - f1_score: 0.9512 - scaled_graph_loss: 0.0273 - val_loss: 1.8338 - val_accuracy: 0.6036 - val_auc: 0.8185 - val_f1_score: 0.6044\n","\n","Epoch 00045: val_accuracy did not improve from 0.64113\n","Epoch 46/100\n","160/160 [==============================] - 126s 785ms/step - loss: 0.1372 - accuracy: 0.9585 - auc: 0.9976 - f1_score: 0.9589 - scaled_graph_loss: 0.0245 - val_loss: 2.5889 - val_accuracy: 0.5661 - val_auc: 0.7951 - val_f1_score: 0.5642\n","\n","Epoch 00046: val_accuracy did not improve from 0.64113\n","Epoch 47/100\n","160/160 [==============================] - 126s 785ms/step - loss: 0.1193 - accuracy: 0.9657 - auc: 0.9982 - f1_score: 0.9657 - scaled_graph_loss: 0.0221 - val_loss: 2.1927 - val_accuracy: 0.5739 - val_auc: 0.8122 - val_f1_score: 0.5715\n","\n","Epoch 00047: val_accuracy did not improve from 0.64113\n","Epoch 48/100\n","160/160 [==============================] - 127s 786ms/step - loss: 0.1408 - accuracy: 0.9581 - auc: 0.9972 - f1_score: 0.9577 - scaled_graph_loss: 0.0252 - val_loss: 2.2421 - val_accuracy: 0.5981 - val_auc: 0.8130 - val_f1_score: 0.5978\n","\n","Epoch 00048: val_accuracy did not improve from 0.64113\n","Epoch 49/100\n","160/160 [==============================] - 126s 785ms/step - loss: 0.1336 - accuracy: 0.9609 - auc: 0.9977 - f1_score: 0.9606 - scaled_graph_loss: 0.0249 - val_loss: 2.1858 - val_accuracy: 0.6083 - val_auc: 0.8231 - val_f1_score: 0.6083\n","\n","Epoch 00049: val_accuracy did not improve from 0.64113\n","Epoch 50/100\n","160/160 [==============================] - 126s 784ms/step - loss: 0.1525 - accuracy: 0.9541 - auc: 0.9969 - f1_score: 0.9542 - scaled_graph_loss: 0.0277 - val_loss: 2.4342 - val_accuracy: 0.5786 - val_auc: 0.8009 - val_f1_score: 0.5793\n","\n","Epoch 00050: val_accuracy did not improve from 0.64113\n","Epoch 51/100\n","160/160 [==============================] - 126s 785ms/step - loss: 0.1464 - accuracy: 0.9537 - auc: 0.9970 - f1_score: 0.9534 - scaled_graph_loss: 0.0271 - val_loss: 2.0559 - val_accuracy: 0.6208 - val_auc: 0.8299 - val_f1_score: 0.6201\n","\n","Epoch 00051: val_accuracy did not improve from 0.64113\n","Epoch 52/100\n","160/160 [==============================] - 126s 784ms/step - loss: 0.1369 - accuracy: 0.9603 - auc: 0.9974 - f1_score: 0.9602 - scaled_graph_loss: 0.0252 - val_loss: 2.3436 - val_accuracy: 0.6083 - val_auc: 0.8218 - val_f1_score: 0.6083\n","\n","Epoch 00052: val_accuracy did not improve from 0.64113\n","Epoch 53/100\n","160/160 [==============================] - 126s 786ms/step - loss: 0.1300 - accuracy: 0.9615 - auc: 0.9976 - f1_score: 0.9616 - scaled_graph_loss: 0.0239 - val_loss: 2.3007 - val_accuracy: 0.5981 - val_auc: 0.8116 - val_f1_score: 0.5969\n","\n","Epoch 00053: val_accuracy did not improve from 0.64113\n","Epoch 54/100\n","160/160 [==============================] - 126s 785ms/step - loss: 0.1177 - accuracy: 0.9641 - auc: 0.9984 - f1_score: 0.9641 - scaled_graph_loss: 0.0227 - val_loss: 2.0170 - val_accuracy: 0.6419 - val_auc: 0.8371 - val_f1_score: 0.6410\n","\n","Epoch 00054: val_accuracy improved from 0.64113 to 0.64191, saving model to /content/drive/MyDrive/AD Expriment II/VGG19_model_checkpoints/vgg19_weights_nsl\n","Epoch 55/100\n","160/160 [==============================] - 127s 786ms/step - loss: 0.1329 - accuracy: 0.9575 - auc: 0.9977 - f1_score: 0.9581 - scaled_graph_loss: 0.0248 - val_loss: 2.6294 - val_accuracy: 0.6333 - val_auc: 0.8220 - val_f1_score: 0.6355\n","\n","Epoch 00055: val_accuracy did not improve from 0.64191\n","Epoch 56/100\n","160/160 [==============================] - 126s 784ms/step - loss: 0.1328 - accuracy: 0.9601 - auc: 0.9975 - f1_score: 0.9595 - scaled_graph_loss: 0.0241 - val_loss: 2.1035 - val_accuracy: 0.5739 - val_auc: 0.7951 - val_f1_score: 0.5718\n","\n","Epoch 00056: val_accuracy did not improve from 0.64191\n","Epoch 57/100\n","160/160 [==============================] - 126s 784ms/step - loss: 0.1170 - accuracy: 0.9651 - auc: 0.9981 - f1_score: 0.9653 - scaled_graph_loss: 0.0222 - val_loss: 2.0027 - val_accuracy: 0.6310 - val_auc: 0.8357 - val_f1_score: 0.6303\n","\n","Epoch 00057: val_accuracy did not improve from 0.64191\n","Epoch 58/100\n","160/160 [==============================] - 126s 784ms/step - loss: 0.1073 - accuracy: 0.9677 - auc: 0.9986 - f1_score: 0.9678 - scaled_graph_loss: 0.0204 - val_loss: 3.1616 - val_accuracy: 0.5528 - val_auc: 0.7720 - val_f1_score: 0.5529\n","\n","Epoch 00058: val_accuracy did not improve from 0.64191\n","Epoch 59/100\n","160/160 [==============================] - 126s 785ms/step - loss: 0.1161 - accuracy: 0.9648 - auc: 0.9982 - f1_score: 0.9650 - scaled_graph_loss: 0.0224 - val_loss: 2.3899 - val_accuracy: 0.6435 - val_auc: 0.8273 - val_f1_score: 0.6434\n","\n","Epoch 00059: val_accuracy improved from 0.64191 to 0.64347, saving model to /content/drive/MyDrive/AD Expriment II/VGG19_model_checkpoints/vgg19_weights_nsl\n","Epoch 60/100\n","160/160 [==============================] - 127s 786ms/step - loss: 0.1303 - accuracy: 0.9583 - auc: 0.9975 - f1_score: 0.9575 - scaled_graph_loss: 0.0237 - val_loss: 2.4128 - val_accuracy: 0.6224 - val_auc: 0.8249 - val_f1_score: 0.6238\n","\n","Epoch 00060: val_accuracy did not improve from 0.64347\n","Epoch 61/100\n","160/160 [==============================] - 127s 786ms/step - loss: 0.1168 - accuracy: 0.9651 - auc: 0.9983 - f1_score: 0.9652 - scaled_graph_loss: 0.0214 - val_loss: 2.0243 - val_accuracy: 0.6145 - val_auc: 0.8348 - val_f1_score: 0.6128\n","\n","Epoch 00061: val_accuracy did not improve from 0.64347\n","Epoch 62/100\n","160/160 [==============================] - 126s 786ms/step - loss: 0.1187 - accuracy: 0.9629 - auc: 0.9978 - f1_score: 0.9633 - scaled_graph_loss: 0.0222 - val_loss: 3.2217 - val_accuracy: 0.5246 - val_auc: 0.7550 - val_f1_score: 0.5245\n","\n","Epoch 00062: val_accuracy did not improve from 0.64347\n","Epoch 63/100\n","160/160 [==============================] - 127s 786ms/step - loss: 0.1107 - accuracy: 0.9667 - auc: 0.9981 - f1_score: 0.9669 - scaled_graph_loss: 0.0210 - val_loss: 3.0824 - val_accuracy: 0.5934 - val_auc: 0.8004 - val_f1_score: 0.5930\n","\n","Epoch 00063: val_accuracy did not improve from 0.64347\n","Epoch 64/100\n","160/160 [==============================] - 126s 784ms/step - loss: 0.1195 - accuracy: 0.9643 - auc: 0.9978 - f1_score: 0.9645 - scaled_graph_loss: 0.0215 - val_loss: 2.3491 - val_accuracy: 0.6067 - val_auc: 0.8142 - val_f1_score: 0.6060\n","\n","Epoch 00064: val_accuracy did not improve from 0.64347\n","Epoch 65/100\n","160/160 [==============================] - 126s 784ms/step - loss: 0.1048 - accuracy: 0.9687 - auc: 0.9985 - f1_score: 0.9689 - scaled_graph_loss: 0.0202 - val_loss: 2.8222 - val_accuracy: 0.5934 - val_auc: 0.8065 - val_f1_score: 0.5922\n","\n","Epoch 00065: val_accuracy did not improve from 0.64347\n","Epoch 66/100\n","160/160 [==============================] - 126s 784ms/step - loss: 0.1174 - accuracy: 0.9643 - auc: 0.9981 - f1_score: 0.9648 - scaled_graph_loss: 0.0230 - val_loss: 3.2267 - val_accuracy: 0.5426 - val_auc: 0.7614 - val_f1_score: 0.5426\n","\n","Epoch 00066: val_accuracy did not improve from 0.64347\n","Epoch 67/100\n","160/160 [==============================] - 126s 785ms/step - loss: 0.1185 - accuracy: 0.9652 - auc: 0.9977 - f1_score: 0.9650 - scaled_graph_loss: 0.0218 - val_loss: 2.8420 - val_accuracy: 0.6177 - val_auc: 0.8156 - val_f1_score: 0.6179\n","\n","Epoch 00067: val_accuracy did not improve from 0.64347\n","Epoch 68/100\n","160/160 [==============================] - 126s 784ms/step - loss: 0.1065 - accuracy: 0.9663 - auc: 0.9985 - f1_score: 0.9667 - scaled_graph_loss: 0.0212 - val_loss: 2.8635 - val_accuracy: 0.5614 - val_auc: 0.7852 - val_f1_score: 0.5610\n","\n","Epoch 00068: val_accuracy did not improve from 0.64347\n","Epoch 69/100\n","160/160 [==============================] - 126s 784ms/step - loss: 0.1135 - accuracy: 0.9645 - auc: 0.9983 - f1_score: 0.9642 - scaled_graph_loss: 0.0222 - val_loss: 2.2834 - val_accuracy: 0.5715 - val_auc: 0.8023 - val_f1_score: 0.5706\n","\n","Epoch 00069: val_accuracy did not improve from 0.64347\n","Epoch 70/100\n","160/160 [==============================] - 126s 784ms/step - loss: 0.1190 - accuracy: 0.9649 - auc: 0.9980 - f1_score: 0.9640 - scaled_graph_loss: 0.0222 - val_loss: 2.3716 - val_accuracy: 0.6364 - val_auc: 0.8297 - val_f1_score: 0.6355\n","\n","Epoch 00070: val_accuracy did not improve from 0.64347\n","Epoch 71/100\n","160/160 [==============================] - 126s 785ms/step - loss: 0.0978 - accuracy: 0.9712 - auc: 0.9986 - f1_score: 0.9709 - scaled_graph_loss: 0.0192 - val_loss: 3.2851 - val_accuracy: 0.5934 - val_auc: 0.8008 - val_f1_score: 0.5948\n","\n","Epoch 00071: val_accuracy did not improve from 0.64347\n","Epoch 72/100\n","160/160 [==============================] - 126s 784ms/step - loss: 0.0953 - accuracy: 0.9701 - auc: 0.9988 - f1_score: 0.9702 - scaled_graph_loss: 0.0187 - val_loss: 2.5637 - val_accuracy: 0.6036 - val_auc: 0.8058 - val_f1_score: 0.6034\n","\n","Epoch 00072: val_accuracy did not improve from 0.64347\n","Epoch 73/100\n","160/160 [==============================] - 126s 784ms/step - loss: 0.1021 - accuracy: 0.9688 - auc: 0.9982 - f1_score: 0.9689 - scaled_graph_loss: 0.0194 - val_loss: 3.8074 - val_accuracy: 0.4676 - val_auc: 0.7003 - val_f1_score: 0.4681\n","\n","Epoch 00073: val_accuracy did not improve from 0.64347\n","Epoch 74/100\n","160/160 [==============================] - 126s 785ms/step - loss: 0.1021 - accuracy: 0.9671 - auc: 0.9987 - f1_score: 0.9671 - scaled_graph_loss: 0.0200 - val_loss: 2.6059 - val_accuracy: 0.6122 - val_auc: 0.8188 - val_f1_score: 0.6118\n","\n","Epoch 00074: val_accuracy did not improve from 0.64347\n","Epoch 75/100\n","160/160 [==============================] - 126s 783ms/step - loss: 0.1164 - accuracy: 0.9685 - auc: 0.9978 - f1_score: 0.9688 - scaled_graph_loss: 0.0219 - val_loss: 2.5778 - val_accuracy: 0.6216 - val_auc: 0.8229 - val_f1_score: 0.6230\n","\n","Epoch 00075: val_accuracy did not improve from 0.64347\n","Epoch 76/100\n","160/160 [==============================] - 126s 784ms/step - loss: 0.0979 - accuracy: 0.9704 - auc: 0.9987 - f1_score: 0.9708 - scaled_graph_loss: 0.0195 - val_loss: 2.5290 - val_accuracy: 0.5817 - val_auc: 0.7977 - val_f1_score: 0.5793\n","\n","Epoch 00076: val_accuracy did not improve from 0.64347\n","Epoch 77/100\n","160/160 [==============================] - 126s 784ms/step - loss: 0.1096 - accuracy: 0.9649 - auc: 0.9985 - f1_score: 0.9645 - scaled_graph_loss: 0.0210 - val_loss: 2.9528 - val_accuracy: 0.6302 - val_auc: 0.8172 - val_f1_score: 0.6314\n","\n","Epoch 00077: val_accuracy did not improve from 0.64347\n","Epoch 78/100\n","160/160 [==============================] - 126s 786ms/step - loss: 0.1096 - accuracy: 0.9636 - auc: 0.9984 - f1_score: 0.9640 - scaled_graph_loss: 0.0208 - val_loss: 4.3139 - val_accuracy: 0.4832 - val_auc: 0.7180 - val_f1_score: 0.4830\n","\n","Epoch 00078: val_accuracy did not improve from 0.64347\n","Epoch 79/100\n","160/160 [==============================] - 126s 784ms/step - loss: 0.1033 - accuracy: 0.9675 - auc: 0.9986 - f1_score: 0.9671 - scaled_graph_loss: 0.0206 - val_loss: 2.8960 - val_accuracy: 0.5872 - val_auc: 0.7968 - val_f1_score: 0.5864\n","\n","Epoch 00079: val_accuracy did not improve from 0.64347\n","Epoch 80/100\n","160/160 [==============================] - 126s 784ms/step - loss: 0.1134 - accuracy: 0.9642 - auc: 0.9982 - f1_score: 0.9646 - scaled_graph_loss: 0.0209 - val_loss: 5.4063 - val_accuracy: 0.4230 - val_auc: 0.6631 - val_f1_score: 0.4227\n","\n","Epoch 00080: val_accuracy did not improve from 0.64347\n","Epoch 81/100\n","160/160 [==============================] - 126s 783ms/step - loss: 0.1129 - accuracy: 0.9634 - auc: 0.9984 - f1_score: 0.9640 - scaled_graph_loss: 0.0220 - val_loss: 2.6605 - val_accuracy: 0.6091 - val_auc: 0.8105 - val_f1_score: 0.6086\n","\n","Epoch 00081: val_accuracy did not improve from 0.64347\n","Epoch 82/100\n","160/160 [==============================] - 126s 783ms/step - loss: 0.1086 - accuracy: 0.9652 - auc: 0.9984 - f1_score: 0.9653 - scaled_graph_loss: 0.0212 - val_loss: 2.3864 - val_accuracy: 0.5794 - val_auc: 0.7995 - val_f1_score: 0.5774\n","\n","Epoch 00082: val_accuracy did not improve from 0.64347\n","Epoch 83/100\n","160/160 [==============================] - 126s 783ms/step - loss: 0.0947 - accuracy: 0.9715 - auc: 0.9984 - f1_score: 0.9708 - scaled_graph_loss: 0.0182 - val_loss: 2.6377 - val_accuracy: 0.5927 - val_auc: 0.7997 - val_f1_score: 0.5928\n","\n","Epoch 00083: val_accuracy did not improve from 0.64347\n","Epoch 84/100\n","160/160 [==============================] - 126s 784ms/step - loss: 0.1013 - accuracy: 0.9703 - auc: 0.9985 - f1_score: 0.9704 - scaled_graph_loss: 0.0189 - val_loss: 2.7706 - val_accuracy: 0.5942 - val_auc: 0.8006 - val_f1_score: 0.5940\n","\n","Epoch 00084: val_accuracy did not improve from 0.64347\n","Epoch 85/100\n","160/160 [==============================] - 126s 783ms/step - loss: 0.0782 - accuracy: 0.9756 - auc: 0.9993 - f1_score: 0.9757 - scaled_graph_loss: 0.0158 - val_loss: 2.2438 - val_accuracy: 0.5911 - val_auc: 0.8187 - val_f1_score: 0.5892\n","\n","Epoch 00085: val_accuracy did not improve from 0.64347\n","Epoch 86/100\n","160/160 [==============================] - 126s 783ms/step - loss: 0.0939 - accuracy: 0.9736 - auc: 0.9985 - f1_score: 0.9733 - scaled_graph_loss: 0.0179 - val_loss: 2.5042 - val_accuracy: 0.6239 - val_auc: 0.8206 - val_f1_score: 0.6256\n","\n","Epoch 00086: val_accuracy did not improve from 0.64347\n","Epoch 87/100\n","160/160 [==============================] - 127s 787ms/step - loss: 0.1041 - accuracy: 0.9673 - auc: 0.9985 - f1_score: 0.9675 - scaled_graph_loss: 0.0201 - val_loss: 3.4692 - val_accuracy: 0.5348 - val_auc: 0.7531 - val_f1_score: 0.5347\n","\n","Epoch 00087: val_accuracy did not improve from 0.64347\n","Epoch 88/100\n","160/160 [==============================] - 127s 786ms/step - loss: 0.0883 - accuracy: 0.9720 - auc: 0.9990 - f1_score: 0.9723 - scaled_graph_loss: 0.0177 - val_loss: 2.6899 - val_accuracy: 0.5848 - val_auc: 0.7976 - val_f1_score: 0.5859\n","\n","Epoch 00088: val_accuracy did not improve from 0.64347\n","Epoch 89/100\n","160/160 [==============================] - 127s 787ms/step - loss: 0.0880 - accuracy: 0.9760 - auc: 0.9990 - f1_score: 0.9762 - scaled_graph_loss: 0.0186 - val_loss: 3.0771 - val_accuracy: 0.6059 - val_auc: 0.8015 - val_f1_score: 0.6050\n","\n","Epoch 00089: val_accuracy did not improve from 0.64347\n","Epoch 90/100\n","160/160 [==============================] - 127s 785ms/step - loss: 0.0823 - accuracy: 0.9731 - auc: 0.9992 - f1_score: 0.9737 - scaled_graph_loss: 0.0165 - val_loss: 3.2889 - val_accuracy: 0.5747 - val_auc: 0.7868 - val_f1_score: 0.5746\n","\n","Epoch 00090: val_accuracy did not improve from 0.64347\n","Epoch 91/100\n","160/160 [==============================] - 127s 786ms/step - loss: 0.0941 - accuracy: 0.9740 - auc: 0.9984 - f1_score: 0.9741 - scaled_graph_loss: 0.0175 - val_loss: 2.4023 - val_accuracy: 0.6357 - val_auc: 0.8275 - val_f1_score: 0.6376\n","\n","Epoch 00091: val_accuracy did not improve from 0.64347\n","Epoch 92/100\n","160/160 [==============================] - 127s 786ms/step - loss: 0.0824 - accuracy: 0.9759 - auc: 0.9989 - f1_score: 0.9766 - scaled_graph_loss: 0.0165 - val_loss: 2.7840 - val_accuracy: 0.6247 - val_auc: 0.8198 - val_f1_score: 0.6250\n","\n","Epoch 00092: val_accuracy did not improve from 0.64347\n","Epoch 93/100\n","160/160 [==============================] - 127s 787ms/step - loss: 0.0849 - accuracy: 0.9746 - auc: 0.9989 - f1_score: 0.9748 - scaled_graph_loss: 0.0168 - val_loss: 3.0949 - val_accuracy: 0.5364 - val_auc: 0.7644 - val_f1_score: 0.5379\n","\n","Epoch 00093: val_accuracy did not improve from 0.64347\n","Epoch 94/100\n","160/160 [==============================] - 129s 787ms/step - loss: 0.0946 - accuracy: 0.9695 - auc: 0.9988 - f1_score: 0.9688 - scaled_graph_loss: 0.0184 - val_loss: 2.9293 - val_accuracy: 0.5848 - val_auc: 0.7980 - val_f1_score: 0.5842\n","\n","Epoch 00094: val_accuracy did not improve from 0.64347\n","Epoch 95/100\n","160/160 [==============================] - 127s 787ms/step - loss: 0.0838 - accuracy: 0.9740 - auc: 0.9989 - f1_score: 0.9746 - scaled_graph_loss: 0.0170 - val_loss: 2.8923 - val_accuracy: 0.6310 - val_auc: 0.8221 - val_f1_score: 0.6304\n","\n","Epoch 00095: val_accuracy did not improve from 0.64347\n","Epoch 96/100\n","160/160 [==============================] - 127s 788ms/step - loss: 0.0818 - accuracy: 0.9763 - auc: 0.9991 - f1_score: 0.9766 - scaled_graph_loss: 0.0158 - val_loss: 3.0039 - val_accuracy: 0.5778 - val_auc: 0.7860 - val_f1_score: 0.5773\n","\n","Epoch 00096: val_accuracy did not improve from 0.64347\n","Epoch 97/100\n","160/160 [==============================] - 127s 787ms/step - loss: 0.0804 - accuracy: 0.9750 - auc: 0.9992 - f1_score: 0.9754 - scaled_graph_loss: 0.0164 - val_loss: 3.3082 - val_accuracy: 0.6059 - val_auc: 0.7928 - val_f1_score: 0.6040\n","\n","Epoch 00097: val_accuracy did not improve from 0.64347\n","Epoch 98/100\n","160/160 [==============================] - 127s 788ms/step - loss: 0.1089 - accuracy: 0.9667 - auc: 0.9982 - f1_score: 0.9674 - scaled_graph_loss: 0.0209 - val_loss: 2.9147 - val_accuracy: 0.6059 - val_auc: 0.8048 - val_f1_score: 0.6050\n","\n","Epoch 00098: val_accuracy did not improve from 0.64347\n","Epoch 99/100\n","160/160 [==============================] - 127s 788ms/step - loss: 0.0840 - accuracy: 0.9753 - auc: 0.9989 - f1_score: 0.9750 - scaled_graph_loss: 0.0166 - val_loss: 3.4807 - val_accuracy: 0.5973 - val_auc: 0.7982 - val_f1_score: 0.5977\n","\n","Epoch 00099: val_accuracy did not improve from 0.64347\n","Epoch 100/100\n","160/160 [==============================] - 127s 786ms/step - loss: 0.0767 - accuracy: 0.9766 - auc: 0.9992 - f1_score: 0.9767 - scaled_graph_loss: 0.0150 - val_loss: 3.2697 - val_accuracy: 0.5731 - val_auc: 0.7757 - val_f1_score: 0.5754\n","\n","Epoch 00100: val_accuracy did not improve from 0.64347\n","Early stopping is not triggered, but best model is restored at epoch 59\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"877FiZyAUJv7","executionInfo":{"status":"ok","timestamp":1605999764346,"user_tz":300,"elapsed":6732,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"bb1456b2-c5f6-482d-ce00-a6a2c4742471"},"source":["graph_reg_model.evaluate(test_image_dataset)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py:543: UserWarning: Input dict contained keys ['id'] which did not match any model input. They will be ignored by the model.\n","  [n for n in tensors.keys() if n not in ref_input_names])\n"],"name":"stderr"},{"output_type":"stream","text":["30/30 [==============================] - 4s 136ms/step - loss: 0.0949 - accuracy: 0.9713 - auc: 0.9969 - f1_score: 0.9710\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[0.09488795697689056,\n"," 0.9712643623352051,\n"," 0.9968827962875366,\n"," 0.9709879755973816]"]},"metadata":{"tags":[]},"execution_count":35}]},{"cell_type":"code","metadata":{"id":"anut2b6BRl6N"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mqiZpSxMXYSO"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"y67bzIq5iebn"},"source":["## 3.3 VGG19-NSL 5th block tunning\n","### val_acc: 0.98, val_auc: 0.99, val_f1_score: 0.98"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xl0BgfDHXgus","executionInfo":{"status":"ok","timestamp":1606000430970,"user_tz":300,"elapsed":1109,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"d8535780-315e-439a-9ec6-6417ca352152"},"source":["'''define params'''\n","params.learning_rate = 0.00005\n","params.checkpoint_restore_path = '/content/drive/My Drive/Projects/codes/VGG19_NSL_model_checkpoints/vgg19_nsl_weights_colab_new_97'\n","params.checkpoint_path='/content/drive/My Drive/Projects/codes/VGG19_NSL_model_checkpoints/vgg19_nsl_weights_colab_new_98'\n","params.early_stop_base_line=0.98\n","params.train_epoch=100\n","params.nsl_multiplier = 0.1\n","params.nsl_sum_over_axis = -1\n","params.nsl_distance_type = nsl.configs.DistanceType.COSINE\n","'''build base model'''\n","base_model = ADModelBuilder(input_shape=params.ad_base_model_input_shape, base_model='vgg19').setup_VGG19_by_layer_names(trainable_layers=['block5_conv1', \n","                                                                                                                                           'block5_conv2', \n","                                                                                                                                           'block5_conv3', \n","                                                                                                                                           'block5_conv4']).get_ADModel()\n","\"\"\"restore NSL model from last training\"\"\"\n","graph_reg_config = nsl.configs.make_graph_reg_config(neighbor_prefix=params.neighbor_prefix,\n","                                                     neighbor_weight_suffix=params.neighbor_weight_suffix,\n","                                                     max_neighbors= params.max_seed_nbr,\n","                                                     multiplier= params.nsl_multiplier,\n","                                                     distance_type= params.nsl_distance_type, \n","                                                     sum_over_axis= params.nsl_sum_over_axis)\n","graph_reg_model = nsl.keras.GraphRegularization(base_model,graph_reg_config)\n","graph_reg_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=params.learning_rate, amsgrad=True), \n","                        loss=tf.losses.CategoricalCrossentropy(),\n","                        metrics=[\"accuracy\",\"AUC\",tfa.metrics.F1Score(num_classes=4, average=\"micro\", threshold = 0.5)])\n","graph_reg_model.load_weights(params.checkpoint_restore_path)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Note: default vgg19 not includes top and has imagenet weights. It is not a trainable model in ADModelBuilder. Setup specific trainable layers in setup_VGG19_by_layer_names or setup_VGG19 function based on the VGG19 layer name or layer number\n","trainable layer:  block5_conv1\n","trainable layer:  block5_conv2\n","trainable layer:  block5_conv3\n","trainable layer:  block5_conv4\n","Model: \"vgg19\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_2 (InputLayer)         [(None, 100, 100, 3)]     0         \n","_________________________________________________________________\n","block1_conv1 (Conv2D)        (None, 100, 100, 64)      1792      \n","_________________________________________________________________\n","block1_conv2 (Conv2D)        (None, 100, 100, 64)      36928     \n","_________________________________________________________________\n","block1_pool (MaxPooling2D)   (None, 50, 50, 64)        0         \n","_________________________________________________________________\n","block2_conv1 (Conv2D)        (None, 50, 50, 128)       73856     \n","_________________________________________________________________\n","block2_conv2 (Conv2D)        (None, 50, 50, 128)       147584    \n","_________________________________________________________________\n","block2_pool (MaxPooling2D)   (None, 25, 25, 128)       0         \n","_________________________________________________________________\n","block3_conv1 (Conv2D)        (None, 25, 25, 256)       295168    \n","_________________________________________________________________\n","block3_conv2 (Conv2D)        (None, 25, 25, 256)       590080    \n","_________________________________________________________________\n","block3_conv3 (Conv2D)        (None, 25, 25, 256)       590080    \n","_________________________________________________________________\n","block3_conv4 (Conv2D)        (None, 25, 25, 256)       590080    \n","_________________________________________________________________\n","block3_pool (MaxPooling2D)   (None, 12, 12, 256)       0         \n","_________________________________________________________________\n","block4_conv1 (Conv2D)        (None, 12, 12, 512)       1180160   \n","_________________________________________________________________\n","block4_conv2 (Conv2D)        (None, 12, 12, 512)       2359808   \n","_________________________________________________________________\n","block4_conv3 (Conv2D)        (None, 12, 12, 512)       2359808   \n","_________________________________________________________________\n","block4_conv4 (Conv2D)        (None, 12, 12, 512)       2359808   \n","_________________________________________________________________\n","block4_pool (MaxPooling2D)   (None, 6, 6, 512)         0         \n","_________________________________________________________________\n","block5_conv1 (Conv2D)        (None, 6, 6, 512)         2359808   \n","_________________________________________________________________\n","block5_conv2 (Conv2D)        (None, 6, 6, 512)         2359808   \n","_________________________________________________________________\n","block5_conv3 (Conv2D)        (None, 6, 6, 512)         2359808   \n","_________________________________________________________________\n","block5_conv4 (Conv2D)        (None, 6, 6, 512)         2359808   \n","_________________________________________________________________\n","block5_pool (MaxPooling2D)   (None, 3, 3, 512)         0         \n","=================================================================\n","Total params: 20,024,384\n","Trainable params: 2,359,808\n","Non-trainable params: 17,664,576\n","_________________________________________________________________\n","Model: \"VGG19_ADModel\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","tensor (InputLayer)          [(None, 100, 100, 3)]     0         \n","_________________________________________________________________\n","vgg19 (Functional)           (None, 3, 3, 512)         20024384  \n","_________________________________________________________________\n","flatten_1 (Flatten)          (None, 4608)              0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 64)                294976    \n","_________________________________________________________________\n","batch_normalization_1 (Batch (None, 64)                256       \n","_________________________________________________________________\n","leaky_re_lu_1 (LeakyReLU)    (None, 64)                0         \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 64)                0         \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 4)                 260       \n","=================================================================\n","Total params: 20,319,876\n","Trainable params: 2,655,172\n","Non-trainable params: 17,664,704\n","_________________________________________________________________\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f6e705d0320>"]},"metadata":{"tags":[]},"execution_count":38}]},{"cell_type":"code","metadata":{"id":"3Yr-yYkzbxel","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606002468556,"user_tz":300,"elapsed":2031809,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"3570ec6c-1dc5-463f-87a5-82766e83df8d"},"source":["\"\"\"set up training checkpoint and earlystop callbacks\"\"\"\n","callback_checkpoints = tf.keras.callbacks.ModelCheckpoint(filepath=params.checkpoint_path, monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=True, mode='max',\n","                                                          save_freq='epoch')\n","callback_earlystop = AccEarlyStop(val_acc_base = params.early_stop_base_line)\n","\"\"\"NSL model training\"\"\"\n","graph_reg_history = graph_reg_model.fit(train_image_dataset, \n","                                        validation_data=test_image_dataset,\n","                                        callbacks = [callback_checkpoints, callback_earlystop],\n","                                        epochs= params.train_epoch,\n","                                        verbose=1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py:543: UserWarning: Input dict contained keys ['id'] which did not match any model input. They will be ignored by the model.\n","  [n for n in tensors.keys() if n not in ref_input_names])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:432: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"],"name":"stderr"},{"output_type":"stream","text":["     69/Unknown - 52s 753ms/step - loss: 1.6121 - accuracy: 0.6404 - auc: 0.8563 - f1_score: 0.6394 - scaled_graph_loss: 0.0153\n","Epoch 00001: val_accuracy improved from -inf to 0.49556, saving model to /content/drive/My Drive/Projects/codes/VGG19_NSL_model_checkpoints/vgg19_nsl_weights_colab_new_98\n","69/69 [==============================] - 61s 881ms/step - loss: 1.6121 - accuracy: 0.6404 - auc: 0.8563 - f1_score: 0.6394 - scaled_graph_loss: 0.0153 - val_loss: 3.0820 - val_accuracy: 0.4956 - val_auc: 0.7293 - val_f1_score: 0.5949\n","Epoch 2/100\n","69/69 [==============================] - ETA: 0s - loss: 0.6040 - accuracy: 0.7492 - auc: 0.9392 - f1_score: 0.7464 - scaled_graph_loss: 0.0110\n","Epoch 00002: val_accuracy improved from 0.49556 to 0.61311, saving model to /content/drive/My Drive/Projects/codes/VGG19_NSL_model_checkpoints/vgg19_nsl_weights_colab_new_98\n","69/69 [==============================] - 57s 831ms/step - loss: 0.6040 - accuracy: 0.7492 - auc: 0.9392 - f1_score: 0.7464 - scaled_graph_loss: 0.0110 - val_loss: 0.9116 - val_accuracy: 0.6131 - val_auc: 0.8836 - val_f1_score: 0.6138\n","Epoch 3/100\n","69/69 [==============================] - ETA: 0s - loss: 0.4842 - accuracy: 0.7966 - auc: 0.9591 - f1_score: 0.7922 - scaled_graph_loss: 0.0094\n","Epoch 00003: val_accuracy improved from 0.61311 to 0.82732, saving model to /content/drive/My Drive/Projects/codes/VGG19_NSL_model_checkpoints/vgg19_nsl_weights_colab_new_98\n","69/69 [==============================] - 60s 872ms/step - loss: 0.4842 - accuracy: 0.7966 - auc: 0.9591 - f1_score: 0.7922 - scaled_graph_loss: 0.0094 - val_loss: 0.4223 - val_accuracy: 0.8273 - val_auc: 0.9701 - val_f1_score: 0.8214\n","Epoch 4/100\n","69/69 [==============================] - ETA: 0s - loss: 0.4076 - accuracy: 0.8324 - auc: 0.9707 - f1_score: 0.8294 - scaled_graph_loss: 0.0085\n","Epoch 00004: val_accuracy did not improve from 0.82732\n","69/69 [==============================] - 59s 859ms/step - loss: 0.4076 - accuracy: 0.8324 - auc: 0.9707 - f1_score: 0.8294 - scaled_graph_loss: 0.0085 - val_loss: 1.1681 - val_accuracy: 0.6280 - val_auc: 0.8567 - val_f1_score: 0.6311\n","Epoch 5/100\n","69/69 [==============================] - ETA: 0s - loss: 0.3492 - accuracy: 0.8627 - auc: 0.9786 - f1_score: 0.8575 - scaled_graph_loss: 0.0077\n","Epoch 00005: val_accuracy did not improve from 0.82732\n","69/69 [==============================] - 60s 863ms/step - loss: 0.3492 - accuracy: 0.8627 - auc: 0.9786 - f1_score: 0.8575 - scaled_graph_loss: 0.0077 - val_loss: 0.6277 - val_accuracy: 0.7508 - val_auc: 0.9437 - val_f1_score: 0.7513\n","Epoch 6/100\n","69/69 [==============================] - ETA: 0s - loss: 0.3072 - accuracy: 0.8766 - auc: 0.9833 - f1_score: 0.8762 - scaled_graph_loss: 0.0075\n","Epoch 00006: val_accuracy did not improve from 0.82732\n","69/69 [==============================] - 60s 863ms/step - loss: 0.3072 - accuracy: 0.8766 - auc: 0.9833 - f1_score: 0.8762 - scaled_graph_loss: 0.0075 - val_loss: 1.0846 - val_accuracy: 0.6816 - val_auc: 0.9029 - val_f1_score: 0.6795\n","Epoch 7/100\n","69/69 [==============================] - ETA: 0s - loss: 0.2731 - accuracy: 0.8970 - auc: 0.9869 - f1_score: 0.8975 - scaled_graph_loss: 0.0069\n","Epoch 00007: val_accuracy did not improve from 0.82732\n","69/69 [==============================] - 60s 864ms/step - loss: 0.2731 - accuracy: 0.8970 - auc: 0.9869 - f1_score: 0.8975 - scaled_graph_loss: 0.0069 - val_loss: 1.4117 - val_accuracy: 0.7085 - val_auc: 0.8693 - val_f1_score: 0.7103\n","Epoch 8/100\n","69/69 [==============================] - ETA: 0s - loss: 0.2322 - accuracy: 0.9114 - auc: 0.9904 - f1_score: 0.9113 - scaled_graph_loss: 0.0063\n","Epoch 00008: val_accuracy did not improve from 0.82732\n","69/69 [==============================] - 59s 861ms/step - loss: 0.2322 - accuracy: 0.9114 - auc: 0.9904 - f1_score: 0.9113 - scaled_graph_loss: 0.0063 - val_loss: 1.0683 - val_accuracy: 0.7200 - val_auc: 0.9138 - val_f1_score: 0.7210\n","Epoch 9/100\n","69/69 [==============================] - ETA: 0s - loss: 0.2201 - accuracy: 0.9152 - auc: 0.9914 - f1_score: 0.9155 - scaled_graph_loss: 0.0059\n","Epoch 00009: val_accuracy did not improve from 0.82732\n","69/69 [==============================] - 59s 860ms/step - loss: 0.2201 - accuracy: 0.9152 - auc: 0.9914 - f1_score: 0.9155 - scaled_graph_loss: 0.0059 - val_loss: 0.8222 - val_accuracy: 0.7283 - val_auc: 0.9272 - val_f1_score: 0.7316\n","Epoch 10/100\n","69/69 [==============================] - ETA: 0s - loss: 0.1721 - accuracy: 0.9336 - auc: 0.9947 - f1_score: 0.9341 - scaled_graph_loss: 0.0054\n","Epoch 00010: val_accuracy did not improve from 0.82732\n","69/69 [==============================] - 60s 862ms/step - loss: 0.1721 - accuracy: 0.9336 - auc: 0.9947 - f1_score: 0.9341 - scaled_graph_loss: 0.0054 - val_loss: 0.9841 - val_accuracy: 0.7095 - val_auc: 0.9180 - val_f1_score: 0.7085\n","Epoch 11/100\n","69/69 [==============================] - ETA: 0s - loss: 0.1637 - accuracy: 0.9402 - auc: 0.9952 - f1_score: 0.9399 - scaled_graph_loss: 0.0050\n","Epoch 00011: val_accuracy improved from 0.82732 to 0.86729, saving model to /content/drive/My Drive/Projects/codes/VGG19_NSL_model_checkpoints/vgg19_nsl_weights_colab_new_98\n","69/69 [==============================] - 60s 868ms/step - loss: 0.1637 - accuracy: 0.9402 - auc: 0.9952 - f1_score: 0.9399 - scaled_graph_loss: 0.0050 - val_loss: 0.3596 - val_accuracy: 0.8673 - val_auc: 0.9800 - val_f1_score: 0.8688\n","Epoch 12/100\n","69/69 [==============================] - ETA: 0s - loss: 0.1479 - accuracy: 0.9460 - auc: 0.9960 - f1_score: 0.9467 - scaled_graph_loss: 0.0047\n","Epoch 00012: val_accuracy improved from 0.86729 to 0.87095, saving model to /content/drive/My Drive/Projects/codes/VGG19_NSL_model_checkpoints/vgg19_nsl_weights_colab_new_98\n","69/69 [==============================] - 60s 875ms/step - loss: 0.1479 - accuracy: 0.9460 - auc: 0.9960 - f1_score: 0.9467 - scaled_graph_loss: 0.0047 - val_loss: 0.3297 - val_accuracy: 0.8710 - val_auc: 0.9828 - val_f1_score: 0.8715\n","Epoch 13/100\n","69/69 [==============================] - ETA: 0s - loss: 0.1295 - accuracy: 0.9551 - auc: 0.9969 - f1_score: 0.9552 - scaled_graph_loss: 0.0041\n","Epoch 00013: val_accuracy improved from 0.87095 to 0.88349, saving model to /content/drive/My Drive/Projects/codes/VGG19_NSL_model_checkpoints/vgg19_nsl_weights_colab_new_98\n","69/69 [==============================] - 60s 870ms/step - loss: 0.1295 - accuracy: 0.9551 - auc: 0.9969 - f1_score: 0.9552 - scaled_graph_loss: 0.0041 - val_loss: 0.3203 - val_accuracy: 0.8835 - val_auc: 0.9827 - val_f1_score: 0.8845\n","Epoch 14/100\n","69/69 [==============================] - ETA: 0s - loss: 0.1166 - accuracy: 0.9567 - auc: 0.9976 - f1_score: 0.9569 - scaled_graph_loss: 0.0040\n","Epoch 00014: val_accuracy did not improve from 0.88349\n","69/69 [==============================] - 59s 861ms/step - loss: 0.1166 - accuracy: 0.9567 - auc: 0.9976 - f1_score: 0.9569 - scaled_graph_loss: 0.0040 - val_loss: 0.9336 - val_accuracy: 0.7926 - val_auc: 0.9327 - val_f1_score: 0.7945\n","Epoch 15/100\n","69/69 [==============================] - ETA: 0s - loss: 0.1153 - accuracy: 0.9559 - auc: 0.9976 - f1_score: 0.9559 - scaled_graph_loss: 0.0040\n","Epoch 00015: val_accuracy did not improve from 0.88349\n","69/69 [==============================] - 60s 863ms/step - loss: 0.1153 - accuracy: 0.9559 - auc: 0.9976 - f1_score: 0.9559 - scaled_graph_loss: 0.0040 - val_loss: 0.4333 - val_accuracy: 0.8647 - val_auc: 0.9743 - val_f1_score: 0.8653\n","Epoch 16/100\n","69/69 [==============================] - ETA: 0s - loss: 0.0859 - accuracy: 0.9718 - auc: 0.9986 - f1_score: 0.9719 - scaled_graph_loss: 0.0029\n","Epoch 00016: val_accuracy did not improve from 0.88349\n","69/69 [==============================] - 60s 863ms/step - loss: 0.0859 - accuracy: 0.9718 - auc: 0.9986 - f1_score: 0.9719 - scaled_graph_loss: 0.0029 - val_loss: 0.3362 - val_accuracy: 0.8751 - val_auc: 0.9828 - val_f1_score: 0.8754\n","Epoch 17/100\n","69/69 [==============================] - ETA: 0s - loss: 0.0687 - accuracy: 0.9792 - auc: 0.9992 - f1_score: 0.9793 - scaled_graph_loss: 0.0025\n","Epoch 00017: val_accuracy did not improve from 0.88349\n","69/69 [==============================] - 59s 862ms/step - loss: 0.0687 - accuracy: 0.9792 - auc: 0.9992 - f1_score: 0.9793 - scaled_graph_loss: 0.0025 - val_loss: 0.6834 - val_accuracy: 0.7923 - val_auc: 0.9531 - val_f1_score: 0.7932\n","Epoch 18/100\n","69/69 [==============================] - ETA: 0s - loss: 0.0775 - accuracy: 0.9742 - auc: 0.9988 - f1_score: 0.9738 - scaled_graph_loss: 0.0027\n","Epoch 00018: val_accuracy improved from 0.88349 to 0.94096, saving model to /content/drive/My Drive/Projects/codes/VGG19_NSL_model_checkpoints/vgg19_nsl_weights_colab_new_98\n","69/69 [==============================] - 60s 872ms/step - loss: 0.0775 - accuracy: 0.9742 - auc: 0.9988 - f1_score: 0.9738 - scaled_graph_loss: 0.0027 - val_loss: 0.1652 - val_accuracy: 0.9410 - val_auc: 0.9941 - val_f1_score: 0.9417\n","Epoch 19/100\n","69/69 [==============================] - ETA: 0s - loss: 0.0750 - accuracy: 0.9736 - auc: 0.9990 - f1_score: 0.9739 - scaled_graph_loss: 0.0026\n","Epoch 00019: val_accuracy did not improve from 0.94096\n","69/69 [==============================] - 60s 863ms/step - loss: 0.0750 - accuracy: 0.9736 - auc: 0.9990 - f1_score: 0.9739 - scaled_graph_loss: 0.0026 - val_loss: 0.5793 - val_accuracy: 0.8022 - val_auc: 0.9609 - val_f1_score: 0.8017\n","Epoch 20/100\n","69/69 [==============================] - ETA: 0s - loss: 0.0584 - accuracy: 0.9812 - auc: 0.9993 - f1_score: 0.9813 - scaled_graph_loss: 0.0020\n","Epoch 00020: val_accuracy did not improve from 0.94096\n","69/69 [==============================] - 59s 862ms/step - loss: 0.0584 - accuracy: 0.9812 - auc: 0.9993 - f1_score: 0.9813 - scaled_graph_loss: 0.0020 - val_loss: 2.1722 - val_accuracy: 0.6722 - val_auc: 0.8434 - val_f1_score: 0.6718\n","Epoch 21/100\n","69/69 [==============================] - ETA: 0s - loss: 0.0649 - accuracy: 0.9779 - auc: 0.9992 - f1_score: 0.9778 - scaled_graph_loss: 0.0023\n","Epoch 00021: val_accuracy improved from 0.94096 to 0.94645, saving model to /content/drive/My Drive/Projects/codes/VGG19_NSL_model_checkpoints/vgg19_nsl_weights_colab_new_98\n","69/69 [==============================] - 60s 867ms/step - loss: 0.0649 - accuracy: 0.9779 - auc: 0.9992 - f1_score: 0.9778 - scaled_graph_loss: 0.0023 - val_loss: 0.1482 - val_accuracy: 0.9464 - val_auc: 0.9949 - val_f1_score: 0.9463\n","Epoch 22/100\n","69/69 [==============================] - ETA: 0s - loss: 0.0572 - accuracy: 0.9823 - auc: 0.9994 - f1_score: 0.9823 - scaled_graph_loss: 0.0019\n","Epoch 00022: val_accuracy did not improve from 0.94645\n","69/69 [==============================] - 60s 863ms/step - loss: 0.0572 - accuracy: 0.9823 - auc: 0.9994 - f1_score: 0.9823 - scaled_graph_loss: 0.0019 - val_loss: 0.3423 - val_accuracy: 0.8892 - val_auc: 0.9819 - val_f1_score: 0.8891\n","Epoch 23/100\n","69/69 [==============================] - ETA: 0s - loss: 0.0422 - accuracy: 0.9879 - auc: 0.9997 - f1_score: 0.9880 - scaled_graph_loss: 0.0015\n","Epoch 00023: val_accuracy did not improve from 0.94645\n","69/69 [==============================] - 59s 858ms/step - loss: 0.0422 - accuracy: 0.9879 - auc: 0.9997 - f1_score: 0.9880 - scaled_graph_loss: 0.0015 - val_loss: 0.1625 - val_accuracy: 0.9431 - val_auc: 0.9935 - val_f1_score: 0.9430\n","Epoch 24/100\n","69/69 [==============================] - ETA: 0s - loss: 0.0412 - accuracy: 0.9860 - auc: 0.9997 - f1_score: 0.9862 - scaled_graph_loss: 0.0015\n","Epoch 00024: val_accuracy did not improve from 0.94645\n","69/69 [==============================] - 59s 861ms/step - loss: 0.0412 - accuracy: 0.9860 - auc: 0.9997 - f1_score: 0.9862 - scaled_graph_loss: 0.0015 - val_loss: 1.2493 - val_accuracy: 0.7751 - val_auc: 0.9109 - val_f1_score: 0.7750\n","Epoch 25/100\n","69/69 [==============================] - ETA: 0s - loss: 0.0613 - accuracy: 0.9790 - auc: 0.9992 - f1_score: 0.9789 - scaled_graph_loss: 0.0022\n","Epoch 00025: val_accuracy did not improve from 0.94645\n","69/69 [==============================] - 60s 863ms/step - loss: 0.0613 - accuracy: 0.9790 - auc: 0.9992 - f1_score: 0.9789 - scaled_graph_loss: 0.0022 - val_loss: 1.4673 - val_accuracy: 0.7100 - val_auc: 0.8900 - val_f1_score: 0.7111\n","Epoch 26/100\n","69/69 [==============================] - ETA: 0s - loss: 0.0505 - accuracy: 0.9837 - auc: 0.9995 - f1_score: 0.9838 - scaled_graph_loss: 0.0017\n","Epoch 00026: val_accuracy did not improve from 0.94645\n","69/69 [==============================] - 59s 862ms/step - loss: 0.0505 - accuracy: 0.9837 - auc: 0.9995 - f1_score: 0.9838 - scaled_graph_loss: 0.0017 - val_loss: 0.6037 - val_accuracy: 0.8145 - val_auc: 0.9610 - val_f1_score: 0.8146\n","Epoch 27/100\n","69/69 [==============================] - ETA: 0s - loss: 0.0341 - accuracy: 0.9892 - auc: 0.9998 - f1_score: 0.9894 - scaled_graph_loss: 0.0012\n","Epoch 00027: val_accuracy improved from 0.94645 to 0.94723, saving model to /content/drive/My Drive/Projects/codes/VGG19_NSL_model_checkpoints/vgg19_nsl_weights_colab_new_98\n","69/69 [==============================] - 60s 869ms/step - loss: 0.0341 - accuracy: 0.9892 - auc: 0.9998 - f1_score: 0.9894 - scaled_graph_loss: 0.0012 - val_loss: 0.1469 - val_accuracy: 0.9472 - val_auc: 0.9943 - val_f1_score: 0.9479\n","Epoch 28/100\n","69/69 [==============================] - ETA: 0s - loss: 0.0251 - accuracy: 0.9935 - auc: 0.9999 - f1_score: 0.9933 - scaled_graph_loss: 9.6133e-04\n","Epoch 00028: val_accuracy did not improve from 0.94723\n","69/69 [==============================] - 59s 860ms/step - loss: 0.0251 - accuracy: 0.9935 - auc: 0.9999 - f1_score: 0.9933 - scaled_graph_loss: 9.6133e-04 - val_loss: 0.1881 - val_accuracy: 0.9292 - val_auc: 0.9930 - val_f1_score: 0.9283\n","Epoch 29/100\n","69/69 [==============================] - ETA: 0s - loss: 0.0370 - accuracy: 0.9886 - auc: 0.9996 - f1_score: 0.9884 - scaled_graph_loss: 0.0013\n","Epoch 00029: val_accuracy did not improve from 0.94723\n","69/69 [==============================] - 60s 864ms/step - loss: 0.0370 - accuracy: 0.9886 - auc: 0.9996 - f1_score: 0.9884 - scaled_graph_loss: 0.0013 - val_loss: 0.5493 - val_accuracy: 0.8443 - val_auc: 0.9666 - val_f1_score: 0.8456\n","Epoch 30/100\n","69/69 [==============================] - ETA: 0s - loss: 0.0272 - accuracy: 0.9921 - auc: 0.9998 - f1_score: 0.9922 - scaled_graph_loss: 9.2939e-04\n","Epoch 00030: val_accuracy did not improve from 0.94723\n","69/69 [==============================] - 60s 863ms/step - loss: 0.0272 - accuracy: 0.9921 - auc: 0.9998 - f1_score: 0.9922 - scaled_graph_loss: 9.2939e-04 - val_loss: 0.7933 - val_accuracy: 0.8009 - val_auc: 0.9468 - val_f1_score: 0.8010\n","Epoch 31/100\n","69/69 [==============================] - ETA: 0s - loss: 0.0329 - accuracy: 0.9905 - auc: 0.9996 - f1_score: 0.9905 - scaled_graph_loss: 0.0013\n","Epoch 00031: val_accuracy did not improve from 0.94723\n","69/69 [==============================] - 60s 863ms/step - loss: 0.0329 - accuracy: 0.9905 - auc: 0.9996 - f1_score: 0.9905 - scaled_graph_loss: 0.0013 - val_loss: 0.1658 - val_accuracy: 0.9446 - val_auc: 0.9926 - val_f1_score: 0.9452\n","Epoch 32/100\n","69/69 [==============================] - ETA: 0s - loss: 0.0249 - accuracy: 0.9934 - auc: 0.9999 - f1_score: 0.9934 - scaled_graph_loss: 8.6392e-04\n","Epoch 00032: val_accuracy improved from 0.94723 to 0.96630, saving model to /content/drive/My Drive/Projects/codes/VGG19_NSL_model_checkpoints/vgg19_nsl_weights_colab_new_98\n","69/69 [==============================] - 60s 871ms/step - loss: 0.0249 - accuracy: 0.9934 - auc: 0.9999 - f1_score: 0.9934 - scaled_graph_loss: 8.6392e-04 - val_loss: 0.0968 - val_accuracy: 0.9663 - val_auc: 0.9972 - val_f1_score: 0.9665\n","Epoch 33/100\n","69/69 [==============================] - ETA: 0s - loss: 0.0128 - accuracy: 0.9983 - auc: 1.0000 - f1_score: 0.9983 - scaled_graph_loss: 3.4883e-04\n","Epoch 00033: val_accuracy improved from 0.96630 to 0.98224, saving model to /content/drive/My Drive/Projects/codes/VGG19_NSL_model_checkpoints/vgg19_nsl_weights_colab_new_98\n","69/69 [==============================] - 60s 870ms/step - loss: 0.0128 - accuracy: 0.9983 - auc: 1.0000 - f1_score: 0.9983 - scaled_graph_loss: 3.4883e-04 - val_loss: 0.0699 - val_accuracy: 0.9822 - val_auc: 0.9973 - val_f1_score: 0.9822\n","Epoch 00034: early stopping\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UhIlqMFhgbcK","executionInfo":{"status":"ok","timestamp":1606002474306,"user_tz":300,"elapsed":5726,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"2e547b6e-6bf5-4569-b0d8-9b4f4399c2aa"},"source":["\"\"\"evaluate tuned model\"\"\"\n","graph_reg_model.evaluate(test_image_dataset)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["30/30 [==============================] - 4s 128ms/step - loss: 0.0699 - accuracy: 0.9822 - auc: 0.9973 - f1_score: 0.9822\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[0.06989272683858871,\n"," 0.9822361469268799,\n"," 0.9973025321960449,\n"," 0.9822361469268799]"]},"metadata":{"tags":[]},"execution_count":40}]},{"cell_type":"code","metadata":{"id":"fuf0qJfrMNz6"},"source":["'''plot confusion mat & calc acc for each label'''\n","test_image_dataset = NSLDataFormat.generate_test_tfr_image_tensor(path_list=tfr_list_test, \n","                                                                  batch_size=4000, \n","                                                                  size=(100,100),\n","                                                                  channels=3,\n","                                                                  shuffle=True)\n","data, data_label = iter(test_image_dataset).get_next()\n","data = data[\"tensor\"]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":450},"id":"aHTNVO-oMN3O","executionInfo":{"status":"ok","timestamp":1606002666564,"user_tz":300,"elapsed":5621,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"3ea513b2-f1d7-4d29-e7f2-0939d46b5f9d"},"source":["ADModelBuilder.plot_confusion_mat(graph_reg_model, data, data_label, \"VGG19_NSL\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py:543: UserWarning: Input dict contained keys ['id'] which did not match any model input. They will be ignored by the model.\n","  [n for n in tensors.keys() if n not in ref_input_names])\n"],"name":"stderr"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x432 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SZbyx6tgMeCw","executionInfo":{"status":"ok","timestamp":1606002675882,"user_tz":300,"elapsed":4703,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"c3b12360-d48c-4103-bb8e-46214da96cc2"},"source":["ADModelBuilder.calc_confu_mat_for_each_label(graph_reg_model, data, data_label)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["TN: [2812 2882 2860 2862]\n","TP: [982 881 932 965]\n","FN: [ 9 57  2  0]\n","FP: [25  8 34  1]\n","Acc: [1897.  1881.5 1896.  1913.5]\n","ER(Error rate): [17.  32.5 18.   0.5]\n","Recall(TP rate): [0.99091826 0.93923241 0.99785867 1.        ]\n","Specialty(TN rate): [0.99118787 0.99723183 0.98825155 0.99965072]\n","Fall Out(FP rate): [0.00881213 0.00276817 0.01174845 0.00034928]\n","Miss Rate(FN rate): [0.00908174 0.06076759 0.00214133 0.        ]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_fE_9cNM7AS9"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YRSBTOx_ZQ2Y"},"source":["# 7.DenseNet121 & DenseNet121-NSL Model Training"]},{"cell_type":"code","metadata":{"id":"KBPizJFmjEvJ"},"source":["'''define hyper params'''\n","params = AD_params()\n","params.max_seed_nbr=5\n","params.batch_size=128\n","params.image_channels =3\n","params.image_size =(100,100)\n","params.ad_base_model_input_shape=(100,100,3)\n","params.train_tfr_path = f'{root_path}train_data.tfr'\n","\n","'''parse train_data.tfr to train image dataset with batch_size at 128'''\n","train_image_dataset = NSLDataFormat.parse_tfr_to_dataset(file_path_list=[params.train_tfr_path],\n","                                                         batch_size=params.batch_size,\n","                                                         max_neighbor_number=params.max_seed_nbr,\n","                                                         image_size=params.image_size,\n","                                                         image_channels=params.image_channels,\n","                                                         shuffle=True)\n","\n","'''load test data with batch_size at 128 '''\n","test_image_dataset = NSLDataFormat.generate_test_tfr_image_tensor(path_list=tfr_list_test, \n","                                                                  batch_size=params.batch_size, \n","                                                                  size=params.image_size,\n","                                                                  channels=params.image_channels,\n","                                                                  shuffle=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"980I6MuXjAix"},"source":["## 4.1 DenseNet Base Model Training\n","### val_acc: 0.9152, val_auc: 0.9906, val_f1_score: 0.91498"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2xyvZj1bcueJ","executionInfo":{"status":"ok","timestamp":1606257155498,"user_tz":300,"elapsed":12197,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"91ab7488-3c10-44ff-f8ba-8ba8ca372877"},"source":["'''define params'''\n","params.learning_rate=0.01\n","params.checkpoint_restore_path='/content/drive/My Drive/Projects/codes/DenseNet_model_checkpoints/densenet_model_weights_new_91'\n","params.checkpoint_path='/content/drive/My Drive/Projects/codes/DenseNet_model_checkpoints/densenet_model_weights_new_91'\n","params.early_stop_base_line=0.91\n","params.train_epoch=100\n","\n","'''build base_model and restore from the last training'''\n","base_model = ADModelBuilder(input_shape=params.ad_base_model_input_shape, base_model='densenet121').get_ADModel()\n","base_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=params.learning_rate, amsgrad=True), \n","                   loss=tf.losses.CategoricalCrossentropy(), \n","                   metrics=['accuracy', 'AUC',tfa.metrics.F1Score(num_classes=4, average=\"micro\", threshold = 0.5)])\n","base_model.load_weights(params.checkpoint_restore_path)\n","\n","'''set up check point & early stopping'''\n","callback_checkpints = tf.keras.callbacks.ModelCheckpoint(filepath= params.checkpoint_path, monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=True, mode='max',\n","                                                         save_freq='epoch',options=None)\n","callback_earlystop = AccEarlyStop(val_acc_base=params.early_stop_base_line)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Note: default DenseNet121 not includes top and has imagenet weights. It is not a trainable model in ADModelBuilder. Please setup trainable layers in setup_DenseNet121 function based on the \"Layer Number\"\n","Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n","29089792/29084464 [==============================] - 0s 0us/step\n","Model: \"DenseNet121_ADModel\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","tensor (InputLayer)          [(None, 100, 100, 3)]     0         \n","_________________________________________________________________\n","densenet121 (Functional)     (None, 3, 3, 1024)        7037504   \n","_________________________________________________________________\n","flatten_1 (Flatten)          (None, 9216)              0         \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 9216)              0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 128)               1179776   \n","_________________________________________________________________\n","batch_normalization_1 (Batch (None, 128)               512       \n","_________________________________________________________________\n","leaky_re_lu_1 (LeakyReLU)    (None, 128)               0         \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 128)               0         \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 4)                 516       \n","=================================================================\n","Total params: 8,218,308\n","Trainable params: 1,180,548\n","Non-trainable params: 7,037,760\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tpy7INugZP2P","executionInfo":{"status":"ok","timestamp":1606003711767,"user_tz":300,"elapsed":861511,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"8d85ed93-249d-4d4d-c6ce-09c403f81010"},"source":["'''train base model'''\n","history = base_model.fit(train_image_dataset,\n","                         validation_data= test_image_dataset,\n","                         callbacks = [callback_checkpints, callback_earlystop],\n","                         epochs=params.train_epoch,\n","                         verbose=1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py:543: UserWarning: Input dict contained keys ['NL_nbr_0_id', 'NL_nbr_0_tensor', 'NL_nbr_0_weight', 'NL_nbr_1_id', 'NL_nbr_1_tensor', 'NL_nbr_1_weight', 'NL_nbr_2_id', 'NL_nbr_2_tensor', 'NL_nbr_2_weight', 'NL_nbr_3_id', 'NL_nbr_3_tensor', 'NL_nbr_3_weight', 'NL_nbr_4_id', 'NL_nbr_4_tensor', 'NL_nbr_4_weight', 'id'] which did not match any model input. They will be ignored by the model.\n","  [n for n in tensors.keys() if n not in ref_input_names])\n"],"name":"stderr"},{"output_type":"stream","text":["     69/Unknown - 14s 206ms/step - loss: 0.9499 - accuracy: 0.5922 - auc: 0.8462 - f1_score: 0.5560"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py:543: UserWarning: Input dict contained keys ['id'] which did not match any model input. They will be ignored by the model.\n","  [n for n in tensors.keys() if n not in ref_input_names])\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Epoch 00001: val_accuracy improved from -inf to 0.64159, saving model to /content/drive/My Drive/Projects/codes/DenseNet_model_checkpoints/densenet_model_weights_new_91\n","69/69 [==============================] - 21s 301ms/step - loss: 0.9499 - accuracy: 0.5922 - auc: 0.8462 - f1_score: 0.5560 - val_loss: 0.7989 - val_accuracy: 0.6416 - val_auc: 0.8905 - val_f1_score: 0.6358\n","Epoch 2/100\n","69/69 [==============================] - ETA: 0s - loss: 0.7284 - accuracy: 0.6709 - auc: 0.9026 - f1_score: 0.6436\n","Epoch 00002: val_accuracy improved from 0.64159 to 0.65648, saving model to /content/drive/My Drive/Projects/codes/DenseNet_model_checkpoints/densenet_model_weights_new_91\n","69/69 [==============================] - 18s 261ms/step - loss: 0.7284 - accuracy: 0.6709 - auc: 0.9026 - f1_score: 0.6436 - val_loss: 0.7371 - val_accuracy: 0.6565 - val_auc: 0.9020 - val_f1_score: 0.6389\n","Epoch 3/100\n","69/69 [==============================] - ETA: 0s - loss: 0.6406 - accuracy: 0.7104 - auc: 0.9244 - f1_score: 0.6970\n","Epoch 00003: val_accuracy improved from 0.65648 to 0.71578, saving model to /content/drive/My Drive/Projects/codes/DenseNet_model_checkpoints/densenet_model_weights_new_91\n","69/69 [==============================] - 18s 260ms/step - loss: 0.6406 - accuracy: 0.7104 - auc: 0.9244 - f1_score: 0.6970 - val_loss: 0.5816 - val_accuracy: 0.7158 - val_auc: 0.9373 - val_f1_score: 0.7035\n","Epoch 4/100\n","69/69 [==============================] - ETA: 0s - loss: 0.6077 - accuracy: 0.7242 - auc: 0.9316 - f1_score: 0.7133\n","Epoch 00004: val_accuracy did not improve from 0.71578\n","69/69 [==============================] - 18s 256ms/step - loss: 0.6077 - accuracy: 0.7242 - auc: 0.9316 - f1_score: 0.7133 - val_loss: 0.5969 - val_accuracy: 0.7113 - val_auc: 0.9385 - val_f1_score: 0.7157\n","Epoch 5/100\n","69/69 [==============================] - ETA: 0s - loss: 0.5739 - accuracy: 0.7404 - auc: 0.9389 - f1_score: 0.7334\n","Epoch 00005: val_accuracy improved from 0.71578 to 0.78945, saving model to /content/drive/My Drive/Projects/codes/DenseNet_model_checkpoints/densenet_model_weights_new_91\n","69/69 [==============================] - 18s 263ms/step - loss: 0.5739 - accuracy: 0.7404 - auc: 0.9389 - f1_score: 0.7334 - val_loss: 0.4825 - val_accuracy: 0.7894 - val_auc: 0.9586 - val_f1_score: 0.7762\n","Epoch 6/100\n","69/69 [==============================] - ETA: 0s - loss: 0.5539 - accuracy: 0.7481 - auc: 0.9431 - f1_score: 0.7392\n","Epoch 00006: val_accuracy improved from 0.78945 to 0.79519, saving model to /content/drive/My Drive/Projects/codes/DenseNet_model_checkpoints/densenet_model_weights_new_91\n","69/69 [==============================] - 18s 259ms/step - loss: 0.5539 - accuracy: 0.7481 - auc: 0.9431 - f1_score: 0.7392 - val_loss: 0.4808 - val_accuracy: 0.7952 - val_auc: 0.9595 - val_f1_score: 0.7871\n","Epoch 7/100\n","69/69 [==============================] - ETA: 0s - loss: 0.5364 - accuracy: 0.7609 - auc: 0.9468 - f1_score: 0.7538\n","Epoch 00007: val_accuracy did not improve from 0.79519\n","69/69 [==============================] - 17s 254ms/step - loss: 0.5364 - accuracy: 0.7609 - auc: 0.9468 - f1_score: 0.7538 - val_loss: 0.5561 - val_accuracy: 0.7490 - val_auc: 0.9437 - val_f1_score: 0.7507\n","Epoch 8/100\n","69/69 [==============================] - ETA: 0s - loss: 0.5285 - accuracy: 0.7650 - auc: 0.9484 - f1_score: 0.7591\n","Epoch 00008: val_accuracy improved from 0.79519 to 0.82053, saving model to /content/drive/My Drive/Projects/codes/DenseNet_model_checkpoints/densenet_model_weights_new_91\n","69/69 [==============================] - 18s 258ms/step - loss: 0.5285 - accuracy: 0.7650 - auc: 0.9484 - f1_score: 0.7591 - val_loss: 0.4163 - val_accuracy: 0.8205 - val_auc: 0.9690 - val_f1_score: 0.8141\n","Epoch 9/100\n","69/69 [==============================] - ETA: 0s - loss: 0.5119 - accuracy: 0.7722 - auc: 0.9514 - f1_score: 0.7646\n","Epoch 00009: val_accuracy did not improve from 0.82053\n","69/69 [==============================] - 18s 256ms/step - loss: 0.5119 - accuracy: 0.7722 - auc: 0.9514 - f1_score: 0.7646 - val_loss: 0.4370 - val_accuracy: 0.8190 - val_auc: 0.9665 - val_f1_score: 0.8115\n","Epoch 10/100\n","69/69 [==============================] - ETA: 0s - loss: 0.5013 - accuracy: 0.7818 - auc: 0.9538 - f1_score: 0.7755\n","Epoch 00010: val_accuracy did not improve from 0.82053\n","69/69 [==============================] - 17s 251ms/step - loss: 0.5013 - accuracy: 0.7818 - auc: 0.9538 - f1_score: 0.7755 - val_loss: 0.4502 - val_accuracy: 0.7947 - val_auc: 0.9623 - val_f1_score: 0.7939\n","Epoch 11/100\n","69/69 [==============================] - ETA: 0s - loss: 0.4956 - accuracy: 0.7794 - auc: 0.9548 - f1_score: 0.7773\n","Epoch 00011: val_accuracy improved from 0.82053 to 0.82419, saving model to /content/drive/My Drive/Projects/codes/DenseNet_model_checkpoints/densenet_model_weights_new_91\n","69/69 [==============================] - 18s 266ms/step - loss: 0.4956 - accuracy: 0.7794 - auc: 0.9548 - f1_score: 0.7773 - val_loss: 0.4056 - val_accuracy: 0.8242 - val_auc: 0.9707 - val_f1_score: 0.8246\n","Epoch 12/100\n","69/69 [==============================] - ETA: 0s - loss: 0.4859 - accuracy: 0.7814 - auc: 0.9562 - f1_score: 0.7777\n","Epoch 00012: val_accuracy improved from 0.82419 to 0.84013, saving model to /content/drive/My Drive/Projects/codes/DenseNet_model_checkpoints/densenet_model_weights_new_91\n","69/69 [==============================] - 18s 260ms/step - loss: 0.4859 - accuracy: 0.7814 - auc: 0.9562 - f1_score: 0.7777 - val_loss: 0.3781 - val_accuracy: 0.8401 - val_auc: 0.9753 - val_f1_score: 0.8368\n","Epoch 13/100\n","69/69 [==============================] - ETA: 0s - loss: 0.4732 - accuracy: 0.7961 - auc: 0.9587 - f1_score: 0.7905\n","Epoch 00013: val_accuracy did not improve from 0.84013\n","69/69 [==============================] - 18s 256ms/step - loss: 0.4732 - accuracy: 0.7961 - auc: 0.9587 - f1_score: 0.7905 - val_loss: 0.3955 - val_accuracy: 0.8276 - val_auc: 0.9713 - val_f1_score: 0.8210\n","Epoch 14/100\n","69/69 [==============================] - ETA: 0s - loss: 0.4732 - accuracy: 0.7951 - auc: 0.9586 - f1_score: 0.7893\n","Epoch 00014: val_accuracy did not improve from 0.84013\n","69/69 [==============================] - 17s 251ms/step - loss: 0.4732 - accuracy: 0.7951 - auc: 0.9586 - f1_score: 0.7893 - val_loss: 0.3780 - val_accuracy: 0.8380 - val_auc: 0.9741 - val_f1_score: 0.8358\n","Epoch 15/100\n","69/69 [==============================] - ETA: 0s - loss: 0.4674 - accuracy: 0.7979 - auc: 0.9601 - f1_score: 0.7948\n","Epoch 00015: val_accuracy did not improve from 0.84013\n","69/69 [==============================] - 17s 251ms/step - loss: 0.4674 - accuracy: 0.7979 - auc: 0.9601 - f1_score: 0.7948 - val_loss: 0.4392 - val_accuracy: 0.7921 - val_auc: 0.9641 - val_f1_score: 0.7884\n","Epoch 16/100\n","69/69 [==============================] - ETA: 0s - loss: 0.4621 - accuracy: 0.8015 - auc: 0.9607 - f1_score: 0.7997\n","Epoch 00016: val_accuracy did not improve from 0.84013\n","69/69 [==============================] - 17s 253ms/step - loss: 0.4621 - accuracy: 0.8015 - auc: 0.9607 - f1_score: 0.7997 - val_loss: 0.3988 - val_accuracy: 0.8263 - val_auc: 0.9704 - val_f1_score: 0.8241\n","Epoch 17/100\n","69/69 [==============================] - ETA: 0s - loss: 0.4572 - accuracy: 0.8007 - auc: 0.9613 - f1_score: 0.7969\n","Epoch 00017: val_accuracy improved from 0.84013 to 0.85502, saving model to /content/drive/My Drive/Projects/codes/DenseNet_model_checkpoints/densenet_model_weights_new_91\n","69/69 [==============================] - 18s 259ms/step - loss: 0.4572 - accuracy: 0.8007 - auc: 0.9613 - f1_score: 0.7969 - val_loss: 0.3552 - val_accuracy: 0.8550 - val_auc: 0.9783 - val_f1_score: 0.8484\n","Epoch 18/100\n","69/69 [==============================] - ETA: 0s - loss: 0.4449 - accuracy: 0.8040 - auc: 0.9635 - f1_score: 0.8019\n","Epoch 00018: val_accuracy improved from 0.85502 to 0.85632, saving model to /content/drive/My Drive/Projects/codes/DenseNet_model_checkpoints/densenet_model_weights_new_91\n","69/69 [==============================] - 18s 262ms/step - loss: 0.4449 - accuracy: 0.8040 - auc: 0.9635 - f1_score: 0.8019 - val_loss: 0.3391 - val_accuracy: 0.8563 - val_auc: 0.9798 - val_f1_score: 0.8574\n","Epoch 19/100\n","69/69 [==============================] - ETA: 0s - loss: 0.4362 - accuracy: 0.8096 - auc: 0.9648 - f1_score: 0.8066\n","Epoch 00019: val_accuracy improved from 0.85632 to 0.86129, saving model to /content/drive/My Drive/Projects/codes/DenseNet_model_checkpoints/densenet_model_weights_new_91\n","69/69 [==============================] - 18s 266ms/step - loss: 0.4362 - accuracy: 0.8096 - auc: 0.9648 - f1_score: 0.8066 - val_loss: 0.3361 - val_accuracy: 0.8613 - val_auc: 0.9804 - val_f1_score: 0.8604\n","Epoch 20/100\n","69/69 [==============================] - ETA: 0s - loss: 0.4302 - accuracy: 0.8147 - auc: 0.9659 - f1_score: 0.8148\n","Epoch 00020: val_accuracy did not improve from 0.86129\n","69/69 [==============================] - 18s 254ms/step - loss: 0.4302 - accuracy: 0.8147 - auc: 0.9659 - f1_score: 0.8148 - val_loss: 0.3528 - val_accuracy: 0.8532 - val_auc: 0.9775 - val_f1_score: 0.8495\n","Epoch 21/100\n","69/69 [==============================] - ETA: 0s - loss: 0.4240 - accuracy: 0.8188 - auc: 0.9668 - f1_score: 0.8172\n","Epoch 00021: val_accuracy did not improve from 0.86129\n","69/69 [==============================] - 18s 254ms/step - loss: 0.4240 - accuracy: 0.8188 - auc: 0.9668 - f1_score: 0.8172 - val_loss: 0.4461 - val_accuracy: 0.7960 - val_auc: 0.9639 - val_f1_score: 0.8022\n","Epoch 22/100\n","69/69 [==============================] - ETA: 0s - loss: 0.4266 - accuracy: 0.8131 - auc: 0.9662 - f1_score: 0.8135\n","Epoch 00022: val_accuracy did not improve from 0.86129\n","69/69 [==============================] - 18s 255ms/step - loss: 0.4266 - accuracy: 0.8131 - auc: 0.9662 - f1_score: 0.8135 - val_loss: 0.3468 - val_accuracy: 0.8503 - val_auc: 0.9781 - val_f1_score: 0.8440\n","Epoch 23/100\n","69/69 [==============================] - ETA: 0s - loss: 0.4261 - accuracy: 0.8174 - auc: 0.9666 - f1_score: 0.8151\n","Epoch 00023: val_accuracy improved from 0.86129 to 0.86442, saving model to /content/drive/My Drive/Projects/codes/DenseNet_model_checkpoints/densenet_model_weights_new_91\n","69/69 [==============================] - 18s 258ms/step - loss: 0.4261 - accuracy: 0.8174 - auc: 0.9666 - f1_score: 0.8151 - val_loss: 0.3341 - val_accuracy: 0.8644 - val_auc: 0.9802 - val_f1_score: 0.8595\n","Epoch 24/100\n","69/69 [==============================] - ETA: 0s - loss: 0.4204 - accuracy: 0.8220 - auc: 0.9674 - f1_score: 0.8189\n","Epoch 00024: val_accuracy did not improve from 0.86442\n","69/69 [==============================] - 18s 256ms/step - loss: 0.4204 - accuracy: 0.8220 - auc: 0.9674 - f1_score: 0.8189 - val_loss: 0.3482 - val_accuracy: 0.8534 - val_auc: 0.9779 - val_f1_score: 0.8526\n","Epoch 25/100\n","69/69 [==============================] - ETA: 0s - loss: 0.4169 - accuracy: 0.8209 - auc: 0.9679 - f1_score: 0.8169\n","Epoch 00025: val_accuracy improved from 0.86442 to 0.88506, saving model to /content/drive/My Drive/Projects/codes/DenseNet_model_checkpoints/densenet_model_weights_new_91\n","69/69 [==============================] - 18s 261ms/step - loss: 0.4169 - accuracy: 0.8209 - auc: 0.9679 - f1_score: 0.8169 - val_loss: 0.3053 - val_accuracy: 0.8851 - val_auc: 0.9845 - val_f1_score: 0.8848\n","Epoch 26/100\n","69/69 [==============================] - ETA: 0s - loss: 0.4076 - accuracy: 0.8220 - auc: 0.9692 - f1_score: 0.8208\n","Epoch 00026: val_accuracy did not improve from 0.88506\n","69/69 [==============================] - 18s 255ms/step - loss: 0.4076 - accuracy: 0.8220 - auc: 0.9692 - f1_score: 0.8208 - val_loss: 0.3138 - val_accuracy: 0.8788 - val_auc: 0.9832 - val_f1_score: 0.8774\n","Epoch 27/100\n","69/69 [==============================] - ETA: 0s - loss: 0.4099 - accuracy: 0.8273 - auc: 0.9691 - f1_score: 0.8244\n","Epoch 00027: val_accuracy did not improve from 0.88506\n","69/69 [==============================] - 18s 260ms/step - loss: 0.4099 - accuracy: 0.8273 - auc: 0.9691 - f1_score: 0.8244 - val_loss: 0.3090 - val_accuracy: 0.8696 - val_auc: 0.9833 - val_f1_score: 0.8684\n","Epoch 28/100\n","69/69 [==============================] - ETA: 0s - loss: 0.3983 - accuracy: 0.8237 - auc: 0.9704 - f1_score: 0.8215\n","Epoch 00028: val_accuracy did not improve from 0.88506\n","69/69 [==============================] - 18s 254ms/step - loss: 0.3983 - accuracy: 0.8237 - auc: 0.9704 - f1_score: 0.8215 - val_loss: 0.3140 - val_accuracy: 0.8694 - val_auc: 0.9822 - val_f1_score: 0.8640\n","Epoch 29/100\n","69/69 [==============================] - ETA: 0s - loss: 0.3974 - accuracy: 0.8249 - auc: 0.9708 - f1_score: 0.8230\n","Epoch 00029: val_accuracy did not improve from 0.88506\n","69/69 [==============================] - 17s 253ms/step - loss: 0.3974 - accuracy: 0.8249 - auc: 0.9708 - f1_score: 0.8230 - val_loss: 0.3060 - val_accuracy: 0.8683 - val_auc: 0.9831 - val_f1_score: 0.8656\n","Epoch 30/100\n","69/69 [==============================] - ETA: 0s - loss: 0.3846 - accuracy: 0.8356 - auc: 0.9727 - f1_score: 0.8321\n","Epoch 00030: val_accuracy improved from 0.88506 to 0.88610, saving model to /content/drive/My Drive/Projects/codes/DenseNet_model_checkpoints/densenet_model_weights_new_91\n","69/69 [==============================] - 18s 260ms/step - loss: 0.3846 - accuracy: 0.8356 - auc: 0.9727 - f1_score: 0.8321 - val_loss: 0.2856 - val_accuracy: 0.8861 - val_auc: 0.9861 - val_f1_score: 0.8838\n","Epoch 31/100\n","69/69 [==============================] - ETA: 0s - loss: 0.3912 - accuracy: 0.8356 - auc: 0.9716 - f1_score: 0.8321\n","Epoch 00031: val_accuracy improved from 0.88610 to 0.89289, saving model to /content/drive/My Drive/Projects/codes/DenseNet_model_checkpoints/densenet_model_weights_new_91\n","69/69 [==============================] - 18s 264ms/step - loss: 0.3912 - accuracy: 0.8356 - auc: 0.9716 - f1_score: 0.8321 - val_loss: 0.2846 - val_accuracy: 0.8929 - val_auc: 0.9862 - val_f1_score: 0.8905\n","Epoch 32/100\n","69/69 [==============================] - ETA: 0s - loss: 0.3801 - accuracy: 0.8424 - auc: 0.9733 - f1_score: 0.8406\n","Epoch 00032: val_accuracy did not improve from 0.89289\n","69/69 [==============================] - 18s 255ms/step - loss: 0.3801 - accuracy: 0.8424 - auc: 0.9733 - f1_score: 0.8406 - val_loss: 0.3144 - val_accuracy: 0.8757 - val_auc: 0.9820 - val_f1_score: 0.8747\n","Epoch 33/100\n","69/69 [==============================] - ETA: 0s - loss: 0.3882 - accuracy: 0.8373 - auc: 0.9721 - f1_score: 0.8347\n","Epoch 00033: val_accuracy did not improve from 0.89289\n","69/69 [==============================] - 18s 254ms/step - loss: 0.3882 - accuracy: 0.8373 - auc: 0.9721 - f1_score: 0.8347 - val_loss: 0.3763 - val_accuracy: 0.8294 - val_auc: 0.9731 - val_f1_score: 0.8287\n","Epoch 34/100\n","69/69 [==============================] - ETA: 0s - loss: 0.3738 - accuracy: 0.8405 - auc: 0.9740 - f1_score: 0.8397\n","Epoch 00034: val_accuracy improved from 0.89289 to 0.90361, saving model to /content/drive/My Drive/Projects/codes/DenseNet_model_checkpoints/densenet_model_weights_new_91\n","69/69 [==============================] - 18s 259ms/step - loss: 0.3738 - accuracy: 0.8405 - auc: 0.9740 - f1_score: 0.8397 - val_loss: 0.2655 - val_accuracy: 0.9036 - val_auc: 0.9887 - val_f1_score: 0.9011\n","Epoch 35/100\n","69/69 [==============================] - ETA: 0s - loss: 0.3732 - accuracy: 0.8416 - auc: 0.9744 - f1_score: 0.8411\n","Epoch 00035: val_accuracy did not improve from 0.90361\n","69/69 [==============================] - 18s 257ms/step - loss: 0.3732 - accuracy: 0.8416 - auc: 0.9744 - f1_score: 0.8411 - val_loss: 0.2842 - val_accuracy: 0.8890 - val_auc: 0.9860 - val_f1_score: 0.8893\n","Epoch 36/100\n","69/69 [==============================] - ETA: 0s - loss: 0.3698 - accuracy: 0.8419 - auc: 0.9745 - f1_score: 0.8416\n","Epoch 00036: val_accuracy did not improve from 0.90361\n","69/69 [==============================] - 18s 254ms/step - loss: 0.3698 - accuracy: 0.8419 - auc: 0.9745 - f1_score: 0.8416 - val_loss: 0.2630 - val_accuracy: 0.9031 - val_auc: 0.9886 - val_f1_score: 0.9020\n","Epoch 37/100\n","69/69 [==============================] - ETA: 0s - loss: 0.3751 - accuracy: 0.8422 - auc: 0.9738 - f1_score: 0.8411\n","Epoch 00037: val_accuracy did not improve from 0.90361\n","69/69 [==============================] - 17s 253ms/step - loss: 0.3751 - accuracy: 0.8422 - auc: 0.9738 - f1_score: 0.8411 - val_loss: 0.2781 - val_accuracy: 0.8911 - val_auc: 0.9866 - val_f1_score: 0.8882\n","Epoch 38/100\n","69/69 [==============================] - ETA: 0s - loss: 0.3779 - accuracy: 0.8388 - auc: 0.9734 - f1_score: 0.8370\n","Epoch 00038: val_accuracy did not improve from 0.90361\n","69/69 [==============================] - 17s 253ms/step - loss: 0.3779 - accuracy: 0.8388 - auc: 0.9734 - f1_score: 0.8370 - val_loss: 0.2721 - val_accuracy: 0.9018 - val_auc: 0.9875 - val_f1_score: 0.9001\n","Epoch 39/100\n","69/69 [==============================] - ETA: 0s - loss: 0.3656 - accuracy: 0.8458 - auc: 0.9751 - f1_score: 0.8455\n","Epoch 00039: val_accuracy did not improve from 0.90361\n","69/69 [==============================] - 18s 254ms/step - loss: 0.3656 - accuracy: 0.8458 - auc: 0.9751 - f1_score: 0.8455 - val_loss: 0.3047 - val_accuracy: 0.8639 - val_auc: 0.9825 - val_f1_score: 0.8632\n","Epoch 40/100\n","69/69 [==============================] - ETA: 0s - loss: 0.3555 - accuracy: 0.8492 - auc: 0.9766 - f1_score: 0.8495\n","Epoch 00040: val_accuracy did not improve from 0.90361\n","69/69 [==============================] - 18s 254ms/step - loss: 0.3555 - accuracy: 0.8492 - auc: 0.9766 - f1_score: 0.8495 - val_loss: 0.2632 - val_accuracy: 0.8945 - val_auc: 0.9873 - val_f1_score: 0.8902\n","Epoch 41/100\n","69/69 [==============================] - ETA: 0s - loss: 0.3610 - accuracy: 0.8464 - auc: 0.9759 - f1_score: 0.8477\n","Epoch 00041: val_accuracy improved from 0.90361 to 0.90883, saving model to /content/drive/My Drive/Projects/codes/DenseNet_model_checkpoints/densenet_model_weights_new_91\n","69/69 [==============================] - 18s 258ms/step - loss: 0.3610 - accuracy: 0.8464 - auc: 0.9759 - f1_score: 0.8477 - val_loss: 0.2543 - val_accuracy: 0.9088 - val_auc: 0.9895 - val_f1_score: 0.9075\n","Epoch 42/100\n","69/69 [==============================] - ETA: 0s - loss: 0.3607 - accuracy: 0.8500 - auc: 0.9760 - f1_score: 0.8499\n","Epoch 00042: val_accuracy improved from 0.90883 to 0.90961, saving model to /content/drive/My Drive/Projects/codes/DenseNet_model_checkpoints/densenet_model_weights_new_91\n","69/69 [==============================] - 18s 261ms/step - loss: 0.3607 - accuracy: 0.8500 - auc: 0.9760 - f1_score: 0.8499 - val_loss: 0.2569 - val_accuracy: 0.9096 - val_auc: 0.9896 - val_f1_score: 0.9107\n","Epoch 43/100\n","69/69 [==============================] - ETA: 0s - loss: 0.3505 - accuracy: 0.8560 - auc: 0.9772 - f1_score: 0.8554\n","Epoch 00043: val_accuracy did not improve from 0.90961\n","69/69 [==============================] - 18s 255ms/step - loss: 0.3505 - accuracy: 0.8560 - auc: 0.9772 - f1_score: 0.8554 - val_loss: 0.2662 - val_accuracy: 0.8994 - val_auc: 0.9880 - val_f1_score: 0.8995\n","Epoch 44/100\n","69/69 [==============================] - ETA: 0s - loss: 0.3523 - accuracy: 0.8499 - auc: 0.9769 - f1_score: 0.8502\n","Epoch 00044: val_accuracy did not improve from 0.90961\n","69/69 [==============================] - 18s 260ms/step - loss: 0.3523 - accuracy: 0.8499 - auc: 0.9769 - f1_score: 0.8502 - val_loss: 0.2638 - val_accuracy: 0.8945 - val_auc: 0.9877 - val_f1_score: 0.8949\n","Epoch 45/100\n","69/69 [==============================] - ETA: 0s - loss: 0.3522 - accuracy: 0.8517 - auc: 0.9769 - f1_score: 0.8521\n","Epoch 00045: val_accuracy did not improve from 0.90961\n","69/69 [==============================] - 18s 254ms/step - loss: 0.3522 - accuracy: 0.8517 - auc: 0.9769 - f1_score: 0.8521 - val_loss: 0.2451 - val_accuracy: 0.9054 - val_auc: 0.9892 - val_f1_score: 0.9034\n","Epoch 46/100\n","69/69 [==============================] - ETA: 0s - loss: 0.3487 - accuracy: 0.8567 - auc: 0.9775 - f1_score: 0.8564\n","Epoch 00046: val_accuracy improved from 0.90961 to 0.91275, saving model to /content/drive/My Drive/Projects/codes/DenseNet_model_checkpoints/densenet_model_weights_new_91\n","69/69 [==============================] - 18s 259ms/step - loss: 0.3487 - accuracy: 0.8567 - auc: 0.9775 - f1_score: 0.8564 - val_loss: 0.2432 - val_accuracy: 0.9127 - val_auc: 0.9902 - val_f1_score: 0.9142\n","Epoch 00047: early stopping\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wyzcCFeOZP1r","executionInfo":{"status":"ok","timestamp":1606003995237,"user_tz":300,"elapsed":3938,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"2bc984e0-317c-468c-d446-abc03100675f"},"source":["'''evaluate base model'''\n","base_model.evaluate(test_image_dataset)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["30/30 [==============================] - 2s 73ms/step - loss: 0.2432 - accuracy: 0.9127 - auc: 0.9902 - f1_score: 0.9142\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[0.24320916831493378,\n"," 0.9127481579780579,\n"," 0.9901851415634155,\n"," 0.9142027497291565]"]},"metadata":{"tags":[]},"execution_count":48}]},{"cell_type":"code","metadata":{"id":"6nBD2RQWKJto"},"source":["'''plot confusion mat & calc acc for each label'''\n","test_image_dataset = NSLDataFormat.generate_test_tfr_image_tensor(path_list=tfr_list_test, \n","                                                                  batch_size=4000, \n","                                                                  size=(100,100),\n","                                                                  channels=3,\n","                                                                  shuffle=True)\n","data, data_label = iter(test_image_dataset).get_next()\n","data = data[\"tensor\"]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":396},"id":"yz9TqB3XKJv_","executionInfo":{"status":"ok","timestamp":1606257167723,"user_tz":300,"elapsed":7450,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"b22e44b4-0e54-44e5-e4d4-2b8f537c7f1c"},"source":["ADModelBuilder.plot_confusion_mat(base_model, data, data_label, \"DenseNet121\")"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x432 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8BFz2NxAKJyD","executionInfo":{"status":"ok","timestamp":1606257170985,"user_tz":300,"elapsed":3239,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"4cbcc389-7974-44bb-8a3d-4a1188dac18d"},"source":["ADModelBuilder.calc_confu_mat_for_each_label(base_model, data, data_label)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["TN: [2770 2652 2866 2862]\n","TP: [874 861 794 965]\n","FN: [117  77 140   0]\n","FP: [ 67 238  28   1]\n","Acc: [0.95193312 0.9177116  0.95611285 0.99973877]\n","ER(Error rate): [0.04806688 0.0822884  0.04388715 0.00026123]\n","Recall(TP rate): [0.88193744 0.91791045 0.85010707 1.        ]\n","Specialty(TN rate): [0.9763835  0.91764706 0.99032481 0.99965072]\n","Fall Out(FP rate): [0.0236165  0.08235294 0.00967519 0.00034928]\n","Miss Rate(FN rate): [0.11806256 0.08208955 0.14989293 0.        ]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Jd0LKKAc5NLM"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aAfKfwGX5x9Y"},"source":["## 4.2 DenseNet_NSL Model Training\n","### val_acc: 0.9227, val_auc: 0.9914, val_f1_score: 0.92\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BY2jbBjQZP1C","executionInfo":{"status":"ok","timestamp":1606005721382,"user_tz":300,"elapsed":1648968,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"633af09c-2dc8-43bf-f34b-634843ceb09f"},"source":["'''define params'''\n","params.learning_rate=0.001\n","params.restore_path = '/content/drive/My Drive/Projects/codes/DenseNet_NSL_model_checkpoints/densenet_nsl_weights_colab_new_92'\n","params.checkpoint_path = '/content/drive/My Drive/Projects/codes/DenseNet_NSL_model_checkpoints/densenet_nsl_weights_colab_new_92'\n","params.early_stop_base_line=0.92\n","params.train_epoch=100\n","params.nsl_multiplier = 0.1\n","params.nsl_sum_over_axis = -1\n","params.nsl_distance_type = nsl.configs.DistanceType.COSINE\n","'''build base_model and restore from the last training'''\n","base_model = ADModelBuilder(input_shape=params.ad_base_model_input_shape, base_model='densenet121').get_ADModel()\n","'''build NSL model on top of base model'''\n","graph_reg_config = nsl.configs.make_graph_reg_config(neighbor_prefix=params.neighbor_prefix,\n","                                                     neighbor_weight_suffix=params.neighbor_weight_suffix,\n","                                                     max_neighbors= params.max_seed_nbr,\n","                                                     multiplier= params.nsl_multiplier,\n","                                                     distance_type= params.nsl_distance_type,\n","                                                     sum_over_axis=params.nsl_sum_over_axis)\n","graph_reg_model = nsl.keras.GraphRegularization(base_model,graph_reg_config)\n","graph_reg_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=params.learning_rate, amsgrad=True),\n","                        loss=tf.losses.CategoricalCrossentropy(),\n","                        metrics=[\"accuracy\",\"AUC\",tfa.metrics.F1Score(num_classes=4, average=\"micro\", threshold = 0.5)])\n","# graph_reg_model.load_weights(params.restore_path)\n","'''set up check point & early stopping'''\n","callback_checkpoints = tf.keras.callbacks.ModelCheckpoint(filepath= params.checkpoint_path, monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=True, mode='max',\n","                                                         save_freq='epoch',options=None)\n","callback_earlystop = AccEarlyStop(val_acc_base=params.early_stop_base_line)\n","'''train the nsl model'''\n","graph_reg_history = graph_reg_model.fit(train_image_dataset, \n","                                        validation_data=test_image_dataset,\n","                                        callbacks = [callback_checkpoints, callback_earlystop],\n","                                        epochs=params.train_epoch,\n","                                        verbose=1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Note: default DenseNet121 not includes top and has imagenet weights. It is not a trainable model in ADModelBuilder. Please setup trainable layers in setup_DenseNet121 function based on the \"Layer Number\"\n","Model: \"DenseNet121_ADModel\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","tensor (InputLayer)          [(None, 100, 100, 3)]     0         \n","_________________________________________________________________\n","densenet121 (Functional)     (None, 3, 3, 1024)        7037504   \n","_________________________________________________________________\n","flatten_3 (Flatten)          (None, 9216)              0         \n","_________________________________________________________________\n","dropout_4 (Dropout)          (None, 9216)              0         \n","_________________________________________________________________\n","dense_6 (Dense)              (None, 128)               1179776   \n","_________________________________________________________________\n","batch_normalization_3 (Batch (None, 128)               512       \n","_________________________________________________________________\n","leaky_re_lu_3 (LeakyReLU)    (None, 128)               0         \n","_________________________________________________________________\n","dropout_5 (Dropout)          (None, 128)               0         \n","_________________________________________________________________\n","dense_7 (Dense)              (None, 4)                 516       \n","=================================================================\n","Total params: 8,218,308\n","Trainable params: 1,180,548\n","Non-trainable params: 7,037,760\n","_________________________________________________________________\n","Epoch 1/100\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py:543: UserWarning: Input dict contained keys ['id'] which did not match any model input. They will be ignored by the model.\n","  [n for n in tensors.keys() if n not in ref_input_names])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:432: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"],"name":"stderr"},{"output_type":"stream","text":["     69/Unknown - 30s 430ms/step - loss: 0.9785 - accuracy: 0.6027 - auc: 0.8538 - f1_score: 0.5904 - scaled_graph_loss: 0.0198\n","Epoch 00001: val_accuracy improved from -inf to 0.69462, saving model to /content/drive/My Drive/Projects/codes/DenseNet_NSL_model_checkpoints/densenet_nsl_weights_colab_new_92\n","69/69 [==============================] - 46s 664ms/step - loss: 0.9785 - accuracy: 0.6027 - auc: 0.8538 - f1_score: 0.5904 - scaled_graph_loss: 0.0198 - val_loss: 0.6903 - val_accuracy: 0.6946 - val_auc: 0.9165 - val_f1_score: 0.6186\n","Epoch 2/100\n","69/69 [==============================] - ETA: 0s - loss: 0.7261 - accuracy: 0.6914 - auc: 0.9103 - f1_score: 0.6771 - scaled_graph_loss: 0.0154\n","Epoch 00002: val_accuracy improved from 0.69462 to 0.72518, saving model to /content/drive/My Drive/Projects/codes/DenseNet_NSL_model_checkpoints/densenet_nsl_weights_colab_new_92\n","69/69 [==============================] - 34s 487ms/step - loss: 0.7261 - accuracy: 0.6914 - auc: 0.9103 - f1_score: 0.6771 - scaled_graph_loss: 0.0154 - val_loss: 0.6106 - val_accuracy: 0.7252 - val_auc: 0.9324 - val_f1_score: 0.7045\n","Epoch 3/100\n","69/69 [==============================] - ETA: 0s - loss: 0.6547 - accuracy: 0.7198 - auc: 0.9257 - f1_score: 0.7075 - scaled_graph_loss: 0.0140\n","Epoch 00003: val_accuracy improved from 0.72518 to 0.72910, saving model to /content/drive/My Drive/Projects/codes/DenseNet_NSL_model_checkpoints/densenet_nsl_weights_colab_new_92\n","69/69 [==============================] - 34s 499ms/step - loss: 0.6547 - accuracy: 0.7198 - auc: 0.9257 - f1_score: 0.7075 - scaled_graph_loss: 0.0140 - val_loss: 0.5833 - val_accuracy: 0.7291 - val_auc: 0.9384 - val_f1_score: 0.7141\n","Epoch 4/100\n","69/69 [==============================] - ETA: 0s - loss: 0.6052 - accuracy: 0.7373 - auc: 0.9359 - f1_score: 0.7262 - scaled_graph_loss: 0.0128\n","Epoch 00004: val_accuracy improved from 0.72910 to 0.78918, saving model to /content/drive/My Drive/Projects/codes/DenseNet_NSL_model_checkpoints/densenet_nsl_weights_colab_new_92\n","69/69 [==============================] - 35s 502ms/step - loss: 0.6052 - accuracy: 0.7373 - auc: 0.9359 - f1_score: 0.7262 - scaled_graph_loss: 0.0128 - val_loss: 0.4898 - val_accuracy: 0.7892 - val_auc: 0.9588 - val_f1_score: 0.7838\n","Epoch 5/100\n","69/69 [==============================] - ETA: 0s - loss: 0.5744 - accuracy: 0.7540 - auc: 0.9425 - f1_score: 0.7416 - scaled_graph_loss: 0.0123\n","Epoch 00005: val_accuracy did not improve from 0.78918\n","69/69 [==============================] - 34s 491ms/step - loss: 0.5744 - accuracy: 0.7540 - auc: 0.9425 - f1_score: 0.7416 - scaled_graph_loss: 0.0123 - val_loss: 0.4823 - val_accuracy: 0.7861 - val_auc: 0.9594 - val_f1_score: 0.7834\n","Epoch 6/100\n","69/69 [==============================] - ETA: 0s - loss: 0.5530 - accuracy: 0.7570 - auc: 0.9465 - f1_score: 0.7516 - scaled_graph_loss: 0.0120\n","Epoch 00006: val_accuracy improved from 0.78918 to 0.81531, saving model to /content/drive/My Drive/Projects/codes/DenseNet_NSL_model_checkpoints/densenet_nsl_weights_colab_new_92\n","69/69 [==============================] - 35s 503ms/step - loss: 0.5530 - accuracy: 0.7570 - auc: 0.9465 - f1_score: 0.7516 - scaled_graph_loss: 0.0120 - val_loss: 0.4441 - val_accuracy: 0.8153 - val_auc: 0.9672 - val_f1_score: 0.7981\n","Epoch 7/100\n","69/69 [==============================] - ETA: 0s - loss: 0.5371 - accuracy: 0.7703 - auc: 0.9493 - f1_score: 0.7592 - scaled_graph_loss: 0.0115\n","Epoch 00007: val_accuracy did not improve from 0.81531\n","69/69 [==============================] - 34s 493ms/step - loss: 0.5371 - accuracy: 0.7703 - auc: 0.9493 - f1_score: 0.7592 - scaled_graph_loss: 0.0115 - val_loss: 0.4399 - val_accuracy: 0.8124 - val_auc: 0.9667 - val_f1_score: 0.7994\n","Epoch 8/100\n","69/69 [==============================] - ETA: 0s - loss: 0.5129 - accuracy: 0.7802 - auc: 0.9542 - f1_score: 0.7731 - scaled_graph_loss: 0.0113\n","Epoch 00008: val_accuracy improved from 0.81531 to 0.82132, saving model to /content/drive/My Drive/Projects/codes/DenseNet_NSL_model_checkpoints/densenet_nsl_weights_colab_new_92\n","69/69 [==============================] - 34s 499ms/step - loss: 0.5129 - accuracy: 0.7802 - auc: 0.9542 - f1_score: 0.7731 - scaled_graph_loss: 0.0113 - val_loss: 0.4321 - val_accuracy: 0.8213 - val_auc: 0.9672 - val_f1_score: 0.8116\n","Epoch 9/100\n","69/69 [==============================] - ETA: 0s - loss: 0.5023 - accuracy: 0.7822 - auc: 0.9560 - f1_score: 0.7767 - scaled_graph_loss: 0.0117\n","Epoch 00009: val_accuracy improved from 0.82132 to 0.82445, saving model to /content/drive/My Drive/Projects/codes/DenseNet_NSL_model_checkpoints/densenet_nsl_weights_colab_new_92\n","69/69 [==============================] - 35s 508ms/step - loss: 0.5023 - accuracy: 0.7822 - auc: 0.9560 - f1_score: 0.7767 - scaled_graph_loss: 0.0117 - val_loss: 0.4196 - val_accuracy: 0.8245 - val_auc: 0.9691 - val_f1_score: 0.8177\n","Epoch 10/100\n","69/69 [==============================] - ETA: 0s - loss: 0.5025 - accuracy: 0.7860 - auc: 0.9561 - f1_score: 0.7798 - scaled_graph_loss: 0.0116\n","Epoch 00010: val_accuracy did not improve from 0.82445\n","69/69 [==============================] - 34s 499ms/step - loss: 0.5025 - accuracy: 0.7860 - auc: 0.9561 - f1_score: 0.7798 - scaled_graph_loss: 0.0116 - val_loss: 0.4224 - val_accuracy: 0.8135 - val_auc: 0.9681 - val_f1_score: 0.8088\n","Epoch 11/100\n","69/69 [==============================] - ETA: 0s - loss: 0.4831 - accuracy: 0.7928 - auc: 0.9596 - f1_score: 0.7882 - scaled_graph_loss: 0.0113\n","Epoch 00011: val_accuracy improved from 0.82445 to 0.83098, saving model to /content/drive/My Drive/Projects/codes/DenseNet_NSL_model_checkpoints/densenet_nsl_weights_colab_new_92\n","69/69 [==============================] - 35s 504ms/step - loss: 0.4831 - accuracy: 0.7928 - auc: 0.9596 - f1_score: 0.7882 - scaled_graph_loss: 0.0113 - val_loss: 0.4016 - val_accuracy: 0.8310 - val_auc: 0.9718 - val_f1_score: 0.8236\n","Epoch 12/100\n","69/69 [==============================] - ETA: 0s - loss: 0.4811 - accuracy: 0.7931 - auc: 0.9595 - f1_score: 0.7875 - scaled_graph_loss: 0.0114\n","Epoch 00012: val_accuracy improved from 0.83098 to 0.83960, saving model to /content/drive/My Drive/Projects/codes/DenseNet_NSL_model_checkpoints/densenet_nsl_weights_colab_new_92\n","69/69 [==============================] - 35s 506ms/step - loss: 0.4811 - accuracy: 0.7931 - auc: 0.9595 - f1_score: 0.7875 - scaled_graph_loss: 0.0114 - val_loss: 0.3953 - val_accuracy: 0.8396 - val_auc: 0.9732 - val_f1_score: 0.8304\n","Epoch 13/100\n","69/69 [==============================] - ETA: 0s - loss: 0.4780 - accuracy: 0.7962 - auc: 0.9601 - f1_score: 0.7908 - scaled_graph_loss: 0.0115\n","Epoch 00013: val_accuracy did not improve from 0.83960\n","69/69 [==============================] - 34s 491ms/step - loss: 0.4780 - accuracy: 0.7962 - auc: 0.9601 - f1_score: 0.7908 - scaled_graph_loss: 0.0115 - val_loss: 0.3939 - val_accuracy: 0.8312 - val_auc: 0.9726 - val_f1_score: 0.8283\n","Epoch 14/100\n","69/69 [==============================] - ETA: 0s - loss: 0.4642 - accuracy: 0.8029 - auc: 0.9624 - f1_score: 0.7997 - scaled_graph_loss: 0.0114\n","Epoch 00014: val_accuracy did not improve from 0.83960\n","69/69 [==============================] - 34s 500ms/step - loss: 0.4642 - accuracy: 0.8029 - auc: 0.9624 - f1_score: 0.7997 - scaled_graph_loss: 0.0114 - val_loss: 0.4248 - val_accuracy: 0.7999 - val_auc: 0.9668 - val_f1_score: 0.7959\n","Epoch 15/100\n","69/69 [==============================] - ETA: 0s - loss: 0.4580 - accuracy: 0.8049 - auc: 0.9635 - f1_score: 0.8031 - scaled_graph_loss: 0.0114\n","Epoch 00015: val_accuracy improved from 0.83960 to 0.84587, saving model to /content/drive/My Drive/Projects/codes/DenseNet_NSL_model_checkpoints/densenet_nsl_weights_colab_new_92\n","69/69 [==============================] - 35s 512ms/step - loss: 0.4580 - accuracy: 0.8049 - auc: 0.9635 - f1_score: 0.8031 - scaled_graph_loss: 0.0114 - val_loss: 0.3784 - val_accuracy: 0.8459 - val_auc: 0.9753 - val_f1_score: 0.8370\n","Epoch 16/100\n","69/69 [==============================] - ETA: 0s - loss: 0.4486 - accuracy: 0.8130 - auc: 0.9650 - f1_score: 0.8092 - scaled_graph_loss: 0.0113\n","Epoch 00016: val_accuracy did not improve from 0.84587\n","69/69 [==============================] - 34s 495ms/step - loss: 0.4486 - accuracy: 0.8130 - auc: 0.9650 - f1_score: 0.8092 - scaled_graph_loss: 0.0113 - val_loss: 0.3862 - val_accuracy: 0.8396 - val_auc: 0.9739 - val_f1_score: 0.8384\n","Epoch 17/100\n","69/69 [==============================] - ETA: 0s - loss: 0.4406 - accuracy: 0.8160 - auc: 0.9663 - f1_score: 0.8121 - scaled_graph_loss: 0.0114\n","Epoch 00017: val_accuracy improved from 0.84587 to 0.86416, saving model to /content/drive/My Drive/Projects/codes/DenseNet_NSL_model_checkpoints/densenet_nsl_weights_colab_new_92\n","69/69 [==============================] - 35s 505ms/step - loss: 0.4406 - accuracy: 0.8160 - auc: 0.9663 - f1_score: 0.8121 - scaled_graph_loss: 0.0114 - val_loss: 0.3493 - val_accuracy: 0.8642 - val_auc: 0.9803 - val_f1_score: 0.8613\n","Epoch 18/100\n","69/69 [==============================] - ETA: 0s - loss: 0.4401 - accuracy: 0.8148 - auc: 0.9663 - f1_score: 0.8099 - scaled_graph_loss: 0.0114\n","Epoch 00018: val_accuracy did not improve from 0.86416\n","69/69 [==============================] - 35s 503ms/step - loss: 0.4401 - accuracy: 0.8148 - auc: 0.9663 - f1_score: 0.8099 - scaled_graph_loss: 0.0114 - val_loss: 0.3796 - val_accuracy: 0.8469 - val_auc: 0.9741 - val_f1_score: 0.8365\n","Epoch 19/100\n","69/69 [==============================] - ETA: 0s - loss: 0.4380 - accuracy: 0.8165 - auc: 0.9666 - f1_score: 0.8122 - scaled_graph_loss: 0.0117\n","Epoch 00019: val_accuracy improved from 0.86416 to 0.88088, saving model to /content/drive/My Drive/Projects/codes/DenseNet_NSL_model_checkpoints/densenet_nsl_weights_colab_new_92\n","69/69 [==============================] - 35s 506ms/step - loss: 0.4380 - accuracy: 0.8165 - auc: 0.9666 - f1_score: 0.8122 - scaled_graph_loss: 0.0117 - val_loss: 0.3285 - val_accuracy: 0.8809 - val_auc: 0.9838 - val_f1_score: 0.8750\n","Epoch 20/100\n","69/69 [==============================] - ETA: 0s - loss: 0.4237 - accuracy: 0.8228 - auc: 0.9689 - f1_score: 0.8185 - scaled_graph_loss: 0.0113\n","Epoch 00020: val_accuracy did not improve from 0.88088\n","69/69 [==============================] - 35s 504ms/step - loss: 0.4237 - accuracy: 0.8228 - auc: 0.9689 - f1_score: 0.8185 - scaled_graph_loss: 0.0113 - val_loss: 0.3517 - val_accuracy: 0.8433 - val_auc: 0.9780 - val_f1_score: 0.8390\n","Epoch 21/100\n","69/69 [==============================] - ETA: 0s - loss: 0.4289 - accuracy: 0.8246 - auc: 0.9681 - f1_score: 0.8221 - scaled_graph_loss: 0.0116\n","Epoch 00021: val_accuracy improved from 0.88088 to 0.88349, saving model to /content/drive/My Drive/Projects/codes/DenseNet_NSL_model_checkpoints/densenet_nsl_weights_colab_new_92\n","69/69 [==============================] - 36s 516ms/step - loss: 0.4289 - accuracy: 0.8246 - auc: 0.9681 - f1_score: 0.8221 - scaled_graph_loss: 0.0116 - val_loss: 0.3154 - val_accuracy: 0.8835 - val_auc: 0.9843 - val_f1_score: 0.8832\n","Epoch 22/100\n","69/69 [==============================] - ETA: 0s - loss: 0.4086 - accuracy: 0.8309 - auc: 0.9712 - f1_score: 0.8276 - scaled_graph_loss: 0.0113\n","Epoch 00022: val_accuracy did not improve from 0.88349\n","69/69 [==============================] - 35s 507ms/step - loss: 0.4086 - accuracy: 0.8309 - auc: 0.9712 - f1_score: 0.8276 - scaled_graph_loss: 0.0113 - val_loss: 0.3341 - val_accuracy: 0.8592 - val_auc: 0.9804 - val_f1_score: 0.8532\n","Epoch 23/100\n","69/69 [==============================] - ETA: 0s - loss: 0.4205 - accuracy: 0.8274 - auc: 0.9695 - f1_score: 0.8236 - scaled_graph_loss: 0.0116\n","Epoch 00023: val_accuracy did not improve from 0.88349\n","69/69 [==============================] - 35s 511ms/step - loss: 0.4205 - accuracy: 0.8274 - auc: 0.9695 - f1_score: 0.8236 - scaled_graph_loss: 0.0116 - val_loss: 0.3292 - val_accuracy: 0.8741 - val_auc: 0.9823 - val_f1_score: 0.8729\n","Epoch 24/100\n","69/69 [==============================] - ETA: 0s - loss: 0.4118 - accuracy: 0.8238 - auc: 0.9706 - f1_score: 0.8228 - scaled_graph_loss: 0.0113\n","Epoch 00024: val_accuracy improved from 0.88349 to 0.89080, saving model to /content/drive/My Drive/Projects/codes/DenseNet_NSL_model_checkpoints/densenet_nsl_weights_colab_new_92\n","69/69 [==============================] - 35s 508ms/step - loss: 0.4118 - accuracy: 0.8238 - auc: 0.9706 - f1_score: 0.8228 - scaled_graph_loss: 0.0113 - val_loss: 0.3063 - val_accuracy: 0.8908 - val_auc: 0.9849 - val_f1_score: 0.8862\n","Epoch 25/100\n","69/69 [==============================] - ETA: 0s - loss: 0.3974 - accuracy: 0.8321 - auc: 0.9728 - f1_score: 0.8321 - scaled_graph_loss: 0.0116\n","Epoch 00025: val_accuracy did not improve from 0.89080\n","69/69 [==============================] - 34s 490ms/step - loss: 0.3974 - accuracy: 0.8321 - auc: 0.9728 - f1_score: 0.8321 - scaled_graph_loss: 0.0116 - val_loss: 0.3086 - val_accuracy: 0.8796 - val_auc: 0.9843 - val_f1_score: 0.8784\n","Epoch 26/100\n","69/69 [==============================] - ETA: 0s - loss: 0.3998 - accuracy: 0.8311 - auc: 0.9722 - f1_score: 0.8300 - scaled_graph_loss: 0.0115\n","Epoch 00026: val_accuracy did not improve from 0.89080\n","69/69 [==============================] - 35s 511ms/step - loss: 0.3998 - accuracy: 0.8311 - auc: 0.9722 - f1_score: 0.8300 - scaled_graph_loss: 0.0115 - val_loss: 0.3132 - val_accuracy: 0.8767 - val_auc: 0.9842 - val_f1_score: 0.8791\n","Epoch 27/100\n","69/69 [==============================] - ETA: 0s - loss: 0.3981 - accuracy: 0.8365 - auc: 0.9727 - f1_score: 0.8352 - scaled_graph_loss: 0.0115\n","Epoch 00027: val_accuracy did not improve from 0.89080\n","69/69 [==============================] - 35s 504ms/step - loss: 0.3981 - accuracy: 0.8365 - auc: 0.9727 - f1_score: 0.8352 - scaled_graph_loss: 0.0115 - val_loss: 0.2985 - val_accuracy: 0.8858 - val_auc: 0.9849 - val_f1_score: 0.8810\n","Epoch 28/100\n","69/69 [==============================] - ETA: 0s - loss: 0.3946 - accuracy: 0.8395 - auc: 0.9733 - f1_score: 0.8382 - scaled_graph_loss: 0.0116\n","Epoch 00028: val_accuracy did not improve from 0.89080\n","69/69 [==============================] - 35s 506ms/step - loss: 0.3946 - accuracy: 0.8395 - auc: 0.9733 - f1_score: 0.8382 - scaled_graph_loss: 0.0116 - val_loss: 0.3094 - val_accuracy: 0.8694 - val_auc: 0.9829 - val_f1_score: 0.8678\n","Epoch 29/100\n","69/69 [==============================] - ETA: 0s - loss: 0.3816 - accuracy: 0.8442 - auc: 0.9749 - f1_score: 0.8428 - scaled_graph_loss: 0.0114\n","Epoch 00029: val_accuracy improved from 0.89080 to 0.89316, saving model to /content/drive/My Drive/Projects/codes/DenseNet_NSL_model_checkpoints/densenet_nsl_weights_colab_new_92\n","69/69 [==============================] - 35s 514ms/step - loss: 0.3816 - accuracy: 0.8442 - auc: 0.9749 - f1_score: 0.8428 - scaled_graph_loss: 0.0114 - val_loss: 0.2869 - val_accuracy: 0.8932 - val_auc: 0.9874 - val_f1_score: 0.8950\n","Epoch 30/100\n","69/69 [==============================] - ETA: 0s - loss: 0.3745 - accuracy: 0.8466 - auc: 0.9758 - f1_score: 0.8436 - scaled_graph_loss: 0.0115\n","Epoch 00030: val_accuracy improved from 0.89316 to 0.89681, saving model to /content/drive/My Drive/Projects/codes/DenseNet_NSL_model_checkpoints/densenet_nsl_weights_colab_new_92\n","69/69 [==============================] - 35s 511ms/step - loss: 0.3745 - accuracy: 0.8466 - auc: 0.9758 - f1_score: 0.8436 - scaled_graph_loss: 0.0115 - val_loss: 0.2922 - val_accuracy: 0.8968 - val_auc: 0.9864 - val_f1_score: 0.8948\n","Epoch 31/100\n","69/69 [==============================] - ETA: 0s - loss: 0.3813 - accuracy: 0.8498 - auc: 0.9751 - f1_score: 0.8472 - scaled_graph_loss: 0.0114\n","Epoch 00031: val_accuracy improved from 0.89681 to 0.90387, saving model to /content/drive/My Drive/Projects/codes/DenseNet_NSL_model_checkpoints/densenet_nsl_weights_colab_new_92\n","69/69 [==============================] - 36s 520ms/step - loss: 0.3813 - accuracy: 0.8498 - auc: 0.9751 - f1_score: 0.8472 - scaled_graph_loss: 0.0114 - val_loss: 0.2728 - val_accuracy: 0.9039 - val_auc: 0.9885 - val_f1_score: 0.9020\n","Epoch 32/100\n","69/69 [==============================] - ETA: 0s - loss: 0.3760 - accuracy: 0.8452 - auc: 0.9755 - f1_score: 0.8426 - scaled_graph_loss: 0.0114\n","Epoch 00032: val_accuracy did not improve from 0.90387\n","69/69 [==============================] - 35s 509ms/step - loss: 0.3760 - accuracy: 0.8452 - auc: 0.9755 - f1_score: 0.8426 - scaled_graph_loss: 0.0114 - val_loss: 0.2782 - val_accuracy: 0.8981 - val_auc: 0.9873 - val_f1_score: 0.8936\n","Epoch 33/100\n","69/69 [==============================] - ETA: 0s - loss: 0.3726 - accuracy: 0.8506 - auc: 0.9761 - f1_score: 0.8468 - scaled_graph_loss: 0.0113\n","Epoch 00033: val_accuracy did not improve from 0.90387\n","69/69 [==============================] - 35s 505ms/step - loss: 0.3726 - accuracy: 0.8506 - auc: 0.9761 - f1_score: 0.8468 - scaled_graph_loss: 0.0113 - val_loss: 0.2705 - val_accuracy: 0.9039 - val_auc: 0.9887 - val_f1_score: 0.9022\n","Epoch 34/100\n","69/69 [==============================] - ETA: 0s - loss: 0.3712 - accuracy: 0.8496 - auc: 0.9763 - f1_score: 0.8464 - scaled_graph_loss: 0.0113\n","Epoch 00034: val_accuracy did not improve from 0.90387\n","69/69 [==============================] - 35s 506ms/step - loss: 0.3712 - accuracy: 0.8496 - auc: 0.9763 - f1_score: 0.8464 - scaled_graph_loss: 0.0113 - val_loss: 0.2759 - val_accuracy: 0.9018 - val_auc: 0.9879 - val_f1_score: 0.9007\n","Epoch 35/100\n","69/69 [==============================] - ETA: 0s - loss: 0.3649 - accuracy: 0.8506 - auc: 0.9769 - f1_score: 0.8504 - scaled_graph_loss: 0.0114\n","Epoch 00035: val_accuracy did not improve from 0.90387\n","69/69 [==============================] - 35s 509ms/step - loss: 0.3649 - accuracy: 0.8506 - auc: 0.9769 - f1_score: 0.8504 - scaled_graph_loss: 0.0114 - val_loss: 0.2633 - val_accuracy: 0.9036 - val_auc: 0.9892 - val_f1_score: 0.9023\n","Epoch 36/100\n","69/69 [==============================] - ETA: 0s - loss: 0.3631 - accuracy: 0.8525 - auc: 0.9774 - f1_score: 0.8528 - scaled_graph_loss: 0.0114\n","Epoch 00036: val_accuracy did not improve from 0.90387\n","69/69 [==============================] - 35s 503ms/step - loss: 0.3631 - accuracy: 0.8525 - auc: 0.9774 - f1_score: 0.8528 - scaled_graph_loss: 0.0114 - val_loss: 0.3001 - val_accuracy: 0.8746 - val_auc: 0.9835 - val_f1_score: 0.8715\n","Epoch 37/100\n","69/69 [==============================] - ETA: 0s - loss: 0.3597 - accuracy: 0.8530 - auc: 0.9775 - f1_score: 0.8515 - scaled_graph_loss: 0.0114\n","Epoch 00037: val_accuracy did not improve from 0.90387\n","69/69 [==============================] - 35s 510ms/step - loss: 0.3597 - accuracy: 0.8530 - auc: 0.9775 - f1_score: 0.8515 - scaled_graph_loss: 0.0114 - val_loss: 0.3367 - val_accuracy: 0.8501 - val_auc: 0.9786 - val_f1_score: 0.8495\n","Epoch 38/100\n","69/69 [==============================] - ETA: 0s - loss: 0.3564 - accuracy: 0.8550 - auc: 0.9782 - f1_score: 0.8561 - scaled_graph_loss: 0.0114\n","Epoch 00038: val_accuracy did not improve from 0.90387\n","69/69 [==============================] - 35s 512ms/step - loss: 0.3564 - accuracy: 0.8550 - auc: 0.9782 - f1_score: 0.8561 - scaled_graph_loss: 0.0114 - val_loss: 0.2909 - val_accuracy: 0.8840 - val_auc: 0.9854 - val_f1_score: 0.8852\n","Epoch 39/100\n","69/69 [==============================] - ETA: 0s - loss: 0.3622 - accuracy: 0.8531 - auc: 0.9773 - f1_score: 0.8515 - scaled_graph_loss: 0.0113\n","Epoch 00039: val_accuracy improved from 0.90387 to 0.90465, saving model to /content/drive/My Drive/Projects/codes/DenseNet_NSL_model_checkpoints/densenet_nsl_weights_colab_new_92\n","69/69 [==============================] - 35s 514ms/step - loss: 0.3622 - accuracy: 0.8531 - auc: 0.9773 - f1_score: 0.8515 - scaled_graph_loss: 0.0113 - val_loss: 0.2682 - val_accuracy: 0.9046 - val_auc: 0.9879 - val_f1_score: 0.9010\n","Epoch 40/100\n","69/69 [==============================] - ETA: 0s - loss: 0.3585 - accuracy: 0.8555 - auc: 0.9780 - f1_score: 0.8573 - scaled_graph_loss: 0.0113\n","Epoch 00040: val_accuracy improved from 0.90465 to 0.91928, saving model to /content/drive/My Drive/Projects/codes/DenseNet_NSL_model_checkpoints/densenet_nsl_weights_colab_new_92\n","69/69 [==============================] - 36s 517ms/step - loss: 0.3585 - accuracy: 0.8555 - auc: 0.9780 - f1_score: 0.8573 - scaled_graph_loss: 0.0113 - val_loss: 0.2423 - val_accuracy: 0.9193 - val_auc: 0.9916 - val_f1_score: 0.9158\n","Epoch 41/100\n","69/69 [==============================] - ETA: 0s - loss: 0.3561 - accuracy: 0.8565 - auc: 0.9780 - f1_score: 0.8542 - scaled_graph_loss: 0.0113\n","Epoch 00041: val_accuracy did not improve from 0.91928\n","69/69 [==============================] - 35s 502ms/step - loss: 0.3561 - accuracy: 0.8565 - auc: 0.9780 - f1_score: 0.8542 - scaled_graph_loss: 0.0113 - val_loss: 0.2629 - val_accuracy: 0.9080 - val_auc: 0.9892 - val_f1_score: 0.9077\n","Epoch 42/100\n","69/69 [==============================] - ETA: 0s - loss: 0.3519 - accuracy: 0.8564 - auc: 0.9786 - f1_score: 0.8545 - scaled_graph_loss: 0.0113\n","Epoch 00042: val_accuracy did not improve from 0.91928\n","69/69 [==============================] - 35s 505ms/step - loss: 0.3519 - accuracy: 0.8564 - auc: 0.9786 - f1_score: 0.8545 - scaled_graph_loss: 0.0113 - val_loss: 0.2461 - val_accuracy: 0.9120 - val_auc: 0.9908 - val_f1_score: 0.9133\n","Epoch 43/100\n","69/69 [==============================] - ETA: 0s - loss: 0.3434 - accuracy: 0.8625 - auc: 0.9798 - f1_score: 0.8625 - scaled_graph_loss: 0.0112\n","Epoch 00043: val_accuracy did not improve from 0.91928\n","69/69 [==============================] - 34s 489ms/step - loss: 0.3434 - accuracy: 0.8625 - auc: 0.9798 - f1_score: 0.8625 - scaled_graph_loss: 0.0112 - val_loss: 0.2375 - val_accuracy: 0.9193 - val_auc: 0.9914 - val_f1_score: 0.9188\n","Epoch 44/100\n","69/69 [==============================] - ETA: 0s - loss: 0.3424 - accuracy: 0.8613 - auc: 0.9799 - f1_score: 0.8617 - scaled_graph_loss: 0.0112\n","Epoch 00044: val_accuracy did not improve from 0.91928\n","69/69 [==============================] - 35s 505ms/step - loss: 0.3424 - accuracy: 0.8613 - auc: 0.9799 - f1_score: 0.8617 - scaled_graph_loss: 0.0112 - val_loss: 0.2402 - val_accuracy: 0.9117 - val_auc: 0.9908 - val_f1_score: 0.9117\n","Epoch 45/100\n","69/69 [==============================] - ETA: 0s - loss: 0.3455 - accuracy: 0.8622 - auc: 0.9794 - f1_score: 0.8600 - scaled_graph_loss: 0.0113\n","Epoch 00045: val_accuracy improved from 0.91928 to 0.92215, saving model to /content/drive/My Drive/Projects/codes/DenseNet_NSL_model_checkpoints/densenet_nsl_weights_colab_new_92\n","69/69 [==============================] - 36s 522ms/step - loss: 0.3455 - accuracy: 0.8622 - auc: 0.9794 - f1_score: 0.8600 - scaled_graph_loss: 0.0113 - val_loss: 0.2339 - val_accuracy: 0.9222 - val_auc: 0.9919 - val_f1_score: 0.9214\n","Epoch 00046: early stopping\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KEo0rokAZPzs","executionInfo":{"status":"ok","timestamp":1606005726014,"user_tz":300,"elapsed":4606,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"903c03bb-8225-4fd8-8b70-f6b7d821e3ba"},"source":["graph_reg_model.evaluate(test_image_dataset)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1/1 [==============================] - 0s 17ms/step - loss: 0.2339 - accuracy: 0.9222 - auc: 0.9919 - f1_score: 0.9214\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[0.23390400409698486,\n"," 0.922152578830719,\n"," 0.9918628334999084,\n"," 0.9213719964027405]"]},"metadata":{"tags":[]},"execution_count":53}]},{"cell_type":"code","metadata":{"id":"SeIDeU8uf5cG"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0XAmOO5ZgGcj"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dg3vzxBShRRh"},"source":["## 4.3 DenseNet_NSL top 20 layers and bottom 50 laysers tuning\n","### val_acc: 0.963, val_auc: 0.991, val_f1_score: 0.963"]},{"cell_type":"code","metadata":{"id":"K5IOkuPWirui"},"source":["'''redefine hyper params'''\n","params = AD_params()\n","params.max_seed_nbr=5\n","params.batch_size=64\n","params.image_channels =3\n","params.image_size =(100,100)\n","params.ad_base_model_input_shape=(100,100,3)\n","params.train_tfr_path = f'{root_path}train_data.tfr'\n","\n","'''parse train_data.tfr to train image dataset with batch_size at 64'''\n","train_image_dataset = NSLDataFormat.parse_tfr_to_dataset(file_path_list=[params.train_tfr_path],\n","                                                         batch_size=params.batch_size,\n","                                                         max_neighbor_number=params.max_seed_nbr,\n","                                                         image_size=params.image_size,\n","                                                         image_channels=params.image_channels,\n","                                                         shuffle=True)\n","\n","'''load test data with batch_size at 64 '''\n","test_image_dataset = NSLDataFormat.generate_test_tfr_image_tensor(path_list=tfr_list_test, \n","                                                                  batch_size=params.batch_size, \n","                                                                  size=params.image_size,\n","                                                                  channels=params.image_channels,\n","                                                                  shuffle=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0EWDr4Po5vgq","executionInfo":{"status":"ok","timestamp":1606007538002,"user_tz":300,"elapsed":1524585,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"9229a22e-46d4-43df-b18d-2828dfeac73f"},"source":["params.learning_rate=0.0001\n","params.restore_path= '/content/drive/My Drive/Projects/codes/DenseNet_NSL_model_checkpoints/densenet_nsl_weights_colab_new_92'\n","params.checkpoint_path = '/content/drive/My Drive/Projects/codes/DenseNet_NSL_model_checkpoints/densenet_nsl_weights_colab_tuning_new_95'\n","params.early_stop_base_line=0.95\n","params.train_epoch=100\n","params.nsl_multiplier = 0.1\n","params.nsl_sum_over_axis = -1\n","params.nsl_distance_type = nsl.configs.DistanceType.COSINE\n","\n","'''build a base model with selected trainable layer'''\n","admodel = ADModelBuilder(input_shape=params.ad_base_model_input_shape, base_model='densenet121').setup_DenseNet121(top_layers=10, middle_layers=None, bottom_layers=50).get_ADModel()\n","'''build NSL model on top of base model'''\n","graph_reg_config = nsl.configs.make_graph_reg_config(neighbor_prefix=params.neighbor_prefix,\n","                                                     neighbor_weight_suffix=params.neighbor_weight_suffix,\n","                                                     max_neighbors= params.max_seed_nbr,\n","                                                     multiplier= params.nsl_multiplier,\n","                                                     distance_type= params.nsl_distance_type,\n","                                                     sum_over_axis= params.nsl_sum_over_axis)\n","graph_reg_model = nsl.keras.GraphRegularization(admodel,graph_reg_config)\n","graph_reg_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=params.learning_rate, amsgrad=True), \n","                        loss=tf.losses.CategoricalCrossentropy(), \n","                        metrics=[\"accuracy\",\"AUC\", tfa.metrics.F1Score(num_classes=4, average=\"micro\", threshold = 0.5)])\n","'''restore the model from last training'''\n","graph_reg_model.load_weights(params.restore_path)\n","''' NSL model training '''\n","callback_checkpoints = tf.keras.callbacks.ModelCheckpoint(filepath=params.checkpoint_path, monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=True, mode='max',\n","                                                          save_freq='epoch',options=None)\n","callback_earlystop = AccEarlyStop(val_acc_base=params.early_stop_base_line)\n","graph_reg_history = graph_reg_model.fit(train_image_dataset, \n","                                        validation_data=test_image_dataset,\n","                                        callbacks = [callback_checkpoints, callback_earlystop],\n","                                        epochs=params.train_epoch,\n","                                        verbose=1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Note: default DenseNet121 not includes top and has imagenet weights. It is not a trainable model in ADModelBuilder. Please setup trainable layers in setup_DenseNet121 function based on the \"Layer Number\"\n","Model: \"densenet121\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_6 (InputLayer)            [(None, 100, 100, 3) 0                                            \n","__________________________________________________________________________________________________\n","zero_padding2d_6 (ZeroPadding2D (None, 106, 106, 3)  0           input_6[0][0]                    \n","__________________________________________________________________________________________________\n","conv1/conv (Conv2D)             (None, 50, 50, 64)   9408        zero_padding2d_6[0][0]           \n","__________________________________________________________________________________________________\n","conv1/bn (BatchNormalization)   (None, 50, 50, 64)   256         conv1/conv[0][0]                 \n","__________________________________________________________________________________________________\n","conv1/relu (Activation)         (None, 50, 50, 64)   0           conv1/bn[0][0]                   \n","__________________________________________________________________________________________________\n","zero_padding2d_7 (ZeroPadding2D (None, 52, 52, 64)   0           conv1/relu[0][0]                 \n","__________________________________________________________________________________________________\n","pool1 (MaxPooling2D)            (None, 25, 25, 64)   0           zero_padding2d_7[0][0]           \n","__________________________________________________________________________________________________\n","conv2_block1_0_bn (BatchNormali (None, 25, 25, 64)   256         pool1[0][0]                      \n","__________________________________________________________________________________________________\n","conv2_block1_0_relu (Activation (None, 25, 25, 64)   0           conv2_block1_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block1_1_conv (Conv2D)    (None, 25, 25, 128)  8192        conv2_block1_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_1_bn (BatchNormali (None, 25, 25, 128)  512         conv2_block1_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_1_relu (Activation (None, 25, 25, 128)  0           conv2_block1_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block1_2_conv (Conv2D)    (None, 25, 25, 32)   36864       conv2_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_concat (Concatenat (None, 25, 25, 96)   0           pool1[0][0]                      \n","                                                                 conv2_block1_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_0_bn (BatchNormali (None, 25, 25, 96)   384         conv2_block1_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_0_relu (Activation (None, 25, 25, 96)   0           conv2_block2_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block2_1_conv (Conv2D)    (None, 25, 25, 128)  12288       conv2_block2_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_1_bn (BatchNormali (None, 25, 25, 128)  512         conv2_block2_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_1_relu (Activation (None, 25, 25, 128)  0           conv2_block2_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block2_2_conv (Conv2D)    (None, 25, 25, 32)   36864       conv2_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_concat (Concatenat (None, 25, 25, 128)  0           conv2_block1_concat[0][0]        \n","                                                                 conv2_block2_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_0_bn (BatchNormali (None, 25, 25, 128)  512         conv2_block2_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_0_relu (Activation (None, 25, 25, 128)  0           conv2_block3_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block3_1_conv (Conv2D)    (None, 25, 25, 128)  16384       conv2_block3_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_1_bn (BatchNormali (None, 25, 25, 128)  512         conv2_block3_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_1_relu (Activation (None, 25, 25, 128)  0           conv2_block3_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block3_2_conv (Conv2D)    (None, 25, 25, 32)   36864       conv2_block3_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_concat (Concatenat (None, 25, 25, 160)  0           conv2_block2_concat[0][0]        \n","                                                                 conv2_block3_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block4_0_bn (BatchNormali (None, 25, 25, 160)  640         conv2_block3_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block4_0_relu (Activation (None, 25, 25, 160)  0           conv2_block4_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block4_1_conv (Conv2D)    (None, 25, 25, 128)  20480       conv2_block4_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block4_1_bn (BatchNormali (None, 25, 25, 128)  512         conv2_block4_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block4_1_relu (Activation (None, 25, 25, 128)  0           conv2_block4_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block4_2_conv (Conv2D)    (None, 25, 25, 32)   36864       conv2_block4_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block4_concat (Concatenat (None, 25, 25, 192)  0           conv2_block3_concat[0][0]        \n","                                                                 conv2_block4_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block5_0_bn (BatchNormali (None, 25, 25, 192)  768         conv2_block4_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block5_0_relu (Activation (None, 25, 25, 192)  0           conv2_block5_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block5_1_conv (Conv2D)    (None, 25, 25, 128)  24576       conv2_block5_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block5_1_bn (BatchNormali (None, 25, 25, 128)  512         conv2_block5_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block5_1_relu (Activation (None, 25, 25, 128)  0           conv2_block5_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block5_2_conv (Conv2D)    (None, 25, 25, 32)   36864       conv2_block5_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block5_concat (Concatenat (None, 25, 25, 224)  0           conv2_block4_concat[0][0]        \n","                                                                 conv2_block5_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block6_0_bn (BatchNormali (None, 25, 25, 224)  896         conv2_block5_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block6_0_relu (Activation (None, 25, 25, 224)  0           conv2_block6_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block6_1_conv (Conv2D)    (None, 25, 25, 128)  28672       conv2_block6_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block6_1_bn (BatchNormali (None, 25, 25, 128)  512         conv2_block6_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block6_1_relu (Activation (None, 25, 25, 128)  0           conv2_block6_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block6_2_conv (Conv2D)    (None, 25, 25, 32)   36864       conv2_block6_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block6_concat (Concatenat (None, 25, 25, 256)  0           conv2_block5_concat[0][0]        \n","                                                                 conv2_block6_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","pool2_bn (BatchNormalization)   (None, 25, 25, 256)  1024        conv2_block6_concat[0][0]        \n","__________________________________________________________________________________________________\n","pool2_relu (Activation)         (None, 25, 25, 256)  0           pool2_bn[0][0]                   \n","__________________________________________________________________________________________________\n","pool2_conv (Conv2D)             (None, 25, 25, 128)  32768       pool2_relu[0][0]                 \n","__________________________________________________________________________________________________\n","pool2_pool (AveragePooling2D)   (None, 12, 12, 128)  0           pool2_conv[0][0]                 \n","__________________________________________________________________________________________________\n","conv3_block1_0_bn (BatchNormali (None, 12, 12, 128)  512         pool2_pool[0][0]                 \n","__________________________________________________________________________________________________\n","conv3_block1_0_relu (Activation (None, 12, 12, 128)  0           conv3_block1_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block1_1_conv (Conv2D)    (None, 12, 12, 128)  16384       conv3_block1_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_1_bn (BatchNormali (None, 12, 12, 128)  512         conv3_block1_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_1_relu (Activation (None, 12, 12, 128)  0           conv3_block1_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block1_2_conv (Conv2D)    (None, 12, 12, 32)   36864       conv3_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_concat (Concatenat (None, 12, 12, 160)  0           pool2_pool[0][0]                 \n","                                                                 conv3_block1_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_0_bn (BatchNormali (None, 12, 12, 160)  640         conv3_block1_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_0_relu (Activation (None, 12, 12, 160)  0           conv3_block2_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block2_1_conv (Conv2D)    (None, 12, 12, 128)  20480       conv3_block2_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_1_bn (BatchNormali (None, 12, 12, 128)  512         conv3_block2_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_1_relu (Activation (None, 12, 12, 128)  0           conv3_block2_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block2_2_conv (Conv2D)    (None, 12, 12, 32)   36864       conv3_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_concat (Concatenat (None, 12, 12, 192)  0           conv3_block1_concat[0][0]        \n","                                                                 conv3_block2_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_0_bn (BatchNormali (None, 12, 12, 192)  768         conv3_block2_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_0_relu (Activation (None, 12, 12, 192)  0           conv3_block3_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block3_1_conv (Conv2D)    (None, 12, 12, 128)  24576       conv3_block3_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_1_bn (BatchNormali (None, 12, 12, 128)  512         conv3_block3_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_1_relu (Activation (None, 12, 12, 128)  0           conv3_block3_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block3_2_conv (Conv2D)    (None, 12, 12, 32)   36864       conv3_block3_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_concat (Concatenat (None, 12, 12, 224)  0           conv3_block2_concat[0][0]        \n","                                                                 conv3_block3_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_0_bn (BatchNormali (None, 12, 12, 224)  896         conv3_block3_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_0_relu (Activation (None, 12, 12, 224)  0           conv3_block4_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block4_1_conv (Conv2D)    (None, 12, 12, 128)  28672       conv3_block4_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_1_bn (BatchNormali (None, 12, 12, 128)  512         conv3_block4_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_1_relu (Activation (None, 12, 12, 128)  0           conv3_block4_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block4_2_conv (Conv2D)    (None, 12, 12, 32)   36864       conv3_block4_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_concat (Concatenat (None, 12, 12, 256)  0           conv3_block3_concat[0][0]        \n","                                                                 conv3_block4_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block5_0_bn (BatchNormali (None, 12, 12, 256)  1024        conv3_block4_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block5_0_relu (Activation (None, 12, 12, 256)  0           conv3_block5_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block5_1_conv (Conv2D)    (None, 12, 12, 128)  32768       conv3_block5_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block5_1_bn (BatchNormali (None, 12, 12, 128)  512         conv3_block5_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block5_1_relu (Activation (None, 12, 12, 128)  0           conv3_block5_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block5_2_conv (Conv2D)    (None, 12, 12, 32)   36864       conv3_block5_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block5_concat (Concatenat (None, 12, 12, 288)  0           conv3_block4_concat[0][0]        \n","                                                                 conv3_block5_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block6_0_bn (BatchNormali (None, 12, 12, 288)  1152        conv3_block5_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block6_0_relu (Activation (None, 12, 12, 288)  0           conv3_block6_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block6_1_conv (Conv2D)    (None, 12, 12, 128)  36864       conv3_block6_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block6_1_bn (BatchNormali (None, 12, 12, 128)  512         conv3_block6_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block6_1_relu (Activation (None, 12, 12, 128)  0           conv3_block6_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block6_2_conv (Conv2D)    (None, 12, 12, 32)   36864       conv3_block6_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block6_concat (Concatenat (None, 12, 12, 320)  0           conv3_block5_concat[0][0]        \n","                                                                 conv3_block6_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block7_0_bn (BatchNormali (None, 12, 12, 320)  1280        conv3_block6_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block7_0_relu (Activation (None, 12, 12, 320)  0           conv3_block7_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block7_1_conv (Conv2D)    (None, 12, 12, 128)  40960       conv3_block7_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block7_1_bn (BatchNormali (None, 12, 12, 128)  512         conv3_block7_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block7_1_relu (Activation (None, 12, 12, 128)  0           conv3_block7_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block7_2_conv (Conv2D)    (None, 12, 12, 32)   36864       conv3_block7_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block7_concat (Concatenat (None, 12, 12, 352)  0           conv3_block6_concat[0][0]        \n","                                                                 conv3_block7_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block8_0_bn (BatchNormali (None, 12, 12, 352)  1408        conv3_block7_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block8_0_relu (Activation (None, 12, 12, 352)  0           conv3_block8_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block8_1_conv (Conv2D)    (None, 12, 12, 128)  45056       conv3_block8_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block8_1_bn (BatchNormali (None, 12, 12, 128)  512         conv3_block8_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block8_1_relu (Activation (None, 12, 12, 128)  0           conv3_block8_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block8_2_conv (Conv2D)    (None, 12, 12, 32)   36864       conv3_block8_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block8_concat (Concatenat (None, 12, 12, 384)  0           conv3_block7_concat[0][0]        \n","                                                                 conv3_block8_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block9_0_bn (BatchNormali (None, 12, 12, 384)  1536        conv3_block8_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block9_0_relu (Activation (None, 12, 12, 384)  0           conv3_block9_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block9_1_conv (Conv2D)    (None, 12, 12, 128)  49152       conv3_block9_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block9_1_bn (BatchNormali (None, 12, 12, 128)  512         conv3_block9_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block9_1_relu (Activation (None, 12, 12, 128)  0           conv3_block9_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block9_2_conv (Conv2D)    (None, 12, 12, 32)   36864       conv3_block9_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block9_concat (Concatenat (None, 12, 12, 416)  0           conv3_block8_concat[0][0]        \n","                                                                 conv3_block9_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block10_0_bn (BatchNormal (None, 12, 12, 416)  1664        conv3_block9_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block10_0_relu (Activatio (None, 12, 12, 416)  0           conv3_block10_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv3_block10_1_conv (Conv2D)   (None, 12, 12, 128)  53248       conv3_block10_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv3_block10_1_bn (BatchNormal (None, 12, 12, 128)  512         conv3_block10_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv3_block10_1_relu (Activatio (None, 12, 12, 128)  0           conv3_block10_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv3_block10_2_conv (Conv2D)   (None, 12, 12, 32)   36864       conv3_block10_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv3_block10_concat (Concatena (None, 12, 12, 448)  0           conv3_block9_concat[0][0]        \n","                                                                 conv3_block10_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv3_block11_0_bn (BatchNormal (None, 12, 12, 448)  1792        conv3_block10_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv3_block11_0_relu (Activatio (None, 12, 12, 448)  0           conv3_block11_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv3_block11_1_conv (Conv2D)   (None, 12, 12, 128)  57344       conv3_block11_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv3_block11_1_bn (BatchNormal (None, 12, 12, 128)  512         conv3_block11_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv3_block11_1_relu (Activatio (None, 12, 12, 128)  0           conv3_block11_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv3_block11_2_conv (Conv2D)   (None, 12, 12, 32)   36864       conv3_block11_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv3_block11_concat (Concatena (None, 12, 12, 480)  0           conv3_block10_concat[0][0]       \n","                                                                 conv3_block11_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv3_block12_0_bn (BatchNormal (None, 12, 12, 480)  1920        conv3_block11_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv3_block12_0_relu (Activatio (None, 12, 12, 480)  0           conv3_block12_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv3_block12_1_conv (Conv2D)   (None, 12, 12, 128)  61440       conv3_block12_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv3_block12_1_bn (BatchNormal (None, 12, 12, 128)  512         conv3_block12_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv3_block12_1_relu (Activatio (None, 12, 12, 128)  0           conv3_block12_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv3_block12_2_conv (Conv2D)   (None, 12, 12, 32)   36864       conv3_block12_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv3_block12_concat (Concatena (None, 12, 12, 512)  0           conv3_block11_concat[0][0]       \n","                                                                 conv3_block12_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","pool3_bn (BatchNormalization)   (None, 12, 12, 512)  2048        conv3_block12_concat[0][0]       \n","__________________________________________________________________________________________________\n","pool3_relu (Activation)         (None, 12, 12, 512)  0           pool3_bn[0][0]                   \n","__________________________________________________________________________________________________\n","pool3_conv (Conv2D)             (None, 12, 12, 256)  131072      pool3_relu[0][0]                 \n","__________________________________________________________________________________________________\n","pool3_pool (AveragePooling2D)   (None, 6, 6, 256)    0           pool3_conv[0][0]                 \n","__________________________________________________________________________________________________\n","conv4_block1_0_bn (BatchNormali (None, 6, 6, 256)    1024        pool3_pool[0][0]                 \n","__________________________________________________________________________________________________\n","conv4_block1_0_relu (Activation (None, 6, 6, 256)    0           conv4_block1_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block1_1_conv (Conv2D)    (None, 6, 6, 128)    32768       conv4_block1_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_1_bn (BatchNormali (None, 6, 6, 128)    512         conv4_block1_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_1_relu (Activation (None, 6, 6, 128)    0           conv4_block1_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block1_2_conv (Conv2D)    (None, 6, 6, 32)     36864       conv4_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_concat (Concatenat (None, 6, 6, 288)    0           pool3_pool[0][0]                 \n","                                                                 conv4_block1_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_0_bn (BatchNormali (None, 6, 6, 288)    1152        conv4_block1_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_0_relu (Activation (None, 6, 6, 288)    0           conv4_block2_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block2_1_conv (Conv2D)    (None, 6, 6, 128)    36864       conv4_block2_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_1_bn (BatchNormali (None, 6, 6, 128)    512         conv4_block2_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_1_relu (Activation (None, 6, 6, 128)    0           conv4_block2_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block2_2_conv (Conv2D)    (None, 6, 6, 32)     36864       conv4_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_concat (Concatenat (None, 6, 6, 320)    0           conv4_block1_concat[0][0]        \n","                                                                 conv4_block2_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_0_bn (BatchNormali (None, 6, 6, 320)    1280        conv4_block2_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_0_relu (Activation (None, 6, 6, 320)    0           conv4_block3_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block3_1_conv (Conv2D)    (None, 6, 6, 128)    40960       conv4_block3_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_1_bn (BatchNormali (None, 6, 6, 128)    512         conv4_block3_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_1_relu (Activation (None, 6, 6, 128)    0           conv4_block3_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block3_2_conv (Conv2D)    (None, 6, 6, 32)     36864       conv4_block3_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_concat (Concatenat (None, 6, 6, 352)    0           conv4_block2_concat[0][0]        \n","                                                                 conv4_block3_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_0_bn (BatchNormali (None, 6, 6, 352)    1408        conv4_block3_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_0_relu (Activation (None, 6, 6, 352)    0           conv4_block4_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block4_1_conv (Conv2D)    (None, 6, 6, 128)    45056       conv4_block4_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_1_bn (BatchNormali (None, 6, 6, 128)    512         conv4_block4_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_1_relu (Activation (None, 6, 6, 128)    0           conv4_block4_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block4_2_conv (Conv2D)    (None, 6, 6, 32)     36864       conv4_block4_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_concat (Concatenat (None, 6, 6, 384)    0           conv4_block3_concat[0][0]        \n","                                                                 conv4_block4_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_0_bn (BatchNormali (None, 6, 6, 384)    1536        conv4_block4_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_0_relu (Activation (None, 6, 6, 384)    0           conv4_block5_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block5_1_conv (Conv2D)    (None, 6, 6, 128)    49152       conv4_block5_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_1_bn (BatchNormali (None, 6, 6, 128)    512         conv4_block5_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_1_relu (Activation (None, 6, 6, 128)    0           conv4_block5_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block5_2_conv (Conv2D)    (None, 6, 6, 32)     36864       conv4_block5_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_concat (Concatenat (None, 6, 6, 416)    0           conv4_block4_concat[0][0]        \n","                                                                 conv4_block5_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_0_bn (BatchNormali (None, 6, 6, 416)    1664        conv4_block5_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_0_relu (Activation (None, 6, 6, 416)    0           conv4_block6_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block6_1_conv (Conv2D)    (None, 6, 6, 128)    53248       conv4_block6_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_1_bn (BatchNormali (None, 6, 6, 128)    512         conv4_block6_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_1_relu (Activation (None, 6, 6, 128)    0           conv4_block6_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block6_2_conv (Conv2D)    (None, 6, 6, 32)     36864       conv4_block6_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_concat (Concatenat (None, 6, 6, 448)    0           conv4_block5_concat[0][0]        \n","                                                                 conv4_block6_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block7_0_bn (BatchNormali (None, 6, 6, 448)    1792        conv4_block6_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block7_0_relu (Activation (None, 6, 6, 448)    0           conv4_block7_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block7_1_conv (Conv2D)    (None, 6, 6, 128)    57344       conv4_block7_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block7_1_bn (BatchNormali (None, 6, 6, 128)    512         conv4_block7_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block7_1_relu (Activation (None, 6, 6, 128)    0           conv4_block7_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block7_2_conv (Conv2D)    (None, 6, 6, 32)     36864       conv4_block7_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block7_concat (Concatenat (None, 6, 6, 480)    0           conv4_block6_concat[0][0]        \n","                                                                 conv4_block7_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block8_0_bn (BatchNormali (None, 6, 6, 480)    1920        conv4_block7_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block8_0_relu (Activation (None, 6, 6, 480)    0           conv4_block8_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block8_1_conv (Conv2D)    (None, 6, 6, 128)    61440       conv4_block8_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block8_1_bn (BatchNormali (None, 6, 6, 128)    512         conv4_block8_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block8_1_relu (Activation (None, 6, 6, 128)    0           conv4_block8_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block8_2_conv (Conv2D)    (None, 6, 6, 32)     36864       conv4_block8_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block8_concat (Concatenat (None, 6, 6, 512)    0           conv4_block7_concat[0][0]        \n","                                                                 conv4_block8_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block9_0_bn (BatchNormali (None, 6, 6, 512)    2048        conv4_block8_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block9_0_relu (Activation (None, 6, 6, 512)    0           conv4_block9_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block9_1_conv (Conv2D)    (None, 6, 6, 128)    65536       conv4_block9_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block9_1_bn (BatchNormali (None, 6, 6, 128)    512         conv4_block9_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block9_1_relu (Activation (None, 6, 6, 128)    0           conv4_block9_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block9_2_conv (Conv2D)    (None, 6, 6, 32)     36864       conv4_block9_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block9_concat (Concatenat (None, 6, 6, 544)    0           conv4_block8_concat[0][0]        \n","                                                                 conv4_block9_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block10_0_bn (BatchNormal (None, 6, 6, 544)    2176        conv4_block9_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block10_0_relu (Activatio (None, 6, 6, 544)    0           conv4_block10_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block10_1_conv (Conv2D)   (None, 6, 6, 128)    69632       conv4_block10_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block10_1_bn (BatchNormal (None, 6, 6, 128)    512         conv4_block10_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block10_1_relu (Activatio (None, 6, 6, 128)    0           conv4_block10_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block10_2_conv (Conv2D)   (None, 6, 6, 32)     36864       conv4_block10_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block10_concat (Concatena (None, 6, 6, 576)    0           conv4_block9_concat[0][0]        \n","                                                                 conv4_block10_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block11_0_bn (BatchNormal (None, 6, 6, 576)    2304        conv4_block10_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block11_0_relu (Activatio (None, 6, 6, 576)    0           conv4_block11_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block11_1_conv (Conv2D)   (None, 6, 6, 128)    73728       conv4_block11_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block11_1_bn (BatchNormal (None, 6, 6, 128)    512         conv4_block11_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block11_1_relu (Activatio (None, 6, 6, 128)    0           conv4_block11_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block11_2_conv (Conv2D)   (None, 6, 6, 32)     36864       conv4_block11_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block11_concat (Concatena (None, 6, 6, 608)    0           conv4_block10_concat[0][0]       \n","                                                                 conv4_block11_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block12_0_bn (BatchNormal (None, 6, 6, 608)    2432        conv4_block11_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block12_0_relu (Activatio (None, 6, 6, 608)    0           conv4_block12_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block12_1_conv (Conv2D)   (None, 6, 6, 128)    77824       conv4_block12_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block12_1_bn (BatchNormal (None, 6, 6, 128)    512         conv4_block12_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block12_1_relu (Activatio (None, 6, 6, 128)    0           conv4_block12_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block12_2_conv (Conv2D)   (None, 6, 6, 32)     36864       conv4_block12_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block12_concat (Concatena (None, 6, 6, 640)    0           conv4_block11_concat[0][0]       \n","                                                                 conv4_block12_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block13_0_bn (BatchNormal (None, 6, 6, 640)    2560        conv4_block12_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block13_0_relu (Activatio (None, 6, 6, 640)    0           conv4_block13_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block13_1_conv (Conv2D)   (None, 6, 6, 128)    81920       conv4_block13_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block13_1_bn (BatchNormal (None, 6, 6, 128)    512         conv4_block13_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block13_1_relu (Activatio (None, 6, 6, 128)    0           conv4_block13_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block13_2_conv (Conv2D)   (None, 6, 6, 32)     36864       conv4_block13_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block13_concat (Concatena (None, 6, 6, 672)    0           conv4_block12_concat[0][0]       \n","                                                                 conv4_block13_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block14_0_bn (BatchNormal (None, 6, 6, 672)    2688        conv4_block13_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block14_0_relu (Activatio (None, 6, 6, 672)    0           conv4_block14_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block14_1_conv (Conv2D)   (None, 6, 6, 128)    86016       conv4_block14_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block14_1_bn (BatchNormal (None, 6, 6, 128)    512         conv4_block14_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block14_1_relu (Activatio (None, 6, 6, 128)    0           conv4_block14_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block14_2_conv (Conv2D)   (None, 6, 6, 32)     36864       conv4_block14_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block14_concat (Concatena (None, 6, 6, 704)    0           conv4_block13_concat[0][0]       \n","                                                                 conv4_block14_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block15_0_bn (BatchNormal (None, 6, 6, 704)    2816        conv4_block14_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block15_0_relu (Activatio (None, 6, 6, 704)    0           conv4_block15_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block15_1_conv (Conv2D)   (None, 6, 6, 128)    90112       conv4_block15_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block15_1_bn (BatchNormal (None, 6, 6, 128)    512         conv4_block15_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block15_1_relu (Activatio (None, 6, 6, 128)    0           conv4_block15_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block15_2_conv (Conv2D)   (None, 6, 6, 32)     36864       conv4_block15_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block15_concat (Concatena (None, 6, 6, 736)    0           conv4_block14_concat[0][0]       \n","                                                                 conv4_block15_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block16_0_bn (BatchNormal (None, 6, 6, 736)    2944        conv4_block15_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block16_0_relu (Activatio (None, 6, 6, 736)    0           conv4_block16_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block16_1_conv (Conv2D)   (None, 6, 6, 128)    94208       conv4_block16_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block16_1_bn (BatchNormal (None, 6, 6, 128)    512         conv4_block16_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block16_1_relu (Activatio (None, 6, 6, 128)    0           conv4_block16_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block16_2_conv (Conv2D)   (None, 6, 6, 32)     36864       conv4_block16_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block16_concat (Concatena (None, 6, 6, 768)    0           conv4_block15_concat[0][0]       \n","                                                                 conv4_block16_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block17_0_bn (BatchNormal (None, 6, 6, 768)    3072        conv4_block16_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block17_0_relu (Activatio (None, 6, 6, 768)    0           conv4_block17_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block17_1_conv (Conv2D)   (None, 6, 6, 128)    98304       conv4_block17_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block17_1_bn (BatchNormal (None, 6, 6, 128)    512         conv4_block17_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block17_1_relu (Activatio (None, 6, 6, 128)    0           conv4_block17_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block17_2_conv (Conv2D)   (None, 6, 6, 32)     36864       conv4_block17_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block17_concat (Concatena (None, 6, 6, 800)    0           conv4_block16_concat[0][0]       \n","                                                                 conv4_block17_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block18_0_bn (BatchNormal (None, 6, 6, 800)    3200        conv4_block17_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block18_0_relu (Activatio (None, 6, 6, 800)    0           conv4_block18_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block18_1_conv (Conv2D)   (None, 6, 6, 128)    102400      conv4_block18_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block18_1_bn (BatchNormal (None, 6, 6, 128)    512         conv4_block18_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block18_1_relu (Activatio (None, 6, 6, 128)    0           conv4_block18_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block18_2_conv (Conv2D)   (None, 6, 6, 32)     36864       conv4_block18_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block18_concat (Concatena (None, 6, 6, 832)    0           conv4_block17_concat[0][0]       \n","                                                                 conv4_block18_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block19_0_bn (BatchNormal (None, 6, 6, 832)    3328        conv4_block18_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block19_0_relu (Activatio (None, 6, 6, 832)    0           conv4_block19_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block19_1_conv (Conv2D)   (None, 6, 6, 128)    106496      conv4_block19_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block19_1_bn (BatchNormal (None, 6, 6, 128)    512         conv4_block19_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block19_1_relu (Activatio (None, 6, 6, 128)    0           conv4_block19_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block19_2_conv (Conv2D)   (None, 6, 6, 32)     36864       conv4_block19_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block19_concat (Concatena (None, 6, 6, 864)    0           conv4_block18_concat[0][0]       \n","                                                                 conv4_block19_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block20_0_bn (BatchNormal (None, 6, 6, 864)    3456        conv4_block19_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block20_0_relu (Activatio (None, 6, 6, 864)    0           conv4_block20_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block20_1_conv (Conv2D)   (None, 6, 6, 128)    110592      conv4_block20_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block20_1_bn (BatchNormal (None, 6, 6, 128)    512         conv4_block20_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block20_1_relu (Activatio (None, 6, 6, 128)    0           conv4_block20_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block20_2_conv (Conv2D)   (None, 6, 6, 32)     36864       conv4_block20_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block20_concat (Concatena (None, 6, 6, 896)    0           conv4_block19_concat[0][0]       \n","                                                                 conv4_block20_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block21_0_bn (BatchNormal (None, 6, 6, 896)    3584        conv4_block20_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block21_0_relu (Activatio (None, 6, 6, 896)    0           conv4_block21_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block21_1_conv (Conv2D)   (None, 6, 6, 128)    114688      conv4_block21_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block21_1_bn (BatchNormal (None, 6, 6, 128)    512         conv4_block21_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block21_1_relu (Activatio (None, 6, 6, 128)    0           conv4_block21_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block21_2_conv (Conv2D)   (None, 6, 6, 32)     36864       conv4_block21_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block21_concat (Concatena (None, 6, 6, 928)    0           conv4_block20_concat[0][0]       \n","                                                                 conv4_block21_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block22_0_bn (BatchNormal (None, 6, 6, 928)    3712        conv4_block21_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block22_0_relu (Activatio (None, 6, 6, 928)    0           conv4_block22_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block22_1_conv (Conv2D)   (None, 6, 6, 128)    118784      conv4_block22_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block22_1_bn (BatchNormal (None, 6, 6, 128)    512         conv4_block22_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block22_1_relu (Activatio (None, 6, 6, 128)    0           conv4_block22_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block22_2_conv (Conv2D)   (None, 6, 6, 32)     36864       conv4_block22_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block22_concat (Concatena (None, 6, 6, 960)    0           conv4_block21_concat[0][0]       \n","                                                                 conv4_block22_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block23_0_bn (BatchNormal (None, 6, 6, 960)    3840        conv4_block22_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block23_0_relu (Activatio (None, 6, 6, 960)    0           conv4_block23_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block23_1_conv (Conv2D)   (None, 6, 6, 128)    122880      conv4_block23_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block23_1_bn (BatchNormal (None, 6, 6, 128)    512         conv4_block23_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block23_1_relu (Activatio (None, 6, 6, 128)    0           conv4_block23_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block23_2_conv (Conv2D)   (None, 6, 6, 32)     36864       conv4_block23_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block23_concat (Concatena (None, 6, 6, 992)    0           conv4_block22_concat[0][0]       \n","                                                                 conv4_block23_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block24_0_bn (BatchNormal (None, 6, 6, 992)    3968        conv4_block23_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block24_0_relu (Activatio (None, 6, 6, 992)    0           conv4_block24_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block24_1_conv (Conv2D)   (None, 6, 6, 128)    126976      conv4_block24_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block24_1_bn (BatchNormal (None, 6, 6, 128)    512         conv4_block24_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block24_1_relu (Activatio (None, 6, 6, 128)    0           conv4_block24_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block24_2_conv (Conv2D)   (None, 6, 6, 32)     36864       conv4_block24_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block24_concat (Concatena (None, 6, 6, 1024)   0           conv4_block23_concat[0][0]       \n","                                                                 conv4_block24_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","pool4_bn (BatchNormalization)   (None, 6, 6, 1024)   4096        conv4_block24_concat[0][0]       \n","__________________________________________________________________________________________________\n","pool4_relu (Activation)         (None, 6, 6, 1024)   0           pool4_bn[0][0]                   \n","__________________________________________________________________________________________________\n","pool4_conv (Conv2D)             (None, 6, 6, 512)    524288      pool4_relu[0][0]                 \n","__________________________________________________________________________________________________\n","pool4_pool (AveragePooling2D)   (None, 3, 3, 512)    0           pool4_conv[0][0]                 \n","__________________________________________________________________________________________________\n","conv5_block1_0_bn (BatchNormali (None, 3, 3, 512)    2048        pool4_pool[0][0]                 \n","__________________________________________________________________________________________________\n","conv5_block1_0_relu (Activation (None, 3, 3, 512)    0           conv5_block1_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block1_1_conv (Conv2D)    (None, 3, 3, 128)    65536       conv5_block1_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block1_1_bn (BatchNormali (None, 3, 3, 128)    512         conv5_block1_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block1_1_relu (Activation (None, 3, 3, 128)    0           conv5_block1_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block1_2_conv (Conv2D)    (None, 3, 3, 32)     36864       conv5_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block1_concat (Concatenat (None, 3, 3, 544)    0           pool4_pool[0][0]                 \n","                                                                 conv5_block1_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block2_0_bn (BatchNormali (None, 3, 3, 544)    2176        conv5_block1_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block2_0_relu (Activation (None, 3, 3, 544)    0           conv5_block2_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block2_1_conv (Conv2D)    (None, 3, 3, 128)    69632       conv5_block2_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block2_1_bn (BatchNormali (None, 3, 3, 128)    512         conv5_block2_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block2_1_relu (Activation (None, 3, 3, 128)    0           conv5_block2_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block2_2_conv (Conv2D)    (None, 3, 3, 32)     36864       conv5_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block2_concat (Concatenat (None, 3, 3, 576)    0           conv5_block1_concat[0][0]        \n","                                                                 conv5_block2_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block3_0_bn (BatchNormali (None, 3, 3, 576)    2304        conv5_block2_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block3_0_relu (Activation (None, 3, 3, 576)    0           conv5_block3_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block3_1_conv (Conv2D)    (None, 3, 3, 128)    73728       conv5_block3_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block3_1_bn (BatchNormali (None, 3, 3, 128)    512         conv5_block3_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block3_1_relu (Activation (None, 3, 3, 128)    0           conv5_block3_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block3_2_conv (Conv2D)    (None, 3, 3, 32)     36864       conv5_block3_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block3_concat (Concatenat (None, 3, 3, 608)    0           conv5_block2_concat[0][0]        \n","                                                                 conv5_block3_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block4_0_bn (BatchNormali (None, 3, 3, 608)    2432        conv5_block3_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block4_0_relu (Activation (None, 3, 3, 608)    0           conv5_block4_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block4_1_conv (Conv2D)    (None, 3, 3, 128)    77824       conv5_block4_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block4_1_bn (BatchNormali (None, 3, 3, 128)    512         conv5_block4_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block4_1_relu (Activation (None, 3, 3, 128)    0           conv5_block4_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block4_2_conv (Conv2D)    (None, 3, 3, 32)     36864       conv5_block4_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block4_concat (Concatenat (None, 3, 3, 640)    0           conv5_block3_concat[0][0]        \n","                                                                 conv5_block4_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block5_0_bn (BatchNormali (None, 3, 3, 640)    2560        conv5_block4_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block5_0_relu (Activation (None, 3, 3, 640)    0           conv5_block5_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block5_1_conv (Conv2D)    (None, 3, 3, 128)    81920       conv5_block5_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block5_1_bn (BatchNormali (None, 3, 3, 128)    512         conv5_block5_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block5_1_relu (Activation (None, 3, 3, 128)    0           conv5_block5_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block5_2_conv (Conv2D)    (None, 3, 3, 32)     36864       conv5_block5_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block5_concat (Concatenat (None, 3, 3, 672)    0           conv5_block4_concat[0][0]        \n","                                                                 conv5_block5_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block6_0_bn (BatchNormali (None, 3, 3, 672)    2688        conv5_block5_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block6_0_relu (Activation (None, 3, 3, 672)    0           conv5_block6_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block6_1_conv (Conv2D)    (None, 3, 3, 128)    86016       conv5_block6_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block6_1_bn (BatchNormali (None, 3, 3, 128)    512         conv5_block6_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block6_1_relu (Activation (None, 3, 3, 128)    0           conv5_block6_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block6_2_conv (Conv2D)    (None, 3, 3, 32)     36864       conv5_block6_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block6_concat (Concatenat (None, 3, 3, 704)    0           conv5_block5_concat[0][0]        \n","                                                                 conv5_block6_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block7_0_bn (BatchNormali (None, 3, 3, 704)    2816        conv5_block6_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block7_0_relu (Activation (None, 3, 3, 704)    0           conv5_block7_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block7_1_conv (Conv2D)    (None, 3, 3, 128)    90112       conv5_block7_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block7_1_bn (BatchNormali (None, 3, 3, 128)    512         conv5_block7_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block7_1_relu (Activation (None, 3, 3, 128)    0           conv5_block7_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block7_2_conv (Conv2D)    (None, 3, 3, 32)     36864       conv5_block7_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block7_concat (Concatenat (None, 3, 3, 736)    0           conv5_block6_concat[0][0]        \n","                                                                 conv5_block7_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block8_0_bn (BatchNormali (None, 3, 3, 736)    2944        conv5_block7_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block8_0_relu (Activation (None, 3, 3, 736)    0           conv5_block8_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block8_1_conv (Conv2D)    (None, 3, 3, 128)    94208       conv5_block8_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block8_1_bn (BatchNormali (None, 3, 3, 128)    512         conv5_block8_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block8_1_relu (Activation (None, 3, 3, 128)    0           conv5_block8_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block8_2_conv (Conv2D)    (None, 3, 3, 32)     36864       conv5_block8_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block8_concat (Concatenat (None, 3, 3, 768)    0           conv5_block7_concat[0][0]        \n","                                                                 conv5_block8_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block9_0_bn (BatchNormali (None, 3, 3, 768)    3072        conv5_block8_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block9_0_relu (Activation (None, 3, 3, 768)    0           conv5_block9_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block9_1_conv (Conv2D)    (None, 3, 3, 128)    98304       conv5_block9_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block9_1_bn (BatchNormali (None, 3, 3, 128)    512         conv5_block9_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block9_1_relu (Activation (None, 3, 3, 128)    0           conv5_block9_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block9_2_conv (Conv2D)    (None, 3, 3, 32)     36864       conv5_block9_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block9_concat (Concatenat (None, 3, 3, 800)    0           conv5_block8_concat[0][0]        \n","                                                                 conv5_block9_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block10_0_bn (BatchNormal (None, 3, 3, 800)    3200        conv5_block9_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block10_0_relu (Activatio (None, 3, 3, 800)    0           conv5_block10_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv5_block10_1_conv (Conv2D)   (None, 3, 3, 128)    102400      conv5_block10_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block10_1_bn (BatchNormal (None, 3, 3, 128)    512         conv5_block10_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block10_1_relu (Activatio (None, 3, 3, 128)    0           conv5_block10_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv5_block10_2_conv (Conv2D)   (None, 3, 3, 32)     36864       conv5_block10_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block10_concat (Concatena (None, 3, 3, 832)    0           conv5_block9_concat[0][0]        \n","                                                                 conv5_block10_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block11_0_bn (BatchNormal (None, 3, 3, 832)    3328        conv5_block10_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block11_0_relu (Activatio (None, 3, 3, 832)    0           conv5_block11_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv5_block11_1_conv (Conv2D)   (None, 3, 3, 128)    106496      conv5_block11_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block11_1_bn (BatchNormal (None, 3, 3, 128)    512         conv5_block11_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block11_1_relu (Activatio (None, 3, 3, 128)    0           conv5_block11_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv5_block11_2_conv (Conv2D)   (None, 3, 3, 32)     36864       conv5_block11_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block11_concat (Concatena (None, 3, 3, 864)    0           conv5_block10_concat[0][0]       \n","                                                                 conv5_block11_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block12_0_bn (BatchNormal (None, 3, 3, 864)    3456        conv5_block11_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block12_0_relu (Activatio (None, 3, 3, 864)    0           conv5_block12_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv5_block12_1_conv (Conv2D)   (None, 3, 3, 128)    110592      conv5_block12_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block12_1_bn (BatchNormal (None, 3, 3, 128)    512         conv5_block12_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block12_1_relu (Activatio (None, 3, 3, 128)    0           conv5_block12_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv5_block12_2_conv (Conv2D)   (None, 3, 3, 32)     36864       conv5_block12_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block12_concat (Concatena (None, 3, 3, 896)    0           conv5_block11_concat[0][0]       \n","                                                                 conv5_block12_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block13_0_bn (BatchNormal (None, 3, 3, 896)    3584        conv5_block12_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block13_0_relu (Activatio (None, 3, 3, 896)    0           conv5_block13_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv5_block13_1_conv (Conv2D)   (None, 3, 3, 128)    114688      conv5_block13_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block13_1_bn (BatchNormal (None, 3, 3, 128)    512         conv5_block13_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block13_1_relu (Activatio (None, 3, 3, 128)    0           conv5_block13_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv5_block13_2_conv (Conv2D)   (None, 3, 3, 32)     36864       conv5_block13_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block13_concat (Concatena (None, 3, 3, 928)    0           conv5_block12_concat[0][0]       \n","                                                                 conv5_block13_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block14_0_bn (BatchNormal (None, 3, 3, 928)    3712        conv5_block13_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block14_0_relu (Activatio (None, 3, 3, 928)    0           conv5_block14_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv5_block14_1_conv (Conv2D)   (None, 3, 3, 128)    118784      conv5_block14_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block14_1_bn (BatchNormal (None, 3, 3, 128)    512         conv5_block14_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block14_1_relu (Activatio (None, 3, 3, 128)    0           conv5_block14_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv5_block14_2_conv (Conv2D)   (None, 3, 3, 32)     36864       conv5_block14_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block14_concat (Concatena (None, 3, 3, 960)    0           conv5_block13_concat[0][0]       \n","                                                                 conv5_block14_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block15_0_bn (BatchNormal (None, 3, 3, 960)    3840        conv5_block14_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block15_0_relu (Activatio (None, 3, 3, 960)    0           conv5_block15_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv5_block15_1_conv (Conv2D)   (None, 3, 3, 128)    122880      conv5_block15_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block15_1_bn (BatchNormal (None, 3, 3, 128)    512         conv5_block15_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block15_1_relu (Activatio (None, 3, 3, 128)    0           conv5_block15_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv5_block15_2_conv (Conv2D)   (None, 3, 3, 32)     36864       conv5_block15_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block15_concat (Concatena (None, 3, 3, 992)    0           conv5_block14_concat[0][0]       \n","                                                                 conv5_block15_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block16_0_bn (BatchNormal (None, 3, 3, 992)    3968        conv5_block15_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block16_0_relu (Activatio (None, 3, 3, 992)    0           conv5_block16_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv5_block16_1_conv (Conv2D)   (None, 3, 3, 128)    126976      conv5_block16_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block16_1_bn (BatchNormal (None, 3, 3, 128)    512         conv5_block16_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block16_1_relu (Activatio (None, 3, 3, 128)    0           conv5_block16_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv5_block16_2_conv (Conv2D)   (None, 3, 3, 32)     36864       conv5_block16_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block16_concat (Concatena (None, 3, 3, 1024)   0           conv5_block15_concat[0][0]       \n","                                                                 conv5_block16_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","bn (BatchNormalization)         (None, 3, 3, 1024)   4096        conv5_block16_concat[0][0]       \n","__________________________________________________________________________________________________\n","relu (Activation)               (None, 3, 3, 1024)   0           bn[0][0]                         \n","==================================================================================================\n","Total params: 7,037,504\n","Trainable params: 1,093,504\n","Non-trainable params: 5,944,000\n","__________________________________________________________________________________________________\n","Model: \"DenseNet121_ADModel\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","tensor (InputLayer)          [(None, 100, 100, 3)]     0         \n","_________________________________________________________________\n","densenet121 (Functional)     (None, 3, 3, 1024)        7037504   \n","_________________________________________________________________\n","flatten_5 (Flatten)          (None, 9216)              0         \n","_________________________________________________________________\n","dropout_8 (Dropout)          (None, 9216)              0         \n","_________________________________________________________________\n","dense_10 (Dense)             (None, 128)               1179776   \n","_________________________________________________________________\n","batch_normalization_5 (Batch (None, 128)               512       \n","_________________________________________________________________\n","leaky_re_lu_5 (LeakyReLU)    (None, 128)               0         \n","_________________________________________________________________\n","dropout_9 (Dropout)          (None, 128)               0         \n","_________________________________________________________________\n","dense_11 (Dense)             (None, 4)                 516       \n","=================================================================\n","Total params: 8,218,308\n","Trainable params: 2,274,052\n","Non-trainable params: 5,944,256\n","_________________________________________________________________\n","Epoch 1/100\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py:543: UserWarning: Input dict contained keys ['id'] which did not match any model input. They will be ignored by the model.\n","  [n for n in tensors.keys() if n not in ref_input_names])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:432: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"],"name":"stderr"},{"output_type":"stream","text":["    137/Unknown - 94s 688ms/step - loss: 0.9150 - accuracy: 0.6490 - auc: 0.8835 - f1_score: 0.6304 - scaled_graph_loss: 0.0116\n","Epoch 00001: val_accuracy improved from -inf to 0.67450, saving model to /content/drive/My Drive/Projects/codes/DenseNet_NSL_model_checkpoints/densenet_nsl_weights_colab_tuning_new_95\n","137/137 [==============================] - 103s 749ms/step - loss: 0.9150 - accuracy: 0.6490 - auc: 0.8835 - f1_score: 0.6304 - scaled_graph_loss: 0.0116 - val_loss: 0.6845 - val_accuracy: 0.6745 - val_auc: 0.9137 - val_f1_score: 0.6421\n","Epoch 2/100\n","137/137 [==============================] - ETA: 0s - loss: 0.5472 - accuracy: 0.7501 - auc: 0.9447 - f1_score: 0.7405 - scaled_graph_loss: 0.0074\n","Epoch 00002: val_accuracy improved from 0.67450 to 0.75235, saving model to /content/drive/My Drive/Projects/codes/DenseNet_NSL_model_checkpoints/densenet_nsl_weights_colab_tuning_new_95\n","137/137 [==============================] - 99s 719ms/step - loss: 0.5472 - accuracy: 0.7501 - auc: 0.9447 - f1_score: 0.7405 - scaled_graph_loss: 0.0074 - val_loss: 0.5997 - val_accuracy: 0.7524 - val_auc: 0.9368 - val_f1_score: 0.7382\n","Epoch 3/100\n","137/137 [==============================] - ETA: 0s - loss: 0.4676 - accuracy: 0.7930 - auc: 0.9601 - f1_score: 0.7866 - scaled_graph_loss: 0.0074\n","Epoch 00003: val_accuracy improved from 0.75235 to 0.77952, saving model to /content/drive/My Drive/Projects/codes/DenseNet_NSL_model_checkpoints/densenet_nsl_weights_colab_tuning_new_95\n","137/137 [==============================] - 99s 719ms/step - loss: 0.4676 - accuracy: 0.7930 - auc: 0.9601 - f1_score: 0.7866 - scaled_graph_loss: 0.0074 - val_loss: 0.4906 - val_accuracy: 0.7795 - val_auc: 0.9559 - val_f1_score: 0.7797\n","Epoch 4/100\n","137/137 [==============================] - ETA: 0s - loss: 0.4022 - accuracy: 0.8260 - auc: 0.9707 - f1_score: 0.8246 - scaled_graph_loss: 0.0075\n","Epoch 00004: val_accuracy improved from 0.77952 to 0.84248, saving model to /content/drive/My Drive/Projects/codes/DenseNet_NSL_model_checkpoints/densenet_nsl_weights_colab_tuning_new_95\n","137/137 [==============================] - 99s 719ms/step - loss: 0.4022 - accuracy: 0.8260 - auc: 0.9707 - f1_score: 0.8246 - scaled_graph_loss: 0.0075 - val_loss: 0.3619 - val_accuracy: 0.8425 - val_auc: 0.9759 - val_f1_score: 0.8392\n","Epoch 5/100\n","137/137 [==============================] - ETA: 0s - loss: 0.3446 - accuracy: 0.8596 - auc: 0.9787 - f1_score: 0.8564 - scaled_graph_loss: 0.0074\n","Epoch 00005: val_accuracy improved from 0.84248 to 0.85763, saving model to /content/drive/My Drive/Projects/codes/DenseNet_NSL_model_checkpoints/densenet_nsl_weights_colab_tuning_new_95\n","137/137 [==============================] - 99s 719ms/step - loss: 0.3446 - accuracy: 0.8596 - auc: 0.9787 - f1_score: 0.8564 - scaled_graph_loss: 0.0074 - val_loss: 0.3392 - val_accuracy: 0.8576 - val_auc: 0.9788 - val_f1_score: 0.8557\n","Epoch 6/100\n","137/137 [==============================] - ETA: 0s - loss: 0.2790 - accuracy: 0.8891 - auc: 0.9860 - f1_score: 0.8877 - scaled_graph_loss: 0.0067\n","Epoch 00006: val_accuracy did not improve from 0.85763\n","137/137 [==============================] - 98s 714ms/step - loss: 0.2790 - accuracy: 0.8891 - auc: 0.9860 - f1_score: 0.8877 - scaled_graph_loss: 0.0067 - val_loss: 0.4133 - val_accuracy: 0.8252 - val_auc: 0.9690 - val_f1_score: 0.8246\n","Epoch 7/100\n","137/137 [==============================] - ETA: 0s - loss: 0.2437 - accuracy: 0.9063 - auc: 0.9893 - f1_score: 0.9059 - scaled_graph_loss: 0.0064\n","Epoch 00007: val_accuracy improved from 0.85763 to 0.92163, saving model to /content/drive/My Drive/Projects/codes/DenseNet_NSL_model_checkpoints/densenet_nsl_weights_colab_tuning_new_95\n","137/137 [==============================] - 98s 719ms/step - loss: 0.2437 - accuracy: 0.9063 - auc: 0.9893 - f1_score: 0.9059 - scaled_graph_loss: 0.0064 - val_loss: 0.2091 - val_accuracy: 0.9216 - val_auc: 0.9914 - val_f1_score: 0.9209\n","Epoch 8/100\n","137/137 [==============================] - ETA: 0s - loss: 0.1747 - accuracy: 0.9324 - auc: 0.9945 - f1_score: 0.9328 - scaled_graph_loss: 0.0053\n","Epoch 00008: val_accuracy did not improve from 0.92163\n","137/137 [==============================] - 98s 715ms/step - loss: 0.1747 - accuracy: 0.9324 - auc: 0.9945 - f1_score: 0.9328 - scaled_graph_loss: 0.0053 - val_loss: 0.3564 - val_accuracy: 0.8595 - val_auc: 0.9776 - val_f1_score: 0.8595\n","Epoch 9/100\n","137/137 [==============================] - ETA: 0s - loss: 0.1585 - accuracy: 0.9407 - auc: 0.9951 - f1_score: 0.9405 - scaled_graph_loss: 0.0051\n","Epoch 00009: val_accuracy did not improve from 0.92163\n","137/137 [==============================] - 98s 716ms/step - loss: 0.1585 - accuracy: 0.9407 - auc: 0.9951 - f1_score: 0.9405 - scaled_graph_loss: 0.0051 - val_loss: 0.4265 - val_accuracy: 0.8467 - val_auc: 0.9725 - val_f1_score: 0.8486\n","Epoch 10/100\n","137/137 [==============================] - ETA: 0s - loss: 0.1290 - accuracy: 0.9539 - auc: 0.9968 - f1_score: 0.9536 - scaled_graph_loss: 0.0044\n","Epoch 00010: val_accuracy improved from 0.92163 to 0.93469, saving model to /content/drive/My Drive/Projects/codes/DenseNet_NSL_model_checkpoints/densenet_nsl_weights_colab_tuning_new_95\n","137/137 [==============================] - 99s 720ms/step - loss: 0.1290 - accuracy: 0.9539 - auc: 0.9968 - f1_score: 0.9536 - scaled_graph_loss: 0.0044 - val_loss: 0.1842 - val_accuracy: 0.9347 - val_auc: 0.9926 - val_f1_score: 0.9355\n","Epoch 11/100\n","137/137 [==============================] - ETA: 0s - loss: 0.1188 - accuracy: 0.9576 - auc: 0.9971 - f1_score: 0.9573 - scaled_graph_loss: 0.0042\n","Epoch 00011: val_accuracy did not improve from 0.93469\n","137/137 [==============================] - 98s 716ms/step - loss: 0.1188 - accuracy: 0.9576 - auc: 0.9971 - f1_score: 0.9573 - scaled_graph_loss: 0.0042 - val_loss: 0.2557 - val_accuracy: 0.9107 - val_auc: 0.9864 - val_f1_score: 0.9112\n","Epoch 12/100\n","137/137 [==============================] - ETA: 0s - loss: 0.1004 - accuracy: 0.9664 - auc: 0.9976 - f1_score: 0.9667 - scaled_graph_loss: 0.0034\n","Epoch 00012: val_accuracy did not improve from 0.93469\n","137/137 [==============================] - 98s 715ms/step - loss: 0.1004 - accuracy: 0.9664 - auc: 0.9976 - f1_score: 0.9667 - scaled_graph_loss: 0.0034 - val_loss: 0.2188 - val_accuracy: 0.9211 - val_auc: 0.9908 - val_f1_score: 0.9212\n","Epoch 13/100\n","137/137 [==============================] - ETA: 0s - loss: 0.0646 - accuracy: 0.9787 - auc: 0.9991 - f1_score: 0.9783 - scaled_graph_loss: 0.0024\n","Epoch 00013: val_accuracy did not improve from 0.93469\n","137/137 [==============================] - 98s 715ms/step - loss: 0.0646 - accuracy: 0.9787 - auc: 0.9991 - f1_score: 0.9783 - scaled_graph_loss: 0.0024 - val_loss: 0.3227 - val_accuracy: 0.8992 - val_auc: 0.9817 - val_f1_score: 0.8986\n","Epoch 14/100\n","137/137 [==============================] - ETA: 0s - loss: 0.0802 - accuracy: 0.9709 - auc: 0.9986 - f1_score: 0.9705 - scaled_graph_loss: 0.0030\n","Epoch 00014: val_accuracy did not improve from 0.93469\n","137/137 [==============================] - 98s 715ms/step - loss: 0.0802 - accuracy: 0.9709 - auc: 0.9986 - f1_score: 0.9705 - scaled_graph_loss: 0.0030 - val_loss: 0.3865 - val_accuracy: 0.8767 - val_auc: 0.9771 - val_f1_score: 0.8760\n","Epoch 15/100\n","137/137 [==============================] - ETA: 0s - loss: 0.0691 - accuracy: 0.9755 - auc: 0.9989 - f1_score: 0.9755 - scaled_graph_loss: 0.0025\n","Epoch 00015: val_accuracy improved from 0.93469 to 0.96343, saving model to /content/drive/My Drive/Projects/codes/DenseNet_NSL_model_checkpoints/densenet_nsl_weights_colab_tuning_new_95\n","137/137 [==============================] - 99s 719ms/step - loss: 0.0691 - accuracy: 0.9755 - auc: 0.9989 - f1_score: 0.9755 - scaled_graph_loss: 0.0025 - val_loss: 0.1276 - val_accuracy: 0.9634 - val_auc: 0.9939 - val_f1_score: 0.9635\n","Epoch 00016: early stopping\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CiySckZVg8GJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606007975746,"user_tz":300,"elapsed":4347,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"263a6fc2-7a08-4f8a-b74d-b90196f44aea"},"source":["'''evalute the test model'''\n","graph_reg_model.evaluate(test_image_dataset)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["60/60 [==============================] - 3s 44ms/step - loss: 0.1276 - accuracy: 0.9634 - auc: 0.9939 - f1_score: 0.9635\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[0.1275724619626999,\n"," 0.9634273648262024,\n"," 0.9939191937446594,\n"," 0.9634959697723389]"]},"metadata":{"tags":[]},"execution_count":58}]},{"cell_type":"code","metadata":{"id":"n1Kudc3XErB-"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pkkMlFWfBTFZ"},"source":["## 4.4 DenseNet_NSL top 20 layers, middle 30 layers and bottom 20 laysers tuning\n","### val_acc: 0.9864, val_auc: 0.9978, val_f1_score: 0.9864"]},{"cell_type":"code","metadata":{"id":"QBK2r_qsg8IR"},"source":["'''redefine hyper params'''\n","params = AD_params()\n","params.max_seed_nbr=5\n","params.batch_size=64\n","params.image_channels =3\n","params.image_size =(100,100)\n","params.ad_base_model_input_shape=(100,100,3)\n","params.nsl_multiplier = 0.1\n","params.nsl_sum_over_axis = -1\n","params.train_tfr_path = f'{root_path}train_data.tfr'\n","\n","'''parse train_data.tfr to train image dataset with batch_size at 64'''\n","train_image_dataset = NSLDataFormat.parse_tfr_to_dataset(file_path_list=[params.train_tfr_path],\n","                                                         batch_size=params.batch_size,\n","                                                         max_neighbor_number=params.max_seed_nbr,\n","                                                         image_size=params.image_size,\n","                                                         image_channels=params.image_channels,\n","                                                         shuffle=True)\n","\n","'''load test data with batch_size at 64 '''\n","test_image_dataset = NSLDataFormat.generate_test_tfr_image_tensor(path_list=tfr_list_test, \n","                                                                  batch_size=params.batch_size, \n","                                                                  size=params.image_size,\n","                                                                  channels=params.image_channels,\n","                                                                  shuffle=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MGAmz0zgZkZZ"},"source":["'''define params'''\n","params.learning_rate=0.000005\n","params.restore_path='/content/drive/My Drive/Projects/codes/DenseNet_NSL_model_checkpoints/densenet_nsl_weights_colab_tuning_new_95'\n","params.checkpoint_path = '/content/drive/My Drive/Projects/codes/DenseNet_NSL_model_checkpoints/densenet_nsl_weights_colab_tuning_98'\n","params.early_stop_base_line=0.98\n","params.train_epoch=100\n","params.nsl_multiplier = 0.1\n","params.nsl_sum_over_axis = -1\n","params.nsl_distance_type = nsl.configs.DistanceType.COSINE\n","'''build a base model with selected trainable layer'''\n","admodel = ADModelBuilder(input_shape=params.ad_base_model_input_shape, base_model='densenet121').setup_DenseNet121(top_layers=20, middle_layers=[185, 215], bottom_layers=20).get_ADModel()\n","'''build NSL model on top of base model'''\n","graph_reg_config = nsl.configs.make_graph_reg_config(neighbor_prefix=params.neighbor_prefix,\n","                                                     neighbor_weight_suffix=params.neighbor_weight_suffix,\n","                                                     max_neighbors= params.max_seed_nbr,\n","                                                     multiplier= params.nsl_multiplier,\n","                                                     distance_type= params.nsl_distance_type,\n","                                                     sum_over_axis= params.nsl_sum_over_axis)\n","graph_reg_model = nsl.keras.GraphRegularization(admodel,graph_reg_config)\n","graph_reg_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=params.learning_rate, amsgrad=True), \n","                        loss=tf.losses.CategoricalCrossentropy(), \n","                        metrics=[\"accuracy\",\"AUC\", tfa.metrics.F1Score(num_classes=4, average=\"micro\", threshold = 0.5)])\n","'''restore the model from last training'''\n","graph_reg_model.load_weights(params.restore_path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"yeQw5zEUg8Cw","executionInfo":{"status":"ok","timestamp":1606257297231,"user_tz":300,"elapsed":14123,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"099c8d0e-9fbd-43e8-cabf-34f93aa2c11b"},"source":["''' NSL model training '''\n","callback_checkpoints = tf.keras.callbacks.ModelCheckpoint(filepath=params.checkpoint_path, monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=True, mode='max',\n","                                                          save_freq='epoch',options=None)\n","callback_earlystop = AccEarlyStop(val_acc_base=params.early_stop_base_line)\n","graph_reg_history = graph_reg_model.fit(train_image_dataset, \n","                                        validation_data=test_image_dataset,\n","                                        callbacks = [callback_checkpoints, callback_earlystop],\n","                                        epochs=params.train_epoch,\n","                                        verbose=1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Note: default DenseNet121 not includes top and has imagenet weights. It is not a trainable model in ADModelBuilder. Please setup trainable layers in setup_DenseNet121 function based on the \"Layer Number\"\n","Model: \"densenet121\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_3 (InputLayer)            [(None, 100, 100, 3) 0                                            \n","__________________________________________________________________________________________________\n","zero_padding2d_2 (ZeroPadding2D (None, 106, 106, 3)  0           input_3[0][0]                    \n","__________________________________________________________________________________________________\n","conv1/conv (Conv2D)             (None, 50, 50, 64)   9408        zero_padding2d_2[0][0]           \n","__________________________________________________________________________________________________\n","conv1/bn (BatchNormalization)   (None, 50, 50, 64)   256         conv1/conv[0][0]                 \n","__________________________________________________________________________________________________\n","conv1/relu (Activation)         (None, 50, 50, 64)   0           conv1/bn[0][0]                   \n","__________________________________________________________________________________________________\n","zero_padding2d_3 (ZeroPadding2D (None, 52, 52, 64)   0           conv1/relu[0][0]                 \n","__________________________________________________________________________________________________\n","pool1 (MaxPooling2D)            (None, 25, 25, 64)   0           zero_padding2d_3[0][0]           \n","__________________________________________________________________________________________________\n","conv2_block1_0_bn (BatchNormali (None, 25, 25, 64)   256         pool1[0][0]                      \n","__________________________________________________________________________________________________\n","conv2_block1_0_relu (Activation (None, 25, 25, 64)   0           conv2_block1_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block1_1_conv (Conv2D)    (None, 25, 25, 128)  8192        conv2_block1_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_1_bn (BatchNormali (None, 25, 25, 128)  512         conv2_block1_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_1_relu (Activation (None, 25, 25, 128)  0           conv2_block1_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block1_2_conv (Conv2D)    (None, 25, 25, 32)   36864       conv2_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_concat (Concatenat (None, 25, 25, 96)   0           pool1[0][0]                      \n","                                                                 conv2_block1_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_0_bn (BatchNormali (None, 25, 25, 96)   384         conv2_block1_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_0_relu (Activation (None, 25, 25, 96)   0           conv2_block2_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block2_1_conv (Conv2D)    (None, 25, 25, 128)  12288       conv2_block2_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_1_bn (BatchNormali (None, 25, 25, 128)  512         conv2_block2_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_1_relu (Activation (None, 25, 25, 128)  0           conv2_block2_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block2_2_conv (Conv2D)    (None, 25, 25, 32)   36864       conv2_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_concat (Concatenat (None, 25, 25, 128)  0           conv2_block1_concat[0][0]        \n","                                                                 conv2_block2_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_0_bn (BatchNormali (None, 25, 25, 128)  512         conv2_block2_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_0_relu (Activation (None, 25, 25, 128)  0           conv2_block3_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block3_1_conv (Conv2D)    (None, 25, 25, 128)  16384       conv2_block3_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_1_bn (BatchNormali (None, 25, 25, 128)  512         conv2_block3_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_1_relu (Activation (None, 25, 25, 128)  0           conv2_block3_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block3_2_conv (Conv2D)    (None, 25, 25, 32)   36864       conv2_block3_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_concat (Concatenat (None, 25, 25, 160)  0           conv2_block2_concat[0][0]        \n","                                                                 conv2_block3_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block4_0_bn (BatchNormali (None, 25, 25, 160)  640         conv2_block3_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block4_0_relu (Activation (None, 25, 25, 160)  0           conv2_block4_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block4_1_conv (Conv2D)    (None, 25, 25, 128)  20480       conv2_block4_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block4_1_bn (BatchNormali (None, 25, 25, 128)  512         conv2_block4_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block4_1_relu (Activation (None, 25, 25, 128)  0           conv2_block4_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block4_2_conv (Conv2D)    (None, 25, 25, 32)   36864       conv2_block4_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block4_concat (Concatenat (None, 25, 25, 192)  0           conv2_block3_concat[0][0]        \n","                                                                 conv2_block4_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block5_0_bn (BatchNormali (None, 25, 25, 192)  768         conv2_block4_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block5_0_relu (Activation (None, 25, 25, 192)  0           conv2_block5_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block5_1_conv (Conv2D)    (None, 25, 25, 128)  24576       conv2_block5_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block5_1_bn (BatchNormali (None, 25, 25, 128)  512         conv2_block5_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block5_1_relu (Activation (None, 25, 25, 128)  0           conv2_block5_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block5_2_conv (Conv2D)    (None, 25, 25, 32)   36864       conv2_block5_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block5_concat (Concatenat (None, 25, 25, 224)  0           conv2_block4_concat[0][0]        \n","                                                                 conv2_block5_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block6_0_bn (BatchNormali (None, 25, 25, 224)  896         conv2_block5_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block6_0_relu (Activation (None, 25, 25, 224)  0           conv2_block6_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block6_1_conv (Conv2D)    (None, 25, 25, 128)  28672       conv2_block6_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block6_1_bn (BatchNormali (None, 25, 25, 128)  512         conv2_block6_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block6_1_relu (Activation (None, 25, 25, 128)  0           conv2_block6_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block6_2_conv (Conv2D)    (None, 25, 25, 32)   36864       conv2_block6_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block6_concat (Concatenat (None, 25, 25, 256)  0           conv2_block5_concat[0][0]        \n","                                                                 conv2_block6_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","pool2_bn (BatchNormalization)   (None, 25, 25, 256)  1024        conv2_block6_concat[0][0]        \n","__________________________________________________________________________________________________\n","pool2_relu (Activation)         (None, 25, 25, 256)  0           pool2_bn[0][0]                   \n","__________________________________________________________________________________________________\n","pool2_conv (Conv2D)             (None, 25, 25, 128)  32768       pool2_relu[0][0]                 \n","__________________________________________________________________________________________________\n","pool2_pool (AveragePooling2D)   (None, 12, 12, 128)  0           pool2_conv[0][0]                 \n","__________________________________________________________________________________________________\n","conv3_block1_0_bn (BatchNormali (None, 12, 12, 128)  512         pool2_pool[0][0]                 \n","__________________________________________________________________________________________________\n","conv3_block1_0_relu (Activation (None, 12, 12, 128)  0           conv3_block1_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block1_1_conv (Conv2D)    (None, 12, 12, 128)  16384       conv3_block1_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_1_bn (BatchNormali (None, 12, 12, 128)  512         conv3_block1_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_1_relu (Activation (None, 12, 12, 128)  0           conv3_block1_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block1_2_conv (Conv2D)    (None, 12, 12, 32)   36864       conv3_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_concat (Concatenat (None, 12, 12, 160)  0           pool2_pool[0][0]                 \n","                                                                 conv3_block1_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_0_bn (BatchNormali (None, 12, 12, 160)  640         conv3_block1_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_0_relu (Activation (None, 12, 12, 160)  0           conv3_block2_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block2_1_conv (Conv2D)    (None, 12, 12, 128)  20480       conv3_block2_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_1_bn (BatchNormali (None, 12, 12, 128)  512         conv3_block2_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_1_relu (Activation (None, 12, 12, 128)  0           conv3_block2_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block2_2_conv (Conv2D)    (None, 12, 12, 32)   36864       conv3_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_concat (Concatenat (None, 12, 12, 192)  0           conv3_block1_concat[0][0]        \n","                                                                 conv3_block2_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_0_bn (BatchNormali (None, 12, 12, 192)  768         conv3_block2_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_0_relu (Activation (None, 12, 12, 192)  0           conv3_block3_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block3_1_conv (Conv2D)    (None, 12, 12, 128)  24576       conv3_block3_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_1_bn (BatchNormali (None, 12, 12, 128)  512         conv3_block3_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_1_relu (Activation (None, 12, 12, 128)  0           conv3_block3_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block3_2_conv (Conv2D)    (None, 12, 12, 32)   36864       conv3_block3_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_concat (Concatenat (None, 12, 12, 224)  0           conv3_block2_concat[0][0]        \n","                                                                 conv3_block3_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_0_bn (BatchNormali (None, 12, 12, 224)  896         conv3_block3_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_0_relu (Activation (None, 12, 12, 224)  0           conv3_block4_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block4_1_conv (Conv2D)    (None, 12, 12, 128)  28672       conv3_block4_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_1_bn (BatchNormali (None, 12, 12, 128)  512         conv3_block4_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_1_relu (Activation (None, 12, 12, 128)  0           conv3_block4_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block4_2_conv (Conv2D)    (None, 12, 12, 32)   36864       conv3_block4_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_concat (Concatenat (None, 12, 12, 256)  0           conv3_block3_concat[0][0]        \n","                                                                 conv3_block4_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block5_0_bn (BatchNormali (None, 12, 12, 256)  1024        conv3_block4_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block5_0_relu (Activation (None, 12, 12, 256)  0           conv3_block5_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block5_1_conv (Conv2D)    (None, 12, 12, 128)  32768       conv3_block5_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block5_1_bn (BatchNormali (None, 12, 12, 128)  512         conv3_block5_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block5_1_relu (Activation (None, 12, 12, 128)  0           conv3_block5_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block5_2_conv (Conv2D)    (None, 12, 12, 32)   36864       conv3_block5_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block5_concat (Concatenat (None, 12, 12, 288)  0           conv3_block4_concat[0][0]        \n","                                                                 conv3_block5_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block6_0_bn (BatchNormali (None, 12, 12, 288)  1152        conv3_block5_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block6_0_relu (Activation (None, 12, 12, 288)  0           conv3_block6_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block6_1_conv (Conv2D)    (None, 12, 12, 128)  36864       conv3_block6_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block6_1_bn (BatchNormali (None, 12, 12, 128)  512         conv3_block6_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block6_1_relu (Activation (None, 12, 12, 128)  0           conv3_block6_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block6_2_conv (Conv2D)    (None, 12, 12, 32)   36864       conv3_block6_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block6_concat (Concatenat (None, 12, 12, 320)  0           conv3_block5_concat[0][0]        \n","                                                                 conv3_block6_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block7_0_bn (BatchNormali (None, 12, 12, 320)  1280        conv3_block6_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block7_0_relu (Activation (None, 12, 12, 320)  0           conv3_block7_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block7_1_conv (Conv2D)    (None, 12, 12, 128)  40960       conv3_block7_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block7_1_bn (BatchNormali (None, 12, 12, 128)  512         conv3_block7_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block7_1_relu (Activation (None, 12, 12, 128)  0           conv3_block7_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block7_2_conv (Conv2D)    (None, 12, 12, 32)   36864       conv3_block7_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block7_concat (Concatenat (None, 12, 12, 352)  0           conv3_block6_concat[0][0]        \n","                                                                 conv3_block7_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block8_0_bn (BatchNormali (None, 12, 12, 352)  1408        conv3_block7_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block8_0_relu (Activation (None, 12, 12, 352)  0           conv3_block8_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block8_1_conv (Conv2D)    (None, 12, 12, 128)  45056       conv3_block8_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block8_1_bn (BatchNormali (None, 12, 12, 128)  512         conv3_block8_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block8_1_relu (Activation (None, 12, 12, 128)  0           conv3_block8_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block8_2_conv (Conv2D)    (None, 12, 12, 32)   36864       conv3_block8_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block8_concat (Concatenat (None, 12, 12, 384)  0           conv3_block7_concat[0][0]        \n","                                                                 conv3_block8_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block9_0_bn (BatchNormali (None, 12, 12, 384)  1536        conv3_block8_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block9_0_relu (Activation (None, 12, 12, 384)  0           conv3_block9_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block9_1_conv (Conv2D)    (None, 12, 12, 128)  49152       conv3_block9_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block9_1_bn (BatchNormali (None, 12, 12, 128)  512         conv3_block9_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block9_1_relu (Activation (None, 12, 12, 128)  0           conv3_block9_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block9_2_conv (Conv2D)    (None, 12, 12, 32)   36864       conv3_block9_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block9_concat (Concatenat (None, 12, 12, 416)  0           conv3_block8_concat[0][0]        \n","                                                                 conv3_block9_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block10_0_bn (BatchNormal (None, 12, 12, 416)  1664        conv3_block9_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block10_0_relu (Activatio (None, 12, 12, 416)  0           conv3_block10_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv3_block10_1_conv (Conv2D)   (None, 12, 12, 128)  53248       conv3_block10_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv3_block10_1_bn (BatchNormal (None, 12, 12, 128)  512         conv3_block10_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv3_block10_1_relu (Activatio (None, 12, 12, 128)  0           conv3_block10_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv3_block10_2_conv (Conv2D)   (None, 12, 12, 32)   36864       conv3_block10_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv3_block10_concat (Concatena (None, 12, 12, 448)  0           conv3_block9_concat[0][0]        \n","                                                                 conv3_block10_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv3_block11_0_bn (BatchNormal (None, 12, 12, 448)  1792        conv3_block10_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv3_block11_0_relu (Activatio (None, 12, 12, 448)  0           conv3_block11_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv3_block11_1_conv (Conv2D)   (None, 12, 12, 128)  57344       conv3_block11_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv3_block11_1_bn (BatchNormal (None, 12, 12, 128)  512         conv3_block11_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv3_block11_1_relu (Activatio (None, 12, 12, 128)  0           conv3_block11_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv3_block11_2_conv (Conv2D)   (None, 12, 12, 32)   36864       conv3_block11_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv3_block11_concat (Concatena (None, 12, 12, 480)  0           conv3_block10_concat[0][0]       \n","                                                                 conv3_block11_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv3_block12_0_bn (BatchNormal (None, 12, 12, 480)  1920        conv3_block11_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv3_block12_0_relu (Activatio (None, 12, 12, 480)  0           conv3_block12_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv3_block12_1_conv (Conv2D)   (None, 12, 12, 128)  61440       conv3_block12_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv3_block12_1_bn (BatchNormal (None, 12, 12, 128)  512         conv3_block12_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv3_block12_1_relu (Activatio (None, 12, 12, 128)  0           conv3_block12_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv3_block12_2_conv (Conv2D)   (None, 12, 12, 32)   36864       conv3_block12_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv3_block12_concat (Concatena (None, 12, 12, 512)  0           conv3_block11_concat[0][0]       \n","                                                                 conv3_block12_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","pool3_bn (BatchNormalization)   (None, 12, 12, 512)  2048        conv3_block12_concat[0][0]       \n","__________________________________________________________________________________________________\n","pool3_relu (Activation)         (None, 12, 12, 512)  0           pool3_bn[0][0]                   \n","__________________________________________________________________________________________________\n","pool3_conv (Conv2D)             (None, 12, 12, 256)  131072      pool3_relu[0][0]                 \n","__________________________________________________________________________________________________\n","pool3_pool (AveragePooling2D)   (None, 6, 6, 256)    0           pool3_conv[0][0]                 \n","__________________________________________________________________________________________________\n","conv4_block1_0_bn (BatchNormali (None, 6, 6, 256)    1024        pool3_pool[0][0]                 \n","__________________________________________________________________________________________________\n","conv4_block1_0_relu (Activation (None, 6, 6, 256)    0           conv4_block1_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block1_1_conv (Conv2D)    (None, 6, 6, 128)    32768       conv4_block1_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_1_bn (BatchNormali (None, 6, 6, 128)    512         conv4_block1_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_1_relu (Activation (None, 6, 6, 128)    0           conv4_block1_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block1_2_conv (Conv2D)    (None, 6, 6, 32)     36864       conv4_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_concat (Concatenat (None, 6, 6, 288)    0           pool3_pool[0][0]                 \n","                                                                 conv4_block1_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_0_bn (BatchNormali (None, 6, 6, 288)    1152        conv4_block1_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_0_relu (Activation (None, 6, 6, 288)    0           conv4_block2_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block2_1_conv (Conv2D)    (None, 6, 6, 128)    36864       conv4_block2_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_1_bn (BatchNormali (None, 6, 6, 128)    512         conv4_block2_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_1_relu (Activation (None, 6, 6, 128)    0           conv4_block2_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block2_2_conv (Conv2D)    (None, 6, 6, 32)     36864       conv4_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_concat (Concatenat (None, 6, 6, 320)    0           conv4_block1_concat[0][0]        \n","                                                                 conv4_block2_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_0_bn (BatchNormali (None, 6, 6, 320)    1280        conv4_block2_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_0_relu (Activation (None, 6, 6, 320)    0           conv4_block3_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block3_1_conv (Conv2D)    (None, 6, 6, 128)    40960       conv4_block3_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_1_bn (BatchNormali (None, 6, 6, 128)    512         conv4_block3_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_1_relu (Activation (None, 6, 6, 128)    0           conv4_block3_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block3_2_conv (Conv2D)    (None, 6, 6, 32)     36864       conv4_block3_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_concat (Concatenat (None, 6, 6, 352)    0           conv4_block2_concat[0][0]        \n","                                                                 conv4_block3_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_0_bn (BatchNormali (None, 6, 6, 352)    1408        conv4_block3_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_0_relu (Activation (None, 6, 6, 352)    0           conv4_block4_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block4_1_conv (Conv2D)    (None, 6, 6, 128)    45056       conv4_block4_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_1_bn (BatchNormali (None, 6, 6, 128)    512         conv4_block4_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_1_relu (Activation (None, 6, 6, 128)    0           conv4_block4_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block4_2_conv (Conv2D)    (None, 6, 6, 32)     36864       conv4_block4_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_concat (Concatenat (None, 6, 6, 384)    0           conv4_block3_concat[0][0]        \n","                                                                 conv4_block4_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_0_bn (BatchNormali (None, 6, 6, 384)    1536        conv4_block4_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_0_relu (Activation (None, 6, 6, 384)    0           conv4_block5_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block5_1_conv (Conv2D)    (None, 6, 6, 128)    49152       conv4_block5_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_1_bn (BatchNormali (None, 6, 6, 128)    512         conv4_block5_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_1_relu (Activation (None, 6, 6, 128)    0           conv4_block5_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block5_2_conv (Conv2D)    (None, 6, 6, 32)     36864       conv4_block5_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_concat (Concatenat (None, 6, 6, 416)    0           conv4_block4_concat[0][0]        \n","                                                                 conv4_block5_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_0_bn (BatchNormali (None, 6, 6, 416)    1664        conv4_block5_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_0_relu (Activation (None, 6, 6, 416)    0           conv4_block6_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block6_1_conv (Conv2D)    (None, 6, 6, 128)    53248       conv4_block6_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_1_bn (BatchNormali (None, 6, 6, 128)    512         conv4_block6_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_1_relu (Activation (None, 6, 6, 128)    0           conv4_block6_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block6_2_conv (Conv2D)    (None, 6, 6, 32)     36864       conv4_block6_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_concat (Concatenat (None, 6, 6, 448)    0           conv4_block5_concat[0][0]        \n","                                                                 conv4_block6_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block7_0_bn (BatchNormali (None, 6, 6, 448)    1792        conv4_block6_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block7_0_relu (Activation (None, 6, 6, 448)    0           conv4_block7_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block7_1_conv (Conv2D)    (None, 6, 6, 128)    57344       conv4_block7_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block7_1_bn (BatchNormali (None, 6, 6, 128)    512         conv4_block7_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block7_1_relu (Activation (None, 6, 6, 128)    0           conv4_block7_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block7_2_conv (Conv2D)    (None, 6, 6, 32)     36864       conv4_block7_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block7_concat (Concatenat (None, 6, 6, 480)    0           conv4_block6_concat[0][0]        \n","                                                                 conv4_block7_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block8_0_bn (BatchNormali (None, 6, 6, 480)    1920        conv4_block7_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block8_0_relu (Activation (None, 6, 6, 480)    0           conv4_block8_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block8_1_conv (Conv2D)    (None, 6, 6, 128)    61440       conv4_block8_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block8_1_bn (BatchNormali (None, 6, 6, 128)    512         conv4_block8_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block8_1_relu (Activation (None, 6, 6, 128)    0           conv4_block8_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block8_2_conv (Conv2D)    (None, 6, 6, 32)     36864       conv4_block8_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block8_concat (Concatenat (None, 6, 6, 512)    0           conv4_block7_concat[0][0]        \n","                                                                 conv4_block8_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block9_0_bn (BatchNormali (None, 6, 6, 512)    2048        conv4_block8_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block9_0_relu (Activation (None, 6, 6, 512)    0           conv4_block9_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block9_1_conv (Conv2D)    (None, 6, 6, 128)    65536       conv4_block9_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block9_1_bn (BatchNormali (None, 6, 6, 128)    512         conv4_block9_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block9_1_relu (Activation (None, 6, 6, 128)    0           conv4_block9_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block9_2_conv (Conv2D)    (None, 6, 6, 32)     36864       conv4_block9_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block9_concat (Concatenat (None, 6, 6, 544)    0           conv4_block8_concat[0][0]        \n","                                                                 conv4_block9_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block10_0_bn (BatchNormal (None, 6, 6, 544)    2176        conv4_block9_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block10_0_relu (Activatio (None, 6, 6, 544)    0           conv4_block10_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block10_1_conv (Conv2D)   (None, 6, 6, 128)    69632       conv4_block10_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block10_1_bn (BatchNormal (None, 6, 6, 128)    512         conv4_block10_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block10_1_relu (Activatio (None, 6, 6, 128)    0           conv4_block10_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block10_2_conv (Conv2D)   (None, 6, 6, 32)     36864       conv4_block10_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block10_concat (Concatena (None, 6, 6, 576)    0           conv4_block9_concat[0][0]        \n","                                                                 conv4_block10_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block11_0_bn (BatchNormal (None, 6, 6, 576)    2304        conv4_block10_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block11_0_relu (Activatio (None, 6, 6, 576)    0           conv4_block11_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block11_1_conv (Conv2D)   (None, 6, 6, 128)    73728       conv4_block11_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block11_1_bn (BatchNormal (None, 6, 6, 128)    512         conv4_block11_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block11_1_relu (Activatio (None, 6, 6, 128)    0           conv4_block11_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block11_2_conv (Conv2D)   (None, 6, 6, 32)     36864       conv4_block11_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block11_concat (Concatena (None, 6, 6, 608)    0           conv4_block10_concat[0][0]       \n","                                                                 conv4_block11_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block12_0_bn (BatchNormal (None, 6, 6, 608)    2432        conv4_block11_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block12_0_relu (Activatio (None, 6, 6, 608)    0           conv4_block12_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block12_1_conv (Conv2D)   (None, 6, 6, 128)    77824       conv4_block12_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block12_1_bn (BatchNormal (None, 6, 6, 128)    512         conv4_block12_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block12_1_relu (Activatio (None, 6, 6, 128)    0           conv4_block12_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block12_2_conv (Conv2D)   (None, 6, 6, 32)     36864       conv4_block12_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block12_concat (Concatena (None, 6, 6, 640)    0           conv4_block11_concat[0][0]       \n","                                                                 conv4_block12_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block13_0_bn (BatchNormal (None, 6, 6, 640)    2560        conv4_block12_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block13_0_relu (Activatio (None, 6, 6, 640)    0           conv4_block13_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block13_1_conv (Conv2D)   (None, 6, 6, 128)    81920       conv4_block13_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block13_1_bn (BatchNormal (None, 6, 6, 128)    512         conv4_block13_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block13_1_relu (Activatio (None, 6, 6, 128)    0           conv4_block13_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block13_2_conv (Conv2D)   (None, 6, 6, 32)     36864       conv4_block13_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block13_concat (Concatena (None, 6, 6, 672)    0           conv4_block12_concat[0][0]       \n","                                                                 conv4_block13_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block14_0_bn (BatchNormal (None, 6, 6, 672)    2688        conv4_block13_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block14_0_relu (Activatio (None, 6, 6, 672)    0           conv4_block14_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block14_1_conv (Conv2D)   (None, 6, 6, 128)    86016       conv4_block14_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block14_1_bn (BatchNormal (None, 6, 6, 128)    512         conv4_block14_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block14_1_relu (Activatio (None, 6, 6, 128)    0           conv4_block14_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block14_2_conv (Conv2D)   (None, 6, 6, 32)     36864       conv4_block14_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block14_concat (Concatena (None, 6, 6, 704)    0           conv4_block13_concat[0][0]       \n","                                                                 conv4_block14_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block15_0_bn (BatchNormal (None, 6, 6, 704)    2816        conv4_block14_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block15_0_relu (Activatio (None, 6, 6, 704)    0           conv4_block15_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block15_1_conv (Conv2D)   (None, 6, 6, 128)    90112       conv4_block15_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block15_1_bn (BatchNormal (None, 6, 6, 128)    512         conv4_block15_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block15_1_relu (Activatio (None, 6, 6, 128)    0           conv4_block15_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block15_2_conv (Conv2D)   (None, 6, 6, 32)     36864       conv4_block15_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block15_concat (Concatena (None, 6, 6, 736)    0           conv4_block14_concat[0][0]       \n","                                                                 conv4_block15_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block16_0_bn (BatchNormal (None, 6, 6, 736)    2944        conv4_block15_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block16_0_relu (Activatio (None, 6, 6, 736)    0           conv4_block16_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block16_1_conv (Conv2D)   (None, 6, 6, 128)    94208       conv4_block16_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block16_1_bn (BatchNormal (None, 6, 6, 128)    512         conv4_block16_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block16_1_relu (Activatio (None, 6, 6, 128)    0           conv4_block16_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block16_2_conv (Conv2D)   (None, 6, 6, 32)     36864       conv4_block16_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block16_concat (Concatena (None, 6, 6, 768)    0           conv4_block15_concat[0][0]       \n","                                                                 conv4_block16_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block17_0_bn (BatchNormal (None, 6, 6, 768)    3072        conv4_block16_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block17_0_relu (Activatio (None, 6, 6, 768)    0           conv4_block17_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block17_1_conv (Conv2D)   (None, 6, 6, 128)    98304       conv4_block17_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block17_1_bn (BatchNormal (None, 6, 6, 128)    512         conv4_block17_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block17_1_relu (Activatio (None, 6, 6, 128)    0           conv4_block17_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block17_2_conv (Conv2D)   (None, 6, 6, 32)     36864       conv4_block17_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block17_concat (Concatena (None, 6, 6, 800)    0           conv4_block16_concat[0][0]       \n","                                                                 conv4_block17_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block18_0_bn (BatchNormal (None, 6, 6, 800)    3200        conv4_block17_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block18_0_relu (Activatio (None, 6, 6, 800)    0           conv4_block18_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block18_1_conv (Conv2D)   (None, 6, 6, 128)    102400      conv4_block18_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block18_1_bn (BatchNormal (None, 6, 6, 128)    512         conv4_block18_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block18_1_relu (Activatio (None, 6, 6, 128)    0           conv4_block18_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block18_2_conv (Conv2D)   (None, 6, 6, 32)     36864       conv4_block18_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block18_concat (Concatena (None, 6, 6, 832)    0           conv4_block17_concat[0][0]       \n","                                                                 conv4_block18_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block19_0_bn (BatchNormal (None, 6, 6, 832)    3328        conv4_block18_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block19_0_relu (Activatio (None, 6, 6, 832)    0           conv4_block19_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block19_1_conv (Conv2D)   (None, 6, 6, 128)    106496      conv4_block19_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block19_1_bn (BatchNormal (None, 6, 6, 128)    512         conv4_block19_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block19_1_relu (Activatio (None, 6, 6, 128)    0           conv4_block19_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block19_2_conv (Conv2D)   (None, 6, 6, 32)     36864       conv4_block19_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block19_concat (Concatena (None, 6, 6, 864)    0           conv4_block18_concat[0][0]       \n","                                                                 conv4_block19_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block20_0_bn (BatchNormal (None, 6, 6, 864)    3456        conv4_block19_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block20_0_relu (Activatio (None, 6, 6, 864)    0           conv4_block20_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block20_1_conv (Conv2D)   (None, 6, 6, 128)    110592      conv4_block20_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block20_1_bn (BatchNormal (None, 6, 6, 128)    512         conv4_block20_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block20_1_relu (Activatio (None, 6, 6, 128)    0           conv4_block20_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block20_2_conv (Conv2D)   (None, 6, 6, 32)     36864       conv4_block20_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block20_concat (Concatena (None, 6, 6, 896)    0           conv4_block19_concat[0][0]       \n","                                                                 conv4_block20_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block21_0_bn (BatchNormal (None, 6, 6, 896)    3584        conv4_block20_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block21_0_relu (Activatio (None, 6, 6, 896)    0           conv4_block21_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block21_1_conv (Conv2D)   (None, 6, 6, 128)    114688      conv4_block21_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block21_1_bn (BatchNormal (None, 6, 6, 128)    512         conv4_block21_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block21_1_relu (Activatio (None, 6, 6, 128)    0           conv4_block21_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block21_2_conv (Conv2D)   (None, 6, 6, 32)     36864       conv4_block21_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block21_concat (Concatena (None, 6, 6, 928)    0           conv4_block20_concat[0][0]       \n","                                                                 conv4_block21_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block22_0_bn (BatchNormal (None, 6, 6, 928)    3712        conv4_block21_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block22_0_relu (Activatio (None, 6, 6, 928)    0           conv4_block22_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block22_1_conv (Conv2D)   (None, 6, 6, 128)    118784      conv4_block22_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block22_1_bn (BatchNormal (None, 6, 6, 128)    512         conv4_block22_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block22_1_relu (Activatio (None, 6, 6, 128)    0           conv4_block22_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block22_2_conv (Conv2D)   (None, 6, 6, 32)     36864       conv4_block22_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block22_concat (Concatena (None, 6, 6, 960)    0           conv4_block21_concat[0][0]       \n","                                                                 conv4_block22_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block23_0_bn (BatchNormal (None, 6, 6, 960)    3840        conv4_block22_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block23_0_relu (Activatio (None, 6, 6, 960)    0           conv4_block23_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block23_1_conv (Conv2D)   (None, 6, 6, 128)    122880      conv4_block23_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block23_1_bn (BatchNormal (None, 6, 6, 128)    512         conv4_block23_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block23_1_relu (Activatio (None, 6, 6, 128)    0           conv4_block23_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block23_2_conv (Conv2D)   (None, 6, 6, 32)     36864       conv4_block23_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block23_concat (Concatena (None, 6, 6, 992)    0           conv4_block22_concat[0][0]       \n","                                                                 conv4_block23_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block24_0_bn (BatchNormal (None, 6, 6, 992)    3968        conv4_block23_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block24_0_relu (Activatio (None, 6, 6, 992)    0           conv4_block24_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block24_1_conv (Conv2D)   (None, 6, 6, 128)    126976      conv4_block24_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block24_1_bn (BatchNormal (None, 6, 6, 128)    512         conv4_block24_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block24_1_relu (Activatio (None, 6, 6, 128)    0           conv4_block24_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block24_2_conv (Conv2D)   (None, 6, 6, 32)     36864       conv4_block24_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block24_concat (Concatena (None, 6, 6, 1024)   0           conv4_block23_concat[0][0]       \n","                                                                 conv4_block24_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","pool4_bn (BatchNormalization)   (None, 6, 6, 1024)   4096        conv4_block24_concat[0][0]       \n","__________________________________________________________________________________________________\n","pool4_relu (Activation)         (None, 6, 6, 1024)   0           pool4_bn[0][0]                   \n","__________________________________________________________________________________________________\n","pool4_conv (Conv2D)             (None, 6, 6, 512)    524288      pool4_relu[0][0]                 \n","__________________________________________________________________________________________________\n","pool4_pool (AveragePooling2D)   (None, 3, 3, 512)    0           pool4_conv[0][0]                 \n","__________________________________________________________________________________________________\n","conv5_block1_0_bn (BatchNormali (None, 3, 3, 512)    2048        pool4_pool[0][0]                 \n","__________________________________________________________________________________________________\n","conv5_block1_0_relu (Activation (None, 3, 3, 512)    0           conv5_block1_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block1_1_conv (Conv2D)    (None, 3, 3, 128)    65536       conv5_block1_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block1_1_bn (BatchNormali (None, 3, 3, 128)    512         conv5_block1_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block1_1_relu (Activation (None, 3, 3, 128)    0           conv5_block1_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block1_2_conv (Conv2D)    (None, 3, 3, 32)     36864       conv5_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block1_concat (Concatenat (None, 3, 3, 544)    0           pool4_pool[0][0]                 \n","                                                                 conv5_block1_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block2_0_bn (BatchNormali (None, 3, 3, 544)    2176        conv5_block1_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block2_0_relu (Activation (None, 3, 3, 544)    0           conv5_block2_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block2_1_conv (Conv2D)    (None, 3, 3, 128)    69632       conv5_block2_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block2_1_bn (BatchNormali (None, 3, 3, 128)    512         conv5_block2_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block2_1_relu (Activation (None, 3, 3, 128)    0           conv5_block2_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block2_2_conv (Conv2D)    (None, 3, 3, 32)     36864       conv5_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block2_concat (Concatenat (None, 3, 3, 576)    0           conv5_block1_concat[0][0]        \n","                                                                 conv5_block2_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block3_0_bn (BatchNormali (None, 3, 3, 576)    2304        conv5_block2_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block3_0_relu (Activation (None, 3, 3, 576)    0           conv5_block3_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block3_1_conv (Conv2D)    (None, 3, 3, 128)    73728       conv5_block3_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block3_1_bn (BatchNormali (None, 3, 3, 128)    512         conv5_block3_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block3_1_relu (Activation (None, 3, 3, 128)    0           conv5_block3_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block3_2_conv (Conv2D)    (None, 3, 3, 32)     36864       conv5_block3_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block3_concat (Concatenat (None, 3, 3, 608)    0           conv5_block2_concat[0][0]        \n","                                                                 conv5_block3_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block4_0_bn (BatchNormali (None, 3, 3, 608)    2432        conv5_block3_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block4_0_relu (Activation (None, 3, 3, 608)    0           conv5_block4_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block4_1_conv (Conv2D)    (None, 3, 3, 128)    77824       conv5_block4_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block4_1_bn (BatchNormali (None, 3, 3, 128)    512         conv5_block4_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block4_1_relu (Activation (None, 3, 3, 128)    0           conv5_block4_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block4_2_conv (Conv2D)    (None, 3, 3, 32)     36864       conv5_block4_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block4_concat (Concatenat (None, 3, 3, 640)    0           conv5_block3_concat[0][0]        \n","                                                                 conv5_block4_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block5_0_bn (BatchNormali (None, 3, 3, 640)    2560        conv5_block4_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block5_0_relu (Activation (None, 3, 3, 640)    0           conv5_block5_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block5_1_conv (Conv2D)    (None, 3, 3, 128)    81920       conv5_block5_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block5_1_bn (BatchNormali (None, 3, 3, 128)    512         conv5_block5_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block5_1_relu (Activation (None, 3, 3, 128)    0           conv5_block5_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block5_2_conv (Conv2D)    (None, 3, 3, 32)     36864       conv5_block5_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block5_concat (Concatenat (None, 3, 3, 672)    0           conv5_block4_concat[0][0]        \n","                                                                 conv5_block5_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block6_0_bn (BatchNormali (None, 3, 3, 672)    2688        conv5_block5_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block6_0_relu (Activation (None, 3, 3, 672)    0           conv5_block6_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block6_1_conv (Conv2D)    (None, 3, 3, 128)    86016       conv5_block6_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block6_1_bn (BatchNormali (None, 3, 3, 128)    512         conv5_block6_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block6_1_relu (Activation (None, 3, 3, 128)    0           conv5_block6_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block6_2_conv (Conv2D)    (None, 3, 3, 32)     36864       conv5_block6_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block6_concat (Concatenat (None, 3, 3, 704)    0           conv5_block5_concat[0][0]        \n","                                                                 conv5_block6_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block7_0_bn (BatchNormali (None, 3, 3, 704)    2816        conv5_block6_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block7_0_relu (Activation (None, 3, 3, 704)    0           conv5_block7_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block7_1_conv (Conv2D)    (None, 3, 3, 128)    90112       conv5_block7_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block7_1_bn (BatchNormali (None, 3, 3, 128)    512         conv5_block7_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block7_1_relu (Activation (None, 3, 3, 128)    0           conv5_block7_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block7_2_conv (Conv2D)    (None, 3, 3, 32)     36864       conv5_block7_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block7_concat (Concatenat (None, 3, 3, 736)    0           conv5_block6_concat[0][0]        \n","                                                                 conv5_block7_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block8_0_bn (BatchNormali (None, 3, 3, 736)    2944        conv5_block7_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block8_0_relu (Activation (None, 3, 3, 736)    0           conv5_block8_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block8_1_conv (Conv2D)    (None, 3, 3, 128)    94208       conv5_block8_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block8_1_bn (BatchNormali (None, 3, 3, 128)    512         conv5_block8_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block8_1_relu (Activation (None, 3, 3, 128)    0           conv5_block8_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block8_2_conv (Conv2D)    (None, 3, 3, 32)     36864       conv5_block8_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block8_concat (Concatenat (None, 3, 3, 768)    0           conv5_block7_concat[0][0]        \n","                                                                 conv5_block8_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block9_0_bn (BatchNormali (None, 3, 3, 768)    3072        conv5_block8_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block9_0_relu (Activation (None, 3, 3, 768)    0           conv5_block9_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block9_1_conv (Conv2D)    (None, 3, 3, 128)    98304       conv5_block9_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block9_1_bn (BatchNormali (None, 3, 3, 128)    512         conv5_block9_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block9_1_relu (Activation (None, 3, 3, 128)    0           conv5_block9_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block9_2_conv (Conv2D)    (None, 3, 3, 32)     36864       conv5_block9_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block9_concat (Concatenat (None, 3, 3, 800)    0           conv5_block8_concat[0][0]        \n","                                                                 conv5_block9_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block10_0_bn (BatchNormal (None, 3, 3, 800)    3200        conv5_block9_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block10_0_relu (Activatio (None, 3, 3, 800)    0           conv5_block10_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv5_block10_1_conv (Conv2D)   (None, 3, 3, 128)    102400      conv5_block10_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block10_1_bn (BatchNormal (None, 3, 3, 128)    512         conv5_block10_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block10_1_relu (Activatio (None, 3, 3, 128)    0           conv5_block10_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv5_block10_2_conv (Conv2D)   (None, 3, 3, 32)     36864       conv5_block10_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block10_concat (Concatena (None, 3, 3, 832)    0           conv5_block9_concat[0][0]        \n","                                                                 conv5_block10_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block11_0_bn (BatchNormal (None, 3, 3, 832)    3328        conv5_block10_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block11_0_relu (Activatio (None, 3, 3, 832)    0           conv5_block11_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv5_block11_1_conv (Conv2D)   (None, 3, 3, 128)    106496      conv5_block11_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block11_1_bn (BatchNormal (None, 3, 3, 128)    512         conv5_block11_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block11_1_relu (Activatio (None, 3, 3, 128)    0           conv5_block11_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv5_block11_2_conv (Conv2D)   (None, 3, 3, 32)     36864       conv5_block11_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block11_concat (Concatena (None, 3, 3, 864)    0           conv5_block10_concat[0][0]       \n","                                                                 conv5_block11_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block12_0_bn (BatchNormal (None, 3, 3, 864)    3456        conv5_block11_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block12_0_relu (Activatio (None, 3, 3, 864)    0           conv5_block12_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv5_block12_1_conv (Conv2D)   (None, 3, 3, 128)    110592      conv5_block12_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block12_1_bn (BatchNormal (None, 3, 3, 128)    512         conv5_block12_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block12_1_relu (Activatio (None, 3, 3, 128)    0           conv5_block12_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv5_block12_2_conv (Conv2D)   (None, 3, 3, 32)     36864       conv5_block12_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block12_concat (Concatena (None, 3, 3, 896)    0           conv5_block11_concat[0][0]       \n","                                                                 conv5_block12_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block13_0_bn (BatchNormal (None, 3, 3, 896)    3584        conv5_block12_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block13_0_relu (Activatio (None, 3, 3, 896)    0           conv5_block13_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv5_block13_1_conv (Conv2D)   (None, 3, 3, 128)    114688      conv5_block13_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block13_1_bn (BatchNormal (None, 3, 3, 128)    512         conv5_block13_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block13_1_relu (Activatio (None, 3, 3, 128)    0           conv5_block13_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv5_block13_2_conv (Conv2D)   (None, 3, 3, 32)     36864       conv5_block13_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block13_concat (Concatena (None, 3, 3, 928)    0           conv5_block12_concat[0][0]       \n","                                                                 conv5_block13_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block14_0_bn (BatchNormal (None, 3, 3, 928)    3712        conv5_block13_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block14_0_relu (Activatio (None, 3, 3, 928)    0           conv5_block14_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv5_block14_1_conv (Conv2D)   (None, 3, 3, 128)    118784      conv5_block14_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block14_1_bn (BatchNormal (None, 3, 3, 128)    512         conv5_block14_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block14_1_relu (Activatio (None, 3, 3, 128)    0           conv5_block14_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv5_block14_2_conv (Conv2D)   (None, 3, 3, 32)     36864       conv5_block14_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block14_concat (Concatena (None, 3, 3, 960)    0           conv5_block13_concat[0][0]       \n","                                                                 conv5_block14_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block15_0_bn (BatchNormal (None, 3, 3, 960)    3840        conv5_block14_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block15_0_relu (Activatio (None, 3, 3, 960)    0           conv5_block15_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv5_block15_1_conv (Conv2D)   (None, 3, 3, 128)    122880      conv5_block15_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block15_1_bn (BatchNormal (None, 3, 3, 128)    512         conv5_block15_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block15_1_relu (Activatio (None, 3, 3, 128)    0           conv5_block15_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv5_block15_2_conv (Conv2D)   (None, 3, 3, 32)     36864       conv5_block15_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block15_concat (Concatena (None, 3, 3, 992)    0           conv5_block14_concat[0][0]       \n","                                                                 conv5_block15_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block16_0_bn (BatchNormal (None, 3, 3, 992)    3968        conv5_block15_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block16_0_relu (Activatio (None, 3, 3, 992)    0           conv5_block16_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv5_block16_1_conv (Conv2D)   (None, 3, 3, 128)    126976      conv5_block16_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block16_1_bn (BatchNormal (None, 3, 3, 128)    512         conv5_block16_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block16_1_relu (Activatio (None, 3, 3, 128)    0           conv5_block16_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv5_block16_2_conv (Conv2D)   (None, 3, 3, 32)     36864       conv5_block16_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block16_concat (Concatena (None, 3, 3, 1024)   0           conv5_block15_concat[0][0]       \n","                                                                 conv5_block16_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","bn (BatchNormalization)         (None, 3, 3, 1024)   4096        conv5_block16_concat[0][0]       \n","__________________________________________________________________________________________________\n","relu (Activation)               (None, 3, 3, 1024)   0           bn[0][0]                         \n","==================================================================================================\n","Total params: 7,037,504\n","Trainable params: 952,384\n","Non-trainable params: 6,085,120\n","__________________________________________________________________________________________________\n","Model: \"DenseNet121_ADModel\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","tensor (InputLayer)          [(None, 100, 100, 3)]     0         \n","_________________________________________________________________\n","densenet121 (Functional)     (None, 3, 3, 1024)        7037504   \n","_________________________________________________________________\n","flatten_2 (Flatten)          (None, 9216)              0         \n","_________________________________________________________________\n","dropout_3 (Dropout)          (None, 9216)              0         \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 128)               1179776   \n","_________________________________________________________________\n","batch_normalization_2 (Batch (None, 128)               512       \n","_________________________________________________________________\n","leaky_re_lu_2 (LeakyReLU)    (None, 128)               0         \n","_________________________________________________________________\n","dropout_4 (Dropout)          (None, 128)               0         \n","_________________________________________________________________\n","dense_5 (Dense)              (None, 4)                 516       \n","=================================================================\n","Total params: 8,218,308\n","Trainable params: 2,132,932\n","Non-trainable params: 6,085,376\n","_________________________________________________________________\n"],"name":"stdout"},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["' NSL model training '"]},"metadata":{"tags":[]},"execution_count":38}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HqUg5ceng8E6","executionInfo":{"status":"ok","timestamp":1606010851862,"user_tz":300,"elapsed":4322,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"bfc735b4-d790-4d3c-dbe3-a6f26926e819"},"source":["'''evalute the test model'''\n","graph_reg_model.evaluate(test_image_dataset)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["60/60 [==============================] - 3s 43ms/step - loss: 0.0425 - accuracy: 0.9864 - auc: 0.9987 - f1_score: 0.9865\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[0.04247911646962166,\n"," 0.9864158630371094,\n"," 0.9987107515335083,\n"," 0.9865447878837585]"]},"metadata":{"tags":[]},"execution_count":61}]},{"cell_type":"code","metadata":{"id":"8IbO8pXDHuoS"},"source":["'''plot confusion mat & calc acc for each label'''\n","test_image_dataset = NSLDataFormat.generate_test_tfr_image_tensor(path_list=tfr_list_test, \n","                                                                  batch_size=4000, \n","                                                                  size=(100,100),\n","                                                                  channels=3,\n","                                                                  shuffle=True)\n","data, data_label = iter(test_image_dataset).get_next()\n","data = data[\"tensor\"]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":396},"id":"PYyy-pklHOzU","executionInfo":{"status":"ok","timestamp":1606257312372,"user_tz":300,"elapsed":7595,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"5fc5653b-cf8f-4f3e-b58c-9bec35d09d80"},"source":["ADModelBuilder.plot_confusion_mat(graph_reg_model, data, data_label, title=\"DenseNet121_NSL\")"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x432 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7sZEk-JFHOxJ","executionInfo":{"status":"ok","timestamp":1606257315550,"user_tz":300,"elapsed":3156,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"9863ee87-38a3-4e75-ed3b-7d205b295da9"},"source":["ADModelBuilder.calc_confu_mat_for_each_label(model=graph_reg_model, data=data, data_label=data_label)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["TN: [2822 2861 2887 2862]\n","TP: [981 919 911 965]\n","FN: [10 19 23  0]\n","FP: [15 29  7  1]\n","Acc: [0.99346917 0.98746082 0.99216301 0.99973877]\n","ER(Error rate): [0.00653083 0.01253918 0.00783699 0.00026123]\n","Recall(TP rate): [0.98990918 0.97974414 0.97537473 1.        ]\n","Specialty(TN rate): [0.99471272 0.9899654  0.9975812  0.99965072]\n","Fall Out(FP rate): [0.00528728 0.0100346  0.0024188  0.00034928]\n","Miss Rate(FN rate): [0.01009082 0.02025586 0.02462527 0.        ]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qQY3nmxy2Va6"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0GWdE1gQKqpF"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KLUpQmqlt3GW"},"source":["#8.Xception & Xception-NSL Model Training"]},{"cell_type":"code","metadata":{"id":"5axk1eIwD6qw"},"source":["'''define hyper params'''\n","params = AD_params()\n","params.max_seed_nbr=5\n","params.batch_size=128\n","params.image_channels =3\n","params.image_size =(100,100)\n","params.ad_base_model_input_shape=(100,100,3)\n","params.graph_path= f'{root_path}AD_graph_aae_kmeans.tsv'\n","params.test_tfr_path =  f'{root_path}test_data.tfr'\n","params.train_tfr_path = f'{root_path}train_data.tfr'\n","\n","'''parse train_data.tfr to train image dataset with batch_size at 128'''\n","train_image_dataset = NSLDataFormat.parse_tfr_to_dataset(file_path_list=[params.train_tfr_path],\n","                                                         batch_size=params.batch_size,\n","                                                         max_neighbor_number=params.max_seed_nbr,\n","                                                         image_size=params.image_size,\n","                                                         image_channels=params.image_channels,\n","                                                         shuffle=True)\n","\n","'''load test data with batch_size at 128 '''\n","test_image_dataset = NSLDataFormat.generate_test_tfr_image_tensor(path_list=tfr_list_test, \n","                                                                  batch_size=params.batch_size, \n","                                                                  size=params.image_size,\n","                                                                  channels=params.image_channels,\n","                                                                  shuffle=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VJqIRkiQ81qg"},"source":["##5.1 Xception Base Model Training\n","### val_acc: 0.901, val_auc: 0.987, val_f1_score: 0.897"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wj2Ei0L1Za0O","executionInfo":{"status":"ok","timestamp":1606257359432,"user_tz":300,"elapsed":7830,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"a70fea5f-21fc-4bf0-f85c-57eaf96c10ac"},"source":["'''define params'''\n","params.learning_rate=0.001\n","params.checkpoint_restore_path='/content/drive/My Drive/Projects/codes/Xception_model_checkpoints/xception_model_new_90'\n","params.checkpoint_path='/content/drive/My Drive/Projects/codes/Xception_model_checkpoints/xception_model_new_90'\n","params.early_stop_base_line=0.90\n","params.train_epoch=50\n","\n","'''build base_model and restore from the last training'''\n","base_model = ADModelBuilder(input_shape=params.ad_base_model_input_shape, base_model='xception').get_ADModel()\n","base_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=params.learning_rate, amsgrad=True), \n","                   loss=tf.losses.CategoricalCrossentropy(), \n","                   metrics=['accuracy', 'AUC',tfa.metrics.F1Score(num_classes=4, average=\"micro\", threshold = 0.5)])\n","base_model.load_weights(params.checkpoint_restore_path)\n","'''set up check point & early stopping'''\n","callback_checkpints = tf.keras.callbacks.ModelCheckpoint(filepath= params.checkpoint_path, monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=True, mode='max',\n","                                                         save_freq='epoch',options=None)\n","callback_earlystop = AccEarlyStop(val_acc_base=params.early_stop_base_line)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Note: default Xception not includes top and has imagenet weights. It is not a trainable model in ADModelBuilder. Please setup trainable layers in setup_Xception function based on the \"Layer Number\"\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n","WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n","Model: \"Xception_ADModel\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","tensor (InputLayer)          [(None, 100, 100, 3)]     0         \n","_________________________________________________________________\n","xception (Functional)        (None, 3, 3, 2048)        20861480  \n","_________________________________________________________________\n","flatten_4 (Flatten)          (None, 18432)             0         \n","_________________________________________________________________\n","dropout_7 (Dropout)          (None, 18432)             0         \n","_________________________________________________________________\n","dense_8 (Dense)              (None, 128)               2359424   \n","_________________________________________________________________\n","batch_normalization_12 (Batc (None, 128)               512       \n","_________________________________________________________________\n","leaky_re_lu_4 (LeakyReLU)    (None, 128)               0         \n","_________________________________________________________________\n","dropout_8 (Dropout)          (None, 128)               0         \n","_________________________________________________________________\n","dense_9 (Dense)              (None, 4)                 516       \n","=================================================================\n","Total params: 23,221,932\n","Trainable params: 2,360,196\n","Non-trainable params: 20,861,736\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jeuKRP8dCAAZ","executionInfo":{"status":"ok","timestamp":1606055078068,"user_tz":300,"elapsed":572218,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"141d59d3-24df-489f-b69d-addea2f5e912"},"source":["'''train base model'''\n","history = base_model.fit(train_image_dataset,\n","                         validation_data= test_image_dataset,\n","                         callbacks = [callback_checkpints, callback_earlystop],\n","                         epochs=params.train_epoch,\n","                         verbose=1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Note: default Xception not includes top and has imagenet weights. It is not a trainable model in ADModelBuilder. Please setup trainable layers in setup_Xception function based on the \"Layer Number\"\n","Model: \"Xception_ADModel\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","tensor (InputLayer)          [(None, 100, 100, 3)]     0         \n","_________________________________________________________________\n","xception (Functional)        (None, 3, 3, 2048)        20861480  \n","_________________________________________________________________\n","flatten_1 (Flatten)          (None, 18432)             0         \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 18432)             0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 128)               2359424   \n","_________________________________________________________________\n","batch_normalization_9 (Batch (None, 128)               512       \n","_________________________________________________________________\n","leaky_re_lu_1 (LeakyReLU)    (None, 128)               0         \n","_________________________________________________________________\n","dropout_3 (Dropout)          (None, 128)               0         \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 4)                 516       \n","=================================================================\n","Total params: 23,221,932\n","Trainable params: 2,360,196\n","Non-trainable params: 20,861,736\n","_________________________________________________________________\n","Epoch 1/50\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py:543: UserWarning: Input dict contained keys ['NL_nbr_0_id', 'NL_nbr_0_tensor', 'NL_nbr_0_weight', 'NL_nbr_1_id', 'NL_nbr_1_tensor', 'NL_nbr_1_weight', 'NL_nbr_2_id', 'NL_nbr_2_tensor', 'NL_nbr_2_weight', 'NL_nbr_3_id', 'NL_nbr_3_tensor', 'NL_nbr_3_weight', 'NL_nbr_4_id', 'NL_nbr_4_tensor', 'NL_nbr_4_weight', 'id'] which did not match any model input. They will be ignored by the model.\n","  [n for n in tensors.keys() if n not in ref_input_names])\n"],"name":"stderr"},{"output_type":"stream","text":["     69/Unknown - 19s 277ms/step - loss: 0.9846 - accuracy: 0.5874 - auc: 0.8402 - f1_score: 0.5660"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py:543: UserWarning: Input dict contained keys ['id'] which did not match any model input. They will be ignored by the model.\n","  [n for n in tensors.keys() if n not in ref_input_names])\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Epoch 00001: val_accuracy improved from -inf to 0.64368, saving model to /content/drive/My Drive/Projects/codes/Xception_model_checkpoints/xception_model_new_90\n","69/69 [==============================] - 29s 417ms/step - loss: 0.9846 - accuracy: 0.5874 - auc: 0.8402 - f1_score: 0.5660 - val_loss: 0.8324 - val_accuracy: 0.6437 - val_auc: 0.8853 - val_f1_score: 0.6391\n","Epoch 2/50\n","69/69 [==============================] - ETA: 0s - loss: 0.7263 - accuracy: 0.6768 - auc: 0.9057 - f1_score: 0.6621\n","Epoch 00002: val_accuracy improved from 0.64368 to 0.69279, saving model to /content/drive/My Drive/Projects/codes/Xception_model_checkpoints/xception_model_new_90\n","69/69 [==============================] - 24s 342ms/step - loss: 0.7263 - accuracy: 0.6768 - auc: 0.9057 - f1_score: 0.6621 - val_loss: 0.6742 - val_accuracy: 0.6928 - val_auc: 0.9195 - val_f1_score: 0.6863\n","Epoch 3/50\n","69/69 [==============================] - ETA: 0s - loss: 0.6480 - accuracy: 0.7086 - auc: 0.9240 - f1_score: 0.6999\n","Epoch 00003: val_accuracy improved from 0.69279 to 0.72309, saving model to /content/drive/My Drive/Projects/codes/Xception_model_checkpoints/xception_model_new_90\n","69/69 [==============================] - 23s 328ms/step - loss: 0.6480 - accuracy: 0.7086 - auc: 0.9240 - f1_score: 0.6999 - val_loss: 0.5882 - val_accuracy: 0.7231 - val_auc: 0.9372 - val_f1_score: 0.7164\n","Epoch 4/50\n","69/69 [==============================] - ETA: 0s - loss: 0.5891 - accuracy: 0.7445 - auc: 0.9373 - f1_score: 0.7311\n","Epoch 00004: val_accuracy did not improve from 0.72309\n","69/69 [==============================] - 22s 320ms/step - loss: 0.5891 - accuracy: 0.7445 - auc: 0.9373 - f1_score: 0.7311 - val_loss: 0.6143 - val_accuracy: 0.7129 - val_auc: 0.9354 - val_f1_score: 0.7178\n","Epoch 5/50\n","69/69 [==============================] - ETA: 0s - loss: 0.5568 - accuracy: 0.7532 - auc: 0.9438 - f1_score: 0.7480\n","Epoch 00005: val_accuracy improved from 0.72309 to 0.77717, saving model to /content/drive/My Drive/Projects/codes/Xception_model_checkpoints/xception_model_new_90\n","69/69 [==============================] - 23s 332ms/step - loss: 0.5568 - accuracy: 0.7532 - auc: 0.9438 - f1_score: 0.7480 - val_loss: 0.5068 - val_accuracy: 0.7772 - val_auc: 0.9548 - val_f1_score: 0.7718\n","Epoch 6/50\n","69/69 [==============================] - ETA: 0s - loss: 0.5257 - accuracy: 0.7709 - auc: 0.9498 - f1_score: 0.7642\n","Epoch 00006: val_accuracy did not improve from 0.77717\n","69/69 [==============================] - 22s 320ms/step - loss: 0.5257 - accuracy: 0.7709 - auc: 0.9498 - f1_score: 0.7642 - val_loss: 0.5394 - val_accuracy: 0.7636 - val_auc: 0.9475 - val_f1_score: 0.7612\n","Epoch 7/50\n","69/69 [==============================] - ETA: 0s - loss: 0.5024 - accuracy: 0.7790 - auc: 0.9540 - f1_score: 0.7728\n","Epoch 00007: val_accuracy did not improve from 0.77717\n","69/69 [==============================] - 22s 319ms/step - loss: 0.5024 - accuracy: 0.7790 - auc: 0.9540 - f1_score: 0.7728 - val_loss: 0.6324 - val_accuracy: 0.7403 - val_auc: 0.9342 - val_f1_score: 0.7394\n","Epoch 8/50\n","69/69 [==============================] - ETA: 0s - loss: 0.4972 - accuracy: 0.7854 - auc: 0.9551 - f1_score: 0.7794\n","Epoch 00008: val_accuracy did not improve from 0.77717\n","69/69 [==============================] - 22s 317ms/step - loss: 0.4972 - accuracy: 0.7854 - auc: 0.9551 - f1_score: 0.7794 - val_loss: 0.6343 - val_accuracy: 0.7095 - val_auc: 0.9295 - val_f1_score: 0.7084\n","Epoch 9/50\n","69/69 [==============================] - ETA: 0s - loss: 0.4834 - accuracy: 0.7911 - auc: 0.9576 - f1_score: 0.7863\n","Epoch 00009: val_accuracy improved from 0.77717 to 0.83229, saving model to /content/drive/My Drive/Projects/codes/Xception_model_checkpoints/xception_model_new_90\n","69/69 [==============================] - 22s 323ms/step - loss: 0.4834 - accuracy: 0.7911 - auc: 0.9576 - f1_score: 0.7863 - val_loss: 0.4077 - val_accuracy: 0.8323 - val_auc: 0.9715 - val_f1_score: 0.8270\n","Epoch 10/50\n","69/69 [==============================] - ETA: 0s - loss: 0.4601 - accuracy: 0.8004 - auc: 0.9614 - f1_score: 0.7964\n","Epoch 00010: val_accuracy improved from 0.83229 to 0.85162, saving model to /content/drive/My Drive/Projects/codes/Xception_model_checkpoints/xception_model_new_90\n","69/69 [==============================] - 23s 332ms/step - loss: 0.4601 - accuracy: 0.8004 - auc: 0.9614 - f1_score: 0.7964 - val_loss: 0.3842 - val_accuracy: 0.8516 - val_auc: 0.9755 - val_f1_score: 0.8499\n","Epoch 11/50\n","69/69 [==============================] - ETA: 0s - loss: 0.4503 - accuracy: 0.8016 - auc: 0.9630 - f1_score: 0.8013\n","Epoch 00011: val_accuracy did not improve from 0.85162\n","69/69 [==============================] - 22s 321ms/step - loss: 0.4503 - accuracy: 0.8016 - auc: 0.9630 - f1_score: 0.8013 - val_loss: 0.4473 - val_accuracy: 0.7939 - val_auc: 0.9629 - val_f1_score: 0.7868\n","Epoch 12/50\n","69/69 [==============================] - ETA: 0s - loss: 0.4281 - accuracy: 0.8192 - auc: 0.9670 - f1_score: 0.8137\n","Epoch 00012: val_accuracy did not improve from 0.85162\n","69/69 [==============================] - 22s 317ms/step - loss: 0.4281 - accuracy: 0.8192 - auc: 0.9670 - f1_score: 0.8137 - val_loss: 0.3788 - val_accuracy: 0.8438 - val_auc: 0.9745 - val_f1_score: 0.8363\n","Epoch 13/50\n","69/69 [==============================] - ETA: 0s - loss: 0.4235 - accuracy: 0.8140 - auc: 0.9672 - f1_score: 0.8112\n","Epoch 00013: val_accuracy improved from 0.85162 to 0.85998, saving model to /content/drive/My Drive/Projects/codes/Xception_model_checkpoints/xception_model_new_90\n","69/69 [==============================] - 23s 330ms/step - loss: 0.4235 - accuracy: 0.8140 - auc: 0.9672 - f1_score: 0.8112 - val_loss: 0.3656 - val_accuracy: 0.8600 - val_auc: 0.9776 - val_f1_score: 0.8547\n","Epoch 14/50\n","69/69 [==============================] - ETA: 0s - loss: 0.4059 - accuracy: 0.8266 - auc: 0.9699 - f1_score: 0.8229\n","Epoch 00014: val_accuracy did not improve from 0.85998\n","69/69 [==============================] - 22s 322ms/step - loss: 0.4059 - accuracy: 0.8266 - auc: 0.9699 - f1_score: 0.8229 - val_loss: 0.4218 - val_accuracy: 0.8302 - val_auc: 0.9677 - val_f1_score: 0.8242\n","Epoch 15/50\n","69/69 [==============================] - ETA: 0s - loss: 0.4157 - accuracy: 0.8197 - auc: 0.9682 - f1_score: 0.8180\n","Epoch 00015: val_accuracy did not improve from 0.85998\n","69/69 [==============================] - 22s 313ms/step - loss: 0.4157 - accuracy: 0.8197 - auc: 0.9682 - f1_score: 0.8180 - val_loss: 0.4569 - val_accuracy: 0.7931 - val_auc: 0.9607 - val_f1_score: 0.7919\n","Epoch 16/50\n","69/69 [==============================] - ETA: 0s - loss: 0.4006 - accuracy: 0.8300 - auc: 0.9707 - f1_score: 0.8266\n","Epoch 00016: val_accuracy improved from 0.85998 to 0.87591, saving model to /content/drive/My Drive/Projects/codes/Xception_model_checkpoints/xception_model_new_90\n","69/69 [==============================] - 22s 324ms/step - loss: 0.4006 - accuracy: 0.8300 - auc: 0.9707 - f1_score: 0.8266 - val_loss: 0.3424 - val_accuracy: 0.8759 - val_auc: 0.9802 - val_f1_score: 0.8705\n","Epoch 17/50\n","69/69 [==============================] - ETA: 0s - loss: 0.3865 - accuracy: 0.8403 - auc: 0.9728 - f1_score: 0.8383\n","Epoch 00017: val_accuracy did not improve from 0.87591\n","69/69 [==============================] - 22s 321ms/step - loss: 0.3865 - accuracy: 0.8403 - auc: 0.9728 - f1_score: 0.8383 - val_loss: 0.3856 - val_accuracy: 0.8331 - val_auc: 0.9728 - val_f1_score: 0.8299\n","Epoch 18/50\n","69/69 [==============================] - ETA: 0s - loss: 0.3990 - accuracy: 0.8274 - auc: 0.9706 - f1_score: 0.8247\n","Epoch 00018: val_accuracy did not improve from 0.87591\n","69/69 [==============================] - 22s 316ms/step - loss: 0.3990 - accuracy: 0.8274 - auc: 0.9706 - f1_score: 0.8247 - val_loss: 0.3577 - val_accuracy: 0.8487 - val_auc: 0.9766 - val_f1_score: 0.8432\n","Epoch 19/50\n","69/69 [==============================] - ETA: 0s - loss: 0.3700 - accuracy: 0.8418 - auc: 0.9749 - f1_score: 0.8409\n","Epoch 00019: val_accuracy did not improve from 0.87591\n","69/69 [==============================] - 22s 313ms/step - loss: 0.3700 - accuracy: 0.8418 - auc: 0.9749 - f1_score: 0.8409 - val_loss: 0.3423 - val_accuracy: 0.8636 - val_auc: 0.9788 - val_f1_score: 0.8621\n","Epoch 20/50\n","69/69 [==============================] - ETA: 0s - loss: 0.3744 - accuracy: 0.8427 - auc: 0.9743 - f1_score: 0.8407\n","Epoch 00020: val_accuracy did not improve from 0.87591\n","69/69 [==============================] - 22s 314ms/step - loss: 0.3744 - accuracy: 0.8427 - auc: 0.9743 - f1_score: 0.8407 - val_loss: 0.3351 - val_accuracy: 0.8715 - val_auc: 0.9802 - val_f1_score: 0.8704\n","Epoch 21/50\n","69/69 [==============================] - ETA: 0s - loss: 0.3678 - accuracy: 0.8447 - auc: 0.9753 - f1_score: 0.8443\n","Epoch 00021: val_accuracy did not improve from 0.87591\n","69/69 [==============================] - 22s 320ms/step - loss: 0.3678 - accuracy: 0.8447 - auc: 0.9753 - f1_score: 0.8443 - val_loss: 0.3393 - val_accuracy: 0.8676 - val_auc: 0.9796 - val_f1_score: 0.8666\n","Epoch 22/50\n","69/69 [==============================] - ETA: 0s - loss: 0.3789 - accuracy: 0.8393 - auc: 0.9737 - f1_score: 0.8379\n","Epoch 00022: val_accuracy improved from 0.87591 to 0.88009, saving model to /content/drive/My Drive/Projects/codes/Xception_model_checkpoints/xception_model_new_90\n","69/69 [==============================] - 23s 331ms/step - loss: 0.3789 - accuracy: 0.8393 - auc: 0.9737 - f1_score: 0.8379 - val_loss: 0.3181 - val_accuracy: 0.8801 - val_auc: 0.9830 - val_f1_score: 0.8788\n","Epoch 23/50\n","69/69 [==============================] - ETA: 0s - loss: 0.3636 - accuracy: 0.8480 - auc: 0.9757 - f1_score: 0.8468\n","Epoch 00023: val_accuracy did not improve from 0.88009\n","69/69 [==============================] - 22s 318ms/step - loss: 0.3636 - accuracy: 0.8480 - auc: 0.9757 - f1_score: 0.8468 - val_loss: 0.3420 - val_accuracy: 0.8668 - val_auc: 0.9791 - val_f1_score: 0.8646\n","Epoch 24/50\n","69/69 [==============================] - ETA: 0s - loss: 0.3503 - accuracy: 0.8555 - auc: 0.9775 - f1_score: 0.8516\n","Epoch 00024: val_accuracy improved from 0.88009 to 0.90125, saving model to /content/drive/My Drive/Projects/codes/Xception_model_checkpoints/xception_model_new_90\n","69/69 [==============================] - 22s 325ms/step - loss: 0.3503 - accuracy: 0.8555 - auc: 0.9775 - f1_score: 0.8516 - val_loss: 0.2796 - val_accuracy: 0.9013 - val_auc: 0.9874 - val_f1_score: 0.8980\n","Epoch 00025: early stopping\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fgKrbn5a9iHy","executionInfo":{"status":"ok","timestamp":1606055083393,"user_tz":300,"elapsed":5297,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"789dba31-dbfd-4b1b-d4f1-c461a6f0ab33"},"source":["\"\"\"evaluate base_model\"\"\"\n","base_model.evaluate(test_image_dataset)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["30/30 [==============================] - 2s 61ms/step - loss: 0.2796 - accuracy: 0.9013 - auc: 0.9874 - f1_score: 0.8980\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[0.27955442667007446,\n"," 0.9012539386749268,\n"," 0.9873639345169067,\n"," 0.8979917764663696]"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":396},"id":"bxUfsjJTxVsb","executionInfo":{"status":"ok","timestamp":1606257460924,"user_tz":300,"elapsed":7208,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"4d5983f5-23a9-48a3-be60-1cc24ba26db0"},"source":["'''plot confusion mat & calc acc for each label'''\n","test_image_dataset = NSLDataFormat.generate_test_tfr_image_tensor(path_list=tfr_list_test, \n","                                                                  batch_size=4000, \n","                                                                  size=(100,100),\n","                                                                  channels=3,\n","                                                                  shuffle=True)\n","data, data_label = iter(test_image_dataset).get_next()\n","data = data[\"tensor\"]\n","ADModelBuilder.plot_confusion_mat(model=base_model, data=data, data_label=data_label, title=\"Xception\", figsize=(6,6))"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x432 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KCUf-aI9GEBL","executionInfo":{"status":"ok","timestamp":1606257464268,"user_tz":300,"elapsed":7998,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"b4387d69-ad66-403e-bd68-5b515c375a3a"},"source":["ADModelBuilder.calc_confu_mat_for_each_label(model=base_model, data=data, data_label=data_label)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["TN: [2704 2708 2838 2856]\n","TP: [890 793 805 962]\n","FN: [101 145 129   3]\n","FP: [133 182  56   7]\n","Acc: [0.93887147 0.9145768  0.95167189 0.99738767]\n","ER(Error rate): [0.06112853 0.0854232  0.04832811 0.00261233]\n","Recall(TP rate): [0.89808274 0.84541578 0.86188437 0.99689119]\n","Specialty(TN rate): [0.95311949 0.93702422 0.98064962 0.99755501]\n","Fall Out(FP rate): [0.04688051 0.06297578 0.01935038 0.00244499]\n","Miss Rate(FN rate): [0.10191726 0.15458422 0.13811563 0.00310881]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JLKaHrGqGEFw"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rTkxi38f9Han"},"source":["##5.2 Xception_NSL Model Training\n","### val_acc: 0.954,val_auc: 0.990,val_f1_score:0.954"]},{"cell_type":"code","metadata":{"id":"8ENVKLvoRFPE"},"source":["'''define hyper params'''\n","params = AD_params()\n","params.max_seed_nbr=5\n","params.batch_size=64\n","params.image_channels =3\n","params.image_size =(100,100)\n","params.ad_base_model_input_shape=(100,100,3)\n","params.train_tfr_path = f'{root_path}train_data.tfr'\n","'''parse train_data.tfr to train image dataset with batch_size at 128'''\n","train_image_dataset = NSLDataFormat.parse_tfr_to_dataset(file_path_list=[params.train_tfr_path],\n","                                                         batch_size=params.batch_size,\n","                                                         max_neighbor_number=params.max_seed_nbr,\n","                                                         image_size=params.image_size,\n","                                                         image_channels=params.image_channels,\n","                                                         shuffle=True)\n","'''load test data with batch_size at 128 '''\n","test_image_dataset = NSLDataFormat.generate_test_tfr_image_tensor(path_list=tfr_list_test, \n","                                                                  batch_size=params.batch_size, \n","                                                                  size=params.image_size,\n","                                                                  channels=params.image_channels,\n","                                                                  shuffle=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H0aFX2Bp9Gnx","executionInfo":{"status":"ok","timestamp":1606056077165,"user_tz":300,"elapsed":540274,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"7f0e0518-073d-4b1d-ad7a-42dc92551e13"},"source":["'''define params'''\n","params.learning_rate=0.00005\n","params.restore_path = '/content/drive/My Drive/Projects/codes/Xception_model_checkpoints/xception_model_new_90'\n","params.checkpoint_path = '/content/drive/My Drive/Projects/codes/Xception_NSL_model_checkpoints/xception_model_95'\n","params.early_stop_base_line=0.95\n","params.train_epoch=50\n","params.nsl_multiplier = 0.1\n","params.nsl_sum_over_axis = -1\n","params.nsl_distance_type = nsl.configs.DistanceType.COSINE\n","'''build base_model and restore from the last training'''\n","base_model = ADModelBuilder(input_shape=params.ad_base_model_input_shape, base_model='xception').setup_Xception(top_layers=10, middle_layers=None, bottom_layers=5).get_ADModel()\n","'''build NSL model on top of base model'''\n","graph_reg_config = nsl.configs.make_graph_reg_config(neighbor_prefix=params.neighbor_prefix,\n","                                                     neighbor_weight_suffix=params.neighbor_weight_suffix,\n","                                                     max_neighbors= params.max_seed_nbr,\n","                                                     multiplier= params.nsl_multiplier,\n","                                                     distance_type= params.nsl_distance_type,\n","                                                     sum_over_axis=params.nsl_sum_over_axis)\n","graph_reg_model = nsl.keras.GraphRegularization(base_model,graph_reg_config)\n","graph_reg_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=params.learning_rate, amsgrad=True),\n","                        loss=tf.losses.CategoricalCrossentropy(),\n","                        metrics=[\"accuracy\",\"AUC\",tfa.metrics.F1Score(num_classes=4, average=\"micro\", threshold = 0.5)])\n","graph_reg_model.load_weights(params.restore_path)\n","'''set up check point & early stopping'''\n","callback_checkpoints = tf.keras.callbacks.ModelCheckpoint(filepath= params.checkpoint_path, monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=True, mode='max',\n","                                                         save_freq='epoch',options=None)\n","callback_earlystop = AccEarlyStop(val_acc_base=params.early_stop_base_line)\n","'''train the nsl model'''\n","graph_reg_history = graph_reg_model.fit(train_image_dataset, \n","                                        validation_data=test_image_dataset,\n","                                        callbacks = [callback_checkpoints, callback_earlystop],\n","                                        epochs=params.train_epoch,\n","                                        verbose=1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Note: default Xception not includes top and has imagenet weights. It is not a trainable model in ADModelBuilder. Please setup trainable layers in setup_Xception function based on the \"Layer Number\"\n","Model: \"xception\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_3 (InputLayer)            [(None, 100, 100, 3) 0                                            \n","__________________________________________________________________________________________________\n","block1_conv1 (Conv2D)           (None, 49, 49, 32)   864         input_3[0][0]                    \n","__________________________________________________________________________________________________\n","block1_conv1_bn (BatchNormaliza (None, 49, 49, 32)   128         block1_conv1[0][0]               \n","__________________________________________________________________________________________________\n","block1_conv1_act (Activation)   (None, 49, 49, 32)   0           block1_conv1_bn[0][0]            \n","__________________________________________________________________________________________________\n","block1_conv2 (Conv2D)           (None, 47, 47, 64)   18432       block1_conv1_act[0][0]           \n","__________________________________________________________________________________________________\n","block1_conv2_bn (BatchNormaliza (None, 47, 47, 64)   256         block1_conv2[0][0]               \n","__________________________________________________________________________________________________\n","block1_conv2_act (Activation)   (None, 47, 47, 64)   0           block1_conv2_bn[0][0]            \n","__________________________________________________________________________________________________\n","block2_sepconv1 (SeparableConv2 (None, 47, 47, 128)  8768        block1_conv2_act[0][0]           \n","__________________________________________________________________________________________________\n","block2_sepconv1_bn (BatchNormal (None, 47, 47, 128)  512         block2_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block2_sepconv2_act (Activation (None, 47, 47, 128)  0           block2_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block2_sepconv2 (SeparableConv2 (None, 47, 47, 128)  17536       block2_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block2_sepconv2_bn (BatchNormal (None, 47, 47, 128)  512         block2_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","conv2d_8 (Conv2D)               (None, 24, 24, 128)  8192        block1_conv2_act[0][0]           \n","__________________________________________________________________________________________________\n","block2_pool (MaxPooling2D)      (None, 24, 24, 128)  0           block2_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","batch_normalization_10 (BatchNo (None, 24, 24, 128)  512         conv2d_8[0][0]                   \n","__________________________________________________________________________________________________\n","add_24 (Add)                    (None, 24, 24, 128)  0           block2_pool[0][0]                \n","                                                                 batch_normalization_10[0][0]     \n","__________________________________________________________________________________________________\n","block3_sepconv1_act (Activation (None, 24, 24, 128)  0           add_24[0][0]                     \n","__________________________________________________________________________________________________\n","block3_sepconv1 (SeparableConv2 (None, 24, 24, 256)  33920       block3_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block3_sepconv1_bn (BatchNormal (None, 24, 24, 256)  1024        block3_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block3_sepconv2_act (Activation (None, 24, 24, 256)  0           block3_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block3_sepconv2 (SeparableConv2 (None, 24, 24, 256)  67840       block3_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block3_sepconv2_bn (BatchNormal (None, 24, 24, 256)  1024        block3_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","conv2d_9 (Conv2D)               (None, 12, 12, 256)  32768       add_24[0][0]                     \n","__________________________________________________________________________________________________\n","block3_pool (MaxPooling2D)      (None, 12, 12, 256)  0           block3_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","batch_normalization_11 (BatchNo (None, 12, 12, 256)  1024        conv2d_9[0][0]                   \n","__________________________________________________________________________________________________\n","add_25 (Add)                    (None, 12, 12, 256)  0           block3_pool[0][0]                \n","                                                                 batch_normalization_11[0][0]     \n","__________________________________________________________________________________________________\n","block4_sepconv1_act (Activation (None, 12, 12, 256)  0           add_25[0][0]                     \n","__________________________________________________________________________________________________\n","block4_sepconv1 (SeparableConv2 (None, 12, 12, 728)  188672      block4_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block4_sepconv1_bn (BatchNormal (None, 12, 12, 728)  2912        block4_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block4_sepconv2_act (Activation (None, 12, 12, 728)  0           block4_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block4_sepconv2 (SeparableConv2 (None, 12, 12, 728)  536536      block4_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block4_sepconv2_bn (BatchNormal (None, 12, 12, 728)  2912        block4_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","conv2d_10 (Conv2D)              (None, 6, 6, 728)    186368      add_25[0][0]                     \n","__________________________________________________________________________________________________\n","block4_pool (MaxPooling2D)      (None, 6, 6, 728)    0           block4_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","batch_normalization_12 (BatchNo (None, 6, 6, 728)    2912        conv2d_10[0][0]                  \n","__________________________________________________________________________________________________\n","add_26 (Add)                    (None, 6, 6, 728)    0           block4_pool[0][0]                \n","                                                                 batch_normalization_12[0][0]     \n","__________________________________________________________________________________________________\n","block5_sepconv1_act (Activation (None, 6, 6, 728)    0           add_26[0][0]                     \n","__________________________________________________________________________________________________\n","block5_sepconv1 (SeparableConv2 (None, 6, 6, 728)    536536      block5_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block5_sepconv1_bn (BatchNormal (None, 6, 6, 728)    2912        block5_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block5_sepconv2_act (Activation (None, 6, 6, 728)    0           block5_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block5_sepconv2 (SeparableConv2 (None, 6, 6, 728)    536536      block5_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block5_sepconv2_bn (BatchNormal (None, 6, 6, 728)    2912        block5_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","block5_sepconv3_act (Activation (None, 6, 6, 728)    0           block5_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","block5_sepconv3 (SeparableConv2 (None, 6, 6, 728)    536536      block5_sepconv3_act[0][0]        \n","__________________________________________________________________________________________________\n","block5_sepconv3_bn (BatchNormal (None, 6, 6, 728)    2912        block5_sepconv3[0][0]            \n","__________________________________________________________________________________________________\n","add_27 (Add)                    (None, 6, 6, 728)    0           block5_sepconv3_bn[0][0]         \n","                                                                 add_26[0][0]                     \n","__________________________________________________________________________________________________\n","block6_sepconv1_act (Activation (None, 6, 6, 728)    0           add_27[0][0]                     \n","__________________________________________________________________________________________________\n","block6_sepconv1 (SeparableConv2 (None, 6, 6, 728)    536536      block6_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block6_sepconv1_bn (BatchNormal (None, 6, 6, 728)    2912        block6_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block6_sepconv2_act (Activation (None, 6, 6, 728)    0           block6_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block6_sepconv2 (SeparableConv2 (None, 6, 6, 728)    536536      block6_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block6_sepconv2_bn (BatchNormal (None, 6, 6, 728)    2912        block6_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","block6_sepconv3_act (Activation (None, 6, 6, 728)    0           block6_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","block6_sepconv3 (SeparableConv2 (None, 6, 6, 728)    536536      block6_sepconv3_act[0][0]        \n","__________________________________________________________________________________________________\n","block6_sepconv3_bn (BatchNormal (None, 6, 6, 728)    2912        block6_sepconv3[0][0]            \n","__________________________________________________________________________________________________\n","add_28 (Add)                    (None, 6, 6, 728)    0           block6_sepconv3_bn[0][0]         \n","                                                                 add_27[0][0]                     \n","__________________________________________________________________________________________________\n","block7_sepconv1_act (Activation (None, 6, 6, 728)    0           add_28[0][0]                     \n","__________________________________________________________________________________________________\n","block7_sepconv1 (SeparableConv2 (None, 6, 6, 728)    536536      block7_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block7_sepconv1_bn (BatchNormal (None, 6, 6, 728)    2912        block7_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block7_sepconv2_act (Activation (None, 6, 6, 728)    0           block7_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block7_sepconv2 (SeparableConv2 (None, 6, 6, 728)    536536      block7_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block7_sepconv2_bn (BatchNormal (None, 6, 6, 728)    2912        block7_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","block7_sepconv3_act (Activation (None, 6, 6, 728)    0           block7_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","block7_sepconv3 (SeparableConv2 (None, 6, 6, 728)    536536      block7_sepconv3_act[0][0]        \n","__________________________________________________________________________________________________\n","block7_sepconv3_bn (BatchNormal (None, 6, 6, 728)    2912        block7_sepconv3[0][0]            \n","__________________________________________________________________________________________________\n","add_29 (Add)                    (None, 6, 6, 728)    0           block7_sepconv3_bn[0][0]         \n","                                                                 add_28[0][0]                     \n","__________________________________________________________________________________________________\n","block8_sepconv1_act (Activation (None, 6, 6, 728)    0           add_29[0][0]                     \n","__________________________________________________________________________________________________\n","block8_sepconv1 (SeparableConv2 (None, 6, 6, 728)    536536      block8_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block8_sepconv1_bn (BatchNormal (None, 6, 6, 728)    2912        block8_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block8_sepconv2_act (Activation (None, 6, 6, 728)    0           block8_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block8_sepconv2 (SeparableConv2 (None, 6, 6, 728)    536536      block8_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block8_sepconv2_bn (BatchNormal (None, 6, 6, 728)    2912        block8_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","block8_sepconv3_act (Activation (None, 6, 6, 728)    0           block8_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","block8_sepconv3 (SeparableConv2 (None, 6, 6, 728)    536536      block8_sepconv3_act[0][0]        \n","__________________________________________________________________________________________________\n","block8_sepconv3_bn (BatchNormal (None, 6, 6, 728)    2912        block8_sepconv3[0][0]            \n","__________________________________________________________________________________________________\n","add_30 (Add)                    (None, 6, 6, 728)    0           block8_sepconv3_bn[0][0]         \n","                                                                 add_29[0][0]                     \n","__________________________________________________________________________________________________\n","block9_sepconv1_act (Activation (None, 6, 6, 728)    0           add_30[0][0]                     \n","__________________________________________________________________________________________________\n","block9_sepconv1 (SeparableConv2 (None, 6, 6, 728)    536536      block9_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block9_sepconv1_bn (BatchNormal (None, 6, 6, 728)    2912        block9_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block9_sepconv2_act (Activation (None, 6, 6, 728)    0           block9_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block9_sepconv2 (SeparableConv2 (None, 6, 6, 728)    536536      block9_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block9_sepconv2_bn (BatchNormal (None, 6, 6, 728)    2912        block9_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","block9_sepconv3_act (Activation (None, 6, 6, 728)    0           block9_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","block9_sepconv3 (SeparableConv2 (None, 6, 6, 728)    536536      block9_sepconv3_act[0][0]        \n","__________________________________________________________________________________________________\n","block9_sepconv3_bn (BatchNormal (None, 6, 6, 728)    2912        block9_sepconv3[0][0]            \n","__________________________________________________________________________________________________\n","add_31 (Add)                    (None, 6, 6, 728)    0           block9_sepconv3_bn[0][0]         \n","                                                                 add_30[0][0]                     \n","__________________________________________________________________________________________________\n","block10_sepconv1_act (Activatio (None, 6, 6, 728)    0           add_31[0][0]                     \n","__________________________________________________________________________________________________\n","block10_sepconv1 (SeparableConv (None, 6, 6, 728)    536536      block10_sepconv1_act[0][0]       \n","__________________________________________________________________________________________________\n","block10_sepconv1_bn (BatchNorma (None, 6, 6, 728)    2912        block10_sepconv1[0][0]           \n","__________________________________________________________________________________________________\n","block10_sepconv2_act (Activatio (None, 6, 6, 728)    0           block10_sepconv1_bn[0][0]        \n","__________________________________________________________________________________________________\n","block10_sepconv2 (SeparableConv (None, 6, 6, 728)    536536      block10_sepconv2_act[0][0]       \n","__________________________________________________________________________________________________\n","block10_sepconv2_bn (BatchNorma (None, 6, 6, 728)    2912        block10_sepconv2[0][0]           \n","__________________________________________________________________________________________________\n","block10_sepconv3_act (Activatio (None, 6, 6, 728)    0           block10_sepconv2_bn[0][0]        \n","__________________________________________________________________________________________________\n","block10_sepconv3 (SeparableConv (None, 6, 6, 728)    536536      block10_sepconv3_act[0][0]       \n","__________________________________________________________________________________________________\n","block10_sepconv3_bn (BatchNorma (None, 6, 6, 728)    2912        block10_sepconv3[0][0]           \n","__________________________________________________________________________________________________\n","add_32 (Add)                    (None, 6, 6, 728)    0           block10_sepconv3_bn[0][0]        \n","                                                                 add_31[0][0]                     \n","__________________________________________________________________________________________________\n","block11_sepconv1_act (Activatio (None, 6, 6, 728)    0           add_32[0][0]                     \n","__________________________________________________________________________________________________\n","block11_sepconv1 (SeparableConv (None, 6, 6, 728)    536536      block11_sepconv1_act[0][0]       \n","__________________________________________________________________________________________________\n","block11_sepconv1_bn (BatchNorma (None, 6, 6, 728)    2912        block11_sepconv1[0][0]           \n","__________________________________________________________________________________________________\n","block11_sepconv2_act (Activatio (None, 6, 6, 728)    0           block11_sepconv1_bn[0][0]        \n","__________________________________________________________________________________________________\n","block11_sepconv2 (SeparableConv (None, 6, 6, 728)    536536      block11_sepconv2_act[0][0]       \n","__________________________________________________________________________________________________\n","block11_sepconv2_bn (BatchNorma (None, 6, 6, 728)    2912        block11_sepconv2[0][0]           \n","__________________________________________________________________________________________________\n","block11_sepconv3_act (Activatio (None, 6, 6, 728)    0           block11_sepconv2_bn[0][0]        \n","__________________________________________________________________________________________________\n","block11_sepconv3 (SeparableConv (None, 6, 6, 728)    536536      block11_sepconv3_act[0][0]       \n","__________________________________________________________________________________________________\n","block11_sepconv3_bn (BatchNorma (None, 6, 6, 728)    2912        block11_sepconv3[0][0]           \n","__________________________________________________________________________________________________\n","add_33 (Add)                    (None, 6, 6, 728)    0           block11_sepconv3_bn[0][0]        \n","                                                                 add_32[0][0]                     \n","__________________________________________________________________________________________________\n","block12_sepconv1_act (Activatio (None, 6, 6, 728)    0           add_33[0][0]                     \n","__________________________________________________________________________________________________\n","block12_sepconv1 (SeparableConv (None, 6, 6, 728)    536536      block12_sepconv1_act[0][0]       \n","__________________________________________________________________________________________________\n","block12_sepconv1_bn (BatchNorma (None, 6, 6, 728)    2912        block12_sepconv1[0][0]           \n","__________________________________________________________________________________________________\n","block12_sepconv2_act (Activatio (None, 6, 6, 728)    0           block12_sepconv1_bn[0][0]        \n","__________________________________________________________________________________________________\n","block12_sepconv2 (SeparableConv (None, 6, 6, 728)    536536      block12_sepconv2_act[0][0]       \n","__________________________________________________________________________________________________\n","block12_sepconv2_bn (BatchNorma (None, 6, 6, 728)    2912        block12_sepconv2[0][0]           \n","__________________________________________________________________________________________________\n","block12_sepconv3_act (Activatio (None, 6, 6, 728)    0           block12_sepconv2_bn[0][0]        \n","__________________________________________________________________________________________________\n","block12_sepconv3 (SeparableConv (None, 6, 6, 728)    536536      block12_sepconv3_act[0][0]       \n","__________________________________________________________________________________________________\n","block12_sepconv3_bn (BatchNorma (None, 6, 6, 728)    2912        block12_sepconv3[0][0]           \n","__________________________________________________________________________________________________\n","add_34 (Add)                    (None, 6, 6, 728)    0           block12_sepconv3_bn[0][0]        \n","                                                                 add_33[0][0]                     \n","__________________________________________________________________________________________________\n","block13_sepconv1_act (Activatio (None, 6, 6, 728)    0           add_34[0][0]                     \n","__________________________________________________________________________________________________\n","block13_sepconv1 (SeparableConv (None, 6, 6, 728)    536536      block13_sepconv1_act[0][0]       \n","__________________________________________________________________________________________________\n","block13_sepconv1_bn (BatchNorma (None, 6, 6, 728)    2912        block13_sepconv1[0][0]           \n","__________________________________________________________________________________________________\n","block13_sepconv2_act (Activatio (None, 6, 6, 728)    0           block13_sepconv1_bn[0][0]        \n","__________________________________________________________________________________________________\n","block13_sepconv2 (SeparableConv (None, 6, 6, 1024)   752024      block13_sepconv2_act[0][0]       \n","__________________________________________________________________________________________________\n","block13_sepconv2_bn (BatchNorma (None, 6, 6, 1024)   4096        block13_sepconv2[0][0]           \n","__________________________________________________________________________________________________\n","conv2d_11 (Conv2D)              (None, 3, 3, 1024)   745472      add_34[0][0]                     \n","__________________________________________________________________________________________________\n","block13_pool (MaxPooling2D)     (None, 3, 3, 1024)   0           block13_sepconv2_bn[0][0]        \n","__________________________________________________________________________________________________\n","batch_normalization_13 (BatchNo (None, 3, 3, 1024)   4096        conv2d_11[0][0]                  \n","__________________________________________________________________________________________________\n","add_35 (Add)                    (None, 3, 3, 1024)   0           block13_pool[0][0]               \n","                                                                 batch_normalization_13[0][0]     \n","__________________________________________________________________________________________________\n","block14_sepconv1 (SeparableConv (None, 3, 3, 1536)   1582080     add_35[0][0]                     \n","__________________________________________________________________________________________________\n","block14_sepconv1_bn (BatchNorma (None, 3, 3, 1536)   6144        block14_sepconv1[0][0]           \n","__________________________________________________________________________________________________\n","block14_sepconv1_act (Activatio (None, 3, 3, 1536)   0           block14_sepconv1_bn[0][0]        \n","__________________________________________________________________________________________________\n","block14_sepconv2 (SeparableConv (None, 3, 3, 2048)   3159552     block14_sepconv1_act[0][0]       \n","__________________________________________________________________________________________________\n","block14_sepconv2_bn (BatchNorma (None, 3, 3, 2048)   8192        block14_sepconv2[0][0]           \n","__________________________________________________________________________________________________\n","block14_sepconv2_act (Activatio (None, 3, 3, 2048)   0           block14_sepconv2_bn[0][0]        \n","==================================================================================================\n","Total params: 20,861,480\n","Trainable params: 3,195,232\n","Non-trainable params: 17,666,248\n","__________________________________________________________________________________________________\n","Model: \"Xception_ADModel\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","tensor (InputLayer)          [(None, 100, 100, 3)]     0         \n","_________________________________________________________________\n","xception (Functional)        (None, 3, 3, 2048)        20861480  \n","_________________________________________________________________\n","flatten_2 (Flatten)          (None, 18432)             0         \n","_________________________________________________________________\n","dropout_4 (Dropout)          (None, 18432)             0         \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 128)               2359424   \n","_________________________________________________________________\n","batch_normalization_14 (Batc (None, 128)               512       \n","_________________________________________________________________\n","leaky_re_lu_2 (LeakyReLU)    (None, 128)               0         \n","_________________________________________________________________\n","dropout_5 (Dropout)          (None, 128)               0         \n","_________________________________________________________________\n","dense_5 (Dense)              (None, 4)                 516       \n","=================================================================\n","Total params: 23,221,932\n","Trainable params: 5,555,428\n","Non-trainable params: 17,666,504\n","_________________________________________________________________\n","Epoch 1/50\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py:543: UserWarning: Input dict contained keys ['id'] which did not match any model input. They will be ignored by the model.\n","  [n for n in tensors.keys() if n not in ref_input_names])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:432: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"],"name":"stderr"},{"output_type":"stream","text":["      2/Unknown - 1s 301ms/step - loss: 3.0072 - accuracy: 0.2500 - auc: 0.5468 - f1_score: 0.2443 - scaled_graph_loss: 0.0239WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2346s vs `on_train_batch_end` time: 0.3666s). Check your callbacks.\n","    137/Unknown - 82s 597ms/step - loss: 0.8293 - accuracy: 0.6618 - auc: 0.8905 - f1_score: 0.6381 - scaled_graph_loss: 0.0105\n","Epoch 00001: val_accuracy improved from -inf to 0.74974, saving model to /content/drive/My Drive/Projects/codes/Xception_NSL_model_checkpoints/xception_model_95\n","137/137 [==============================] - 88s 645ms/step - loss: 0.8293 - accuracy: 0.6618 - auc: 0.8905 - f1_score: 0.6381 - scaled_graph_loss: 0.0105 - val_loss: 0.5496 - val_accuracy: 0.7497 - val_auc: 0.9468 - val_f1_score: 0.6678\n","Epoch 2/50\n","137/137 [==============================] - ETA: 0s - loss: 0.4557 - accuracy: 0.8036 - auc: 0.9631 - f1_score: 0.7962 - scaled_graph_loss: 0.0080\n","Epoch 00002: val_accuracy improved from 0.74974 to 0.83699, saving model to /content/drive/My Drive/Projects/codes/Xception_NSL_model_checkpoints/xception_model_95\n","137/137 [==============================] - 86s 626ms/step - loss: 0.4557 - accuracy: 0.8036 - auc: 0.9631 - f1_score: 0.7962 - scaled_graph_loss: 0.0080 - val_loss: 0.3770 - val_accuracy: 0.8370 - val_auc: 0.9743 - val_f1_score: 0.8360\n","Epoch 3/50\n","137/137 [==============================] - ETA: 0s - loss: 0.3232 - accuracy: 0.8726 - auc: 0.9817 - f1_score: 0.8710 - scaled_graph_loss: 0.0074\n","Epoch 00003: val_accuracy improved from 0.83699 to 0.90543, saving model to /content/drive/My Drive/Projects/codes/Xception_NSL_model_checkpoints/xception_model_95\n","137/137 [==============================] - 85s 623ms/step - loss: 0.3232 - accuracy: 0.8726 - auc: 0.9817 - f1_score: 0.8710 - scaled_graph_loss: 0.0074 - val_loss: 0.2457 - val_accuracy: 0.9054 - val_auc: 0.9892 - val_f1_score: 0.9035\n","Epoch 4/50\n","137/137 [==============================] - ETA: 0s - loss: 0.2171 - accuracy: 0.9191 - auc: 0.9916 - f1_score: 0.9180 - scaled_graph_loss: 0.0060\n","Epoch 00004: val_accuracy improved from 0.90543 to 0.92320, saving model to /content/drive/My Drive/Projects/codes/Xception_NSL_model_checkpoints/xception_model_95\n","137/137 [==============================] - 86s 624ms/step - loss: 0.2171 - accuracy: 0.9191 - auc: 0.9916 - f1_score: 0.9180 - scaled_graph_loss: 0.0060 - val_loss: 0.2039 - val_accuracy: 0.9232 - val_auc: 0.9916 - val_f1_score: 0.9231\n","Epoch 5/50\n","137/137 [==============================] - ETA: 0s - loss: 0.1431 - accuracy: 0.9495 - auc: 0.9963 - f1_score: 0.9510 - scaled_graph_loss: 0.0045\n","Epoch 00005: val_accuracy improved from 0.92320 to 0.93835, saving model to /content/drive/My Drive/Projects/codes/Xception_NSL_model_checkpoints/xception_model_95\n","137/137 [==============================] - 86s 626ms/step - loss: 0.1431 - accuracy: 0.9495 - auc: 0.9963 - f1_score: 0.9510 - scaled_graph_loss: 0.0045 - val_loss: 0.1686 - val_accuracy: 0.9383 - val_auc: 0.9938 - val_f1_score: 0.9393\n","Epoch 6/50\n","137/137 [==============================] - ETA: 0s - loss: 0.0973 - accuracy: 0.9681 - auc: 0.9983 - f1_score: 0.9678 - scaled_graph_loss: 0.0033\n","Epoch 00006: val_accuracy improved from 0.93835 to 0.95089, saving model to /content/drive/My Drive/Projects/codes/Xception_NSL_model_checkpoints/xception_model_95\n","137/137 [==============================] - 85s 622ms/step - loss: 0.0973 - accuracy: 0.9681 - auc: 0.9983 - f1_score: 0.9678 - scaled_graph_loss: 0.0033 - val_loss: 0.1488 - val_accuracy: 0.9509 - val_auc: 0.9944 - val_f1_score: 0.9505\n","Epoch 00007: early stopping\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZixNdkut9Gpr"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QBplEqmx1pm1"},"source":["##5.3 Xception_NSL Model top 10 and bottom 5 layers tunning\n","### val_acc: 0.972, val_auc: 0.996, val_f1_score: 0.971"]},{"cell_type":"code","metadata":{"id":"RQfQgpa29Grs"},"source":["'''define hyper params'''\n","params = AD_params()\n","params.max_seed_nbr=5\n","params.batch_size=64\n","params.image_channels =3\n","params.image_size =(100,100)\n","params.ad_base_model_input_shape=(100,100,3)\n","params.train_tfr_path = f'{root_path}train_data.tfr'\n","\n","'''parse train_data.tfr to train image dataset with batch_size at 128'''\n","train_image_dataset = NSLDataFormat.parse_tfr_to_dataset(file_path_list=[params.train_tfr_path],\n","                                                         batch_size=params.batch_size,\n","                                                         max_neighbor_number=params.max_seed_nbr,\n","                                                         image_size=params.image_size,\n","                                                         image_channels=params.image_channels,\n","                                                         shuffle=True)\n","'''load test data with batch_size at 128 '''\n","test_image_dataset = NSLDataFormat.generate_test_tfr_image_tensor(path_list=tfr_list_test, \n","                                                                  batch_size=params.batch_size, \n","                                                                  size=params.image_size,\n","                                                                  channels=params.image_channels,\n","                                                                  shuffle=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qn_OeO8Pag-J","executionInfo":{"status":"ok","timestamp":1606257657532,"user_tz":300,"elapsed":6991,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"df2ecf16-59aa-4ce0-f837-a5ac632d9ec7"},"source":["'''define params'''\n","params.learning_rate=0.00001\n","params.restore_path = '/content/drive/My Drive/Projects/codes/Xception_NSL_model_checkpoints/xception_model_95'\n","params.checkpoint_path = '/content/drive/My Drive/Projects/codes/Xception_NSL_model_checkpoints/xception_model_new_98'\n","params.early_stop_base_line=0.98\n","params.train_epoch=50\n","params.nsl_multiplier = 0.1\n","params.nsl_sum_over_axis = -1\n","params.nsl_distance_type = nsl.configs.DistanceType.COSINE\n","'''build base_model and restore from the last training'''\n","base_model = ADModelBuilder(input_shape=params.ad_base_model_input_shape, base_model='xception').setup_Xception(top_layers=10, middle_layers=None, bottom_layers=5).get_ADModel()\n","'''build NSL model on top of base model'''\n","graph_reg_config = nsl.configs.make_graph_reg_config(neighbor_prefix=params.neighbor_prefix,\n","                                                     neighbor_weight_suffix=params.neighbor_weight_suffix,\n","                                                     max_neighbors= params.max_seed_nbr,\n","                                                     multiplier= params.nsl_multiplier,\n","                                                     distance_type= params.nsl_distance_type,\n","                                                     sum_over_axis=params.nsl_sum_over_axis)\n","graph_reg_model = nsl.keras.GraphRegularization(base_model,graph_reg_config)\n","graph_reg_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=params.learning_rate, amsgrad=True),\n","                        loss=tf.losses.CategoricalCrossentropy(),\n","                        metrics=[\"accuracy\",\"AUC\",tfa.metrics.F1Score(num_classes=4, average=\"micro\", threshold = 0.5)])\n","graph_reg_model.load_weights(params.restore_path)\n","'''set up check point & early stopping'''\n","callback_checkpoints = tf.keras.callbacks.ModelCheckpoint(filepath= params.checkpoint_path, monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=True, mode='max',\n","                                                         save_freq='epoch',options=None)\n","callback_earlystop = AccEarlyStop(val_acc_base=params.early_stop_base_line)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Note: default Xception not includes top and has imagenet weights. It is not a trainable model in ADModelBuilder. Please setup trainable layers in setup_Xception function based on the \"Layer Number\"\n","Model: \"xception\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_7 (InputLayer)            [(None, 100, 100, 3) 0                                            \n","__________________________________________________________________________________________________\n","block1_conv1 (Conv2D)           (None, 49, 49, 32)   864         input_7[0][0]                    \n","__________________________________________________________________________________________________\n","block1_conv1_bn (BatchNormaliza (None, 49, 49, 32)   128         block1_conv1[0][0]               \n","__________________________________________________________________________________________________\n","block1_conv1_act (Activation)   (None, 49, 49, 32)   0           block1_conv1_bn[0][0]            \n","__________________________________________________________________________________________________\n","block1_conv2 (Conv2D)           (None, 47, 47, 64)   18432       block1_conv1_act[0][0]           \n","__________________________________________________________________________________________________\n","block1_conv2_bn (BatchNormaliza (None, 47, 47, 64)   256         block1_conv2[0][0]               \n","__________________________________________________________________________________________________\n","block1_conv2_act (Activation)   (None, 47, 47, 64)   0           block1_conv2_bn[0][0]            \n","__________________________________________________________________________________________________\n","block2_sepconv1 (SeparableConv2 (None, 47, 47, 128)  8768        block1_conv2_act[0][0]           \n","__________________________________________________________________________________________________\n","block2_sepconv1_bn (BatchNormal (None, 47, 47, 128)  512         block2_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block2_sepconv2_act (Activation (None, 47, 47, 128)  0           block2_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block2_sepconv2 (SeparableConv2 (None, 47, 47, 128)  17536       block2_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block2_sepconv2_bn (BatchNormal (None, 47, 47, 128)  512         block2_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","conv2d_12 (Conv2D)              (None, 24, 24, 128)  8192        block1_conv2_act[0][0]           \n","__________________________________________________________________________________________________\n","block2_pool (MaxPooling2D)      (None, 24, 24, 128)  0           block2_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","batch_normalization_18 (BatchNo (None, 24, 24, 128)  512         conv2d_12[0][0]                  \n","__________________________________________________________________________________________________\n","add_36 (Add)                    (None, 24, 24, 128)  0           block2_pool[0][0]                \n","                                                                 batch_normalization_18[0][0]     \n","__________________________________________________________________________________________________\n","block3_sepconv1_act (Activation (None, 24, 24, 128)  0           add_36[0][0]                     \n","__________________________________________________________________________________________________\n","block3_sepconv1 (SeparableConv2 (None, 24, 24, 256)  33920       block3_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block3_sepconv1_bn (BatchNormal (None, 24, 24, 256)  1024        block3_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block3_sepconv2_act (Activation (None, 24, 24, 256)  0           block3_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block3_sepconv2 (SeparableConv2 (None, 24, 24, 256)  67840       block3_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block3_sepconv2_bn (BatchNormal (None, 24, 24, 256)  1024        block3_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","conv2d_13 (Conv2D)              (None, 12, 12, 256)  32768       add_36[0][0]                     \n","__________________________________________________________________________________________________\n","block3_pool (MaxPooling2D)      (None, 12, 12, 256)  0           block3_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","batch_normalization_19 (BatchNo (None, 12, 12, 256)  1024        conv2d_13[0][0]                  \n","__________________________________________________________________________________________________\n","add_37 (Add)                    (None, 12, 12, 256)  0           block3_pool[0][0]                \n","                                                                 batch_normalization_19[0][0]     \n","__________________________________________________________________________________________________\n","block4_sepconv1_act (Activation (None, 12, 12, 256)  0           add_37[0][0]                     \n","__________________________________________________________________________________________________\n","block4_sepconv1 (SeparableConv2 (None, 12, 12, 728)  188672      block4_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block4_sepconv1_bn (BatchNormal (None, 12, 12, 728)  2912        block4_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block4_sepconv2_act (Activation (None, 12, 12, 728)  0           block4_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block4_sepconv2 (SeparableConv2 (None, 12, 12, 728)  536536      block4_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block4_sepconv2_bn (BatchNormal (None, 12, 12, 728)  2912        block4_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","conv2d_14 (Conv2D)              (None, 6, 6, 728)    186368      add_37[0][0]                     \n","__________________________________________________________________________________________________\n","block4_pool (MaxPooling2D)      (None, 6, 6, 728)    0           block4_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","batch_normalization_20 (BatchNo (None, 6, 6, 728)    2912        conv2d_14[0][0]                  \n","__________________________________________________________________________________________________\n","add_38 (Add)                    (None, 6, 6, 728)    0           block4_pool[0][0]                \n","                                                                 batch_normalization_20[0][0]     \n","__________________________________________________________________________________________________\n","block5_sepconv1_act (Activation (None, 6, 6, 728)    0           add_38[0][0]                     \n","__________________________________________________________________________________________________\n","block5_sepconv1 (SeparableConv2 (None, 6, 6, 728)    536536      block5_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block5_sepconv1_bn (BatchNormal (None, 6, 6, 728)    2912        block5_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block5_sepconv2_act (Activation (None, 6, 6, 728)    0           block5_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block5_sepconv2 (SeparableConv2 (None, 6, 6, 728)    536536      block5_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block5_sepconv2_bn (BatchNormal (None, 6, 6, 728)    2912        block5_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","block5_sepconv3_act (Activation (None, 6, 6, 728)    0           block5_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","block5_sepconv3 (SeparableConv2 (None, 6, 6, 728)    536536      block5_sepconv3_act[0][0]        \n","__________________________________________________________________________________________________\n","block5_sepconv3_bn (BatchNormal (None, 6, 6, 728)    2912        block5_sepconv3[0][0]            \n","__________________________________________________________________________________________________\n","add_39 (Add)                    (None, 6, 6, 728)    0           block5_sepconv3_bn[0][0]         \n","                                                                 add_38[0][0]                     \n","__________________________________________________________________________________________________\n","block6_sepconv1_act (Activation (None, 6, 6, 728)    0           add_39[0][0]                     \n","__________________________________________________________________________________________________\n","block6_sepconv1 (SeparableConv2 (None, 6, 6, 728)    536536      block6_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block6_sepconv1_bn (BatchNormal (None, 6, 6, 728)    2912        block6_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block6_sepconv2_act (Activation (None, 6, 6, 728)    0           block6_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block6_sepconv2 (SeparableConv2 (None, 6, 6, 728)    536536      block6_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block6_sepconv2_bn (BatchNormal (None, 6, 6, 728)    2912        block6_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","block6_sepconv3_act (Activation (None, 6, 6, 728)    0           block6_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","block6_sepconv3 (SeparableConv2 (None, 6, 6, 728)    536536      block6_sepconv3_act[0][0]        \n","__________________________________________________________________________________________________\n","block6_sepconv3_bn (BatchNormal (None, 6, 6, 728)    2912        block6_sepconv3[0][0]            \n","__________________________________________________________________________________________________\n","add_40 (Add)                    (None, 6, 6, 728)    0           block6_sepconv3_bn[0][0]         \n","                                                                 add_39[0][0]                     \n","__________________________________________________________________________________________________\n","block7_sepconv1_act (Activation (None, 6, 6, 728)    0           add_40[0][0]                     \n","__________________________________________________________________________________________________\n","block7_sepconv1 (SeparableConv2 (None, 6, 6, 728)    536536      block7_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block7_sepconv1_bn (BatchNormal (None, 6, 6, 728)    2912        block7_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block7_sepconv2_act (Activation (None, 6, 6, 728)    0           block7_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block7_sepconv2 (SeparableConv2 (None, 6, 6, 728)    536536      block7_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block7_sepconv2_bn (BatchNormal (None, 6, 6, 728)    2912        block7_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","block7_sepconv3_act (Activation (None, 6, 6, 728)    0           block7_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","block7_sepconv3 (SeparableConv2 (None, 6, 6, 728)    536536      block7_sepconv3_act[0][0]        \n","__________________________________________________________________________________________________\n","block7_sepconv3_bn (BatchNormal (None, 6, 6, 728)    2912        block7_sepconv3[0][0]            \n","__________________________________________________________________________________________________\n","add_41 (Add)                    (None, 6, 6, 728)    0           block7_sepconv3_bn[0][0]         \n","                                                                 add_40[0][0]                     \n","__________________________________________________________________________________________________\n","block8_sepconv1_act (Activation (None, 6, 6, 728)    0           add_41[0][0]                     \n","__________________________________________________________________________________________________\n","block8_sepconv1 (SeparableConv2 (None, 6, 6, 728)    536536      block8_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block8_sepconv1_bn (BatchNormal (None, 6, 6, 728)    2912        block8_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block8_sepconv2_act (Activation (None, 6, 6, 728)    0           block8_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block8_sepconv2 (SeparableConv2 (None, 6, 6, 728)    536536      block8_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block8_sepconv2_bn (BatchNormal (None, 6, 6, 728)    2912        block8_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","block8_sepconv3_act (Activation (None, 6, 6, 728)    0           block8_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","block8_sepconv3 (SeparableConv2 (None, 6, 6, 728)    536536      block8_sepconv3_act[0][0]        \n","__________________________________________________________________________________________________\n","block8_sepconv3_bn (BatchNormal (None, 6, 6, 728)    2912        block8_sepconv3[0][0]            \n","__________________________________________________________________________________________________\n","add_42 (Add)                    (None, 6, 6, 728)    0           block8_sepconv3_bn[0][0]         \n","                                                                 add_41[0][0]                     \n","__________________________________________________________________________________________________\n","block9_sepconv1_act (Activation (None, 6, 6, 728)    0           add_42[0][0]                     \n","__________________________________________________________________________________________________\n","block9_sepconv1 (SeparableConv2 (None, 6, 6, 728)    536536      block9_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block9_sepconv1_bn (BatchNormal (None, 6, 6, 728)    2912        block9_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block9_sepconv2_act (Activation (None, 6, 6, 728)    0           block9_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block9_sepconv2 (SeparableConv2 (None, 6, 6, 728)    536536      block9_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block9_sepconv2_bn (BatchNormal (None, 6, 6, 728)    2912        block9_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","block9_sepconv3_act (Activation (None, 6, 6, 728)    0           block9_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","block9_sepconv3 (SeparableConv2 (None, 6, 6, 728)    536536      block9_sepconv3_act[0][0]        \n","__________________________________________________________________________________________________\n","block9_sepconv3_bn (BatchNormal (None, 6, 6, 728)    2912        block9_sepconv3[0][0]            \n","__________________________________________________________________________________________________\n","add_43 (Add)                    (None, 6, 6, 728)    0           block9_sepconv3_bn[0][0]         \n","                                                                 add_42[0][0]                     \n","__________________________________________________________________________________________________\n","block10_sepconv1_act (Activatio (None, 6, 6, 728)    0           add_43[0][0]                     \n","__________________________________________________________________________________________________\n","block10_sepconv1 (SeparableConv (None, 6, 6, 728)    536536      block10_sepconv1_act[0][0]       \n","__________________________________________________________________________________________________\n","block10_sepconv1_bn (BatchNorma (None, 6, 6, 728)    2912        block10_sepconv1[0][0]           \n","__________________________________________________________________________________________________\n","block10_sepconv2_act (Activatio (None, 6, 6, 728)    0           block10_sepconv1_bn[0][0]        \n","__________________________________________________________________________________________________\n","block10_sepconv2 (SeparableConv (None, 6, 6, 728)    536536      block10_sepconv2_act[0][0]       \n","__________________________________________________________________________________________________\n","block10_sepconv2_bn (BatchNorma (None, 6, 6, 728)    2912        block10_sepconv2[0][0]           \n","__________________________________________________________________________________________________\n","block10_sepconv3_act (Activatio (None, 6, 6, 728)    0           block10_sepconv2_bn[0][0]        \n","__________________________________________________________________________________________________\n","block10_sepconv3 (SeparableConv (None, 6, 6, 728)    536536      block10_sepconv3_act[0][0]       \n","__________________________________________________________________________________________________\n","block10_sepconv3_bn (BatchNorma (None, 6, 6, 728)    2912        block10_sepconv3[0][0]           \n","__________________________________________________________________________________________________\n","add_44 (Add)                    (None, 6, 6, 728)    0           block10_sepconv3_bn[0][0]        \n","                                                                 add_43[0][0]                     \n","__________________________________________________________________________________________________\n","block11_sepconv1_act (Activatio (None, 6, 6, 728)    0           add_44[0][0]                     \n","__________________________________________________________________________________________________\n","block11_sepconv1 (SeparableConv (None, 6, 6, 728)    536536      block11_sepconv1_act[0][0]       \n","__________________________________________________________________________________________________\n","block11_sepconv1_bn (BatchNorma (None, 6, 6, 728)    2912        block11_sepconv1[0][0]           \n","__________________________________________________________________________________________________\n","block11_sepconv2_act (Activatio (None, 6, 6, 728)    0           block11_sepconv1_bn[0][0]        \n","__________________________________________________________________________________________________\n","block11_sepconv2 (SeparableConv (None, 6, 6, 728)    536536      block11_sepconv2_act[0][0]       \n","__________________________________________________________________________________________________\n","block11_sepconv2_bn (BatchNorma (None, 6, 6, 728)    2912        block11_sepconv2[0][0]           \n","__________________________________________________________________________________________________\n","block11_sepconv3_act (Activatio (None, 6, 6, 728)    0           block11_sepconv2_bn[0][0]        \n","__________________________________________________________________________________________________\n","block11_sepconv3 (SeparableConv (None, 6, 6, 728)    536536      block11_sepconv3_act[0][0]       \n","__________________________________________________________________________________________________\n","block11_sepconv3_bn (BatchNorma (None, 6, 6, 728)    2912        block11_sepconv3[0][0]           \n","__________________________________________________________________________________________________\n","add_45 (Add)                    (None, 6, 6, 728)    0           block11_sepconv3_bn[0][0]        \n","                                                                 add_44[0][0]                     \n","__________________________________________________________________________________________________\n","block12_sepconv1_act (Activatio (None, 6, 6, 728)    0           add_45[0][0]                     \n","__________________________________________________________________________________________________\n","block12_sepconv1 (SeparableConv (None, 6, 6, 728)    536536      block12_sepconv1_act[0][0]       \n","__________________________________________________________________________________________________\n","block12_sepconv1_bn (BatchNorma (None, 6, 6, 728)    2912        block12_sepconv1[0][0]           \n","__________________________________________________________________________________________________\n","block12_sepconv2_act (Activatio (None, 6, 6, 728)    0           block12_sepconv1_bn[0][0]        \n","__________________________________________________________________________________________________\n","block12_sepconv2 (SeparableConv (None, 6, 6, 728)    536536      block12_sepconv2_act[0][0]       \n","__________________________________________________________________________________________________\n","block12_sepconv2_bn (BatchNorma (None, 6, 6, 728)    2912        block12_sepconv2[0][0]           \n","__________________________________________________________________________________________________\n","block12_sepconv3_act (Activatio (None, 6, 6, 728)    0           block12_sepconv2_bn[0][0]        \n","__________________________________________________________________________________________________\n","block12_sepconv3 (SeparableConv (None, 6, 6, 728)    536536      block12_sepconv3_act[0][0]       \n","__________________________________________________________________________________________________\n","block12_sepconv3_bn (BatchNorma (None, 6, 6, 728)    2912        block12_sepconv3[0][0]           \n","__________________________________________________________________________________________________\n","add_46 (Add)                    (None, 6, 6, 728)    0           block12_sepconv3_bn[0][0]        \n","                                                                 add_45[0][0]                     \n","__________________________________________________________________________________________________\n","block13_sepconv1_act (Activatio (None, 6, 6, 728)    0           add_46[0][0]                     \n","__________________________________________________________________________________________________\n","block13_sepconv1 (SeparableConv (None, 6, 6, 728)    536536      block13_sepconv1_act[0][0]       \n","__________________________________________________________________________________________________\n","block13_sepconv1_bn (BatchNorma (None, 6, 6, 728)    2912        block13_sepconv1[0][0]           \n","__________________________________________________________________________________________________\n","block13_sepconv2_act (Activatio (None, 6, 6, 728)    0           block13_sepconv1_bn[0][0]        \n","__________________________________________________________________________________________________\n","block13_sepconv2 (SeparableConv (None, 6, 6, 1024)   752024      block13_sepconv2_act[0][0]       \n","__________________________________________________________________________________________________\n","block13_sepconv2_bn (BatchNorma (None, 6, 6, 1024)   4096        block13_sepconv2[0][0]           \n","__________________________________________________________________________________________________\n","conv2d_15 (Conv2D)              (None, 3, 3, 1024)   745472      add_46[0][0]                     \n","__________________________________________________________________________________________________\n","block13_pool (MaxPooling2D)     (None, 3, 3, 1024)   0           block13_sepconv2_bn[0][0]        \n","__________________________________________________________________________________________________\n","batch_normalization_21 (BatchNo (None, 3, 3, 1024)   4096        conv2d_15[0][0]                  \n","__________________________________________________________________________________________________\n","add_47 (Add)                    (None, 3, 3, 1024)   0           block13_pool[0][0]               \n","                                                                 batch_normalization_21[0][0]     \n","__________________________________________________________________________________________________\n","block14_sepconv1 (SeparableConv (None, 3, 3, 1536)   1582080     add_47[0][0]                     \n","__________________________________________________________________________________________________\n","block14_sepconv1_bn (BatchNorma (None, 3, 3, 1536)   6144        block14_sepconv1[0][0]           \n","__________________________________________________________________________________________________\n","block14_sepconv1_act (Activatio (None, 3, 3, 1536)   0           block14_sepconv1_bn[0][0]        \n","__________________________________________________________________________________________________\n","block14_sepconv2 (SeparableConv (None, 3, 3, 2048)   3159552     block14_sepconv1_act[0][0]       \n","__________________________________________________________________________________________________\n","block14_sepconv2_bn (BatchNorma (None, 3, 3, 2048)   8192        block14_sepconv2[0][0]           \n","__________________________________________________________________________________________________\n","block14_sepconv2_act (Activatio (None, 3, 3, 2048)   0           block14_sepconv2_bn[0][0]        \n","==================================================================================================\n","Total params: 20,861,480\n","Trainable params: 3,195,232\n","Non-trainable params: 17,666,248\n","__________________________________________________________________________________________________\n","Model: \"Xception_ADModel\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","tensor (InputLayer)          [(None, 100, 100, 3)]     0         \n","_________________________________________________________________\n","xception (Functional)        (None, 3, 3, 2048)        20861480  \n","_________________________________________________________________\n","flatten_6 (Flatten)          (None, 18432)             0         \n","_________________________________________________________________\n","dropout_11 (Dropout)         (None, 18432)             0         \n","_________________________________________________________________\n","dense_12 (Dense)             (None, 128)               2359424   \n","_________________________________________________________________\n","batch_normalization_22 (Batc (None, 128)               512       \n","_________________________________________________________________\n","leaky_re_lu_6 (LeakyReLU)    (None, 128)               0         \n","_________________________________________________________________\n","dropout_12 (Dropout)         (None, 128)               0         \n","_________________________________________________________________\n","dense_13 (Dense)             (None, 4)                 516       \n","=================================================================\n","Total params: 23,221,932\n","Trainable params: 5,555,428\n","Non-trainable params: 17,666,504\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TVbtWj9t1oqo","executionInfo":{"status":"ok","timestamp":1606057680269,"user_tz":300,"elapsed":1050510,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"89ff8458-fbd8-453a-8009-544a9cbed844"},"source":["'''train the nsl model'''\n","graph_reg_history = graph_reg_model.fit(train_image_dataset, \n","                                        validation_data=test_image_dataset,\n","                                        callbacks = [callback_checkpoints, callback_earlystop],\n","                                        epochs=params.train_epoch,\n","                                        verbose=1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Note: default Xception not includes top and has imagenet weights. It is not a trainable model in ADModelBuilder. Please setup trainable layers in setup_Xception function based on the \"Layer Number\"\n","Model: \"xception\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_4 (InputLayer)            [(None, 100, 100, 3) 0                                            \n","__________________________________________________________________________________________________\n","block1_conv1 (Conv2D)           (None, 49, 49, 32)   864         input_4[0][0]                    \n","__________________________________________________________________________________________________\n","block1_conv1_bn (BatchNormaliza (None, 49, 49, 32)   128         block1_conv1[0][0]               \n","__________________________________________________________________________________________________\n","block1_conv1_act (Activation)   (None, 49, 49, 32)   0           block1_conv1_bn[0][0]            \n","__________________________________________________________________________________________________\n","block1_conv2 (Conv2D)           (None, 47, 47, 64)   18432       block1_conv1_act[0][0]           \n","__________________________________________________________________________________________________\n","block1_conv2_bn (BatchNormaliza (None, 47, 47, 64)   256         block1_conv2[0][0]               \n","__________________________________________________________________________________________________\n","block1_conv2_act (Activation)   (None, 47, 47, 64)   0           block1_conv2_bn[0][0]            \n","__________________________________________________________________________________________________\n","block2_sepconv1 (SeparableConv2 (None, 47, 47, 128)  8768        block1_conv2_act[0][0]           \n","__________________________________________________________________________________________________\n","block2_sepconv1_bn (BatchNormal (None, 47, 47, 128)  512         block2_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block2_sepconv2_act (Activation (None, 47, 47, 128)  0           block2_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block2_sepconv2 (SeparableConv2 (None, 47, 47, 128)  17536       block2_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block2_sepconv2_bn (BatchNormal (None, 47, 47, 128)  512         block2_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","conv2d_12 (Conv2D)              (None, 24, 24, 128)  8192        block1_conv2_act[0][0]           \n","__________________________________________________________________________________________________\n","block2_pool (MaxPooling2D)      (None, 24, 24, 128)  0           block2_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","batch_normalization_15 (BatchNo (None, 24, 24, 128)  512         conv2d_12[0][0]                  \n","__________________________________________________________________________________________________\n","add_36 (Add)                    (None, 24, 24, 128)  0           block2_pool[0][0]                \n","                                                                 batch_normalization_15[0][0]     \n","__________________________________________________________________________________________________\n","block3_sepconv1_act (Activation (None, 24, 24, 128)  0           add_36[0][0]                     \n","__________________________________________________________________________________________________\n","block3_sepconv1 (SeparableConv2 (None, 24, 24, 256)  33920       block3_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block3_sepconv1_bn (BatchNormal (None, 24, 24, 256)  1024        block3_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block3_sepconv2_act (Activation (None, 24, 24, 256)  0           block3_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block3_sepconv2 (SeparableConv2 (None, 24, 24, 256)  67840       block3_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block3_sepconv2_bn (BatchNormal (None, 24, 24, 256)  1024        block3_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","conv2d_13 (Conv2D)              (None, 12, 12, 256)  32768       add_36[0][0]                     \n","__________________________________________________________________________________________________\n","block3_pool (MaxPooling2D)      (None, 12, 12, 256)  0           block3_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","batch_normalization_16 (BatchNo (None, 12, 12, 256)  1024        conv2d_13[0][0]                  \n","__________________________________________________________________________________________________\n","add_37 (Add)                    (None, 12, 12, 256)  0           block3_pool[0][0]                \n","                                                                 batch_normalization_16[0][0]     \n","__________________________________________________________________________________________________\n","block4_sepconv1_act (Activation (None, 12, 12, 256)  0           add_37[0][0]                     \n","__________________________________________________________________________________________________\n","block4_sepconv1 (SeparableConv2 (None, 12, 12, 728)  188672      block4_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block4_sepconv1_bn (BatchNormal (None, 12, 12, 728)  2912        block4_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block4_sepconv2_act (Activation (None, 12, 12, 728)  0           block4_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block4_sepconv2 (SeparableConv2 (None, 12, 12, 728)  536536      block4_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block4_sepconv2_bn (BatchNormal (None, 12, 12, 728)  2912        block4_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","conv2d_14 (Conv2D)              (None, 6, 6, 728)    186368      add_37[0][0]                     \n","__________________________________________________________________________________________________\n","block4_pool (MaxPooling2D)      (None, 6, 6, 728)    0           block4_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","batch_normalization_17 (BatchNo (None, 6, 6, 728)    2912        conv2d_14[0][0]                  \n","__________________________________________________________________________________________________\n","add_38 (Add)                    (None, 6, 6, 728)    0           block4_pool[0][0]                \n","                                                                 batch_normalization_17[0][0]     \n","__________________________________________________________________________________________________\n","block5_sepconv1_act (Activation (None, 6, 6, 728)    0           add_38[0][0]                     \n","__________________________________________________________________________________________________\n","block5_sepconv1 (SeparableConv2 (None, 6, 6, 728)    536536      block5_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block5_sepconv1_bn (BatchNormal (None, 6, 6, 728)    2912        block5_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block5_sepconv2_act (Activation (None, 6, 6, 728)    0           block5_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block5_sepconv2 (SeparableConv2 (None, 6, 6, 728)    536536      block5_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block5_sepconv2_bn (BatchNormal (None, 6, 6, 728)    2912        block5_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","block5_sepconv3_act (Activation (None, 6, 6, 728)    0           block5_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","block5_sepconv3 (SeparableConv2 (None, 6, 6, 728)    536536      block5_sepconv3_act[0][0]        \n","__________________________________________________________________________________________________\n","block5_sepconv3_bn (BatchNormal (None, 6, 6, 728)    2912        block5_sepconv3[0][0]            \n","__________________________________________________________________________________________________\n","add_39 (Add)                    (None, 6, 6, 728)    0           block5_sepconv3_bn[0][0]         \n","                                                                 add_38[0][0]                     \n","__________________________________________________________________________________________________\n","block6_sepconv1_act (Activation (None, 6, 6, 728)    0           add_39[0][0]                     \n","__________________________________________________________________________________________________\n","block6_sepconv1 (SeparableConv2 (None, 6, 6, 728)    536536      block6_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block6_sepconv1_bn (BatchNormal (None, 6, 6, 728)    2912        block6_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block6_sepconv2_act (Activation (None, 6, 6, 728)    0           block6_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block6_sepconv2 (SeparableConv2 (None, 6, 6, 728)    536536      block6_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block6_sepconv2_bn (BatchNormal (None, 6, 6, 728)    2912        block6_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","block6_sepconv3_act (Activation (None, 6, 6, 728)    0           block6_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","block6_sepconv3 (SeparableConv2 (None, 6, 6, 728)    536536      block6_sepconv3_act[0][0]        \n","__________________________________________________________________________________________________\n","block6_sepconv3_bn (BatchNormal (None, 6, 6, 728)    2912        block6_sepconv3[0][0]            \n","__________________________________________________________________________________________________\n","add_40 (Add)                    (None, 6, 6, 728)    0           block6_sepconv3_bn[0][0]         \n","                                                                 add_39[0][0]                     \n","__________________________________________________________________________________________________\n","block7_sepconv1_act (Activation (None, 6, 6, 728)    0           add_40[0][0]                     \n","__________________________________________________________________________________________________\n","block7_sepconv1 (SeparableConv2 (None, 6, 6, 728)    536536      block7_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block7_sepconv1_bn (BatchNormal (None, 6, 6, 728)    2912        block7_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block7_sepconv2_act (Activation (None, 6, 6, 728)    0           block7_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block7_sepconv2 (SeparableConv2 (None, 6, 6, 728)    536536      block7_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block7_sepconv2_bn (BatchNormal (None, 6, 6, 728)    2912        block7_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","block7_sepconv3_act (Activation (None, 6, 6, 728)    0           block7_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","block7_sepconv3 (SeparableConv2 (None, 6, 6, 728)    536536      block7_sepconv3_act[0][0]        \n","__________________________________________________________________________________________________\n","block7_sepconv3_bn (BatchNormal (None, 6, 6, 728)    2912        block7_sepconv3[0][0]            \n","__________________________________________________________________________________________________\n","add_41 (Add)                    (None, 6, 6, 728)    0           block7_sepconv3_bn[0][0]         \n","                                                                 add_40[0][0]                     \n","__________________________________________________________________________________________________\n","block8_sepconv1_act (Activation (None, 6, 6, 728)    0           add_41[0][0]                     \n","__________________________________________________________________________________________________\n","block8_sepconv1 (SeparableConv2 (None, 6, 6, 728)    536536      block8_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block8_sepconv1_bn (BatchNormal (None, 6, 6, 728)    2912        block8_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block8_sepconv2_act (Activation (None, 6, 6, 728)    0           block8_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block8_sepconv2 (SeparableConv2 (None, 6, 6, 728)    536536      block8_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block8_sepconv2_bn (BatchNormal (None, 6, 6, 728)    2912        block8_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","block8_sepconv3_act (Activation (None, 6, 6, 728)    0           block8_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","block8_sepconv3 (SeparableConv2 (None, 6, 6, 728)    536536      block8_sepconv3_act[0][0]        \n","__________________________________________________________________________________________________\n","block8_sepconv3_bn (BatchNormal (None, 6, 6, 728)    2912        block8_sepconv3[0][0]            \n","__________________________________________________________________________________________________\n","add_42 (Add)                    (None, 6, 6, 728)    0           block8_sepconv3_bn[0][0]         \n","                                                                 add_41[0][0]                     \n","__________________________________________________________________________________________________\n","block9_sepconv1_act (Activation (None, 6, 6, 728)    0           add_42[0][0]                     \n","__________________________________________________________________________________________________\n","block9_sepconv1 (SeparableConv2 (None, 6, 6, 728)    536536      block9_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block9_sepconv1_bn (BatchNormal (None, 6, 6, 728)    2912        block9_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block9_sepconv2_act (Activation (None, 6, 6, 728)    0           block9_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block9_sepconv2 (SeparableConv2 (None, 6, 6, 728)    536536      block9_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block9_sepconv2_bn (BatchNormal (None, 6, 6, 728)    2912        block9_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","block9_sepconv3_act (Activation (None, 6, 6, 728)    0           block9_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","block9_sepconv3 (SeparableConv2 (None, 6, 6, 728)    536536      block9_sepconv3_act[0][0]        \n","__________________________________________________________________________________________________\n","block9_sepconv3_bn (BatchNormal (None, 6, 6, 728)    2912        block9_sepconv3[0][0]            \n","__________________________________________________________________________________________________\n","add_43 (Add)                    (None, 6, 6, 728)    0           block9_sepconv3_bn[0][0]         \n","                                                                 add_42[0][0]                     \n","__________________________________________________________________________________________________\n","block10_sepconv1_act (Activatio (None, 6, 6, 728)    0           add_43[0][0]                     \n","__________________________________________________________________________________________________\n","block10_sepconv1 (SeparableConv (None, 6, 6, 728)    536536      block10_sepconv1_act[0][0]       \n","__________________________________________________________________________________________________\n","block10_sepconv1_bn (BatchNorma (None, 6, 6, 728)    2912        block10_sepconv1[0][0]           \n","__________________________________________________________________________________________________\n","block10_sepconv2_act (Activatio (None, 6, 6, 728)    0           block10_sepconv1_bn[0][0]        \n","__________________________________________________________________________________________________\n","block10_sepconv2 (SeparableConv (None, 6, 6, 728)    536536      block10_sepconv2_act[0][0]       \n","__________________________________________________________________________________________________\n","block10_sepconv2_bn (BatchNorma (None, 6, 6, 728)    2912        block10_sepconv2[0][0]           \n","__________________________________________________________________________________________________\n","block10_sepconv3_act (Activatio (None, 6, 6, 728)    0           block10_sepconv2_bn[0][0]        \n","__________________________________________________________________________________________________\n","block10_sepconv3 (SeparableConv (None, 6, 6, 728)    536536      block10_sepconv3_act[0][0]       \n","__________________________________________________________________________________________________\n","block10_sepconv3_bn (BatchNorma (None, 6, 6, 728)    2912        block10_sepconv3[0][0]           \n","__________________________________________________________________________________________________\n","add_44 (Add)                    (None, 6, 6, 728)    0           block10_sepconv3_bn[0][0]        \n","                                                                 add_43[0][0]                     \n","__________________________________________________________________________________________________\n","block11_sepconv1_act (Activatio (None, 6, 6, 728)    0           add_44[0][0]                     \n","__________________________________________________________________________________________________\n","block11_sepconv1 (SeparableConv (None, 6, 6, 728)    536536      block11_sepconv1_act[0][0]       \n","__________________________________________________________________________________________________\n","block11_sepconv1_bn (BatchNorma (None, 6, 6, 728)    2912        block11_sepconv1[0][0]           \n","__________________________________________________________________________________________________\n","block11_sepconv2_act (Activatio (None, 6, 6, 728)    0           block11_sepconv1_bn[0][0]        \n","__________________________________________________________________________________________________\n","block11_sepconv2 (SeparableConv (None, 6, 6, 728)    536536      block11_sepconv2_act[0][0]       \n","__________________________________________________________________________________________________\n","block11_sepconv2_bn (BatchNorma (None, 6, 6, 728)    2912        block11_sepconv2[0][0]           \n","__________________________________________________________________________________________________\n","block11_sepconv3_act (Activatio (None, 6, 6, 728)    0           block11_sepconv2_bn[0][0]        \n","__________________________________________________________________________________________________\n","block11_sepconv3 (SeparableConv (None, 6, 6, 728)    536536      block11_sepconv3_act[0][0]       \n","__________________________________________________________________________________________________\n","block11_sepconv3_bn (BatchNorma (None, 6, 6, 728)    2912        block11_sepconv3[0][0]           \n","__________________________________________________________________________________________________\n","add_45 (Add)                    (None, 6, 6, 728)    0           block11_sepconv3_bn[0][0]        \n","                                                                 add_44[0][0]                     \n","__________________________________________________________________________________________________\n","block12_sepconv1_act (Activatio (None, 6, 6, 728)    0           add_45[0][0]                     \n","__________________________________________________________________________________________________\n","block12_sepconv1 (SeparableConv (None, 6, 6, 728)    536536      block12_sepconv1_act[0][0]       \n","__________________________________________________________________________________________________\n","block12_sepconv1_bn (BatchNorma (None, 6, 6, 728)    2912        block12_sepconv1[0][0]           \n","__________________________________________________________________________________________________\n","block12_sepconv2_act (Activatio (None, 6, 6, 728)    0           block12_sepconv1_bn[0][0]        \n","__________________________________________________________________________________________________\n","block12_sepconv2 (SeparableConv (None, 6, 6, 728)    536536      block12_sepconv2_act[0][0]       \n","__________________________________________________________________________________________________\n","block12_sepconv2_bn (BatchNorma (None, 6, 6, 728)    2912        block12_sepconv2[0][0]           \n","__________________________________________________________________________________________________\n","block12_sepconv3_act (Activatio (None, 6, 6, 728)    0           block12_sepconv2_bn[0][0]        \n","__________________________________________________________________________________________________\n","block12_sepconv3 (SeparableConv (None, 6, 6, 728)    536536      block12_sepconv3_act[0][0]       \n","__________________________________________________________________________________________________\n","block12_sepconv3_bn (BatchNorma (None, 6, 6, 728)    2912        block12_sepconv3[0][0]           \n","__________________________________________________________________________________________________\n","add_46 (Add)                    (None, 6, 6, 728)    0           block12_sepconv3_bn[0][0]        \n","                                                                 add_45[0][0]                     \n","__________________________________________________________________________________________________\n","block13_sepconv1_act (Activatio (None, 6, 6, 728)    0           add_46[0][0]                     \n","__________________________________________________________________________________________________\n","block13_sepconv1 (SeparableConv (None, 6, 6, 728)    536536      block13_sepconv1_act[0][0]       \n","__________________________________________________________________________________________________\n","block13_sepconv1_bn (BatchNorma (None, 6, 6, 728)    2912        block13_sepconv1[0][0]           \n","__________________________________________________________________________________________________\n","block13_sepconv2_act (Activatio (None, 6, 6, 728)    0           block13_sepconv1_bn[0][0]        \n","__________________________________________________________________________________________________\n","block13_sepconv2 (SeparableConv (None, 6, 6, 1024)   752024      block13_sepconv2_act[0][0]       \n","__________________________________________________________________________________________________\n","block13_sepconv2_bn (BatchNorma (None, 6, 6, 1024)   4096        block13_sepconv2[0][0]           \n","__________________________________________________________________________________________________\n","conv2d_15 (Conv2D)              (None, 3, 3, 1024)   745472      add_46[0][0]                     \n","__________________________________________________________________________________________________\n","block13_pool (MaxPooling2D)     (None, 3, 3, 1024)   0           block13_sepconv2_bn[0][0]        \n","__________________________________________________________________________________________________\n","batch_normalization_18 (BatchNo (None, 3, 3, 1024)   4096        conv2d_15[0][0]                  \n","__________________________________________________________________________________________________\n","add_47 (Add)                    (None, 3, 3, 1024)   0           block13_pool[0][0]               \n","                                                                 batch_normalization_18[0][0]     \n","__________________________________________________________________________________________________\n","block14_sepconv1 (SeparableConv (None, 3, 3, 1536)   1582080     add_47[0][0]                     \n","__________________________________________________________________________________________________\n","block14_sepconv1_bn (BatchNorma (None, 3, 3, 1536)   6144        block14_sepconv1[0][0]           \n","__________________________________________________________________________________________________\n","block14_sepconv1_act (Activatio (None, 3, 3, 1536)   0           block14_sepconv1_bn[0][0]        \n","__________________________________________________________________________________________________\n","block14_sepconv2 (SeparableConv (None, 3, 3, 2048)   3159552     block14_sepconv1_act[0][0]       \n","__________________________________________________________________________________________________\n","block14_sepconv2_bn (BatchNorma (None, 3, 3, 2048)   8192        block14_sepconv2[0][0]           \n","__________________________________________________________________________________________________\n","block14_sepconv2_act (Activatio (None, 3, 3, 2048)   0           block14_sepconv2_bn[0][0]        \n","==================================================================================================\n","Total params: 20,861,480\n","Trainable params: 3,195,232\n","Non-trainable params: 17,666,248\n","__________________________________________________________________________________________________\n","Model: \"Xception_ADModel\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","tensor (InputLayer)          [(None, 100, 100, 3)]     0         \n","_________________________________________________________________\n","xception (Functional)        (None, 3, 3, 2048)        20861480  \n","_________________________________________________________________\n","flatten_3 (Flatten)          (None, 18432)             0         \n","_________________________________________________________________\n","dropout_6 (Dropout)          (None, 18432)             0         \n","_________________________________________________________________\n","dense_6 (Dense)              (None, 128)               2359424   \n","_________________________________________________________________\n","batch_normalization_19 (Batc (None, 128)               512       \n","_________________________________________________________________\n","leaky_re_lu_3 (LeakyReLU)    (None, 128)               0         \n","_________________________________________________________________\n","dropout_7 (Dropout)          (None, 128)               0         \n","_________________________________________________________________\n","dense_7 (Dense)              (None, 4)                 516       \n","=================================================================\n","Total params: 23,221,932\n","Trainable params: 5,555,428\n","Non-trainable params: 17,666,504\n","_________________________________________________________________\n","Epoch 1/50\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py:543: UserWarning: Input dict contained keys ['id'] which did not match any model input. They will be ignored by the model.\n","  [n for n in tensors.keys() if n not in ref_input_names])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:432: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"],"name":"stderr"},{"output_type":"stream","text":["      2/Unknown - 1s 297ms/step - loss: 0.0806 - accuracy: 0.9766 - auc: 0.9992 - f1_score: 0.9725 - scaled_graph_loss: 0.0031WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2242s vs `on_train_batch_end` time: 0.3688s). Check your callbacks.\n","    137/Unknown - 80s 587ms/step - loss: 0.0793 - accuracy: 0.9744 - auc: 0.9987 - f1_score: 0.9745 - scaled_graph_loss: 0.0028\n","Epoch 00001: val_accuracy improved from -inf to 0.95690, saving model to /content/drive/My Drive/Projects/codes/Xception_NSL_model_checkpoints/xception_model_new_98\n","137/137 [==============================] - 87s 635ms/step - loss: 0.0793 - accuracy: 0.9744 - auc: 0.9987 - f1_score: 0.9745 - scaled_graph_loss: 0.0028 - val_loss: 0.1284 - val_accuracy: 0.9569 - val_auc: 0.9962 - val_f1_score: 0.9694\n","Epoch 2/50\n","137/137 [==============================] - ETA: 0s - loss: 0.0607 - accuracy: 0.9817 - auc: 0.9991 - f1_score: 0.9816 - scaled_graph_loss: 0.0022\n","Epoch 00002: val_accuracy did not improve from 0.95690\n","137/137 [==============================] - 85s 617ms/step - loss: 0.0607 - accuracy: 0.9817 - auc: 0.9991 - f1_score: 0.9816 - scaled_graph_loss: 0.0022 - val_loss: 0.1722 - val_accuracy: 0.9420 - val_auc: 0.9935 - val_f1_score: 0.9422\n","Epoch 3/50\n","137/137 [==============================] - ETA: 0s - loss: 0.0487 - accuracy: 0.9830 - auc: 0.9996 - f1_score: 0.9831 - scaled_graph_loss: 0.0018\n","Epoch 00003: val_accuracy improved from 0.95690 to 0.97048, saving model to /content/drive/My Drive/Projects/codes/Xception_NSL_model_checkpoints/xception_model_new_98\n","137/137 [==============================] - 86s 625ms/step - loss: 0.0487 - accuracy: 0.9830 - auc: 0.9996 - f1_score: 0.9831 - scaled_graph_loss: 0.0018 - val_loss: 0.0989 - val_accuracy: 0.9705 - val_auc: 0.9969 - val_f1_score: 0.9706\n","Epoch 4/50\n","137/137 [==============================] - ETA: 0s - loss: 0.0364 - accuracy: 0.9889 - auc: 0.9998 - f1_score: 0.9889 - scaled_graph_loss: 0.0013\n","Epoch 00004: val_accuracy did not improve from 0.97048\n","137/137 [==============================] - 85s 617ms/step - loss: 0.0364 - accuracy: 0.9889 - auc: 0.9998 - f1_score: 0.9889 - scaled_graph_loss: 0.0013 - val_loss: 0.1047 - val_accuracy: 0.9687 - val_auc: 0.9966 - val_f1_score: 0.9693\n","Epoch 5/50\n","137/137 [==============================] - ETA: 0s - loss: 0.0245 - accuracy: 0.9926 - auc: 0.9998 - f1_score: 0.9927 - scaled_graph_loss: 9.2308e-04\n","Epoch 00005: val_accuracy did not improve from 0.97048\n","137/137 [==============================] - 84s 617ms/step - loss: 0.0245 - accuracy: 0.9926 - auc: 0.9998 - f1_score: 0.9927 - scaled_graph_loss: 9.2308e-04 - val_loss: 0.0981 - val_accuracy: 0.9702 - val_auc: 0.9965 - val_f1_score: 0.9701\n","Epoch 6/50\n","137/137 [==============================] - ETA: 0s - loss: 0.0237 - accuracy: 0.9924 - auc: 0.9999 - f1_score: 0.9921 - scaled_graph_loss: 8.9044e-04\n","Epoch 00006: val_accuracy improved from 0.97048 to 0.97466, saving model to /content/drive/My Drive/Projects/codes/Xception_NSL_model_checkpoints/xception_model_new_98\n","137/137 [==============================] - 85s 624ms/step - loss: 0.0237 - accuracy: 0.9924 - auc: 0.9999 - f1_score: 0.9921 - scaled_graph_loss: 8.9044e-04 - val_loss: 0.0839 - val_accuracy: 0.9747 - val_auc: 0.9972 - val_f1_score: 0.9750\n","Epoch 7/50\n","137/137 [==============================] - ETA: 0s - loss: 0.0160 - accuracy: 0.9960 - auc: 1.0000 - f1_score: 0.9961 - scaled_graph_loss: 6.6281e-04\n","Epoch 00007: val_accuracy improved from 0.97466 to 0.97571, saving model to /content/drive/My Drive/Projects/codes/Xception_NSL_model_checkpoints/xception_model_new_98\n","137/137 [==============================] - 86s 626ms/step - loss: 0.0160 - accuracy: 0.9960 - auc: 1.0000 - f1_score: 0.9961 - scaled_graph_loss: 6.6281e-04 - val_loss: 0.0918 - val_accuracy: 0.9757 - val_auc: 0.9966 - val_f1_score: 0.9756\n","Epoch 8/50\n","137/137 [==============================] - ETA: 0s - loss: 0.0221 - accuracy: 0.9935 - auc: 0.9998 - f1_score: 0.9935 - scaled_graph_loss: 7.9495e-04\n","Epoch 00008: val_accuracy did not improve from 0.97571\n","137/137 [==============================] - 84s 616ms/step - loss: 0.0221 - accuracy: 0.9935 - auc: 0.9998 - f1_score: 0.9935 - scaled_graph_loss: 7.9495e-04 - val_loss: 0.0923 - val_accuracy: 0.9747 - val_auc: 0.9960 - val_f1_score: 0.9742\n","Epoch 9/50\n","137/137 [==============================] - ETA: 0s - loss: 0.0213 - accuracy: 0.9929 - auc: 0.9999 - f1_score: 0.9929 - scaled_graph_loss: 8.2664e-04\n","Epoch 00009: val_accuracy did not improve from 0.97571\n","137/137 [==============================] - 85s 618ms/step - loss: 0.0213 - accuracy: 0.9929 - auc: 0.9999 - f1_score: 0.9929 - scaled_graph_loss: 8.2664e-04 - val_loss: 0.0948 - val_accuracy: 0.9741 - val_auc: 0.9965 - val_f1_score: 0.9741\n","Epoch 10/50\n","137/137 [==============================] - ETA: 0s - loss: 0.0250 - accuracy: 0.9919 - auc: 0.9997 - f1_score: 0.9919 - scaled_graph_loss: 9.2941e-04\n","Epoch 00010: val_accuracy did not improve from 0.97571\n","137/137 [==============================] - 84s 616ms/step - loss: 0.0250 - accuracy: 0.9919 - auc: 0.9997 - f1_score: 0.9919 - scaled_graph_loss: 9.2941e-04 - val_loss: 0.0962 - val_accuracy: 0.9734 - val_auc: 0.9961 - val_f1_score: 0.9733\n","Epoch 11/50\n","137/137 [==============================] - ETA: 0s - loss: 0.0326 - accuracy: 0.9887 - auc: 0.9997 - f1_score: 0.9888 - scaled_graph_loss: 0.0012\n","Epoch 00011: val_accuracy did not improve from 0.97571\n","137/137 [==============================] - 84s 616ms/step - loss: 0.0326 - accuracy: 0.9887 - auc: 0.9997 - f1_score: 0.9888 - scaled_graph_loss: 0.0012 - val_loss: 0.1056 - val_accuracy: 0.9702 - val_auc: 0.9958 - val_f1_score: 0.9698\n","Epoch 12/50\n","137/137 [==============================] - ETA: 0s - loss: 0.0202 - accuracy: 0.9942 - auc: 0.9997 - f1_score: 0.9942 - scaled_graph_loss: 7.1435e-04\n","Epoch 00012: val_accuracy improved from 0.97571 to 0.98250, saving model to /content/drive/My Drive/Projects/codes/Xception_NSL_model_checkpoints/xception_model_new_98\n","137/137 [==============================] - 85s 623ms/step - loss: 0.0202 - accuracy: 0.9942 - auc: 0.9997 - f1_score: 0.9942 - scaled_graph_loss: 7.1435e-04 - val_loss: 0.0692 - val_accuracy: 0.9825 - val_auc: 0.9970 - val_f1_score: 0.9824\n","Epoch 00013: early stopping\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oy7GjSCq9Gtw","executionInfo":{"status":"ok","timestamp":1606057683877,"user_tz":300,"elapsed":1042122,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"59009e08-e54b-40d6-8ed8-ceff3424664c"},"source":["'''evaluate the model'''\n","graph_reg_model.evaluate(test_image_dataset)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["60/60 [==============================] - 2s 34ms/step - loss: 0.0692 - accuracy: 0.9825 - auc: 0.9970 - f1_score: 0.9824\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[0.06918579339981079,\n"," 0.9824973940849304,\n"," 0.9970408082008362,\n"," 0.9823644757270813]"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"HYv6Ly9Y9GwB"},"source":["'''plot confusion mat & calc acc for each label'''\n","test_image_dataset = NSLDataFormat.generate_test_tfr_image_tensor(path_list=tfr_list_test, \n","                                                                  batch_size=4000, \n","                                                                  size=(100,100),\n","                                                                  channels=3,\n","                                                                  shuffle=True)\n","data, data_label = iter(test_image_dataset).get_next()\n","data = data[\"tensor\"]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":518},"id":"i82NDBcl9GyF","executionInfo":{"status":"ok","timestamp":1606257703694,"user_tz":300,"elapsed":4985,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"b6d11f58-2807-46c8-d4e4-04fbbdaf2a8a"},"source":["ADModelBuilder.plot_confusion_mat(model=graph_reg_model, data=data, data_label=data_label, title=\"Xception_NSL\", figsize=(6,6))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n","WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x432 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1gb6XWrr9G0B","executionInfo":{"status":"ok","timestamp":1606257706976,"user_tz":300,"elapsed":7678,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"c7d3fd72-f0c9-4dae-e36a-8bc829fcb8b1"},"source":["ADModelBuilder.calc_confu_mat_for_each_label(model=graph_reg_model, data=data, data_label=data_label)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["TN: [2817 2864 2874 2862]\n","TP: [971 901 924 965]\n","FN: [20 37 10  0]\n","FP: [20 26 20  1]\n","Acc: [0.98955068 0.98354232 0.99216301 0.99973877]\n","ER(Error rate): [0.01044932 0.01645768 0.00783699 0.00026123]\n","Recall(TP rate): [0.97981837 0.96055437 0.98929336 1.        ]\n","Specialty(TN rate): [0.9929503  0.99100346 0.99308915 0.99965072]\n","Fall Out(FP rate): [0.0070497  0.00899654 0.00691085 0.00034928]\n","Miss Rate(FN rate): [0.02018163 0.03944563 0.01070664 0.        ]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vdqXEIl89G4K"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eZvjZITyuaMt"},"source":[""],"execution_count":null,"outputs":[]}]}