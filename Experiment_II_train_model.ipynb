{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Experiment_II_train_model.ipynb","provenance":[],"collapsed_sections":["rTkxi38f9Han"],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"xZlaIJnq3nGD"},"source":["## Model Training (Done on Google Collab)\n","### VGG19 train & tune\n","### DenseNet train & tune\n","### Xception train & tune"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ejixluTATVDy","executionInfo":{"status":"ok","timestamp":1618853894773,"user_tz":240,"elapsed":765,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"51ff6f35-726a-4b9e-b249-89546e8df661"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":15,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"BN5T7AsM5iA0"},"source":["# 1.Package & Dependencies Setup"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pORElq4lpDpD","executionInfo":{"status":"ok","timestamp":1618853909028,"user_tz":240,"elapsed":7348,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"fc8983dd-6ea9-40d8-91e3-b3836a760b7a"},"source":["\"\"\"Install NSL package\"\"\"\n","!pip install --upgrade neural_structured_learning\n","!pip install tensorflow-addons"],"execution_count":16,"outputs":[{"output_type":"stream","text":["Requirement already up-to-date: neural_structured_learning in /usr/local/lib/python3.7/dist-packages (1.3.1)\n","Requirement already satisfied, skipping upgrade: absl-py in /usr/local/lib/python3.7/dist-packages (from neural_structured_learning) (0.12.0)\n","Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.7/dist-packages (from neural_structured_learning) (1.15.0)\n","Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.7/dist-packages (from neural_structured_learning) (1.4.1)\n","Requirement already satisfied, skipping upgrade: attrs in /usr/local/lib/python3.7/dist-packages (from neural_structured_learning) (20.3.0)\n","Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy->neural_structured_learning) (1.19.5)\n","Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.7/dist-packages (0.12.1)\n","Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0y7x5Ku4pHI5","executionInfo":{"status":"ok","timestamp":1618853909029,"user_tz":240,"elapsed":6621,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"027995ee-cc1c-4f46-a58d-85479713a428"},"source":["import numpy as np\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","from neural_structured_learning.tools import graph_utils\n","import neural_structured_learning as nsl\n","import tensorflow_addons as tfa\n","from copy import deepcopy\n","from sklearn.metrics import multilabel_confusion_matrix\n","import random\n","import os\n","import PIL\n","import time\n","import re\n","\n","tf.keras.backend.clear_session()\n","print(\"tensorflow version: \", tf.__version__)\n","print(\"keras version\", tf.keras.__version__)\n","print(\"Eager mode: \", tf.executing_eagerly())\n","print(\"GPU is\", \"available\" if tf.config.experimental.list_physical_devices('GPU') else \"NOT AVAILABLE\")"],"execution_count":17,"outputs":[{"output_type":"stream","text":["tensorflow version:  2.4.1\n","keras version 2.4.0\n","Eager mode:  True\n","GPU is available\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fIT8u-ur2-Tn","executionInfo":{"status":"ok","timestamp":1618853909029,"user_tz":240,"elapsed":5665,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}}},"source":["from graph_data_processing import GraphDataProcess\n","from AAE_model import AAE\n","from Kmeans import KMeans, KMeansModels\n","from nsl_data_processing import GenerateTrainTestDict, NSLDataFormat\n","from AD_model_builder import AD_params, ADModelBuilder, AccEarlyStop"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"GX74Sd5dUCA6","executionInfo":{"status":"ok","timestamp":1618853910105,"user_tz":240,"elapsed":1065,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}}},"source":["''' label definition: NonDemented - 0, VeryMildDemented - 1, MildDemented -2, ModerateDemented -3 '''\n","label_list = ['NonDemented', 'VeryMildDemented', 'MildDemented', 'ModerateDemented']\n","root_path = '/content/drive/MyDrive/AD Expriment II/graph_images/'\n","train_root_path = f'{root_path}train/'\n","test_root_path = f'{root_path}test/'\n","\n","train_path_list = [f'{train_root_path}{label}/' for label in label_list]\n","train_tfr_list = [f'{train_root_path}{label}.tfr' for label in label_list]\n","\n","test_path_list = [f'{test_root_path}{label}/' for label in label_list]\n","test_tfr_list = [f'{test_root_path}{label}.tfr' for label in label_list]\n","\n","tfr_rep_list = [f'{train_root_path}{label}_AAErep.tfr' for label in label_list]\n","\n","train_tfr_path = f'{train_root_path}train_data.tfr'"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"wZmCxER147rD","executionInfo":{"status":"ok","timestamp":1618853910332,"user_tz":240,"elapsed":340,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}}},"source":[""],"execution_count":19,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yBqQepbk4729"},"source":["#2.VGG19 & VGG19-NSL Model Training"]},{"cell_type":"code","metadata":{"id":"I7z0hDGW4khr"},"source":["'''define hyper params'''\n","params = AD_params()\n","params.max_seed_nbr=5\n","params.batch_size=64\n","params.image_channels =3\n","params.image_size =(100,100)\n","params.ad_base_model_input_shape=(100,100,3)\n","params.train_tfr_path = train_tfr_path\n","\n","'''parse train_data.tfr to train image dataset with batch_size at 128'''\n","train_image_dataset = NSLDataFormat.parse_tfr_to_dataset(file_path_list=[params.train_tfr_path],\n","                                                         batch_size=params.batch_size,\n","                                                         max_neighbor_number=params.max_seed_nbr,\n","                                                         image_size=params.image_size,\n","                                                         image_channels=params.image_channels,\n","                                                         shuffle=True)\n","\n","'''load test data with batch_size at 128 '''\n","test_image_dataset = NSLDataFormat.generate_test_tfr_image_tensor(path_list=test_tfr_list, \n","                                                                  batch_size=params.batch_size, \n","                                                                  size=params.image_size,\n","                                                                  channels=params.image_channels,\n","                                                                  shuffle=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Nts7SfZMjVeQ"},"source":["## 2.1 VGG19 Base Model Training\n","### val_acc: 0.64, val_auc: 0.89, val_f1_score: 0.64"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A2Nx9izfXeoG","executionInfo":{"status":"ok","timestamp":1617716713672,"user_tz":240,"elapsed":1449,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"6390c1b4-8279-4340-9734-577a35a91d8a"},"source":["'''define params'''\n","params.learning_rate=0.001\n","params.checkpoint_path = '/content/drive/MyDrive/AD Expriment II/VGG19_model_checkpoints/vgg19_weights_base'\n","params.early_stop_base_line=0.90\n","params.train_epoch=50\n","\"\"\"build a base_model and restore weights from last training\"\"\"\n","base_model = ADModelBuilder(input_shape=params.ad_base_model_input_shape, base_model='vgg19').get_ADModel()\n","base_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=params.learning_rate), \n","                   loss=tf.losses.CategoricalCrossentropy(), \n","                   metrics=['accuracy', 'AUC',  tfa.metrics.F1Score(num_classes=4, average=\"micro\", threshold = 0.5)])\n","base_model.load_weights(params.checkpoint_path)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Note: default vgg19 not includes top and has imagenet weights. It is not a trainable model in ADModelBuilder. Setup specific trainable layers in setup_VGG19_by_layer_names or setup_VGG19 function based on the VGG19 layer name or layer number\n","Model: \"VGG19_ADModel\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","tensor (InputLayer)          [(None, 100, 100, 3)]     0         \n","_________________________________________________________________\n","vgg19 (Functional)           (None, 3, 3, 512)         20024384  \n","_________________________________________________________________\n","flatten_8 (Flatten)          (None, 4608)              0         \n","_________________________________________________________________\n","dense_16 (Dense)             (None, 32)                147488    \n","_________________________________________________________________\n","batch_normalization_8 (Batch (None, 32)                128       \n","_________________________________________________________________\n","leaky_re_lu_8 (LeakyReLU)    (None, 32)                0         \n","_________________________________________________________________\n","dropout_8 (Dropout)          (None, 32)                0         \n","_________________________________________________________________\n","dense_17 (Dense)             (None, 4)                 132       \n","=================================================================\n","Total params: 20,172,132\n","Trainable params: 147,684\n","Non-trainable params: 20,024,448\n","_________________________________________________________________\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f5e20f009d0>"]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2UaS25Lt4kqZ","executionInfo":{"status":"ok","timestamp":1617716687817,"user_tz":240,"elapsed":1456624,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"a4acf616-0a3d-4086-8472-b648775acf4a"},"source":["'''train base model'''\n","callback_checkpoints = tf.keras.callbacks.ModelCheckpoint(filepath=params.checkpoint_path, monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=True, \n","                                                          mode='max',save_freq='epoch',options=None)\n","\n","callback_earlystop = AccEarlyStop(val_acc_base=params.early_stop_base_line)\n","\n","history = base_model.fit(train_image_dataset,\n","                         validation_data= test_image_dataset,\n","                         callbacks = [callback_checkpoints, callback_earlystop],\n","                         epochs=params.train_epoch,\n","                         verbose=1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/50\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py:595: UserWarning: Input dict contained keys ['NL_nbr_0_id', 'NL_nbr_0_tensor', 'NL_nbr_0_weight', 'NL_nbr_1_id', 'NL_nbr_1_tensor', 'NL_nbr_1_weight', 'NL_nbr_2_id', 'NL_nbr_2_tensor', 'NL_nbr_2_weight', 'NL_nbr_3_id', 'NL_nbr_3_tensor', 'NL_nbr_3_weight', 'NL_nbr_4_id', 'NL_nbr_4_tensor', 'NL_nbr_4_weight', 'id'] which did not match any model input. They will be ignored by the model.\n","  [n for n in tensors.keys() if n not in ref_input_names])\n"],"name":"stderr"},{"output_type":"stream","text":["    160/Unknown - 28s 159ms/step - loss: 1.0112 - accuracy: 0.5801 - auc: 0.8262 - f1_score: 0.4933"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py:595: UserWarning: Input dict contained keys ['id'] which did not match any model input. They will be ignored by the model.\n","  [n for n in tensors.keys() if n not in ref_input_names])\n"],"name":"stderr"},{"output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r160/160 [==============================] - 31s 182ms/step - loss: 1.0101 - accuracy: 0.5805 - auc: 0.8265 - f1_score: 0.4937 - val_loss: 1.4173 - val_accuracy: 0.3753 - val_auc: 0.6352 - val_f1_score: 0.2414\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.37529, saving model to /content/drive/MyDrive/AD Expriment II/VGG19_model_checkpoints/vgg19_weights_base\n","Epoch 2/50\n","160/160 [==============================] - 30s 181ms/step - loss: 0.6073 - accuracy: 0.7445 - auc: 0.9359 - f1_score: 0.6846 - val_loss: 1.1158 - val_accuracy: 0.5465 - val_auc: 0.8065 - val_f1_score: 0.4966\n","\n","Epoch 00002: val_accuracy improved from 0.37529 to 0.54652, saving model to /content/drive/MyDrive/AD Expriment II/VGG19_model_checkpoints/vgg19_weights_base\n","Epoch 3/50\n","160/160 [==============================] - 30s 179ms/step - loss: 0.5309 - accuracy: 0.7771 - auc: 0.9508 - f1_score: 0.7323 - val_loss: 1.4043 - val_accuracy: 0.4934 - val_auc: 0.7588 - val_f1_score: 0.4842\n","\n","Epoch 00003: val_accuracy did not improve from 0.54652\n","Epoch 4/50\n","160/160 [==============================] - 29s 174ms/step - loss: 0.4637 - accuracy: 0.8051 - auc: 0.9621 - f1_score: 0.7666 - val_loss: 1.3021 - val_accuracy: 0.5426 - val_auc: 0.8100 - val_f1_score: 0.5196\n","\n","Epoch 00004: val_accuracy did not improve from 0.54652\n","Epoch 5/50\n","160/160 [==============================] - 29s 174ms/step - loss: 0.4286 - accuracy: 0.8203 - auc: 0.9677 - f1_score: 0.7931 - val_loss: 1.4733 - val_accuracy: 0.5371 - val_auc: 0.8033 - val_f1_score: 0.5295\n","\n","Epoch 00005: val_accuracy did not improve from 0.54652\n","Epoch 6/50\n","160/160 [==============================] - 29s 174ms/step - loss: 0.3707 - accuracy: 0.8537 - auc: 0.9761 - f1_score: 0.8242 - val_loss: 2.8030 - val_accuracy: 0.5012 - val_auc: 0.7529 - val_f1_score: 0.5008\n","\n","Epoch 00006: val_accuracy did not improve from 0.54652\n","Epoch 7/50\n","160/160 [==============================] - 29s 175ms/step - loss: 0.3618 - accuracy: 0.8497 - auc: 0.9767 - f1_score: 0.8321 - val_loss: 2.0773 - val_accuracy: 0.5012 - val_auc: 0.7349 - val_f1_score: 0.4986\n","\n","Epoch 00007: val_accuracy did not improve from 0.54652\n","Epoch 8/50\n","160/160 [==============================] - 29s 178ms/step - loss: 0.3519 - accuracy: 0.8548 - auc: 0.9778 - f1_score: 0.8366 - val_loss: 1.0411 - val_accuracy: 0.5966 - val_auc: 0.8484 - val_f1_score: 0.5396\n","\n","Epoch 00008: val_accuracy improved from 0.54652 to 0.59656, saving model to /content/drive/MyDrive/AD Expriment II/VGG19_model_checkpoints/vgg19_weights_base\n","Epoch 9/50\n","160/160 [==============================] - 30s 180ms/step - loss: 0.3104 - accuracy: 0.8758 - auc: 0.9829 - f1_score: 0.8619 - val_loss: 2.0243 - val_accuracy: 0.4691 - val_auc: 0.7404 - val_f1_score: 0.4690\n","\n","Epoch 00009: val_accuracy did not improve from 0.59656\n","Epoch 10/50\n","160/160 [==============================] - 29s 174ms/step - loss: 0.3284 - accuracy: 0.8633 - auc: 0.9804 - f1_score: 0.8514 - val_loss: 1.6579 - val_accuracy: 0.5442 - val_auc: 0.7994 - val_f1_score: 0.5328\n","\n","Epoch 00010: val_accuracy did not improve from 0.59656\n","Epoch 11/50\n","160/160 [==============================] - 29s 173ms/step - loss: 0.2944 - accuracy: 0.8852 - auc: 0.9844 - f1_score: 0.8714 - val_loss: 2.5107 - val_accuracy: 0.4363 - val_auc: 0.7575 - val_f1_score: 0.4222\n","\n","Epoch 00011: val_accuracy did not improve from 0.59656\n","Epoch 12/50\n","160/160 [==============================] - 29s 176ms/step - loss: 0.2960 - accuracy: 0.8802 - auc: 0.9839 - f1_score: 0.8687 - val_loss: 1.3722 - val_accuracy: 0.6013 - val_auc: 0.8475 - val_f1_score: 0.5872\n","\n","Epoch 00012: val_accuracy improved from 0.59656 to 0.60125, saving model to /content/drive/MyDrive/AD Expriment II/VGG19_model_checkpoints/vgg19_weights_base\n","Epoch 13/50\n","160/160 [==============================] - 30s 180ms/step - loss: 0.2695 - accuracy: 0.8963 - auc: 0.9866 - f1_score: 0.8810 - val_loss: 1.8227 - val_accuracy: 0.5434 - val_auc: 0.7900 - val_f1_score: 0.5336\n","\n","Epoch 00013: val_accuracy did not improve from 0.60125\n","Epoch 14/50\n","160/160 [==============================] - 29s 174ms/step - loss: 0.2442 - accuracy: 0.9024 - auc: 0.9893 - f1_score: 0.8933 - val_loss: 1.2758 - val_accuracy: 0.6036 - val_auc: 0.8274 - val_f1_score: 0.5752\n","\n","Epoch 00014: val_accuracy improved from 0.60125 to 0.60360, saving model to /content/drive/MyDrive/AD Expriment II/VGG19_model_checkpoints/vgg19_weights_base\n","Epoch 15/50\n","160/160 [==============================] - 29s 175ms/step - loss: 0.2627 - accuracy: 0.9005 - auc: 0.9873 - f1_score: 0.8872 - val_loss: 1.6509 - val_accuracy: 0.5145 - val_auc: 0.7805 - val_f1_score: 0.4890\n","\n","Epoch 00015: val_accuracy did not improve from 0.60360\n","Epoch 16/50\n","160/160 [==============================] - 29s 176ms/step - loss: 0.2422 - accuracy: 0.9043 - auc: 0.9892 - f1_score: 0.8975 - val_loss: 1.4873 - val_accuracy: 0.5364 - val_auc: 0.7994 - val_f1_score: 0.5138\n","\n","Epoch 00016: val_accuracy did not improve from 0.60360\n","Epoch 17/50\n","160/160 [==============================] - 29s 177ms/step - loss: 0.2233 - accuracy: 0.9081 - auc: 0.9908 - f1_score: 0.9005 - val_loss: 1.4856 - val_accuracy: 0.5934 - val_auc: 0.8299 - val_f1_score: 0.5815\n","\n","Epoch 00017: val_accuracy did not improve from 0.60360\n","Epoch 18/50\n","160/160 [==============================] - 28s 173ms/step - loss: 0.2381 - accuracy: 0.9033 - auc: 0.9892 - f1_score: 0.8972 - val_loss: 2.4064 - val_accuracy: 0.4629 - val_auc: 0.7405 - val_f1_score: 0.4499\n","\n","Epoch 00018: val_accuracy did not improve from 0.60360\n","Epoch 19/50\n","160/160 [==============================] - 29s 176ms/step - loss: 0.2209 - accuracy: 0.9128 - auc: 0.9907 - f1_score: 0.9052 - val_loss: 1.4362 - val_accuracy: 0.5520 - val_auc: 0.8066 - val_f1_score: 0.5183\n","\n","Epoch 00019: val_accuracy did not improve from 0.60360\n","Epoch 20/50\n","160/160 [==============================] - 29s 176ms/step - loss: 0.2169 - accuracy: 0.9133 - auc: 0.9911 - f1_score: 0.9089 - val_loss: 2.8384 - val_accuracy: 0.5481 - val_auc: 0.7513 - val_f1_score: 0.5449\n","\n","Epoch 00020: val_accuracy did not improve from 0.60360\n","Epoch 21/50\n","160/160 [==============================] - 29s 174ms/step - loss: 0.2083 - accuracy: 0.9188 - auc: 0.9918 - f1_score: 0.9136 - val_loss: 1.5050 - val_accuracy: 0.5708 - val_auc: 0.8038 - val_f1_score: 0.5380\n","\n","Epoch 00021: val_accuracy did not improve from 0.60360\n","Epoch 22/50\n","160/160 [==============================] - 28s 172ms/step - loss: 0.2012 - accuracy: 0.9211 - auc: 0.9923 - f1_score: 0.9156 - val_loss: 1.7340 - val_accuracy: 0.5489 - val_auc: 0.8014 - val_f1_score: 0.5220\n","\n","Epoch 00022: val_accuracy did not improve from 0.60360\n","Epoch 23/50\n","160/160 [==============================] - 28s 172ms/step - loss: 0.1877 - accuracy: 0.9254 - auc: 0.9934 - f1_score: 0.9214 - val_loss: 3.5733 - val_accuracy: 0.4027 - val_auc: 0.6858 - val_f1_score: 0.3910\n","\n","Epoch 00023: val_accuracy did not improve from 0.60360\n","Epoch 24/50\n","160/160 [==============================] - 29s 173ms/step - loss: 0.1904 - accuracy: 0.9250 - auc: 0.9931 - f1_score: 0.9200 - val_loss: 1.7248 - val_accuracy: 0.5966 - val_auc: 0.8263 - val_f1_score: 0.5892\n","\n","Epoch 00024: val_accuracy did not improve from 0.60360\n","Epoch 25/50\n","160/160 [==============================] - 28s 173ms/step - loss: 0.1913 - accuracy: 0.9264 - auc: 0.9929 - f1_score: 0.9213 - val_loss: 1.6498 - val_accuracy: 0.5676 - val_auc: 0.8117 - val_f1_score: 0.5509\n","\n","Epoch 00025: val_accuracy did not improve from 0.60360\n","Epoch 26/50\n","160/160 [==============================] - 28s 173ms/step - loss: 0.1835 - accuracy: 0.9306 - auc: 0.9936 - f1_score: 0.9249 - val_loss: 2.1964 - val_accuracy: 0.5536 - val_auc: 0.7881 - val_f1_score: 0.5451\n","\n","Epoch 00026: val_accuracy did not improve from 0.60360\n","Epoch 27/50\n","160/160 [==============================] - 28s 173ms/step - loss: 0.1833 - accuracy: 0.9275 - auc: 0.9935 - f1_score: 0.9239 - val_loss: 1.9755 - val_accuracy: 0.5833 - val_auc: 0.8199 - val_f1_score: 0.5773\n","\n","Epoch 00027: val_accuracy did not improve from 0.60360\n","Epoch 28/50\n","160/160 [==============================] - 29s 173ms/step - loss: 0.1732 - accuracy: 0.9325 - auc: 0.9940 - f1_score: 0.9287 - val_loss: 1.8168 - val_accuracy: 0.6044 - val_auc: 0.8251 - val_f1_score: 0.5927\n","\n","Epoch 00028: val_accuracy improved from 0.60360 to 0.60438, saving model to /content/drive/MyDrive/AD Expriment II/VGG19_model_checkpoints/vgg19_weights_base\n","Epoch 29/50\n","160/160 [==============================] - 29s 176ms/step - loss: 0.1704 - accuracy: 0.9333 - auc: 0.9943 - f1_score: 0.9295 - val_loss: 1.9750 - val_accuracy: 0.5324 - val_auc: 0.7856 - val_f1_score: 0.5077\n","\n","Epoch 00029: val_accuracy did not improve from 0.60438\n","Epoch 30/50\n","160/160 [==============================] - 29s 174ms/step - loss: 0.1788 - accuracy: 0.9309 - auc: 0.9937 - f1_score: 0.9258 - val_loss: 1.4785 - val_accuracy: 0.6372 - val_auc: 0.8520 - val_f1_score: 0.6280\n","\n","Epoch 00030: val_accuracy improved from 0.60438 to 0.63722, saving model to /content/drive/MyDrive/AD Expriment II/VGG19_model_checkpoints/vgg19_weights_base\n","Epoch 31/50\n","160/160 [==============================] - 29s 177ms/step - loss: 0.1652 - accuracy: 0.9333 - auc: 0.9948 - f1_score: 0.9311 - val_loss: 2.6618 - val_accuracy: 0.4699 - val_auc: 0.7220 - val_f1_score: 0.4551\n","\n","Epoch 00031: val_accuracy did not improve from 0.63722\n","Epoch 32/50\n","160/160 [==============================] - 29s 175ms/step - loss: 0.1759 - accuracy: 0.9331 - auc: 0.9941 - f1_score: 0.9279 - val_loss: 2.4301 - val_accuracy: 0.5324 - val_auc: 0.7823 - val_f1_score: 0.5164\n","\n","Epoch 00032: val_accuracy did not improve from 0.63722\n","Epoch 33/50\n","160/160 [==============================] - 29s 175ms/step - loss: 0.1636 - accuracy: 0.9354 - auc: 0.9948 - f1_score: 0.9322 - val_loss: 2.0971 - val_accuracy: 0.5512 - val_auc: 0.7942 - val_f1_score: 0.5439\n","\n","Epoch 00033: val_accuracy did not improve from 0.63722\n","Epoch 34/50\n","160/160 [==============================] - 29s 173ms/step - loss: 0.1544 - accuracy: 0.9402 - auc: 0.9953 - f1_score: 0.9370 - val_loss: 2.5889 - val_accuracy: 0.4777 - val_auc: 0.7247 - val_f1_score: 0.4767\n","\n","Epoch 00034: val_accuracy did not improve from 0.63722\n","Epoch 35/50\n","160/160 [==============================] - 28s 173ms/step - loss: 0.1494 - accuracy: 0.9435 - auc: 0.9956 - f1_score: 0.9400 - val_loss: 2.2309 - val_accuracy: 0.5661 - val_auc: 0.7969 - val_f1_score: 0.5628\n","\n","Epoch 00035: val_accuracy did not improve from 0.63722\n","Epoch 36/50\n","160/160 [==============================] - 28s 171ms/step - loss: 0.1527 - accuracy: 0.9438 - auc: 0.9952 - f1_score: 0.9410 - val_loss: 2.5139 - val_accuracy: 0.4722 - val_auc: 0.7380 - val_f1_score: 0.4570\n","\n","Epoch 00036: val_accuracy did not improve from 0.63722\n","Epoch 37/50\n","160/160 [==============================] - 28s 173ms/step - loss: 0.1420 - accuracy: 0.9461 - auc: 0.9961 - f1_score: 0.9408 - val_loss: 2.9417 - val_accuracy: 0.5942 - val_auc: 0.8060 - val_f1_score: 0.5897\n","\n","Epoch 00037: val_accuracy did not improve from 0.63722\n","Epoch 38/50\n","160/160 [==============================] - 28s 173ms/step - loss: 0.1399 - accuracy: 0.9477 - auc: 0.9962 - f1_score: 0.9427 - val_loss: 1.9932 - val_accuracy: 0.6044 - val_auc: 0.8282 - val_f1_score: 0.5921\n","\n","Epoch 00038: val_accuracy did not improve from 0.63722\n","Epoch 39/50\n","160/160 [==============================] - 28s 172ms/step - loss: 0.1488 - accuracy: 0.9437 - auc: 0.9954 - f1_score: 0.9416 - val_loss: 1.9766 - val_accuracy: 0.5794 - val_auc: 0.8160 - val_f1_score: 0.5657\n","\n","Epoch 00039: val_accuracy did not improve from 0.63722\n","Epoch 40/50\n","160/160 [==============================] - 29s 175ms/step - loss: 0.1495 - accuracy: 0.9413 - auc: 0.9957 - f1_score: 0.9372 - val_loss: 2.4554 - val_accuracy: 0.5074 - val_auc: 0.7457 - val_f1_score: 0.4908\n","\n","Epoch 00040: val_accuracy did not improve from 0.63722\n","Epoch 41/50\n","160/160 [==============================] - 29s 177ms/step - loss: 0.1454 - accuracy: 0.9438 - auc: 0.9958 - f1_score: 0.9386 - val_loss: 2.5013 - val_accuracy: 0.5027 - val_auc: 0.7383 - val_f1_score: 0.4842\n","\n","Epoch 00041: val_accuracy did not improve from 0.63722\n","Epoch 42/50\n","160/160 [==============================] - 29s 177ms/step - loss: 0.1225 - accuracy: 0.9550 - auc: 0.9971 - f1_score: 0.9519 - val_loss: 1.9526 - val_accuracy: 0.6145 - val_auc: 0.8224 - val_f1_score: 0.6025\n","\n","Epoch 00042: val_accuracy did not improve from 0.63722\n","Epoch 43/50\n","160/160 [==============================] - 29s 179ms/step - loss: 0.1330 - accuracy: 0.9516 - auc: 0.9962 - f1_score: 0.9493 - val_loss: 1.7322 - val_accuracy: 0.6169 - val_auc: 0.8356 - val_f1_score: 0.6059\n","\n","Epoch 00043: val_accuracy did not improve from 0.63722\n","Epoch 44/50\n","160/160 [==============================] - 29s 177ms/step - loss: 0.1318 - accuracy: 0.9500 - auc: 0.9965 - f1_score: 0.9472 - val_loss: 2.2116 - val_accuracy: 0.5895 - val_auc: 0.8169 - val_f1_score: 0.5862\n","\n","Epoch 00044: val_accuracy did not improve from 0.63722\n","Epoch 45/50\n","160/160 [==============================] - 29s 178ms/step - loss: 0.1233 - accuracy: 0.9540 - auc: 0.9969 - f1_score: 0.9521 - val_loss: 2.4948 - val_accuracy: 0.5504 - val_auc: 0.7981 - val_f1_score: 0.5459\n","\n","Epoch 00045: val_accuracy did not improve from 0.63722\n","Epoch 46/50\n","160/160 [==============================] - 29s 179ms/step - loss: 0.1402 - accuracy: 0.9454 - auc: 0.9959 - f1_score: 0.9446 - val_loss: 2.5069 - val_accuracy: 0.5825 - val_auc: 0.8063 - val_f1_score: 0.5730\n","\n","Epoch 00046: val_accuracy did not improve from 0.63722\n","Epoch 47/50\n","160/160 [==============================] - 29s 177ms/step - loss: 0.1205 - accuracy: 0.9519 - auc: 0.9972 - f1_score: 0.9505 - val_loss: 2.4071 - val_accuracy: 0.5950 - val_auc: 0.8016 - val_f1_score: 0.5826\n","\n","Epoch 00047: val_accuracy did not improve from 0.63722\n","Epoch 48/50\n","160/160 [==============================] - 29s 176ms/step - loss: 0.1256 - accuracy: 0.9506 - auc: 0.9968 - f1_score: 0.9487 - val_loss: 2.7537 - val_accuracy: 0.5082 - val_auc: 0.7559 - val_f1_score: 0.4961\n","\n","Epoch 00048: val_accuracy did not improve from 0.63722\n","Epoch 49/50\n","160/160 [==============================] - 29s 177ms/step - loss: 0.1271 - accuracy: 0.9534 - auc: 0.9965 - f1_score: 0.9512 - val_loss: 4.1697 - val_accuracy: 0.4300 - val_auc: 0.6638 - val_f1_score: 0.4215\n","\n","Epoch 00049: val_accuracy did not improve from 0.63722\n","Epoch 50/50\n","160/160 [==============================] - 29s 178ms/step - loss: 0.1262 - accuracy: 0.9504 - auc: 0.9967 - f1_score: 0.9487 - val_loss: 2.6211 - val_accuracy: 0.5301 - val_auc: 0.7727 - val_f1_score: 0.5300\n","\n","Epoch 00050: val_accuracy did not improve from 0.63722\n","Early stopping is not triggered, but best model is restored at epoch 30\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lVP_CDnTbGaF","executionInfo":{"status":"ok","timestamp":1617714875929,"user_tz":240,"elapsed":3748,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"c52d7bcc-e581-4865-b072-3c5170baeef7"},"source":["'''evaluate the base model'''\n","base_model.evaluate(test_image_dataset)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1/1 [==============================] - 3s 3s/step - loss: 1.4312 - accuracy: 0.6403 - auc: 0.8503 - f1_score: 0.6390\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[1.4311827421188354,\n"," 0.6403440237045288,\n"," 0.8503028750419617,\n"," 0.6390205025672913]"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"mZdKTQIbLIhz"},"source":["'''plot confusion mat & calc acc for each label'''\n","test_image_dataset = NSLDataFormat.generate_test_tfr_image_tensor(path_list=test_tfr_list, \n","                                                                  batch_size=4000, \n","                                                                  size=(100,100),\n","                                                                  channels=3,\n","                                                                  shuffle=True)\n","data, data_label = iter(test_image_dataset).get_next()\n","data = data[\"tensor\"]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GGee70DfXROB","executionInfo":{"status":"ok","timestamp":1617714876787,"user_tz":240,"elapsed":3777,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"4335fec9-b581-46b4-a9d9-3fe975548ae8"},"source":["len(data)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1279"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":396},"id":"RDbn8__LLIjv","executionInfo":{"status":"ok","timestamp":1617714880272,"user_tz":240,"elapsed":4986,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"7352c72f-32a1-4593-f68c-00c97d65529c"},"source":["ADModelBuilder.plot_confusion_mat(base_model, data, data_label, \"VGG19\")"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x432 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"YVlyP5V1LIm3"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TDkD2QMS6b-_"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mPorVq79jeYK"},"source":["## 2.2 VGG19-NSL Model Training\n","### val_acc: 0.63, val_auc: 0.82 , val_f1_score: 0.63 "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4FsrX9lrC1hY","executionInfo":{"status":"ok","timestamp":1617806149760,"user_tz":240,"elapsed":1137,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"63975f7d-e1ce-4a93-c84b-af55fc0a02a1"},"source":["'''define params'''\n","params.learning_rate=0.001\n","params.checkpoint_path ='/content/drive/MyDrive/AD Expriment II/VGG19_model_checkpoints/vgg19_weights_nsl'\n","params.early_stop_base_line=0.70\n","params.train_epoch=30\n","params.nsl_multiplier = 0.01\n","params.nsl_sum_over_axis = -1\n","params.nsl_distance_type = nsl.configs.DistanceType.COSINE\n","\n","\"\"\"build a base_model\"\"\"\n","base_model = ADModelBuilder(input_shape=params.ad_base_model_input_shape, base_model='vgg19').get_ADModel()\n","\n","\"\"\"build a NSL model on top of the base model and retore weights from last training\"\"\"\n","graph_reg_config = nsl.configs.make_graph_reg_config(neighbor_prefix=params.neighbor_prefix,\n","                                                     neighbor_weight_suffix=params.neighbor_weight_suffix,\n","                                                     max_neighbors= params.max_seed_nbr,\n","                                                     multiplier= params.nsl_multiplier,\n","                                                     distance_type= params.nsl_distance_type,\n","                                                     sum_over_axis= params.nsl_sum_over_axis)\n","\n","graph_reg_model = nsl.keras.GraphRegularization(base_model,graph_reg_config)\n","\n","graph_reg_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=params.learning_rate, amsgrad=True), \n","                        loss=tf.losses.CategoricalCrossentropy(), \n","                        metrics=[\"accuracy\",\"AUC\", tfa.metrics.F1Score(num_classes=4, average=\"micro\", threshold = 0.5)])\n","graph_reg_model.load_weights(params.checkpoint_path)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Note: default vgg19 not includes top and has imagenet weights. It is not a trainable model in ADModelBuilder. Setup specific trainable layers in setup_VGG19_by_layer_names or setup_VGG19 function based on the VGG19 layer name or layer number\n","Model: \"VGG19_ADModel\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","tensor (InputLayer)          [(None, 100, 100, 3)]     0         \n","_________________________________________________________________\n","vgg19 (Functional)           (None, 3, 3, 512)         20024384  \n","_________________________________________________________________\n","flatten_1 (Flatten)          (None, 4608)              0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 16)                73744     \n","_________________________________________________________________\n","batch_normalization_1 (Batch (None, 16)                64        \n","_________________________________________________________________\n","leaky_re_lu_1 (LeakyReLU)    (None, 16)                0         \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 16)                0         \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 4)                 68        \n","=================================================================\n","Total params: 20,098,260\n","Trainable params: 73,844\n","Non-trainable params: 20,024,416\n","_________________________________________________________________\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f1469cc8bd0>"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"84c5v3r04ktO","executionInfo":{"status":"ok","timestamp":1617808398264,"user_tz":240,"elapsed":2244825,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"0a92de43-52fd-4e51-c691-9d709dd29696"},"source":["''' setup early stoping and checkpoints '''\n","callback_checkpoints = tf.keras.callbacks.ModelCheckpoint(filepath=params.checkpoint_path, monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=True, mode='max',\n","                                                         save_freq='epoch',options=None)\n","\n","callback_earlystop = AccEarlyStop(val_acc_base=params.early_stop_base_line)\n","\n","'''NSL model training'''\n","graph_reg_history = graph_reg_model.fit(train_image_dataset, \n","                                        validation_data=test_image_dataset,\n","                                        callbacks = [callback_checkpoints, callback_earlystop],\n","                                        epochs=params.train_epoch,\n","                                        verbose=1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/30\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py:595: UserWarning: Input dict contained keys ['id'] which did not match any model input. They will be ignored by the model.\n","  [n for n in tensors.keys() if n not in ref_input_names])\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/GraphRegularization/graph_loss/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/GraphRegularization/graph_loss/Reshape:0\", shape=(None, 4), dtype=float32), dense_shape=Tensor(\"gradient_tape/GraphRegularization/graph_loss/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"shape. This may consume a large amount of memory.\" % value)\n"],"name":"stderr"},{"output_type":"stream","text":["160/160 [==============================] - 78s 474ms/step - loss: 0.1486 - accuracy: 0.9443 - auc: 0.9957 - f1_score: 0.9432 - scaled_graph_loss: 6.7404e-04 - val_loss: 1.9059 - val_accuracy: 0.6153 - val_auc: 0.8326 - val_f1_score: 0.9033\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.61532, saving model to /content/drive/MyDrive/AD Expriment II/VGG19_model_checkpoints/vgg19_weights_nsl\n","Epoch 2/30\n","160/160 [==============================] - 75s 463ms/step - loss: 0.1538 - accuracy: 0.9393 - auc: 0.9955 - f1_score: 0.9403 - scaled_graph_loss: 6.9551e-04 - val_loss: 2.6825 - val_accuracy: 0.5559 - val_auc: 0.7794 - val_f1_score: 0.5570\n","\n","Epoch 00002: val_accuracy did not improve from 0.61532\n","Epoch 3/30\n","160/160 [==============================] - 74s 461ms/step - loss: 0.1642 - accuracy: 0.9378 - auc: 0.9948 - f1_score: 0.9373 - scaled_graph_loss: 7.2718e-04 - val_loss: 3.1422 - val_accuracy: 0.5176 - val_auc: 0.7519 - val_f1_score: 0.5169\n","\n","Epoch 00003: val_accuracy did not improve from 0.61532\n","Epoch 4/30\n","160/160 [==============================] - 75s 463ms/step - loss: 0.1561 - accuracy: 0.9398 - auc: 0.9954 - f1_score: 0.9401 - scaled_graph_loss: 7.1583e-04 - val_loss: 2.8461 - val_accuracy: 0.5653 - val_auc: 0.7852 - val_f1_score: 0.5651\n","\n","Epoch 00004: val_accuracy did not improve from 0.61532\n","Epoch 5/30\n","160/160 [==============================] - 74s 461ms/step - loss: 0.1649 - accuracy: 0.9389 - auc: 0.9945 - f1_score: 0.9380 - scaled_graph_loss: 7.3458e-04 - val_loss: 2.1273 - val_accuracy: 0.5934 - val_auc: 0.8042 - val_f1_score: 0.5944\n","\n","Epoch 00005: val_accuracy did not improve from 0.61532\n","Epoch 6/30\n","160/160 [==============================] - 74s 462ms/step - loss: 0.1427 - accuracy: 0.9440 - auc: 0.9962 - f1_score: 0.9446 - scaled_graph_loss: 6.8978e-04 - val_loss: 2.2703 - val_accuracy: 0.6130 - val_auc: 0.8211 - val_f1_score: 0.6132\n","\n","Epoch 00006: val_accuracy did not improve from 0.61532\n","Epoch 7/30\n","160/160 [==============================] - 75s 463ms/step - loss: 0.1508 - accuracy: 0.9401 - auc: 0.9955 - f1_score: 0.9396 - scaled_graph_loss: 6.9532e-04 - val_loss: 3.9789 - val_accuracy: 0.4652 - val_auc: 0.6943 - val_f1_score: 0.4643\n","\n","Epoch 00007: val_accuracy did not improve from 0.61532\n","Epoch 8/30\n","160/160 [==============================] - 75s 463ms/step - loss: 0.1551 - accuracy: 0.9388 - auc: 0.9954 - f1_score: 0.9395 - scaled_graph_loss: 7.3255e-04 - val_loss: 2.8172 - val_accuracy: 0.5708 - val_auc: 0.7934 - val_f1_score: 0.5724\n","\n","Epoch 00008: val_accuracy did not improve from 0.61532\n","Epoch 9/30\n","160/160 [==============================] - 75s 463ms/step - loss: 0.1377 - accuracy: 0.9475 - auc: 0.9962 - f1_score: 0.9475 - scaled_graph_loss: 6.3493e-04 - val_loss: 2.7700 - val_accuracy: 0.6130 - val_auc: 0.8088 - val_f1_score: 0.6117\n","\n","Epoch 00009: val_accuracy did not improve from 0.61532\n","Epoch 10/30\n","160/160 [==============================] - 74s 462ms/step - loss: 0.1597 - accuracy: 0.9414 - auc: 0.9946 - f1_score: 0.9393 - scaled_graph_loss: 7.0284e-04 - val_loss: 2.6220 - val_accuracy: 0.5090 - val_auc: 0.7463 - val_f1_score: 0.5069\n","\n","Epoch 00010: val_accuracy did not improve from 0.61532\n","Epoch 11/30\n","160/160 [==============================] - 74s 461ms/step - loss: 0.1561 - accuracy: 0.9397 - auc: 0.9951 - f1_score: 0.9400 - scaled_graph_loss: 6.9458e-04 - val_loss: 2.1600 - val_accuracy: 0.6013 - val_auc: 0.8157 - val_f1_score: 0.5994\n","\n","Epoch 00011: val_accuracy did not improve from 0.61532\n","Epoch 12/30\n","160/160 [==============================] - 74s 461ms/step - loss: 0.1493 - accuracy: 0.9409 - auc: 0.9956 - f1_score: 0.9418 - scaled_graph_loss: 6.9180e-04 - val_loss: 2.6991 - val_accuracy: 0.5403 - val_auc: 0.7706 - val_f1_score: 0.5421\n","\n","Epoch 00012: val_accuracy did not improve from 0.61532\n","Epoch 13/30\n","160/160 [==============================] - 75s 463ms/step - loss: 0.1443 - accuracy: 0.9472 - auc: 0.9958 - f1_score: 0.9478 - scaled_graph_loss: 6.5213e-04 - val_loss: 3.7988 - val_accuracy: 0.5418 - val_auc: 0.7443 - val_f1_score: 0.5402\n","\n","Epoch 00013: val_accuracy did not improve from 0.61532\n","Epoch 14/30\n","160/160 [==============================] - 74s 460ms/step - loss: 0.1394 - accuracy: 0.9462 - auc: 0.9961 - f1_score: 0.9457 - scaled_graph_loss: 6.6456e-04 - val_loss: 2.2015 - val_accuracy: 0.5817 - val_auc: 0.8002 - val_f1_score: 0.5807\n","\n","Epoch 00014: val_accuracy did not improve from 0.61532\n","Epoch 15/30\n","160/160 [==============================] - 75s 462ms/step - loss: 0.1407 - accuracy: 0.9453 - auc: 0.9962 - f1_score: 0.9453 - scaled_graph_loss: 6.6013e-04 - val_loss: 2.5665 - val_accuracy: 0.6286 - val_auc: 0.8202 - val_f1_score: 0.6281\n","\n","Epoch 00015: val_accuracy improved from 0.61532 to 0.62862, saving model to /content/drive/MyDrive/AD Expriment II/VGG19_model_checkpoints/vgg19_weights_nsl\n","Epoch 16/30\n","160/160 [==============================] - 75s 463ms/step - loss: 0.1404 - accuracy: 0.9470 - auc: 0.9960 - f1_score: 0.9477 - scaled_graph_loss: 6.5473e-04 - val_loss: 2.3366 - val_accuracy: 0.6357 - val_auc: 0.8260 - val_f1_score: 0.6355\n","\n","Epoch 00016: val_accuracy improved from 0.62862 to 0.63565, saving model to /content/drive/MyDrive/AD Expriment II/VGG19_model_checkpoints/vgg19_weights_nsl\n","Epoch 17/30\n","160/160 [==============================] - 74s 461ms/step - loss: 0.1326 - accuracy: 0.9499 - auc: 0.9967 - f1_score: 0.9494 - scaled_graph_loss: 6.1778e-04 - val_loss: 2.4530 - val_accuracy: 0.6185 - val_auc: 0.8195 - val_f1_score: 0.6185\n","\n","Epoch 00017: val_accuracy did not improve from 0.63565\n","Epoch 18/30\n","160/160 [==============================] - 75s 462ms/step - loss: 0.1424 - accuracy: 0.9437 - auc: 0.9959 - f1_score: 0.9439 - scaled_graph_loss: 6.6127e-04 - val_loss: 2.7050 - val_accuracy: 0.6114 - val_auc: 0.7975 - val_f1_score: 0.6127\n","\n","Epoch 00018: val_accuracy did not improve from 0.63565\n","Epoch 19/30\n","160/160 [==============================] - 75s 462ms/step - loss: 0.1401 - accuracy: 0.9454 - auc: 0.9963 - f1_score: 0.9458 - scaled_graph_loss: 6.4539e-04 - val_loss: 3.5434 - val_accuracy: 0.4292 - val_auc: 0.6731 - val_f1_score: 0.4286\n","\n","Epoch 00019: val_accuracy did not improve from 0.63565\n","Epoch 20/30\n","160/160 [==============================] - 74s 462ms/step - loss: 0.1282 - accuracy: 0.9507 - auc: 0.9967 - f1_score: 0.9511 - scaled_graph_loss: 6.1321e-04 - val_loss: 2.2671 - val_accuracy: 0.5887 - val_auc: 0.8066 - val_f1_score: 0.5883\n","\n","Epoch 00020: val_accuracy did not improve from 0.63565\n","Epoch 21/30\n","160/160 [==============================] - 75s 463ms/step - loss: 0.1253 - accuracy: 0.9538 - auc: 0.9969 - f1_score: 0.9525 - scaled_graph_loss: 5.8181e-04 - val_loss: 2.7905 - val_accuracy: 0.5379 - val_auc: 0.7734 - val_f1_score: 0.5343\n","\n","Epoch 00021: val_accuracy did not improve from 0.63565\n","Epoch 22/30\n","160/160 [==============================] - 75s 462ms/step - loss: 0.1361 - accuracy: 0.9493 - auc: 0.9963 - f1_score: 0.9491 - scaled_graph_loss: 6.1968e-04 - val_loss: 2.6618 - val_accuracy: 0.5676 - val_auc: 0.7845 - val_f1_score: 0.5639\n","\n","Epoch 00022: val_accuracy did not improve from 0.63565\n","Epoch 23/30\n","160/160 [==============================] - 75s 463ms/step - loss: 0.1481 - accuracy: 0.9436 - auc: 0.9954 - f1_score: 0.9439 - scaled_graph_loss: 6.8202e-04 - val_loss: 3.0070 - val_accuracy: 0.5622 - val_auc: 0.7797 - val_f1_score: 0.5627\n","\n","Epoch 00023: val_accuracy did not improve from 0.63565\n","Epoch 24/30\n","160/160 [==============================] - 75s 462ms/step - loss: 0.1345 - accuracy: 0.9480 - auc: 0.9964 - f1_score: 0.9479 - scaled_graph_loss: 6.1657e-04 - val_loss: 3.1459 - val_accuracy: 0.5661 - val_auc: 0.7859 - val_f1_score: 0.5664\n","\n","Epoch 00024: val_accuracy did not improve from 0.63565\n","Epoch 25/30\n","160/160 [==============================] - 74s 460ms/step - loss: 0.1344 - accuracy: 0.9495 - auc: 0.9965 - f1_score: 0.9503 - scaled_graph_loss: 6.1468e-04 - val_loss: 2.7792 - val_accuracy: 0.5676 - val_auc: 0.7841 - val_f1_score: 0.5670\n","\n","Epoch 00025: val_accuracy did not improve from 0.63565\n","Epoch 26/30\n","160/160 [==============================] - 75s 463ms/step - loss: 0.1280 - accuracy: 0.9516 - auc: 0.9969 - f1_score: 0.9512 - scaled_graph_loss: 5.8868e-04 - val_loss: 2.7471 - val_accuracy: 0.6130 - val_auc: 0.8162 - val_f1_score: 0.6137\n","\n","Epoch 00026: val_accuracy did not improve from 0.63565\n","Epoch 27/30\n","160/160 [==============================] - 75s 463ms/step - loss: 0.1294 - accuracy: 0.9506 - auc: 0.9965 - f1_score: 0.9505 - scaled_graph_loss: 6.0041e-04 - val_loss: 2.2123 - val_accuracy: 0.6044 - val_auc: 0.8207 - val_f1_score: 0.6053\n","\n","Epoch 00027: val_accuracy did not improve from 0.63565\n","Epoch 28/30\n","160/160 [==============================] - 74s 460ms/step - loss: 0.1140 - accuracy: 0.9558 - auc: 0.9976 - f1_score: 0.9564 - scaled_graph_loss: 5.4767e-04 - val_loss: 2.3431 - val_accuracy: 0.6028 - val_auc: 0.8073 - val_f1_score: 0.6034\n","\n","Epoch 00028: val_accuracy did not improve from 0.63565\n","Epoch 29/30\n","160/160 [==============================] - 75s 463ms/step - loss: 0.1217 - accuracy: 0.9544 - auc: 0.9971 - f1_score: 0.9535 - scaled_graph_loss: 5.9051e-04 - val_loss: 2.8941 - val_accuracy: 0.5723 - val_auc: 0.7950 - val_f1_score: 0.5733\n","\n","Epoch 00029: val_accuracy did not improve from 0.63565\n","Epoch 30/30\n","160/160 [==============================] - 75s 463ms/step - loss: 0.1137 - accuracy: 0.9568 - auc: 0.9975 - f1_score: 0.9570 - scaled_graph_loss: 5.6349e-04 - val_loss: 2.2441 - val_accuracy: 0.6059 - val_auc: 0.8191 - val_f1_score: 0.6054\n","\n","Epoch 00030: val_accuracy did not improve from 0.63565\n","Early stopping is not triggered, but best model is restored at epoch 16\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"877FiZyAUJv7","executionInfo":{"status":"ok","timestamp":1617808415958,"user_tz":240,"elapsed":2259,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"e75a57a7-8278-4471-ebc5-4266a1a6439e"},"source":["graph_reg_model.evaluate(test_image_dataset)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["20/20 [==============================] - 2s 74ms/step - loss: 2.3366 - accuracy: 0.6357 - auc: 0.8260 - f1_score: 0.6355\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[2.3365843296051025, 0.6356528401374817, 0.8260239958763123, 0.635469913482666]"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"anut2b6BRl6N"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mqiZpSxMXYSO"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"y67bzIq5iebn"},"source":["## 2.3 VGG19-NSL Model tunning\n","### val_acc: 0.68, val_auc: 0.86, val_f1_score: 0.68"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xl0BgfDHXgus","executionInfo":{"status":"ok","timestamp":1617890526023,"user_tz":240,"elapsed":6783,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"9890ff2b-e370-47c7-9315-3e9c9c180647"},"source":["'''define params'''\n","params.learning_rate = 0.000005\n","params.checkpoint_restore_path = '/content/drive/MyDrive/AD Expriment II/VGG19_model_checkpoints/vgg19_weights_nsl'\n","params.checkpoint_path= '/content/drive/MyDrive/AD Expriment II/VGG19_model_checkpoints/vgg19_weights_nsl_tuning'\n","params.early_stop_base_line=0.70\n","params.train_epoch=50\n","params.nsl_multiplier = 0.005\n","params.nsl_sum_over_axis = -1\n","params.nsl_distance_type = nsl.configs.DistanceType.COSINE\n","'''build base model'''\n","base_model = ADModelBuilder(input_shape=params.ad_base_model_input_shape, base_model='vgg19').setup_VGG19_by_layer_names(trainable_layers=['block1_conv1', 'block3_conv4' ,'block5_conv4']).get_ADModel()\n","\n","\"\"\"restore NSL model from last training\"\"\"\n","graph_reg_config = nsl.configs.make_graph_reg_config(neighbor_prefix=params.neighbor_prefix,\n","                                                     neighbor_weight_suffix=params.neighbor_weight_suffix,\n","                                                     max_neighbors= params.max_seed_nbr,\n","                                                     multiplier= params.nsl_multiplier,\n","                                                     distance_type= params.nsl_distance_type, \n","                                                     sum_over_axis= params.nsl_sum_over_axis)\n","\n","graph_reg_model = nsl.keras.GraphRegularization(base_model,graph_reg_config)\n","\n","graph_reg_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=params.learning_rate, amsgrad=True), \n","                        loss=tf.losses.CategoricalCrossentropy(),\n","                        metrics=[\"accuracy\",\"AUC\",tfa.metrics.F1Score(num_classes=4, average=\"micro\", threshold = 0.5)])\n","\n","graph_reg_model.load_weights(params.checkpoint_path)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Note: default vgg19 not includes top and has imagenet weights. It is not a trainable model in ADModelBuilder. Setup specific trainable layers in setup_VGG19_by_layer_names or setup_VGG19 function based on the VGG19 layer name or layer number\n","trainable layer:  block1_conv1\n","trainable layer:  block3_conv4\n","trainable layer:  block5_conv4\n","Model: \"vgg19\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_5 (InputLayer)         [(None, 100, 100, 3)]     0         \n","_________________________________________________________________\n","block1_conv1 (Conv2D)        (None, 100, 100, 64)      1792      \n","_________________________________________________________________\n","block1_conv2 (Conv2D)        (None, 100, 100, 64)      36928     \n","_________________________________________________________________\n","block1_pool (MaxPooling2D)   (None, 50, 50, 64)        0         \n","_________________________________________________________________\n","block2_conv1 (Conv2D)        (None, 50, 50, 128)       73856     \n","_________________________________________________________________\n","block2_conv2 (Conv2D)        (None, 50, 50, 128)       147584    \n","_________________________________________________________________\n","block2_pool (MaxPooling2D)   (None, 25, 25, 128)       0         \n","_________________________________________________________________\n","block3_conv1 (Conv2D)        (None, 25, 25, 256)       295168    \n","_________________________________________________________________\n","block3_conv2 (Conv2D)        (None, 25, 25, 256)       590080    \n","_________________________________________________________________\n","block3_conv3 (Conv2D)        (None, 25, 25, 256)       590080    \n","_________________________________________________________________\n","block3_conv4 (Conv2D)        (None, 25, 25, 256)       590080    \n","_________________________________________________________________\n","block3_pool (MaxPooling2D)   (None, 12, 12, 256)       0         \n","_________________________________________________________________\n","block4_conv1 (Conv2D)        (None, 12, 12, 512)       1180160   \n","_________________________________________________________________\n","block4_conv2 (Conv2D)        (None, 12, 12, 512)       2359808   \n","_________________________________________________________________\n","block4_conv3 (Conv2D)        (None, 12, 12, 512)       2359808   \n","_________________________________________________________________\n","block4_conv4 (Conv2D)        (None, 12, 12, 512)       2359808   \n","_________________________________________________________________\n","block4_pool (MaxPooling2D)   (None, 6, 6, 512)         0         \n","_________________________________________________________________\n","block5_conv1 (Conv2D)        (None, 6, 6, 512)         2359808   \n","_________________________________________________________________\n","block5_conv2 (Conv2D)        (None, 6, 6, 512)         2359808   \n","_________________________________________________________________\n","block5_conv3 (Conv2D)        (None, 6, 6, 512)         2359808   \n","_________________________________________________________________\n","block5_conv4 (Conv2D)        (None, 6, 6, 512)         2359808   \n","_________________________________________________________________\n","block5_pool (MaxPooling2D)   (None, 3, 3, 512)         0         \n","=================================================================\n","Total params: 20,024,384\n","Trainable params: 2,359,808\n","Non-trainable params: 17,664,576\n","_________________________________________________________________\n","Model: \"VGG19_ADModel\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","tensor (InputLayer)          [(None, 100, 100, 3)]     0         \n","_________________________________________________________________\n","vgg19 (Functional)           (None, 3, 3, 512)         20024384  \n","_________________________________________________________________\n","flatten_4 (Flatten)          (None, 4608)              0         \n","_________________________________________________________________\n","dense_8 (Dense)              (None, 16)                73744     \n","_________________________________________________________________\n","batch_normalization_4 (Batch (None, 16)                64        \n","_________________________________________________________________\n","leaky_re_lu_4 (LeakyReLU)    (None, 16)                0         \n","_________________________________________________________________\n","dropout_4 (Dropout)          (None, 16)                0         \n","_________________________________________________________________\n","dense_9 (Dense)              (None, 4)                 68        \n","=================================================================\n","Total params: 20,098,260\n","Trainable params: 2,433,652\n","Non-trainable params: 17,664,608\n","_________________________________________________________________\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f7b1bd90590>"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"3Yr-yYkzbxel","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617894427986,"user_tz":240,"elapsed":3899772,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"2cd16266-bfb8-4c21-a81f-c8cb59fba7bf"},"source":["\"\"\"set up training checkpoint and earlystop callbacks\"\"\"\n","callback_checkpoints = tf.keras.callbacks.ModelCheckpoint(filepath=params.checkpoint_path, monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=True, mode='max', save_freq='epoch')\n","\n","callback_earlystop = AccEarlyStop(val_acc_base = params.early_stop_base_line)\n","\n","\"\"\"NSL model training\"\"\"\n","graph_reg_history = graph_reg_model.fit(train_image_dataset, \n","                                        validation_data=test_image_dataset,\n","                                        callbacks = [callback_checkpoints, callback_earlystop],\n","                                        epochs= params.train_epoch,\n","                                        verbose=1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/50\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py:595: UserWarning: Input dict contained keys ['id'] which did not match any model input. They will be ignored by the model.\n","  [n for n in tensors.keys() if n not in ref_input_names])\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/GraphRegularization/graph_loss/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/GraphRegularization/graph_loss/Reshape:0\", shape=(None, 4), dtype=float32), dense_shape=Tensor(\"gradient_tape/GraphRegularization/graph_loss/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"shape. This may consume a large amount of memory.\" % value)\n"],"name":"stderr"},{"output_type":"stream","text":["160/160 [==============================] - 71s 428ms/step - loss: 0.0342 - accuracy: 0.9904 - auc: 0.9999 - f1_score: 0.9901 - scaled_graph_loss: 7.0651e-05 - val_loss: 2.9772 - val_accuracy: 0.5942 - val_auc: 0.7943 - val_f1_score: 0.9461\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.59421, saving model to /content/drive/MyDrive/AD Expriment II/VGG19_model_checkpoints/vgg19_weights_nsl_tuning\n","Epoch 2/50\n","160/160 [==============================] - 73s 451ms/step - loss: 0.0340 - accuracy: 0.9903 - auc: 0.9998 - f1_score: 0.9904 - scaled_graph_loss: 7.8045e-05 - val_loss: 1.9575 - val_accuracy: 0.6873 - val_auc: 0.8606 - val_f1_score: 0.6872\n","\n","Epoch 00002: val_accuracy improved from 0.59421 to 0.68726, saving model to /content/drive/MyDrive/AD Expriment II/VGG19_model_checkpoints/vgg19_weights_nsl_tuning\n","Epoch 3/50\n","160/160 [==============================] - 76s 471ms/step - loss: 0.0370 - accuracy: 0.9896 - auc: 0.9996 - f1_score: 0.9895 - scaled_graph_loss: 8.0414e-05 - val_loss: 3.1772 - val_accuracy: 0.5997 - val_auc: 0.7912 - val_f1_score: 0.5969\n","\n","Epoch 00003: val_accuracy did not improve from 0.68726\n","Epoch 4/50\n","160/160 [==============================] - 78s 480ms/step - loss: 0.0362 - accuracy: 0.9886 - auc: 0.9998 - f1_score: 0.9888 - scaled_graph_loss: 8.1341e-05 - val_loss: 2.5117 - val_accuracy: 0.6263 - val_auc: 0.8162 - val_f1_score: 0.6278\n","\n","Epoch 00004: val_accuracy did not improve from 0.68726\n","Epoch 5/50\n","160/160 [==============================] - 77s 480ms/step - loss: 0.0260 - accuracy: 0.9933 - auc: 0.9999 - f1_score: 0.9934 - scaled_graph_loss: 5.7768e-05 - val_loss: 2.5874 - val_accuracy: 0.6349 - val_auc: 0.8306 - val_f1_score: 0.6353\n","\n","Epoch 00005: val_accuracy did not improve from 0.68726\n","Epoch 6/50\n","160/160 [==============================] - 78s 482ms/step - loss: 0.0267 - accuracy: 0.9933 - auc: 0.9999 - f1_score: 0.9936 - scaled_graph_loss: 5.5954e-05 - val_loss: 2.4050 - val_accuracy: 0.6489 - val_auc: 0.8269 - val_f1_score: 0.6491\n","\n","Epoch 00006: val_accuracy did not improve from 0.68726\n","Epoch 7/50\n","160/160 [==============================] - 78s 481ms/step - loss: 0.0299 - accuracy: 0.9915 - auc: 0.9999 - f1_score: 0.9915 - scaled_graph_loss: 6.1604e-05 - val_loss: 2.0872 - val_accuracy: 0.6833 - val_auc: 0.8496 - val_f1_score: 0.6819\n","\n","Epoch 00007: val_accuracy did not improve from 0.68726\n","Epoch 8/50\n","160/160 [==============================] - 78s 482ms/step - loss: 0.0224 - accuracy: 0.9939 - auc: 1.0000 - f1_score: 0.9939 - scaled_graph_loss: 4.8494e-05 - val_loss: 2.6960 - val_accuracy: 0.6403 - val_auc: 0.8211 - val_f1_score: 0.6386\n","\n","Epoch 00008: val_accuracy did not improve from 0.68726\n","Epoch 9/50\n","160/160 [==============================] - 78s 482ms/step - loss: 0.0202 - accuracy: 0.9950 - auc: 1.0000 - f1_score: 0.9947 - scaled_graph_loss: 4.4582e-05 - val_loss: 3.3979 - val_accuracy: 0.5864 - val_auc: 0.7912 - val_f1_score: 0.5869\n","\n","Epoch 00009: val_accuracy did not improve from 0.68726\n","Epoch 10/50\n","160/160 [==============================] - 78s 481ms/step - loss: 0.0256 - accuracy: 0.9933 - auc: 0.9998 - f1_score: 0.9932 - scaled_graph_loss: 5.9098e-05 - val_loss: 2.5353 - val_accuracy: 0.6372 - val_auc: 0.8325 - val_f1_score: 0.6392\n","\n","Epoch 00010: val_accuracy did not improve from 0.68726\n","Epoch 11/50\n","160/160 [==============================] - 78s 482ms/step - loss: 0.0215 - accuracy: 0.9959 - auc: 0.9999 - f1_score: 0.9956 - scaled_graph_loss: 4.7420e-05 - val_loss: 2.3514 - val_accuracy: 0.6638 - val_auc: 0.8407 - val_f1_score: 0.6630\n","\n","Epoch 00011: val_accuracy did not improve from 0.68726\n","Epoch 12/50\n","160/160 [==============================] - 78s 483ms/step - loss: 0.0195 - accuracy: 0.9950 - auc: 0.9999 - f1_score: 0.9951 - scaled_graph_loss: 4.3061e-05 - val_loss: 2.8871 - val_accuracy: 0.6701 - val_auc: 0.8364 - val_f1_score: 0.6711\n","\n","Epoch 00012: val_accuracy did not improve from 0.68726\n","Epoch 13/50\n","160/160 [==============================] - 78s 482ms/step - loss: 0.0342 - accuracy: 0.9902 - auc: 0.9996 - f1_score: 0.9901 - scaled_graph_loss: 7.0735e-05 - val_loss: 2.4687 - val_accuracy: 0.6294 - val_auc: 0.8238 - val_f1_score: 0.6267\n","\n","Epoch 00013: val_accuracy did not improve from 0.68726\n","Epoch 14/50\n","160/160 [==============================] - 78s 482ms/step - loss: 0.0425 - accuracy: 0.9858 - auc: 0.9997 - f1_score: 0.9859 - scaled_graph_loss: 1.0354e-04 - val_loss: 4.2911 - val_accuracy: 0.5192 - val_auc: 0.7346 - val_f1_score: 0.5191\n","\n","Epoch 00014: val_accuracy did not improve from 0.68726\n","Epoch 15/50\n","160/160 [==============================] - 77s 480ms/step - loss: 0.0333 - accuracy: 0.9909 - auc: 0.9998 - f1_score: 0.9909 - scaled_graph_loss: 7.3374e-05 - val_loss: 2.3635 - val_accuracy: 0.6482 - val_auc: 0.8265 - val_f1_score: 0.6464\n","\n","Epoch 00015: val_accuracy did not improve from 0.68726\n","Epoch 16/50\n","160/160 [==============================] - 78s 482ms/step - loss: 0.0579 - accuracy: 0.9803 - auc: 0.9989 - f1_score: 0.9799 - scaled_graph_loss: 1.2221e-04 - val_loss: 2.1124 - val_accuracy: 0.6607 - val_auc: 0.8497 - val_f1_score: 0.6598\n","\n","Epoch 00016: val_accuracy did not improve from 0.68726\n","Epoch 17/50\n","160/160 [==============================] - 78s 481ms/step - loss: 0.0293 - accuracy: 0.9908 - auc: 0.9999 - f1_score: 0.9909 - scaled_graph_loss: 6.5131e-05 - val_loss: 2.0243 - val_accuracy: 0.6771 - val_auc: 0.8582 - val_f1_score: 0.6769\n","\n","Epoch 00017: val_accuracy did not improve from 0.68726\n","Epoch 18/50\n","160/160 [==============================] - 78s 482ms/step - loss: 0.0229 - accuracy: 0.9948 - auc: 0.9999 - f1_score: 0.9948 - scaled_graph_loss: 4.9767e-05 - val_loss: 2.9828 - val_accuracy: 0.6216 - val_auc: 0.8105 - val_f1_score: 0.6185\n","\n","Epoch 00018: val_accuracy did not improve from 0.68726\n","Epoch 19/50\n","160/160 [==============================] - 78s 480ms/step - loss: 0.0219 - accuracy: 0.9938 - auc: 0.9999 - f1_score: 0.9939 - scaled_graph_loss: 4.9504e-05 - val_loss: 2.7055 - val_accuracy: 0.6591 - val_auc: 0.8310 - val_f1_score: 0.6612\n","\n","Epoch 00019: val_accuracy did not improve from 0.68726\n","Epoch 20/50\n","160/160 [==============================] - 78s 482ms/step - loss: 0.0187 - accuracy: 0.9946 - auc: 1.0000 - f1_score: 0.9948 - scaled_graph_loss: 4.5109e-05 - val_loss: 4.6125 - val_accuracy: 0.5731 - val_auc: 0.7571 - val_f1_score: 0.5730\n","\n","Epoch 00020: val_accuracy did not improve from 0.68726\n","Epoch 21/50\n","160/160 [==============================] - 78s 481ms/step - loss: 0.0262 - accuracy: 0.9929 - auc: 0.9999 - f1_score: 0.9929 - scaled_graph_loss: 5.8313e-05 - val_loss: 3.7432 - val_accuracy: 0.5043 - val_auc: 0.7278 - val_f1_score: 0.5043\n","\n","Epoch 00021: val_accuracy did not improve from 0.68726\n","Epoch 22/50\n","160/160 [==============================] - 78s 482ms/step - loss: 0.0249 - accuracy: 0.9940 - auc: 0.9999 - f1_score: 0.9944 - scaled_graph_loss: 5.5840e-05 - val_loss: 7.0298 - val_accuracy: 0.4722 - val_auc: 0.6764 - val_f1_score: 0.4706\n","\n","Epoch 00022: val_accuracy did not improve from 0.68726\n","Epoch 23/50\n","160/160 [==============================] - 78s 482ms/step - loss: 0.0449 - accuracy: 0.9867 - auc: 0.9992 - f1_score: 0.9867 - scaled_graph_loss: 9.4326e-05 - val_loss: 2.5420 - val_accuracy: 0.6364 - val_auc: 0.8235 - val_f1_score: 0.6356\n","\n","Epoch 00023: val_accuracy did not improve from 0.68726\n","Epoch 24/50\n","160/160 [==============================] - 78s 482ms/step - loss: 0.0193 - accuracy: 0.9951 - auc: 1.0000 - f1_score: 0.9948 - scaled_graph_loss: 4.2203e-05 - val_loss: 2.8533 - val_accuracy: 0.6372 - val_auc: 0.8081 - val_f1_score: 0.6369\n","\n","Epoch 00024: val_accuracy did not improve from 0.68726\n","Epoch 25/50\n","160/160 [==============================] - 78s 482ms/step - loss: 0.0180 - accuracy: 0.9960 - auc: 1.0000 - f1_score: 0.9959 - scaled_graph_loss: 4.0155e-05 - val_loss: 2.8136 - val_accuracy: 0.6529 - val_auc: 0.8179 - val_f1_score: 0.6523\n","\n","Epoch 00025: val_accuracy did not improve from 0.68726\n","Epoch 26/50\n","160/160 [==============================] - 78s 482ms/step - loss: 0.0240 - accuracy: 0.9938 - auc: 0.9999 - f1_score: 0.9939 - scaled_graph_loss: 5.2327e-05 - val_loss: 3.3947 - val_accuracy: 0.5981 - val_auc: 0.7919 - val_f1_score: 0.5964\n","\n","Epoch 00026: val_accuracy did not improve from 0.68726\n","Epoch 27/50\n","160/160 [==============================] - 78s 483ms/step - loss: 0.0245 - accuracy: 0.9938 - auc: 0.9999 - f1_score: 0.9939 - scaled_graph_loss: 5.6450e-05 - val_loss: 2.9124 - val_accuracy: 0.6310 - val_auc: 0.8233 - val_f1_score: 0.6314\n","\n","Epoch 00027: val_accuracy did not improve from 0.68726\n","Epoch 28/50\n","160/160 [==============================] - 78s 482ms/step - loss: 0.0303 - accuracy: 0.9922 - auc: 0.9998 - f1_score: 0.9921 - scaled_graph_loss: 6.7786e-05 - val_loss: 2.8957 - val_accuracy: 0.6357 - val_auc: 0.8142 - val_f1_score: 0.6325\n","\n","Epoch 00028: val_accuracy did not improve from 0.68726\n","Epoch 29/50\n","160/160 [==============================] - 78s 483ms/step - loss: 0.0256 - accuracy: 0.9921 - auc: 0.9999 - f1_score: 0.9922 - scaled_graph_loss: 5.7630e-05 - val_loss: 2.5818 - val_accuracy: 0.6458 - val_auc: 0.8241 - val_f1_score: 0.6465\n","\n","Epoch 00029: val_accuracy did not improve from 0.68726\n","Epoch 30/50\n","160/160 [==============================] - 78s 482ms/step - loss: 0.0263 - accuracy: 0.9927 - auc: 0.9999 - f1_score: 0.9926 - scaled_graph_loss: 6.3728e-05 - val_loss: 3.0643 - val_accuracy: 0.6364 - val_auc: 0.8218 - val_f1_score: 0.6364\n","\n","Epoch 00030: val_accuracy did not improve from 0.68726\n","Epoch 31/50\n","160/160 [==============================] - 78s 482ms/step - loss: 0.0249 - accuracy: 0.9928 - auc: 0.9999 - f1_score: 0.9930 - scaled_graph_loss: 5.7294e-05 - val_loss: 4.0492 - val_accuracy: 0.5442 - val_auc: 0.7553 - val_f1_score: 0.5406\n","\n","Epoch 00031: val_accuracy did not improve from 0.68726\n","Epoch 32/50\n","160/160 [==============================] - 78s 483ms/step - loss: 0.0206 - accuracy: 0.9942 - auc: 1.0000 - f1_score: 0.9939 - scaled_graph_loss: 4.7313e-05 - val_loss: 2.5129 - val_accuracy: 0.6810 - val_auc: 0.8473 - val_f1_score: 0.6789\n","\n","Epoch 00032: val_accuracy did not improve from 0.68726\n","Epoch 33/50\n","160/160 [==============================] - 78s 482ms/step - loss: 0.0154 - accuracy: 0.9964 - auc: 1.0000 - f1_score: 0.9963 - scaled_graph_loss: 3.5752e-05 - val_loss: 2.6153 - val_accuracy: 0.6763 - val_auc: 0.8392 - val_f1_score: 0.6761\n","\n","Epoch 00033: val_accuracy did not improve from 0.68726\n","Epoch 34/50\n","160/160 [==============================] - 78s 483ms/step - loss: 0.0162 - accuracy: 0.9955 - auc: 1.0000 - f1_score: 0.9958 - scaled_graph_loss: 3.6727e-05 - val_loss: 3.3808 - val_accuracy: 0.5637 - val_auc: 0.7754 - val_f1_score: 0.5639\n","\n","Epoch 00034: val_accuracy did not improve from 0.68726\n","Epoch 35/50\n","160/160 [==============================] - 78s 482ms/step - loss: 0.0134 - accuracy: 0.9966 - auc: 1.0000 - f1_score: 0.9967 - scaled_graph_loss: 3.1232e-05 - val_loss: 3.3558 - val_accuracy: 0.6263 - val_auc: 0.8117 - val_f1_score: 0.6250\n","\n","Epoch 00035: val_accuracy did not improve from 0.68726\n","Epoch 36/50\n","160/160 [==============================] - 78s 482ms/step - loss: 0.0156 - accuracy: 0.9965 - auc: 1.0000 - f1_score: 0.9963 - scaled_graph_loss: 3.3853e-05 - val_loss: 3.1721 - val_accuracy: 0.6403 - val_auc: 0.8173 - val_f1_score: 0.6386\n","\n","Epoch 00036: val_accuracy did not improve from 0.68726\n","Epoch 37/50\n","160/160 [==============================] - 78s 482ms/step - loss: 0.0154 - accuracy: 0.9960 - auc: 1.0000 - f1_score: 0.9962 - scaled_graph_loss: 3.1824e-05 - val_loss: 3.0936 - val_accuracy: 0.6403 - val_auc: 0.8127 - val_f1_score: 0.6374\n","\n","Epoch 00037: val_accuracy did not improve from 0.68726\n","Epoch 38/50\n","160/160 [==============================] - 78s 482ms/step - loss: 0.0135 - accuracy: 0.9967 - auc: 1.0000 - f1_score: 0.9966 - scaled_graph_loss: 3.2395e-05 - val_loss: 2.6368 - val_accuracy: 0.6833 - val_auc: 0.8428 - val_f1_score: 0.6813\n","\n","Epoch 00038: val_accuracy did not improve from 0.68726\n","Epoch 39/50\n","160/160 [==============================] - 78s 481ms/step - loss: 0.0123 - accuracy: 0.9969 - auc: 1.0000 - f1_score: 0.9970 - scaled_graph_loss: 2.5569e-05 - val_loss: 2.5061 - val_accuracy: 0.6685 - val_auc: 0.8423 - val_f1_score: 0.6682\n","\n","Epoch 00039: val_accuracy did not improve from 0.68726\n","Epoch 40/50\n","160/160 [==============================] - 78s 482ms/step - loss: 0.0134 - accuracy: 0.9964 - auc: 1.0000 - f1_score: 0.9964 - scaled_graph_loss: 2.9713e-05 - val_loss: 2.8052 - val_accuracy: 0.6497 - val_auc: 0.8283 - val_f1_score: 0.6514\n","\n","Epoch 00040: val_accuracy did not improve from 0.68726\n","Epoch 41/50\n","160/160 [==============================] - 78s 483ms/step - loss: 0.0149 - accuracy: 0.9971 - auc: 0.9999 - f1_score: 0.9968 - scaled_graph_loss: 3.2979e-05 - val_loss: 4.6948 - val_accuracy: 0.5645 - val_auc: 0.7556 - val_f1_score: 0.5637\n","\n","Epoch 00041: val_accuracy did not improve from 0.68726\n","Epoch 42/50\n","160/160 [==============================] - 78s 482ms/step - loss: 0.0133 - accuracy: 0.9968 - auc: 1.0000 - f1_score: 0.9969 - scaled_graph_loss: 2.7393e-05 - val_loss: 2.5559 - val_accuracy: 0.6575 - val_auc: 0.8403 - val_f1_score: 0.6585\n","\n","Epoch 00042: val_accuracy did not improve from 0.68726\n","Epoch 43/50\n","160/160 [==============================] - 78s 481ms/step - loss: 0.0124 - accuracy: 0.9968 - auc: 1.0000 - f1_score: 0.9969 - scaled_graph_loss: 2.7805e-05 - val_loss: 3.6461 - val_accuracy: 0.5973 - val_auc: 0.7886 - val_f1_score: 0.5985\n","\n","Epoch 00043: val_accuracy did not improve from 0.68726\n","Epoch 44/50\n","160/160 [==============================] - 78s 482ms/step - loss: 0.0258 - accuracy: 0.9923 - auc: 0.9998 - f1_score: 0.9920 - scaled_graph_loss: 5.9304e-05 - val_loss: 3.8508 - val_accuracy: 0.6302 - val_auc: 0.7977 - val_f1_score: 0.6293\n","\n","Epoch 00044: val_accuracy did not improve from 0.68726\n","Epoch 45/50\n","160/160 [==============================] - 78s 482ms/step - loss: 0.0411 - accuracy: 0.9861 - auc: 0.9995 - f1_score: 0.9860 - scaled_graph_loss: 9.4467e-05 - val_loss: 2.4148 - val_accuracy: 0.6716 - val_auc: 0.8533 - val_f1_score: 0.6703\n","\n","Epoch 00045: val_accuracy did not improve from 0.68726\n","Epoch 46/50\n","160/160 [==============================] - 78s 483ms/step - loss: 0.0186 - accuracy: 0.9939 - auc: 1.0000 - f1_score: 0.9939 - scaled_graph_loss: 4.2677e-05 - val_loss: 3.6436 - val_accuracy: 0.5895 - val_auc: 0.7800 - val_f1_score: 0.5899\n","\n","Epoch 00046: val_accuracy did not improve from 0.68726\n","Epoch 47/50\n","160/160 [==============================] - 78s 483ms/step - loss: 0.0133 - accuracy: 0.9967 - auc: 1.0000 - f1_score: 0.9968 - scaled_graph_loss: 2.9554e-05 - val_loss: 4.1330 - val_accuracy: 0.5801 - val_auc: 0.7742 - val_f1_score: 0.5796\n","\n","Epoch 00047: val_accuracy did not improve from 0.68726\n","Epoch 48/50\n","160/160 [==============================] - 86s 486ms/step - loss: 0.0137 - accuracy: 0.9967 - auc: 1.0000 - f1_score: 0.9967 - scaled_graph_loss: 2.9468e-05 - val_loss: 2.6348 - val_accuracy: 0.6669 - val_auc: 0.8391 - val_f1_score: 0.6638\n","\n","Epoch 00048: val_accuracy did not improve from 0.68726\n","Epoch 49/50\n","160/160 [==============================] - 78s 482ms/step - loss: 0.0252 - accuracy: 0.9923 - auc: 0.9998 - f1_score: 0.9925 - scaled_graph_loss: 5.2909e-05 - val_loss: 3.1094 - val_accuracy: 0.6231 - val_auc: 0.8114 - val_f1_score: 0.6216\n","\n","Epoch 00049: val_accuracy did not improve from 0.68726\n","Epoch 50/50\n","160/160 [==============================] - 84s 486ms/step - loss: 0.0193 - accuracy: 0.9955 - auc: 0.9999 - f1_score: 0.9950 - scaled_graph_loss: 4.4492e-05 - val_loss: 2.9534 - val_accuracy: 0.6474 - val_auc: 0.8270 - val_f1_score: 0.6486\n","\n","Epoch 00050: val_accuracy did not improve from 0.68726\n","Early stopping is not triggered, but best model is restored at epoch 2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UhIlqMFhgbcK","executionInfo":{"status":"ok","timestamp":1617894437379,"user_tz":240,"elapsed":2448,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"f22c999d-a92d-43b9-a7ed-e4fb5df7805e"},"source":["\"\"\"evaluate tuned model\"\"\"\n","graph_reg_model.evaluate(test_image_dataset)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1/1 [==============================] - 2s 2s/step - loss: 1.9575 - accuracy: 0.6873 - auc: 0.8606 - f1_score: 0.6872\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[1.9574897289276123,\n"," 0.6872556805610657,\n"," 0.8606342077255249,\n"," 0.6871552467346191]"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"fuf0qJfrMNz6"},"source":["'''plot confusion mat & calc acc for each label'''\n","test_image_dataset = NSLDataFormat.generate_test_tfr_image_tensor(path_list=test_tfr_list, \n","                                                                  batch_size=4000, \n","                                                                  size=(100,100),\n","                                                                  channels=3,\n","                                                                  shuffle=True)\n","data, data_label = iter(test_image_dataset).get_next()\n","data = data[\"tensor\"]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":396},"id":"aHTNVO-oMN3O","executionInfo":{"status":"ok","timestamp":1617894439681,"user_tz":240,"elapsed":2686,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"62fc9797-b8e4-415e-86fa-6eb207ff65a2"},"source":["ADModelBuilder.plot_confusion_mat(graph_reg_model, data, data_label, \"VGG19_NSL\")"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x432 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"SZbyx6tgMeCw"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_fE_9cNM7AS9"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YRSBTOx_ZQ2Y"},"source":["# 3.DenseNet121 & DenseNet121-NSL Model Training"]},{"cell_type":"code","metadata":{"id":"KBPizJFmjEvJ"},"source":["'''define hyper params'''\n","params = AD_params()\n","params.max_seed_nbr=5\n","params.batch_size=128\n","params.image_channels =3\n","params.image_size =(100,100)\n","params.ad_base_model_input_shape=(100,100,3)\n","params.train_tfr_path = train_tfr_path\n","\n","'''parse train_data.tfr to train image dataset with batch_size at 64'''\n","train_image_dataset = NSLDataFormat.parse_tfr_to_dataset(file_path_list=[params.train_tfr_path],\n","                                                         batch_size=params.batch_size,\n","                                                         max_neighbor_number=params.max_seed_nbr,\n","                                                         image_size=params.image_size,\n","                                                         image_channels=params.image_channels,\n","                                                         shuffle=True)\n","\n","'''load test data with batch_size at 64 '''\n","test_image_dataset = NSLDataFormat.generate_test_tfr_image_tensor(path_list=test_tfr_list, \n","                                                                  batch_size=params.batch_size, \n","                                                                  size=params.image_size,\n","                                                                  channels=params.image_channels,\n","                                                                  shuffle=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"980I6MuXjAix"},"source":["## 3.1 DenseNet Base Model Training\n","### val_acc: 0.61, val_auc: 0.85, val_f1_score: 0.60 "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2xyvZj1bcueJ","executionInfo":{"status":"ok","timestamp":1618572362724,"user_tz":240,"elapsed":3904,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"fdd37215-e7cc-4e36-fa86-e239b20611fd"},"source":["'''define params'''\n","params.learning_rate=0.005\n","params.checkpoint_restore_path='/content/drive/MyDrive/AD Expriment II/DenseNet_model_checkpoints/densenet_weights'\n","params.checkpoint_path='/content/drive/MyDrive/AD Expriment II/DenseNet_model_checkpoints/densenet_weights'\n","params.early_stop_base_line=0.70\n","params.train_epoch=50\n","\n","'''build base_model and restore from the last training'''\n","base_model = ADModelBuilder(input_shape=params.ad_base_model_input_shape, base_model='densenet121').get_ADModel()\n","\n","base_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=params.learning_rate, amsgrad=True), \n","                   loss=tf.losses.CategoricalCrossentropy(), \n","                   metrics=['accuracy', 'AUC',tfa.metrics.F1Score(num_classes=4, average=\"micro\", threshold = 0.5)])\n","\n","# base_model.load_weights(params.checkpoint_restore_path)\n","\n","'''set up check point & early stopping'''\n","callback_checkpints = tf.keras.callbacks.ModelCheckpoint(filepath= params.checkpoint_path, monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=True, mode='max',\n","                                                         save_freq='epoch',options=None)\n","\n","callback_earlystop = AccEarlyStop(val_acc_base=params.early_stop_base_line)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Note: default DenseNet121 not includes top and has imagenet weights. It is not a trainable model in ADModelBuilder. Please setup trainable layers in setup_DenseNet121 function based on the \"Layer Number\"\n","Model: \"DenseNet121_ADModel\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","tensor (InputLayer)          [(None, 100, 100, 3)]     0         \n","_________________________________________________________________\n","densenet121 (Functional)     (None, 3, 3, 1024)        7037504   \n","_________________________________________________________________\n","flatten_3 (Flatten)          (None, 9216)              0         \n","_________________________________________________________________\n","dropout_6 (Dropout)          (None, 9216)              0         \n","_________________________________________________________________\n","dense_6 (Dense)              (None, 32)                294944    \n","_________________________________________________________________\n","batch_normalization_3 (Batch (None, 32)                128       \n","_________________________________________________________________\n","leaky_re_lu_3 (LeakyReLU)    (None, 32)                0         \n","_________________________________________________________________\n","dropout_7 (Dropout)          (None, 32)                0         \n","_________________________________________________________________\n","dense_7 (Dense)              (None, 4)                 132       \n","=================================================================\n","Total params: 7,332,708\n","Trainable params: 295,140\n","Non-trainable params: 7,037,568\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tpy7INugZP2P","executionInfo":{"status":"ok","timestamp":1618573367274,"user_tz":240,"elapsed":1001783,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"ef057faa-c15a-4c25-af37-7ea87d8f702f"},"source":["'''train base model'''\n","history = base_model.fit(train_image_dataset,\n","                         validation_data= test_image_dataset,\n","                         callbacks = [callback_checkpints, callback_earlystop],\n","                         epochs=params.train_epoch,\n","                         verbose=1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/50\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py:595: UserWarning: Input dict contained keys ['NL_nbr_0_id', 'NL_nbr_0_tensor', 'NL_nbr_0_weight', 'NL_nbr_1_id', 'NL_nbr_1_tensor', 'NL_nbr_1_weight', 'NL_nbr_2_id', 'NL_nbr_2_tensor', 'NL_nbr_2_weight', 'NL_nbr_3_id', 'NL_nbr_3_tensor', 'NL_nbr_3_weight', 'NL_nbr_4_id', 'NL_nbr_4_tensor', 'NL_nbr_4_weight', 'id'] which did not match any model input. They will be ignored by the model.\n","  [n for n in tensors.keys() if n not in ref_input_names])\n"],"name":"stderr"},{"output_type":"stream","text":["     80/Unknown - 26s 240ms/step - loss: 1.0793 - accuracy: 0.5513 - auc: 0.8067 - f1_score: 0.5097"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py:595: UserWarning: Input dict contained keys ['id'] which did not match any model input. They will be ignored by the model.\n","  [n for n in tensors.keys() if n not in ref_input_names])\n"],"name":"stderr"},{"output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r80/80 [==============================] - 29s 279ms/step - loss: 1.0771 - accuracy: 0.5519 - auc: 0.8073 - f1_score: 0.5103 - val_loss: 1.1650 - val_accuracy: 0.5113 - val_auc: 0.8189 - val_f1_score: 0.5029\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.51134, saving model to /content/drive/MyDrive/AD Expriment II/DenseNet_model_checkpoints/densenet_weights\n","Epoch 2/50\n","80/80 [==============================] - 20s 240ms/step - loss: 0.6907 - accuracy: 0.6897 - auc: 0.9137 - f1_score: 0.6640 - val_loss: 1.0876 - val_accuracy: 0.5199 - val_auc: 0.8202 - val_f1_score: 0.5060\n","\n","Epoch 00002: val_accuracy improved from 0.51134 to 0.51994, saving model to /content/drive/MyDrive/AD Expriment II/DenseNet_model_checkpoints/densenet_weights\n","Epoch 3/50\n","80/80 [==============================] - 20s 238ms/step - loss: 0.6191 - accuracy: 0.7267 - auc: 0.9305 - f1_score: 0.7107 - val_loss: 0.9327 - val_accuracy: 0.5614 - val_auc: 0.8416 - val_f1_score: 0.5304\n","\n","Epoch 00003: val_accuracy improved from 0.51994 to 0.56138, saving model to /content/drive/MyDrive/AD Expriment II/DenseNet_model_checkpoints/densenet_weights\n","Epoch 4/50\n","80/80 [==============================] - 20s 241ms/step - loss: 0.5851 - accuracy: 0.7388 - auc: 0.9368 - f1_score: 0.7262 - val_loss: 1.0732 - val_accuracy: 0.5590 - val_auc: 0.8328 - val_f1_score: 0.5416\n","\n","Epoch 00004: val_accuracy did not improve from 0.56138\n","Epoch 5/50\n","80/80 [==============================] - 20s 237ms/step - loss: 0.5634 - accuracy: 0.7446 - auc: 0.9417 - f1_score: 0.7405 - val_loss: 0.9974 - val_accuracy: 0.5637 - val_auc: 0.8404 - val_f1_score: 0.5470\n","\n","Epoch 00005: val_accuracy improved from 0.56138 to 0.56372, saving model to /content/drive/MyDrive/AD Expriment II/DenseNet_model_checkpoints/densenet_weights\n","Epoch 6/50\n","80/80 [==============================] - 20s 239ms/step - loss: 0.5246 - accuracy: 0.7702 - auc: 0.9495 - f1_score: 0.7605 - val_loss: 1.1080 - val_accuracy: 0.5582 - val_auc: 0.8317 - val_f1_score: 0.5503\n","\n","Epoch 00006: val_accuracy did not improve from 0.56372\n","Epoch 7/50\n","80/80 [==============================] - 19s 236ms/step - loss: 0.5124 - accuracy: 0.7771 - auc: 0.9520 - f1_score: 0.7691 - val_loss: 1.1980 - val_accuracy: 0.5645 - val_auc: 0.8309 - val_f1_score: 0.5529\n","\n","Epoch 00007: val_accuracy improved from 0.56372 to 0.56450, saving model to /content/drive/MyDrive/AD Expriment II/DenseNet_model_checkpoints/densenet_weights\n","Epoch 8/50\n","80/80 [==============================] - 20s 239ms/step - loss: 0.5064 - accuracy: 0.7747 - auc: 0.9524 - f1_score: 0.7698 - val_loss: 1.0088 - val_accuracy: 0.5450 - val_auc: 0.8351 - val_f1_score: 0.5320\n","\n","Epoch 00008: val_accuracy did not improve from 0.56450\n","Epoch 9/50\n","80/80 [==============================] - 19s 235ms/step - loss: 0.5004 - accuracy: 0.7778 - auc: 0.9535 - f1_score: 0.7680 - val_loss: 1.0023 - val_accuracy: 0.5801 - val_auc: 0.8417 - val_f1_score: 0.5611\n","\n","Epoch 00009: val_accuracy improved from 0.56450 to 0.58014, saving model to /content/drive/MyDrive/AD Expriment II/DenseNet_model_checkpoints/densenet_weights\n","Epoch 10/50\n","80/80 [==============================] - 20s 236ms/step - loss: 0.4809 - accuracy: 0.7893 - auc: 0.9575 - f1_score: 0.7862 - val_loss: 1.1044 - val_accuracy: 0.5293 - val_auc: 0.8221 - val_f1_score: 0.5255\n","\n","Epoch 00010: val_accuracy did not improve from 0.58014\n","Epoch 11/50\n","80/80 [==============================] - 19s 236ms/step - loss: 0.4690 - accuracy: 0.7939 - auc: 0.9591 - f1_score: 0.7872 - val_loss: 0.9995 - val_accuracy: 0.5747 - val_auc: 0.8390 - val_f1_score: 0.5552\n","\n","Epoch 00011: val_accuracy did not improve from 0.58014\n","Epoch 12/50\n","80/80 [==============================] - 19s 236ms/step - loss: 0.4595 - accuracy: 0.8015 - auc: 0.9611 - f1_score: 0.7968 - val_loss: 1.1117 - val_accuracy: 0.5747 - val_auc: 0.8401 - val_f1_score: 0.5675\n","\n","Epoch 00012: val_accuracy did not improve from 0.58014\n","Epoch 13/50\n","80/80 [==============================] - 20s 237ms/step - loss: 0.4689 - accuracy: 0.7894 - auc: 0.9590 - f1_score: 0.7850 - val_loss: 1.0213 - val_accuracy: 0.5622 - val_auc: 0.8405 - val_f1_score: 0.5498\n","\n","Epoch 00013: val_accuracy did not improve from 0.58014\n","Epoch 14/50\n","80/80 [==============================] - 20s 237ms/step - loss: 0.4518 - accuracy: 0.8001 - auc: 0.9622 - f1_score: 0.7990 - val_loss: 1.1541 - val_accuracy: 0.5770 - val_auc: 0.8406 - val_f1_score: 0.5651\n","\n","Epoch 00014: val_accuracy did not improve from 0.58014\n","Epoch 15/50\n","80/80 [==============================] - 19s 236ms/step - loss: 0.4460 - accuracy: 0.8070 - auc: 0.9631 - f1_score: 0.8023 - val_loss: 1.1428 - val_accuracy: 0.5887 - val_auc: 0.8404 - val_f1_score: 0.5853\n","\n","Epoch 00015: val_accuracy improved from 0.58014 to 0.58874, saving model to /content/drive/MyDrive/AD Expriment II/DenseNet_model_checkpoints/densenet_weights\n","Epoch 16/50\n","80/80 [==============================] - 20s 237ms/step - loss: 0.4414 - accuracy: 0.8043 - auc: 0.9636 - f1_score: 0.8024 - val_loss: 1.0559 - val_accuracy: 0.5676 - val_auc: 0.8380 - val_f1_score: 0.5504\n","\n","Epoch 00016: val_accuracy did not improve from 0.58874\n","Epoch 17/50\n","80/80 [==============================] - 19s 236ms/step - loss: 0.4360 - accuracy: 0.8137 - auc: 0.9650 - f1_score: 0.8114 - val_loss: 1.0675 - val_accuracy: 0.5786 - val_auc: 0.8401 - val_f1_score: 0.5680\n","\n","Epoch 00017: val_accuracy did not improve from 0.58874\n","Epoch 18/50\n","80/80 [==============================] - 19s 235ms/step - loss: 0.4381 - accuracy: 0.8124 - auc: 0.9646 - f1_score: 0.8088 - val_loss: 1.0232 - val_accuracy: 0.5848 - val_auc: 0.8476 - val_f1_score: 0.5802\n","\n","Epoch 00018: val_accuracy did not improve from 0.58874\n","Epoch 19/50\n","80/80 [==============================] - 19s 235ms/step - loss: 0.4232 - accuracy: 0.8187 - auc: 0.9668 - f1_score: 0.8169 - val_loss: 1.0355 - val_accuracy: 0.5794 - val_auc: 0.8401 - val_f1_score: 0.5657\n","\n","Epoch 00019: val_accuracy did not improve from 0.58874\n","Epoch 20/50\n","80/80 [==============================] - 19s 236ms/step - loss: 0.4363 - accuracy: 0.8072 - auc: 0.9650 - f1_score: 0.8054 - val_loss: 1.2271 - val_accuracy: 0.5723 - val_auc: 0.8362 - val_f1_score: 0.5609\n","\n","Epoch 00020: val_accuracy did not improve from 0.58874\n","Epoch 21/50\n","80/80 [==============================] - 19s 236ms/step - loss: 0.4489 - accuracy: 0.8013 - auc: 0.9624 - f1_score: 0.8010 - val_loss: 1.1370 - val_accuracy: 0.5942 - val_auc: 0.8432 - val_f1_score: 0.5837\n","\n","Epoch 00021: val_accuracy improved from 0.58874 to 0.59421, saving model to /content/drive/MyDrive/AD Expriment II/DenseNet_model_checkpoints/densenet_weights\n","Epoch 22/50\n","80/80 [==============================] - 20s 238ms/step - loss: 0.4123 - accuracy: 0.8202 - auc: 0.9683 - f1_score: 0.8183 - val_loss: 1.1872 - val_accuracy: 0.5887 - val_auc: 0.8406 - val_f1_score: 0.5815\n","\n","Epoch 00022: val_accuracy did not improve from 0.59421\n","Epoch 23/50\n","80/80 [==============================] - 19s 236ms/step - loss: 0.4046 - accuracy: 0.8270 - auc: 0.9697 - f1_score: 0.8240 - val_loss: 1.0830 - val_accuracy: 0.5911 - val_auc: 0.8463 - val_f1_score: 0.5809\n","\n","Epoch 00023: val_accuracy did not improve from 0.59421\n","Epoch 24/50\n","80/80 [==============================] - 19s 236ms/step - loss: 0.4239 - accuracy: 0.8182 - auc: 0.9666 - f1_score: 0.8141 - val_loss: 1.0741 - val_accuracy: 0.5864 - val_auc: 0.8453 - val_f1_score: 0.5794\n","\n","Epoch 00024: val_accuracy did not improve from 0.59421\n","Epoch 25/50\n","80/80 [==============================] - 19s 236ms/step - loss: 0.4136 - accuracy: 0.8186 - auc: 0.9681 - f1_score: 0.8148 - val_loss: 1.2256 - val_accuracy: 0.5903 - val_auc: 0.8412 - val_f1_score: 0.5851\n","\n","Epoch 00025: val_accuracy did not improve from 0.59421\n","Epoch 26/50\n","80/80 [==============================] - 19s 236ms/step - loss: 0.3989 - accuracy: 0.8279 - auc: 0.9703 - f1_score: 0.8246 - val_loss: 1.1275 - val_accuracy: 0.5887 - val_auc: 0.8433 - val_f1_score: 0.5797\n","\n","Epoch 00026: val_accuracy did not improve from 0.59421\n","Epoch 27/50\n","80/80 [==============================] - 19s 236ms/step - loss: 0.3919 - accuracy: 0.8323 - auc: 0.9716 - f1_score: 0.8315 - val_loss: 1.0760 - val_accuracy: 0.5895 - val_auc: 0.8435 - val_f1_score: 0.5864\n","\n","Epoch 00027: val_accuracy did not improve from 0.59421\n","Epoch 28/50\n","80/80 [==============================] - 20s 238ms/step - loss: 0.3897 - accuracy: 0.8364 - auc: 0.9718 - f1_score: 0.8337 - val_loss: 1.2020 - val_accuracy: 0.5801 - val_auc: 0.8380 - val_f1_score: 0.5693\n","\n","Epoch 00028: val_accuracy did not improve from 0.59421\n","Epoch 29/50\n","80/80 [==============================] - 19s 237ms/step - loss: 0.3927 - accuracy: 0.8329 - auc: 0.9712 - f1_score: 0.8305 - val_loss: 1.1084 - val_accuracy: 0.5958 - val_auc: 0.8453 - val_f1_score: 0.5887\n","\n","Epoch 00029: val_accuracy improved from 0.59421 to 0.59578, saving model to /content/drive/MyDrive/AD Expriment II/DenseNet_model_checkpoints/densenet_weights\n","Epoch 30/50\n","80/80 [==============================] - 20s 238ms/step - loss: 0.3831 - accuracy: 0.8401 - auc: 0.9726 - f1_score: 0.8369 - val_loss: 1.1415 - val_accuracy: 0.5598 - val_auc: 0.8369 - val_f1_score: 0.5560\n","\n","Epoch 00030: val_accuracy did not improve from 0.59578\n","Epoch 31/50\n","80/80 [==============================] - 19s 236ms/step - loss: 0.3896 - accuracy: 0.8319 - auc: 0.9718 - f1_score: 0.8301 - val_loss: 1.2393 - val_accuracy: 0.5747 - val_auc: 0.8403 - val_f1_score: 0.5707\n","\n","Epoch 00031: val_accuracy did not improve from 0.59578\n","Epoch 32/50\n","80/80 [==============================] - 20s 237ms/step - loss: 0.3968 - accuracy: 0.8294 - auc: 0.9707 - f1_score: 0.8279 - val_loss: 1.0810 - val_accuracy: 0.5911 - val_auc: 0.8482 - val_f1_score: 0.5830\n","\n","Epoch 00032: val_accuracy did not improve from 0.59578\n","Epoch 33/50\n","80/80 [==============================] - 20s 237ms/step - loss: 0.3838 - accuracy: 0.8404 - auc: 0.9726 - f1_score: 0.8370 - val_loss: 1.0879 - val_accuracy: 0.6028 - val_auc: 0.8497 - val_f1_score: 0.5903\n","\n","Epoch 00033: val_accuracy improved from 0.59578 to 0.60281, saving model to /content/drive/MyDrive/AD Expriment II/DenseNet_model_checkpoints/densenet_weights\n","Epoch 34/50\n","80/80 [==============================] - 20s 238ms/step - loss: 0.3851 - accuracy: 0.8333 - auc: 0.9724 - f1_score: 0.8326 - val_loss: 1.3948 - val_accuracy: 0.5700 - val_auc: 0.8298 - val_f1_score: 0.5614\n","\n","Epoch 00034: val_accuracy did not improve from 0.60281\n","Epoch 35/50\n","80/80 [==============================] - 19s 236ms/step - loss: 0.3815 - accuracy: 0.8410 - auc: 0.9729 - f1_score: 0.8397 - val_loss: 1.2103 - val_accuracy: 0.5942 - val_auc: 0.8440 - val_f1_score: 0.5885\n","\n","Epoch 00035: val_accuracy did not improve from 0.60281\n","Epoch 36/50\n","80/80 [==============================] - 20s 237ms/step - loss: 0.3647 - accuracy: 0.8462 - auc: 0.9752 - f1_score: 0.8459 - val_loss: 1.2784 - val_accuracy: 0.5817 - val_auc: 0.8389 - val_f1_score: 0.5826\n","\n","Epoch 00036: val_accuracy did not improve from 0.60281\n","Epoch 37/50\n","80/80 [==============================] - 20s 240ms/step - loss: 0.3899 - accuracy: 0.8372 - auc: 0.9718 - f1_score: 0.8356 - val_loss: 1.2409 - val_accuracy: 0.5973 - val_auc: 0.8431 - val_f1_score: 0.5841\n","\n","Epoch 00037: val_accuracy did not improve from 0.60281\n","Epoch 38/50\n","80/80 [==============================] - 19s 235ms/step - loss: 0.3749 - accuracy: 0.8390 - auc: 0.9738 - f1_score: 0.8395 - val_loss: 1.1457 - val_accuracy: 0.6013 - val_auc: 0.8476 - val_f1_score: 0.5923\n","\n","Epoch 00038: val_accuracy did not improve from 0.60281\n","Epoch 39/50\n","80/80 [==============================] - 19s 236ms/step - loss: 0.3592 - accuracy: 0.8526 - auc: 0.9759 - f1_score: 0.8476 - val_loss: 1.2206 - val_accuracy: 0.5379 - val_auc: 0.8241 - val_f1_score: 0.5344\n","\n","Epoch 00039: val_accuracy did not improve from 0.60281\n","Epoch 40/50\n","80/80 [==============================] - 20s 238ms/step - loss: 0.3667 - accuracy: 0.8411 - auc: 0.9749 - f1_score: 0.8417 - val_loss: 1.0602 - val_accuracy: 0.6013 - val_auc: 0.8510 - val_f1_score: 0.5937\n","\n","Epoch 00040: val_accuracy did not improve from 0.60281\n","Epoch 41/50\n","80/80 [==============================] - 19s 235ms/step - loss: 0.3675 - accuracy: 0.8446 - auc: 0.9747 - f1_score: 0.8406 - val_loss: 1.2212 - val_accuracy: 0.5958 - val_auc: 0.8463 - val_f1_score: 0.5896\n","\n","Epoch 00041: val_accuracy did not improve from 0.60281\n","Epoch 42/50\n","80/80 [==============================] - 20s 237ms/step - loss: 0.3628 - accuracy: 0.8482 - auc: 0.9754 - f1_score: 0.8460 - val_loss: 1.3262 - val_accuracy: 0.5809 - val_auc: 0.8388 - val_f1_score: 0.5789\n","\n","Epoch 00042: val_accuracy did not improve from 0.60281\n","Epoch 43/50\n","80/80 [==============================] - 20s 238ms/step - loss: 0.3680 - accuracy: 0.8415 - auc: 0.9748 - f1_score: 0.8413 - val_loss: 1.1639 - val_accuracy: 0.6083 - val_auc: 0.8471 - val_f1_score: 0.6018\n","\n","Epoch 00043: val_accuracy improved from 0.60281 to 0.60829, saving model to /content/drive/MyDrive/AD Expriment II/DenseNet_model_checkpoints/densenet_weights\n","Epoch 44/50\n","80/80 [==============================] - 20s 240ms/step - loss: 0.3610 - accuracy: 0.8452 - auc: 0.9757 - f1_score: 0.8432 - val_loss: 1.2098 - val_accuracy: 0.5934 - val_auc: 0.8423 - val_f1_score: 0.5836\n","\n","Epoch 00044: val_accuracy did not improve from 0.60829\n","Epoch 45/50\n","80/80 [==============================] - 20s 237ms/step - loss: 0.3634 - accuracy: 0.8472 - auc: 0.9755 - f1_score: 0.8460 - val_loss: 1.1322 - val_accuracy: 0.6020 - val_auc: 0.8492 - val_f1_score: 0.5973\n","\n","Epoch 00045: val_accuracy did not improve from 0.60829\n","Epoch 46/50\n","80/80 [==============================] - 20s 238ms/step - loss: 0.3452 - accuracy: 0.8506 - auc: 0.9778 - f1_score: 0.8505 - val_loss: 1.1089 - val_accuracy: 0.6106 - val_auc: 0.8511 - val_f1_score: 0.5994\n","\n","Epoch 00046: val_accuracy improved from 0.60829 to 0.61063, saving model to /content/drive/MyDrive/AD Expriment II/DenseNet_model_checkpoints/densenet_weights\n","Epoch 47/50\n","80/80 [==============================] - 20s 237ms/step - loss: 0.3481 - accuracy: 0.8512 - auc: 0.9774 - f1_score: 0.8504 - val_loss: 1.1098 - val_accuracy: 0.5989 - val_auc: 0.8490 - val_f1_score: 0.5848\n","\n","Epoch 00047: val_accuracy did not improve from 0.61063\n","Epoch 48/50\n","80/80 [==============================] - 20s 237ms/step - loss: 0.3648 - accuracy: 0.8440 - auc: 0.9748 - f1_score: 0.8436 - val_loss: 1.1981 - val_accuracy: 0.6091 - val_auc: 0.8502 - val_f1_score: 0.6048\n","\n","Epoch 00048: val_accuracy did not improve from 0.61063\n","Epoch 49/50\n","80/80 [==============================] - 19s 236ms/step - loss: 0.3569 - accuracy: 0.8485 - auc: 0.9763 - f1_score: 0.8489 - val_loss: 1.1528 - val_accuracy: 0.6036 - val_auc: 0.8480 - val_f1_score: 0.5980\n","\n","Epoch 00049: val_accuracy did not improve from 0.61063\n","Epoch 50/50\n","80/80 [==============================] - 20s 237ms/step - loss: 0.3402 - accuracy: 0.8534 - auc: 0.9784 - f1_score: 0.8532 - val_loss: 1.1750 - val_accuracy: 0.5973 - val_auc: 0.8462 - val_f1_score: 0.5906\n","\n","Epoch 00050: val_accuracy did not improve from 0.61063\n","Early stopping is not triggered, but best model is restored at epoch 46\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wyzcCFeOZP1r","executionInfo":{"status":"ok","timestamp":1618573379979,"user_tz":240,"elapsed":1828,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"316dcda6-6495-45ef-8410-a3660910ec52"},"source":["'''evaluate base model'''\n","base_model.evaluate(test_image_dataset)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1/1 [==============================] - 1s 1s/step - loss: 1.1089 - accuracy: 0.6106 - auc: 0.8511 - f1_score: 0.5994\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[1.1089028120040894,\n"," 0.6106333136558533,\n"," 0.8510772585868835,\n"," 0.5994260311126709]"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"6nBD2RQWKJto"},"source":["'''plot confusion mat & calc acc for each label'''\n","test_image_dataset = NSLDataFormat.generate_test_tfr_image_tensor(path_list=test_tfr_list, \n","                                                                  batch_size=4000, \n","                                                                  size=(100,100),\n","                                                                  channels=3,\n","                                                                  shuffle=True)\n","data, data_label = iter(test_image_dataset).get_next()\n","data = data[\"tensor\"]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":396},"id":"yz9TqB3XKJv_","executionInfo":{"status":"ok","timestamp":1618573392801,"user_tz":240,"elapsed":1566,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"b2989197-5983-433d-d6fd-34d29be1a447"},"source":["ADModelBuilder.plot_confusion_mat(base_model, data, data_label, \"DenseNet121\")"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x432 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"8BFz2NxAKJyD"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Jd0LKKAc5NLM"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aAfKfwGX5x9Y"},"source":["## 3.2 DenseNet_NSL Model Training\n","### val_acc: 0.60, val_auc: 0.85, val_f1_score: 0.59\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BY2jbBjQZP1C","executionInfo":{"status":"ok","timestamp":1618573548552,"user_tz":240,"elapsed":3943,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"4086f598-b0c0-4607-b902-990d63ecf6f3"},"source":["'''define params'''\n","params.learning_rate=0.005\n","params.restore_path = '/content/drive/MyDrive/AD Expriment II/DenseNet_model_checkpoints/densenet_nsl_weights'\n","params.checkpoint_path = '/content/drive/MyDrive/AD Expriment II/DenseNet_model_checkpoints/densenet_nsl_weights'\n","params.early_stop_base_line=0.65\n","params.train_epoch=50\n","params.nsl_multiplier = 0.005\n","params.nsl_sum_over_axis = -1\n","params.nsl_distance_type = nsl.configs.DistanceType.COSINE\n","\n","'''build base_model and restore from the last training'''\n","base_model = ADModelBuilder(input_shape=params.ad_base_model_input_shape, base_model='densenet121').get_ADModel()\n","\n","'''build NSL model on top of base model'''\n","graph_reg_config = nsl.configs.make_graph_reg_config(neighbor_prefix=params.neighbor_prefix,\n","                                                     neighbor_weight_suffix=params.neighbor_weight_suffix,\n","                                                     max_neighbors= params.max_seed_nbr,\n","                                                     multiplier= params.nsl_multiplier,\n","                                                     distance_type= params.nsl_distance_type,\n","                                                     sum_over_axis=params.nsl_sum_over_axis)\n","graph_reg_model = nsl.keras.GraphRegularization(base_model,graph_reg_config)\n","graph_reg_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=params.learning_rate, amsgrad=True),\n","                        loss=tf.losses.CategoricalCrossentropy(),\n","                        metrics=[\"accuracy\",\"AUC\",tfa.metrics.F1Score(num_classes=4, average=\"micro\", threshold = 0.5)])\n","\n","# graph_reg_model.load_weights(params.restore_path)\n","'''set up check point & early stopping'''\n","callback_checkpoints = tf.keras.callbacks.ModelCheckpoint(filepath= params.checkpoint_path, monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=True, mode='max', save_freq='epoch',options=None)\n","callback_earlystop = AccEarlyStop(val_acc_base=params.early_stop_base_line)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Note: default DenseNet121 not includes top and has imagenet weights. It is not a trainable model in ADModelBuilder. Please setup trainable layers in setup_DenseNet121 function based on the \"Layer Number\"\n","Model: \"DenseNet121_ADModel\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","tensor (InputLayer)          [(None, 100, 100, 3)]     0         \n","_________________________________________________________________\n","densenet121 (Functional)     (None, 3, 3, 1024)        7037504   \n","_________________________________________________________________\n","flatten_6 (Flatten)          (None, 9216)              0         \n","_________________________________________________________________\n","dropout_12 (Dropout)         (None, 9216)              0         \n","_________________________________________________________________\n","dense_12 (Dense)             (None, 32)                294944    \n","_________________________________________________________________\n","batch_normalization_6 (Batch (None, 32)                128       \n","_________________________________________________________________\n","leaky_re_lu_6 (LeakyReLU)    (None, 32)                0         \n","_________________________________________________________________\n","dropout_13 (Dropout)         (None, 32)                0         \n","_________________________________________________________________\n","dense_13 (Dense)             (None, 4)                 132       \n","=================================================================\n","Total params: 7,332,708\n","Trainable params: 295,140\n","Non-trainable params: 7,037,568\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zfVdJD-ff1BO","executionInfo":{"status":"ok","timestamp":1618575723514,"user_tz":240,"elapsed":2171249,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"d23cba9d-699f-4ab1-e412-b42cf5a87761"},"source":["'''train the nsl model'''\n","graph_reg_history = graph_reg_model.fit(train_image_dataset, \n","                                        validation_data=test_image_dataset,\n","                                        callbacks = [callback_checkpoints, callback_earlystop],\n","                                        epochs=params.train_epoch,\n","                                        verbose=1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/50\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py:595: UserWarning: Input dict contained keys ['id'] which did not match any model input. They will be ignored by the model.\n","  [n for n in tensors.keys() if n not in ref_input_names])\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/GraphRegularization/graph_loss/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/GraphRegularization/graph_loss/Reshape:0\", shape=(None, 4), dtype=float32), dense_shape=Tensor(\"gradient_tape/GraphRegularization/graph_loss/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"shape. This may consume a large amount of memory.\" % value)\n"],"name":"stderr"},{"output_type":"stream","text":["80/80 [==============================] - 69s 633ms/step - loss: 0.9899 - accuracy: 0.5700 - auc: 0.8274 - f1_score: 0.5272 - scaled_graph_loss: 7.1967e-04 - val_loss: 0.9882 - val_accuracy: 0.5403 - val_auc: 0.8239 - val_f1_score: 0.5757\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.54027, saving model to /content/drive/MyDrive/AD Expriment II/DenseNet_model_checkpoints/densenet_nsl_weights\n","Epoch 2/50\n","80/80 [==============================] - 43s 527ms/step - loss: 0.6759 - accuracy: 0.7045 - auc: 0.9178 - f1_score: 0.6812 - scaled_graph_loss: 5.7534e-04 - val_loss: 1.0293 - val_accuracy: 0.5426 - val_auc: 0.8313 - val_f1_score: 0.5348\n","\n","Epoch 00002: val_accuracy improved from 0.54027 to 0.54261, saving model to /content/drive/MyDrive/AD Expriment II/DenseNet_model_checkpoints/densenet_nsl_weights\n","Epoch 3/50\n","80/80 [==============================] - 42s 517ms/step - loss: 0.5909 - accuracy: 0.7378 - auc: 0.9366 - f1_score: 0.7239 - scaled_graph_loss: 5.7662e-04 - val_loss: 1.0261 - val_accuracy: 0.5645 - val_auc: 0.8362 - val_f1_score: 0.5496\n","\n","Epoch 00003: val_accuracy improved from 0.54261 to 0.56450, saving model to /content/drive/MyDrive/AD Expriment II/DenseNet_model_checkpoints/densenet_nsl_weights\n","Epoch 4/50\n","80/80 [==============================] - 43s 523ms/step - loss: 0.5660 - accuracy: 0.7469 - auc: 0.9416 - f1_score: 0.7316 - scaled_graph_loss: 5.6979e-04 - val_loss: 1.1417 - val_accuracy: 0.4824 - val_auc: 0.7768 - val_f1_score: 0.4561\n","\n","Epoch 00004: val_accuracy did not improve from 0.56450\n","Epoch 5/50\n","80/80 [==============================] - 42s 522ms/step - loss: 0.5487 - accuracy: 0.7571 - auc: 0.9447 - f1_score: 0.7472 - scaled_graph_loss: 5.8539e-04 - val_loss: 1.2228 - val_accuracy: 0.5481 - val_auc: 0.8281 - val_f1_score: 0.5402\n","\n","Epoch 00005: val_accuracy did not improve from 0.56450\n","Epoch 6/50\n","80/80 [==============================] - 42s 518ms/step - loss: 0.5352 - accuracy: 0.7638 - auc: 0.9472 - f1_score: 0.7550 - scaled_graph_loss: 6.0343e-04 - val_loss: 0.9828 - val_accuracy: 0.5801 - val_auc: 0.8468 - val_f1_score: 0.5605\n","\n","Epoch 00006: val_accuracy improved from 0.56450 to 0.58014, saving model to /content/drive/MyDrive/AD Expriment II/DenseNet_model_checkpoints/densenet_nsl_weights\n","Epoch 7/50\n","80/80 [==============================] - 42s 521ms/step - loss: 0.5057 - accuracy: 0.7730 - auc: 0.9532 - f1_score: 0.7692 - scaled_graph_loss: 6.1452e-04 - val_loss: 0.9944 - val_accuracy: 0.5442 - val_auc: 0.8341 - val_f1_score: 0.5289\n","\n","Epoch 00007: val_accuracy did not improve from 0.58014\n","Epoch 8/50\n","80/80 [==============================] - 43s 523ms/step - loss: 0.5110 - accuracy: 0.7775 - auc: 0.9518 - f1_score: 0.7698 - scaled_graph_loss: 6.1293e-04 - val_loss: 1.0226 - val_accuracy: 0.5285 - val_auc: 0.8308 - val_f1_score: 0.5215\n","\n","Epoch 00008: val_accuracy did not improve from 0.58014\n","Epoch 9/50\n","80/80 [==============================] - 42s 520ms/step - loss: 0.4840 - accuracy: 0.7892 - auc: 0.9568 - f1_score: 0.7817 - scaled_graph_loss: 6.2694e-04 - val_loss: 1.0709 - val_accuracy: 0.5747 - val_auc: 0.8438 - val_f1_score: 0.5699\n","\n","Epoch 00009: val_accuracy did not improve from 0.58014\n","Epoch 10/50\n","80/80 [==============================] - 43s 530ms/step - loss: 0.4899 - accuracy: 0.7844 - auc: 0.9558 - f1_score: 0.7784 - scaled_graph_loss: 6.2956e-04 - val_loss: 1.0551 - val_accuracy: 0.5747 - val_auc: 0.8384 - val_f1_score: 0.5601\n","\n","Epoch 00010: val_accuracy did not improve from 0.58014\n","Epoch 11/50\n","80/80 [==============================] - 43s 529ms/step - loss: 0.4627 - accuracy: 0.7997 - auc: 0.9605 - f1_score: 0.7947 - scaled_graph_loss: 6.1198e-04 - val_loss: 0.9992 - val_accuracy: 0.5676 - val_auc: 0.8446 - val_f1_score: 0.5611\n","\n","Epoch 00011: val_accuracy did not improve from 0.58014\n","Epoch 12/50\n","80/80 [==============================] - 43s 523ms/step - loss: 0.4581 - accuracy: 0.7978 - auc: 0.9615 - f1_score: 0.7953 - scaled_graph_loss: 6.0220e-04 - val_loss: 1.0080 - val_accuracy: 0.5551 - val_auc: 0.8441 - val_f1_score: 0.5490\n","\n","Epoch 00012: val_accuracy did not improve from 0.58014\n","Epoch 13/50\n","80/80 [==============================] - 43s 528ms/step - loss: 0.4470 - accuracy: 0.8083 - auc: 0.9633 - f1_score: 0.8025 - scaled_graph_loss: 6.1303e-04 - val_loss: 1.1667 - val_accuracy: 0.5786 - val_auc: 0.8398 - val_f1_score: 0.5693\n","\n","Epoch 00013: val_accuracy did not improve from 0.58014\n","Epoch 14/50\n","80/80 [==============================] - 43s 529ms/step - loss: 0.4312 - accuracy: 0.8085 - auc: 0.9658 - f1_score: 0.8095 - scaled_graph_loss: 6.0114e-04 - val_loss: 1.0820 - val_accuracy: 0.5809 - val_auc: 0.8436 - val_f1_score: 0.5713\n","\n","Epoch 00014: val_accuracy improved from 0.58014 to 0.58092, saving model to /content/drive/MyDrive/AD Expriment II/DenseNet_model_checkpoints/densenet_nsl_weights\n","Epoch 15/50\n","80/80 [==============================] - 43s 524ms/step - loss: 0.4364 - accuracy: 0.8121 - auc: 0.9649 - f1_score: 0.8097 - scaled_graph_loss: 6.3167e-04 - val_loss: 1.1055 - val_accuracy: 0.5676 - val_auc: 0.8419 - val_f1_score: 0.5573\n","\n","Epoch 00015: val_accuracy did not improve from 0.58092\n","Epoch 16/50\n","80/80 [==============================] - 42s 519ms/step - loss: 0.4353 - accuracy: 0.8119 - auc: 0.9650 - f1_score: 0.8089 - scaled_graph_loss: 6.3298e-04 - val_loss: 1.1482 - val_accuracy: 0.5903 - val_auc: 0.8428 - val_f1_score: 0.5837\n","\n","Epoch 00016: val_accuracy improved from 0.58092 to 0.59030, saving model to /content/drive/MyDrive/AD Expriment II/DenseNet_model_checkpoints/densenet_nsl_weights\n","Epoch 17/50\n","80/80 [==============================] - 42s 514ms/step - loss: 0.4267 - accuracy: 0.8173 - auc: 0.9667 - f1_score: 0.8162 - scaled_graph_loss: 6.5195e-04 - val_loss: 1.1876 - val_accuracy: 0.5770 - val_auc: 0.8425 - val_f1_score: 0.5694\n","\n","Epoch 00017: val_accuracy did not improve from 0.59030\n","Epoch 18/50\n","80/80 [==============================] - 43s 527ms/step - loss: 0.4310 - accuracy: 0.8119 - auc: 0.9658 - f1_score: 0.8102 - scaled_graph_loss: 6.2209e-04 - val_loss: 1.1125 - val_accuracy: 0.5895 - val_auc: 0.8479 - val_f1_score: 0.5801\n","\n","Epoch 00018: val_accuracy did not improve from 0.59030\n","Epoch 19/50\n","80/80 [==============================] - 41s 503ms/step - loss: 0.4221 - accuracy: 0.8198 - auc: 0.9673 - f1_score: 0.8176 - scaled_graph_loss: 6.3820e-04 - val_loss: 1.0739 - val_accuracy: 0.5880 - val_auc: 0.8483 - val_f1_score: 0.5815\n","\n","Epoch 00019: val_accuracy did not improve from 0.59030\n","Epoch 20/50\n","80/80 [==============================] - 43s 525ms/step - loss: 0.4264 - accuracy: 0.8172 - auc: 0.9667 - f1_score: 0.8152 - scaled_graph_loss: 6.2387e-04 - val_loss: 1.1268 - val_accuracy: 0.5911 - val_auc: 0.8475 - val_f1_score: 0.5855\n","\n","Epoch 00020: val_accuracy improved from 0.59030 to 0.59109, saving model to /content/drive/MyDrive/AD Expriment II/DenseNet_model_checkpoints/densenet_nsl_weights\n","Epoch 21/50\n","80/80 [==============================] - 42s 519ms/step - loss: 0.4057 - accuracy: 0.8226 - auc: 0.9695 - f1_score: 0.8209 - scaled_graph_loss: 6.4510e-04 - val_loss: 1.0698 - val_accuracy: 0.5958 - val_auc: 0.8505 - val_f1_score: 0.5901\n","\n","Epoch 00021: val_accuracy improved from 0.59109 to 0.59578, saving model to /content/drive/MyDrive/AD Expriment II/DenseNet_model_checkpoints/densenet_nsl_weights\n","Epoch 22/50\n","80/80 [==============================] - 42s 522ms/step - loss: 0.3995 - accuracy: 0.8327 - auc: 0.9707 - f1_score: 0.8297 - scaled_graph_loss: 6.3470e-04 - val_loss: 1.0913 - val_accuracy: 0.5786 - val_auc: 0.8447 - val_f1_score: 0.5704\n","\n","Epoch 00022: val_accuracy did not improve from 0.59578\n","Epoch 23/50\n","80/80 [==============================] - 43s 526ms/step - loss: 0.4061 - accuracy: 0.8192 - auc: 0.9693 - f1_score: 0.8194 - scaled_graph_loss: 6.2501e-04 - val_loss: 1.0396 - val_accuracy: 0.5825 - val_auc: 0.8519 - val_f1_score: 0.5740\n","\n","Epoch 00023: val_accuracy did not improve from 0.59578\n","Epoch 24/50\n","80/80 [==============================] - 43s 526ms/step - loss: 0.3933 - accuracy: 0.8310 - auc: 0.9713 - f1_score: 0.8298 - scaled_graph_loss: 6.3982e-04 - val_loss: 1.0724 - val_accuracy: 0.6083 - val_auc: 0.8544 - val_f1_score: 0.6005\n","\n","Epoch 00024: val_accuracy improved from 0.59578 to 0.60829, saving model to /content/drive/MyDrive/AD Expriment II/DenseNet_model_checkpoints/densenet_nsl_weights\n","Epoch 25/50\n","80/80 [==============================] - 43s 523ms/step - loss: 0.4010 - accuracy: 0.8279 - auc: 0.9702 - f1_score: 0.8274 - scaled_graph_loss: 6.4393e-04 - val_loss: 1.0180 - val_accuracy: 0.6044 - val_auc: 0.8556 - val_f1_score: 0.5979\n","\n","Epoch 00025: val_accuracy did not improve from 0.60829\n","Epoch 26/50\n","80/80 [==============================] - 41s 505ms/step - loss: 0.3915 - accuracy: 0.8319 - auc: 0.9718 - f1_score: 0.8295 - scaled_graph_loss: 6.0671e-04 - val_loss: 1.0883 - val_accuracy: 0.5848 - val_auc: 0.8467 - val_f1_score: 0.5798\n","\n","Epoch 00026: val_accuracy did not improve from 0.60829\n","Epoch 27/50\n","80/80 [==============================] - 43s 527ms/step - loss: 0.3861 - accuracy: 0.8363 - auc: 0.9727 - f1_score: 0.8336 - scaled_graph_loss: 6.2600e-04 - val_loss: 0.9869 - val_accuracy: 0.5934 - val_auc: 0.8526 - val_f1_score: 0.5830\n","\n","Epoch 00027: val_accuracy did not improve from 0.60829\n","Epoch 28/50\n","80/80 [==============================] - 43s 526ms/step - loss: 0.4039 - accuracy: 0.8292 - auc: 0.9698 - f1_score: 0.8255 - scaled_graph_loss: 6.3584e-04 - val_loss: 1.1874 - val_accuracy: 0.5778 - val_auc: 0.8430 - val_f1_score: 0.5707\n","\n","Epoch 00028: val_accuracy did not improve from 0.60829\n","Epoch 29/50\n","80/80 [==============================] - 42s 521ms/step - loss: 0.3824 - accuracy: 0.8379 - auc: 0.9731 - f1_score: 0.8378 - scaled_graph_loss: 6.1321e-04 - val_loss: 1.1359 - val_accuracy: 0.5997 - val_auc: 0.8487 - val_f1_score: 0.5860\n","\n","Epoch 00029: val_accuracy did not improve from 0.60829\n","Epoch 30/50\n","80/80 [==============================] - 43s 524ms/step - loss: 0.3840 - accuracy: 0.8353 - auc: 0.9727 - f1_score: 0.8345 - scaled_graph_loss: 6.3345e-04 - val_loss: 1.1485 - val_accuracy: 0.5739 - val_auc: 0.8443 - val_f1_score: 0.5681\n","\n","Epoch 00030: val_accuracy did not improve from 0.60829\n","Epoch 31/50\n","80/80 [==============================] - 43s 525ms/step - loss: 0.3806 - accuracy: 0.8401 - auc: 0.9731 - f1_score: 0.8358 - scaled_graph_loss: 6.3459e-04 - val_loss: 1.1451 - val_accuracy: 0.5942 - val_auc: 0.8467 - val_f1_score: 0.5855\n","\n","Epoch 00031: val_accuracy did not improve from 0.60829\n","Epoch 32/50\n","80/80 [==============================] - 43s 525ms/step - loss: 0.3945 - accuracy: 0.8289 - auc: 0.9708 - f1_score: 0.8263 - scaled_graph_loss: 6.3569e-04 - val_loss: 1.2410 - val_accuracy: 0.5880 - val_auc: 0.8430 - val_f1_score: 0.5803\n","\n","Epoch 00032: val_accuracy did not improve from 0.60829\n","Epoch 33/50\n","80/80 [==============================] - 43s 528ms/step - loss: 0.3744 - accuracy: 0.8412 - auc: 0.9740 - f1_score: 0.8390 - scaled_graph_loss: 6.3768e-04 - val_loss: 1.1965 - val_accuracy: 0.5903 - val_auc: 0.8457 - val_f1_score: 0.5872\n","\n","Epoch 00033: val_accuracy did not improve from 0.60829\n","Epoch 34/50\n","80/80 [==============================] - 42s 522ms/step - loss: 0.3708 - accuracy: 0.8465 - auc: 0.9745 - f1_score: 0.8439 - scaled_graph_loss: 6.2675e-04 - val_loss: 1.2382 - val_accuracy: 0.5825 - val_auc: 0.8398 - val_f1_score: 0.5799\n","\n","Epoch 00034: val_accuracy did not improve from 0.60829\n","Epoch 35/50\n","80/80 [==============================] - 43s 527ms/step - loss: 0.3807 - accuracy: 0.8360 - auc: 0.9731 - f1_score: 0.8350 - scaled_graph_loss: 6.5571e-04 - val_loss: 1.1910 - val_accuracy: 0.5880 - val_auc: 0.8421 - val_f1_score: 0.5714\n","\n","Epoch 00035: val_accuracy did not improve from 0.60829\n","Epoch 36/50\n","80/80 [==============================] - 43s 526ms/step - loss: 0.3734 - accuracy: 0.8412 - auc: 0.9742 - f1_score: 0.8362 - scaled_graph_loss: 6.1182e-04 - val_loss: 1.1423 - val_accuracy: 0.5997 - val_auc: 0.8528 - val_f1_score: 0.5998\n","\n","Epoch 00036: val_accuracy did not improve from 0.60829\n","Epoch 37/50\n","80/80 [==============================] - 43s 524ms/step - loss: 0.3644 - accuracy: 0.8470 - auc: 0.9755 - f1_score: 0.8445 - scaled_graph_loss: 6.2522e-04 - val_loss: 1.2276 - val_accuracy: 0.5895 - val_auc: 0.8426 - val_f1_score: 0.5818\n","\n","Epoch 00037: val_accuracy did not improve from 0.60829\n","Epoch 38/50\n","80/80 [==============================] - 42s 522ms/step - loss: 0.3574 - accuracy: 0.8489 - auc: 0.9764 - f1_score: 0.8472 - scaled_graph_loss: 6.2071e-04 - val_loss: 1.1661 - val_accuracy: 0.6044 - val_auc: 0.8489 - val_f1_score: 0.5969\n","\n","Epoch 00038: val_accuracy did not improve from 0.60829\n","Epoch 39/50\n","80/80 [==============================] - 42s 521ms/step - loss: 0.3676 - accuracy: 0.8375 - auc: 0.9747 - f1_score: 0.8370 - scaled_graph_loss: 6.4497e-04 - val_loss: 1.0826 - val_accuracy: 0.5934 - val_auc: 0.8535 - val_f1_score: 0.5855\n","\n","Epoch 00039: val_accuracy did not improve from 0.60829\n","Epoch 40/50\n","80/80 [==============================] - 42s 523ms/step - loss: 0.3606 - accuracy: 0.8510 - auc: 0.9759 - f1_score: 0.8505 - scaled_graph_loss: 6.2783e-04 - val_loss: 1.2041 - val_accuracy: 0.5919 - val_auc: 0.8497 - val_f1_score: 0.5884\n","\n","Epoch 00040: val_accuracy did not improve from 0.60829\n","Epoch 41/50\n","80/80 [==============================] - 43s 534ms/step - loss: 0.3547 - accuracy: 0.8481 - auc: 0.9765 - f1_score: 0.8464 - scaled_graph_loss: 6.2021e-04 - val_loss: 1.1623 - val_accuracy: 0.5895 - val_auc: 0.8472 - val_f1_score: 0.5833\n","\n","Epoch 00041: val_accuracy did not improve from 0.60829\n","Epoch 42/50\n","80/80 [==============================] - 43s 525ms/step - loss: 0.3525 - accuracy: 0.8477 - auc: 0.9768 - f1_score: 0.8445 - scaled_graph_loss: 6.3143e-04 - val_loss: 1.1064 - val_accuracy: 0.6067 - val_auc: 0.8511 - val_f1_score: 0.5998\n","\n","Epoch 00042: val_accuracy did not improve from 0.60829\n","Epoch 43/50\n","80/80 [==============================] - 43s 525ms/step - loss: 0.3546 - accuracy: 0.8516 - auc: 0.9766 - f1_score: 0.8495 - scaled_graph_loss: 6.3154e-04 - val_loss: 1.1878 - val_accuracy: 0.5934 - val_auc: 0.8482 - val_f1_score: 0.5892\n","\n","Epoch 00043: val_accuracy did not improve from 0.60829\n","Epoch 44/50\n","80/80 [==============================] - 43s 529ms/step - loss: 0.3634 - accuracy: 0.8456 - auc: 0.9755 - f1_score: 0.8435 - scaled_graph_loss: 6.2116e-04 - val_loss: 1.2152 - val_accuracy: 0.5661 - val_auc: 0.8414 - val_f1_score: 0.5621\n","\n","Epoch 00044: val_accuracy did not improve from 0.60829\n","Epoch 45/50\n","80/80 [==============================] - 43s 533ms/step - loss: 0.3747 - accuracy: 0.8442 - auc: 0.9741 - f1_score: 0.8438 - scaled_graph_loss: 6.4915e-04 - val_loss: 1.1309 - val_accuracy: 0.6036 - val_auc: 0.8527 - val_f1_score: 0.5986\n","\n","Epoch 00045: val_accuracy did not improve from 0.60829\n","Epoch 46/50\n","80/80 [==============================] - 43s 530ms/step - loss: 0.3583 - accuracy: 0.8494 - auc: 0.9762 - f1_score: 0.8473 - scaled_graph_loss: 6.2199e-04 - val_loss: 1.0458 - val_accuracy: 0.6005 - val_auc: 0.8536 - val_f1_score: 0.5966\n","\n","Epoch 00046: val_accuracy did not improve from 0.60829\n","Epoch 47/50\n","80/80 [==============================] - 43s 533ms/step - loss: 0.3538 - accuracy: 0.8481 - auc: 0.9767 - f1_score: 0.8472 - scaled_graph_loss: 6.2467e-04 - val_loss: 1.0697 - val_accuracy: 0.6059 - val_auc: 0.8558 - val_f1_score: 0.5996\n","\n","Epoch 00047: val_accuracy did not improve from 0.60829\n","Epoch 48/50\n","80/80 [==============================] - 43s 525ms/step - loss: 0.3379 - accuracy: 0.8603 - auc: 0.9789 - f1_score: 0.8588 - scaled_graph_loss: 6.0366e-04 - val_loss: 1.2255 - val_accuracy: 0.5895 - val_auc: 0.8453 - val_f1_score: 0.5846\n","\n","Epoch 00048: val_accuracy did not improve from 0.60829\n","Epoch 49/50\n","80/80 [==============================] - 43s 527ms/step - loss: 0.3488 - accuracy: 0.8515 - auc: 0.9772 - f1_score: 0.8498 - scaled_graph_loss: 6.3529e-04 - val_loss: 1.1292 - val_accuracy: 0.5856 - val_auc: 0.8493 - val_f1_score: 0.5847\n","\n","Epoch 00049: val_accuracy did not improve from 0.60829\n","Epoch 50/50\n","80/80 [==============================] - 43s 525ms/step - loss: 0.3520 - accuracy: 0.8504 - auc: 0.9770 - f1_score: 0.8486 - scaled_graph_loss: 6.3182e-04 - val_loss: 1.1792 - val_accuracy: 0.5801 - val_auc: 0.8444 - val_f1_score: 0.5795\n","\n","Epoch 00050: val_accuracy did not improve from 0.60829\n","Early stopping is not triggered, but best model is restored at epoch 24\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KEo0rokAZPzs","executionInfo":{"status":"ok","timestamp":1618575724803,"user_tz":240,"elapsed":2170862,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"2d9c7c9c-8ce1-4b3c-8661-9df432500f95"},"source":["graph_reg_model.evaluate(test_image_dataset)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1/1 [==============================] - 1s 1s/step - loss: 1.0724 - accuracy: 0.6083 - auc: 0.8544 - f1_score: 0.6005\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[1.0724372863769531,\n"," 0.6082877516746521,\n"," 0.8544427752494812,\n"," 0.6004882454872131]"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"code","metadata":{"id":"SeIDeU8uf5cG"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0XAmOO5ZgGcj"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dg3vzxBShRRh"},"source":["## 3.3 DenseNet_NSL top 20 layers and bottom 20 laysers tuning\n","### val_acc: 0.73, val_auc: 0.89, val_f1_score: 0.73"]},{"cell_type":"code","metadata":{"id":"K5IOkuPWirui","executionInfo":{"status":"ok","timestamp":1618838651786,"user_tz":240,"elapsed":5687,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}}},"source":["'''redefine hyper params'''\n","params = AD_params()\n","params.max_seed_nbr=5\n","params.batch_size=64\n","params.image_channels =3\n","params.image_size =(100,100)\n","params.ad_base_model_input_shape=(100,100,3)\n","params.train_tfr_path = train_tfr_path\n","\n","'''parse train_data.tfr to train image dataset with batch_size at 64'''\n","train_image_dataset = NSLDataFormat.parse_tfr_to_dataset(file_path_list=[params.train_tfr_path],\n","                                                         batch_size=params.batch_size,\n","                                                         max_neighbor_number=params.max_seed_nbr,\n","                                                         image_size=params.image_size,\n","                                                         image_channels=params.image_channels,\n","                                                         shuffle=True)\n","\n","'''load test data with batch_size at 64 '''\n","test_image_dataset = NSLDataFormat.generate_test_tfr_image_tensor(path_list=test_tfr_list, \n","                                                                  batch_size=params.batch_size, \n","                                                                  size=params.image_size,\n","                                                                  channels=params.image_channels,\n","                                                                  shuffle=True)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0EWDr4Po5vgq","executionInfo":{"status":"ok","timestamp":1618838669106,"user_tz":240,"elapsed":22548,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"552b8ae8-0008-4023-d1c1-5b04c661c2ed"},"source":["params.learning_rate=0.0001\n","params.restore_path= '/content/drive/MyDrive/AD Expriment II/DenseNet_model_checkpoints/densenet_nsl_weights'\n","params.checkpoint_path = '/content/drive/MyDrive/AD Expriment II/DenseNet_model_checkpoints/densenet_nsl_weights'\n","params.early_stop_base_line=0.80\n","params.train_epoch=50\n","params.nsl_multiplier = 0.0005\n","params.nsl_sum_over_axis = -1\n","params.nsl_distance_type = nsl.configs.DistanceType.COSINE\n","\n","'''build a base model with selected trainable layer'''\n","admodel = ADModelBuilder(input_shape=params.ad_base_model_input_shape, base_model='densenet121').setup_DenseNet121(top_layers=20, middle_layers=None, bottom_layers=30).get_ADModel()\n","\n","'''build NSL model on top of base model'''\n","graph_reg_config = nsl.configs.make_graph_reg_config(neighbor_prefix=params.neighbor_prefix,\n","                                                     neighbor_weight_suffix=params.neighbor_weight_suffix,\n","                                                     max_neighbors= params.max_seed_nbr,\n","                                                     multiplier= params.nsl_multiplier,\n","                                                     distance_type= params.nsl_distance_type,\n","                                                     sum_over_axis= params.nsl_sum_over_axis)\n","graph_reg_model = nsl.keras.GraphRegularization(admodel,graph_reg_config)\n","graph_reg_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=params.learning_rate, amsgrad=True), \n","                        loss=tf.losses.CategoricalCrossentropy(), \n","                        metrics=[\"accuracy\",\"AUC\", tfa.metrics.F1Score(num_classes=4, average=\"micro\", threshold = 0.5)])\n","\n","'''restore the model from last training'''\n","graph_reg_model.load_weights(params.restore_path)\n","\n","''' NSL model training '''\n","callback_checkpoints = tf.keras.callbacks.ModelCheckpoint(filepath=params.checkpoint_path, monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=True, mode='max',\n","                                                          save_freq='epoch',options=None)\n","callback_earlystop = AccEarlyStop(val_acc_base=params.early_stop_base_line)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Note: default DenseNet121 not includes top and has imagenet weights. It is not a trainable model in ADModelBuilder. Please setup trainable layers in setup_DenseNet121 function based on the \"Layer Number\"\n","Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n","29089792/29084464 [==============================] - 1s 0us/step\n","Model: \"densenet121\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 100, 100, 3) 0                                            \n","__________________________________________________________________________________________________\n","zero_padding2d (ZeroPadding2D)  (None, 106, 106, 3)  0           input_1[0][0]                    \n","__________________________________________________________________________________________________\n","conv1/conv (Conv2D)             (None, 50, 50, 64)   9408        zero_padding2d[0][0]             \n","__________________________________________________________________________________________________\n","conv1/bn (BatchNormalization)   (None, 50, 50, 64)   256         conv1/conv[0][0]                 \n","__________________________________________________________________________________________________\n","conv1/relu (Activation)         (None, 50, 50, 64)   0           conv1/bn[0][0]                   \n","__________________________________________________________________________________________________\n","zero_padding2d_1 (ZeroPadding2D (None, 52, 52, 64)   0           conv1/relu[0][0]                 \n","__________________________________________________________________________________________________\n","pool1 (MaxPooling2D)            (None, 25, 25, 64)   0           zero_padding2d_1[0][0]           \n","__________________________________________________________________________________________________\n","conv2_block1_0_bn (BatchNormali (None, 25, 25, 64)   256         pool1[0][0]                      \n","__________________________________________________________________________________________________\n","conv2_block1_0_relu (Activation (None, 25, 25, 64)   0           conv2_block1_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block1_1_conv (Conv2D)    (None, 25, 25, 128)  8192        conv2_block1_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_1_bn (BatchNormali (None, 25, 25, 128)  512         conv2_block1_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_1_relu (Activation (None, 25, 25, 128)  0           conv2_block1_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block1_2_conv (Conv2D)    (None, 25, 25, 32)   36864       conv2_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_concat (Concatenat (None, 25, 25, 96)   0           pool1[0][0]                      \n","                                                                 conv2_block1_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_0_bn (BatchNormali (None, 25, 25, 96)   384         conv2_block1_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_0_relu (Activation (None, 25, 25, 96)   0           conv2_block2_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block2_1_conv (Conv2D)    (None, 25, 25, 128)  12288       conv2_block2_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_1_bn (BatchNormali (None, 25, 25, 128)  512         conv2_block2_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_1_relu (Activation (None, 25, 25, 128)  0           conv2_block2_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block2_2_conv (Conv2D)    (None, 25, 25, 32)   36864       conv2_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_concat (Concatenat (None, 25, 25, 128)  0           conv2_block1_concat[0][0]        \n","                                                                 conv2_block2_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_0_bn (BatchNormali (None, 25, 25, 128)  512         conv2_block2_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_0_relu (Activation (None, 25, 25, 128)  0           conv2_block3_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block3_1_conv (Conv2D)    (None, 25, 25, 128)  16384       conv2_block3_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_1_bn (BatchNormali (None, 25, 25, 128)  512         conv2_block3_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_1_relu (Activation (None, 25, 25, 128)  0           conv2_block3_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block3_2_conv (Conv2D)    (None, 25, 25, 32)   36864       conv2_block3_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_concat (Concatenat (None, 25, 25, 160)  0           conv2_block2_concat[0][0]        \n","                                                                 conv2_block3_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block4_0_bn (BatchNormali (None, 25, 25, 160)  640         conv2_block3_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block4_0_relu (Activation (None, 25, 25, 160)  0           conv2_block4_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block4_1_conv (Conv2D)    (None, 25, 25, 128)  20480       conv2_block4_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block4_1_bn (BatchNormali (None, 25, 25, 128)  512         conv2_block4_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block4_1_relu (Activation (None, 25, 25, 128)  0           conv2_block4_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block4_2_conv (Conv2D)    (None, 25, 25, 32)   36864       conv2_block4_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block4_concat (Concatenat (None, 25, 25, 192)  0           conv2_block3_concat[0][0]        \n","                                                                 conv2_block4_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block5_0_bn (BatchNormali (None, 25, 25, 192)  768         conv2_block4_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block5_0_relu (Activation (None, 25, 25, 192)  0           conv2_block5_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block5_1_conv (Conv2D)    (None, 25, 25, 128)  24576       conv2_block5_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block5_1_bn (BatchNormali (None, 25, 25, 128)  512         conv2_block5_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block5_1_relu (Activation (None, 25, 25, 128)  0           conv2_block5_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block5_2_conv (Conv2D)    (None, 25, 25, 32)   36864       conv2_block5_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block5_concat (Concatenat (None, 25, 25, 224)  0           conv2_block4_concat[0][0]        \n","                                                                 conv2_block5_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block6_0_bn (BatchNormali (None, 25, 25, 224)  896         conv2_block5_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block6_0_relu (Activation (None, 25, 25, 224)  0           conv2_block6_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block6_1_conv (Conv2D)    (None, 25, 25, 128)  28672       conv2_block6_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block6_1_bn (BatchNormali (None, 25, 25, 128)  512         conv2_block6_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block6_1_relu (Activation (None, 25, 25, 128)  0           conv2_block6_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block6_2_conv (Conv2D)    (None, 25, 25, 32)   36864       conv2_block6_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block6_concat (Concatenat (None, 25, 25, 256)  0           conv2_block5_concat[0][0]        \n","                                                                 conv2_block6_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","pool2_bn (BatchNormalization)   (None, 25, 25, 256)  1024        conv2_block6_concat[0][0]        \n","__________________________________________________________________________________________________\n","pool2_relu (Activation)         (None, 25, 25, 256)  0           pool2_bn[0][0]                   \n","__________________________________________________________________________________________________\n","pool2_conv (Conv2D)             (None, 25, 25, 128)  32768       pool2_relu[0][0]                 \n","__________________________________________________________________________________________________\n","pool2_pool (AveragePooling2D)   (None, 12, 12, 128)  0           pool2_conv[0][0]                 \n","__________________________________________________________________________________________________\n","conv3_block1_0_bn (BatchNormali (None, 12, 12, 128)  512         pool2_pool[0][0]                 \n","__________________________________________________________________________________________________\n","conv3_block1_0_relu (Activation (None, 12, 12, 128)  0           conv3_block1_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block1_1_conv (Conv2D)    (None, 12, 12, 128)  16384       conv3_block1_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_1_bn (BatchNormali (None, 12, 12, 128)  512         conv3_block1_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_1_relu (Activation (None, 12, 12, 128)  0           conv3_block1_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block1_2_conv (Conv2D)    (None, 12, 12, 32)   36864       conv3_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_concat (Concatenat (None, 12, 12, 160)  0           pool2_pool[0][0]                 \n","                                                                 conv3_block1_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_0_bn (BatchNormali (None, 12, 12, 160)  640         conv3_block1_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_0_relu (Activation (None, 12, 12, 160)  0           conv3_block2_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block2_1_conv (Conv2D)    (None, 12, 12, 128)  20480       conv3_block2_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_1_bn (BatchNormali (None, 12, 12, 128)  512         conv3_block2_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_1_relu (Activation (None, 12, 12, 128)  0           conv3_block2_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block2_2_conv (Conv2D)    (None, 12, 12, 32)   36864       conv3_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_concat (Concatenat (None, 12, 12, 192)  0           conv3_block1_concat[0][0]        \n","                                                                 conv3_block2_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_0_bn (BatchNormali (None, 12, 12, 192)  768         conv3_block2_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_0_relu (Activation (None, 12, 12, 192)  0           conv3_block3_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block3_1_conv (Conv2D)    (None, 12, 12, 128)  24576       conv3_block3_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_1_bn (BatchNormali (None, 12, 12, 128)  512         conv3_block3_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_1_relu (Activation (None, 12, 12, 128)  0           conv3_block3_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block3_2_conv (Conv2D)    (None, 12, 12, 32)   36864       conv3_block3_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_concat (Concatenat (None, 12, 12, 224)  0           conv3_block2_concat[0][0]        \n","                                                                 conv3_block3_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_0_bn (BatchNormali (None, 12, 12, 224)  896         conv3_block3_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_0_relu (Activation (None, 12, 12, 224)  0           conv3_block4_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block4_1_conv (Conv2D)    (None, 12, 12, 128)  28672       conv3_block4_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_1_bn (BatchNormali (None, 12, 12, 128)  512         conv3_block4_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_1_relu (Activation (None, 12, 12, 128)  0           conv3_block4_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block4_2_conv (Conv2D)    (None, 12, 12, 32)   36864       conv3_block4_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_concat (Concatenat (None, 12, 12, 256)  0           conv3_block3_concat[0][0]        \n","                                                                 conv3_block4_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block5_0_bn (BatchNormali (None, 12, 12, 256)  1024        conv3_block4_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block5_0_relu (Activation (None, 12, 12, 256)  0           conv3_block5_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block5_1_conv (Conv2D)    (None, 12, 12, 128)  32768       conv3_block5_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block5_1_bn (BatchNormali (None, 12, 12, 128)  512         conv3_block5_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block5_1_relu (Activation (None, 12, 12, 128)  0           conv3_block5_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block5_2_conv (Conv2D)    (None, 12, 12, 32)   36864       conv3_block5_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block5_concat (Concatenat (None, 12, 12, 288)  0           conv3_block4_concat[0][0]        \n","                                                                 conv3_block5_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block6_0_bn (BatchNormali (None, 12, 12, 288)  1152        conv3_block5_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block6_0_relu (Activation (None, 12, 12, 288)  0           conv3_block6_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block6_1_conv (Conv2D)    (None, 12, 12, 128)  36864       conv3_block6_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block6_1_bn (BatchNormali (None, 12, 12, 128)  512         conv3_block6_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block6_1_relu (Activation (None, 12, 12, 128)  0           conv3_block6_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block6_2_conv (Conv2D)    (None, 12, 12, 32)   36864       conv3_block6_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block6_concat (Concatenat (None, 12, 12, 320)  0           conv3_block5_concat[0][0]        \n","                                                                 conv3_block6_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block7_0_bn (BatchNormali (None, 12, 12, 320)  1280        conv3_block6_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block7_0_relu (Activation (None, 12, 12, 320)  0           conv3_block7_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block7_1_conv (Conv2D)    (None, 12, 12, 128)  40960       conv3_block7_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block7_1_bn (BatchNormali (None, 12, 12, 128)  512         conv3_block7_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block7_1_relu (Activation (None, 12, 12, 128)  0           conv3_block7_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block7_2_conv (Conv2D)    (None, 12, 12, 32)   36864       conv3_block7_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block7_concat (Concatenat (None, 12, 12, 352)  0           conv3_block6_concat[0][0]        \n","                                                                 conv3_block7_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block8_0_bn (BatchNormali (None, 12, 12, 352)  1408        conv3_block7_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block8_0_relu (Activation (None, 12, 12, 352)  0           conv3_block8_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block8_1_conv (Conv2D)    (None, 12, 12, 128)  45056       conv3_block8_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block8_1_bn (BatchNormali (None, 12, 12, 128)  512         conv3_block8_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block8_1_relu (Activation (None, 12, 12, 128)  0           conv3_block8_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block8_2_conv (Conv2D)    (None, 12, 12, 32)   36864       conv3_block8_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block8_concat (Concatenat (None, 12, 12, 384)  0           conv3_block7_concat[0][0]        \n","                                                                 conv3_block8_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block9_0_bn (BatchNormali (None, 12, 12, 384)  1536        conv3_block8_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block9_0_relu (Activation (None, 12, 12, 384)  0           conv3_block9_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block9_1_conv (Conv2D)    (None, 12, 12, 128)  49152       conv3_block9_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block9_1_bn (BatchNormali (None, 12, 12, 128)  512         conv3_block9_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block9_1_relu (Activation (None, 12, 12, 128)  0           conv3_block9_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block9_2_conv (Conv2D)    (None, 12, 12, 32)   36864       conv3_block9_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block9_concat (Concatenat (None, 12, 12, 416)  0           conv3_block8_concat[0][0]        \n","                                                                 conv3_block9_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block10_0_bn (BatchNormal (None, 12, 12, 416)  1664        conv3_block9_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block10_0_relu (Activatio (None, 12, 12, 416)  0           conv3_block10_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv3_block10_1_conv (Conv2D)   (None, 12, 12, 128)  53248       conv3_block10_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv3_block10_1_bn (BatchNormal (None, 12, 12, 128)  512         conv3_block10_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv3_block10_1_relu (Activatio (None, 12, 12, 128)  0           conv3_block10_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv3_block10_2_conv (Conv2D)   (None, 12, 12, 32)   36864       conv3_block10_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv3_block10_concat (Concatena (None, 12, 12, 448)  0           conv3_block9_concat[0][0]        \n","                                                                 conv3_block10_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv3_block11_0_bn (BatchNormal (None, 12, 12, 448)  1792        conv3_block10_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv3_block11_0_relu (Activatio (None, 12, 12, 448)  0           conv3_block11_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv3_block11_1_conv (Conv2D)   (None, 12, 12, 128)  57344       conv3_block11_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv3_block11_1_bn (BatchNormal (None, 12, 12, 128)  512         conv3_block11_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv3_block11_1_relu (Activatio (None, 12, 12, 128)  0           conv3_block11_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv3_block11_2_conv (Conv2D)   (None, 12, 12, 32)   36864       conv3_block11_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv3_block11_concat (Concatena (None, 12, 12, 480)  0           conv3_block10_concat[0][0]       \n","                                                                 conv3_block11_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv3_block12_0_bn (BatchNormal (None, 12, 12, 480)  1920        conv3_block11_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv3_block12_0_relu (Activatio (None, 12, 12, 480)  0           conv3_block12_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv3_block12_1_conv (Conv2D)   (None, 12, 12, 128)  61440       conv3_block12_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv3_block12_1_bn (BatchNormal (None, 12, 12, 128)  512         conv3_block12_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv3_block12_1_relu (Activatio (None, 12, 12, 128)  0           conv3_block12_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv3_block12_2_conv (Conv2D)   (None, 12, 12, 32)   36864       conv3_block12_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv3_block12_concat (Concatena (None, 12, 12, 512)  0           conv3_block11_concat[0][0]       \n","                                                                 conv3_block12_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","pool3_bn (BatchNormalization)   (None, 12, 12, 512)  2048        conv3_block12_concat[0][0]       \n","__________________________________________________________________________________________________\n","pool3_relu (Activation)         (None, 12, 12, 512)  0           pool3_bn[0][0]                   \n","__________________________________________________________________________________________________\n","pool3_conv (Conv2D)             (None, 12, 12, 256)  131072      pool3_relu[0][0]                 \n","__________________________________________________________________________________________________\n","pool3_pool (AveragePooling2D)   (None, 6, 6, 256)    0           pool3_conv[0][0]                 \n","__________________________________________________________________________________________________\n","conv4_block1_0_bn (BatchNormali (None, 6, 6, 256)    1024        pool3_pool[0][0]                 \n","__________________________________________________________________________________________________\n","conv4_block1_0_relu (Activation (None, 6, 6, 256)    0           conv4_block1_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block1_1_conv (Conv2D)    (None, 6, 6, 128)    32768       conv4_block1_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_1_bn (BatchNormali (None, 6, 6, 128)    512         conv4_block1_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_1_relu (Activation (None, 6, 6, 128)    0           conv4_block1_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block1_2_conv (Conv2D)    (None, 6, 6, 32)     36864       conv4_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_concat (Concatenat (None, 6, 6, 288)    0           pool3_pool[0][0]                 \n","                                                                 conv4_block1_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_0_bn (BatchNormali (None, 6, 6, 288)    1152        conv4_block1_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_0_relu (Activation (None, 6, 6, 288)    0           conv4_block2_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block2_1_conv (Conv2D)    (None, 6, 6, 128)    36864       conv4_block2_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_1_bn (BatchNormali (None, 6, 6, 128)    512         conv4_block2_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_1_relu (Activation (None, 6, 6, 128)    0           conv4_block2_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block2_2_conv (Conv2D)    (None, 6, 6, 32)     36864       conv4_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_concat (Concatenat (None, 6, 6, 320)    0           conv4_block1_concat[0][0]        \n","                                                                 conv4_block2_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_0_bn (BatchNormali (None, 6, 6, 320)    1280        conv4_block2_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_0_relu (Activation (None, 6, 6, 320)    0           conv4_block3_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block3_1_conv (Conv2D)    (None, 6, 6, 128)    40960       conv4_block3_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_1_bn (BatchNormali (None, 6, 6, 128)    512         conv4_block3_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_1_relu (Activation (None, 6, 6, 128)    0           conv4_block3_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block3_2_conv (Conv2D)    (None, 6, 6, 32)     36864       conv4_block3_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_concat (Concatenat (None, 6, 6, 352)    0           conv4_block2_concat[0][0]        \n","                                                                 conv4_block3_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_0_bn (BatchNormali (None, 6, 6, 352)    1408        conv4_block3_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_0_relu (Activation (None, 6, 6, 352)    0           conv4_block4_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block4_1_conv (Conv2D)    (None, 6, 6, 128)    45056       conv4_block4_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_1_bn (BatchNormali (None, 6, 6, 128)    512         conv4_block4_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_1_relu (Activation (None, 6, 6, 128)    0           conv4_block4_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block4_2_conv (Conv2D)    (None, 6, 6, 32)     36864       conv4_block4_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_concat (Concatenat (None, 6, 6, 384)    0           conv4_block3_concat[0][0]        \n","                                                                 conv4_block4_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_0_bn (BatchNormali (None, 6, 6, 384)    1536        conv4_block4_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_0_relu (Activation (None, 6, 6, 384)    0           conv4_block5_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block5_1_conv (Conv2D)    (None, 6, 6, 128)    49152       conv4_block5_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_1_bn (BatchNormali (None, 6, 6, 128)    512         conv4_block5_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_1_relu (Activation (None, 6, 6, 128)    0           conv4_block5_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block5_2_conv (Conv2D)    (None, 6, 6, 32)     36864       conv4_block5_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_concat (Concatenat (None, 6, 6, 416)    0           conv4_block4_concat[0][0]        \n","                                                                 conv4_block5_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_0_bn (BatchNormali (None, 6, 6, 416)    1664        conv4_block5_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_0_relu (Activation (None, 6, 6, 416)    0           conv4_block6_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block6_1_conv (Conv2D)    (None, 6, 6, 128)    53248       conv4_block6_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_1_bn (BatchNormali (None, 6, 6, 128)    512         conv4_block6_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_1_relu (Activation (None, 6, 6, 128)    0           conv4_block6_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block6_2_conv (Conv2D)    (None, 6, 6, 32)     36864       conv4_block6_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_concat (Concatenat (None, 6, 6, 448)    0           conv4_block5_concat[0][0]        \n","                                                                 conv4_block6_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block7_0_bn (BatchNormali (None, 6, 6, 448)    1792        conv4_block6_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block7_0_relu (Activation (None, 6, 6, 448)    0           conv4_block7_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block7_1_conv (Conv2D)    (None, 6, 6, 128)    57344       conv4_block7_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block7_1_bn (BatchNormali (None, 6, 6, 128)    512         conv4_block7_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block7_1_relu (Activation (None, 6, 6, 128)    0           conv4_block7_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block7_2_conv (Conv2D)    (None, 6, 6, 32)     36864       conv4_block7_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block7_concat (Concatenat (None, 6, 6, 480)    0           conv4_block6_concat[0][0]        \n","                                                                 conv4_block7_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block8_0_bn (BatchNormali (None, 6, 6, 480)    1920        conv4_block7_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block8_0_relu (Activation (None, 6, 6, 480)    0           conv4_block8_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block8_1_conv (Conv2D)    (None, 6, 6, 128)    61440       conv4_block8_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block8_1_bn (BatchNormali (None, 6, 6, 128)    512         conv4_block8_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block8_1_relu (Activation (None, 6, 6, 128)    0           conv4_block8_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block8_2_conv (Conv2D)    (None, 6, 6, 32)     36864       conv4_block8_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block8_concat (Concatenat (None, 6, 6, 512)    0           conv4_block7_concat[0][0]        \n","                                                                 conv4_block8_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block9_0_bn (BatchNormali (None, 6, 6, 512)    2048        conv4_block8_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block9_0_relu (Activation (None, 6, 6, 512)    0           conv4_block9_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block9_1_conv (Conv2D)    (None, 6, 6, 128)    65536       conv4_block9_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block9_1_bn (BatchNormali (None, 6, 6, 128)    512         conv4_block9_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block9_1_relu (Activation (None, 6, 6, 128)    0           conv4_block9_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block9_2_conv (Conv2D)    (None, 6, 6, 32)     36864       conv4_block9_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block9_concat (Concatenat (None, 6, 6, 544)    0           conv4_block8_concat[0][0]        \n","                                                                 conv4_block9_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block10_0_bn (BatchNormal (None, 6, 6, 544)    2176        conv4_block9_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block10_0_relu (Activatio (None, 6, 6, 544)    0           conv4_block10_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block10_1_conv (Conv2D)   (None, 6, 6, 128)    69632       conv4_block10_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block10_1_bn (BatchNormal (None, 6, 6, 128)    512         conv4_block10_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block10_1_relu (Activatio (None, 6, 6, 128)    0           conv4_block10_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block10_2_conv (Conv2D)   (None, 6, 6, 32)     36864       conv4_block10_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block10_concat (Concatena (None, 6, 6, 576)    0           conv4_block9_concat[0][0]        \n","                                                                 conv4_block10_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block11_0_bn (BatchNormal (None, 6, 6, 576)    2304        conv4_block10_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block11_0_relu (Activatio (None, 6, 6, 576)    0           conv4_block11_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block11_1_conv (Conv2D)   (None, 6, 6, 128)    73728       conv4_block11_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block11_1_bn (BatchNormal (None, 6, 6, 128)    512         conv4_block11_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block11_1_relu (Activatio (None, 6, 6, 128)    0           conv4_block11_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block11_2_conv (Conv2D)   (None, 6, 6, 32)     36864       conv4_block11_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block11_concat (Concatena (None, 6, 6, 608)    0           conv4_block10_concat[0][0]       \n","                                                                 conv4_block11_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block12_0_bn (BatchNormal (None, 6, 6, 608)    2432        conv4_block11_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block12_0_relu (Activatio (None, 6, 6, 608)    0           conv4_block12_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block12_1_conv (Conv2D)   (None, 6, 6, 128)    77824       conv4_block12_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block12_1_bn (BatchNormal (None, 6, 6, 128)    512         conv4_block12_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block12_1_relu (Activatio (None, 6, 6, 128)    0           conv4_block12_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block12_2_conv (Conv2D)   (None, 6, 6, 32)     36864       conv4_block12_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block12_concat (Concatena (None, 6, 6, 640)    0           conv4_block11_concat[0][0]       \n","                                                                 conv4_block12_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block13_0_bn (BatchNormal (None, 6, 6, 640)    2560        conv4_block12_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block13_0_relu (Activatio (None, 6, 6, 640)    0           conv4_block13_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block13_1_conv (Conv2D)   (None, 6, 6, 128)    81920       conv4_block13_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block13_1_bn (BatchNormal (None, 6, 6, 128)    512         conv4_block13_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block13_1_relu (Activatio (None, 6, 6, 128)    0           conv4_block13_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block13_2_conv (Conv2D)   (None, 6, 6, 32)     36864       conv4_block13_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block13_concat (Concatena (None, 6, 6, 672)    0           conv4_block12_concat[0][0]       \n","                                                                 conv4_block13_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block14_0_bn (BatchNormal (None, 6, 6, 672)    2688        conv4_block13_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block14_0_relu (Activatio (None, 6, 6, 672)    0           conv4_block14_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block14_1_conv (Conv2D)   (None, 6, 6, 128)    86016       conv4_block14_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block14_1_bn (BatchNormal (None, 6, 6, 128)    512         conv4_block14_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block14_1_relu (Activatio (None, 6, 6, 128)    0           conv4_block14_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block14_2_conv (Conv2D)   (None, 6, 6, 32)     36864       conv4_block14_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block14_concat (Concatena (None, 6, 6, 704)    0           conv4_block13_concat[0][0]       \n","                                                                 conv4_block14_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block15_0_bn (BatchNormal (None, 6, 6, 704)    2816        conv4_block14_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block15_0_relu (Activatio (None, 6, 6, 704)    0           conv4_block15_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block15_1_conv (Conv2D)   (None, 6, 6, 128)    90112       conv4_block15_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block15_1_bn (BatchNormal (None, 6, 6, 128)    512         conv4_block15_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block15_1_relu (Activatio (None, 6, 6, 128)    0           conv4_block15_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block15_2_conv (Conv2D)   (None, 6, 6, 32)     36864       conv4_block15_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block15_concat (Concatena (None, 6, 6, 736)    0           conv4_block14_concat[0][0]       \n","                                                                 conv4_block15_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block16_0_bn (BatchNormal (None, 6, 6, 736)    2944        conv4_block15_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block16_0_relu (Activatio (None, 6, 6, 736)    0           conv4_block16_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block16_1_conv (Conv2D)   (None, 6, 6, 128)    94208       conv4_block16_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block16_1_bn (BatchNormal (None, 6, 6, 128)    512         conv4_block16_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block16_1_relu (Activatio (None, 6, 6, 128)    0           conv4_block16_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block16_2_conv (Conv2D)   (None, 6, 6, 32)     36864       conv4_block16_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block16_concat (Concatena (None, 6, 6, 768)    0           conv4_block15_concat[0][0]       \n","                                                                 conv4_block16_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block17_0_bn (BatchNormal (None, 6, 6, 768)    3072        conv4_block16_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block17_0_relu (Activatio (None, 6, 6, 768)    0           conv4_block17_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block17_1_conv (Conv2D)   (None, 6, 6, 128)    98304       conv4_block17_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block17_1_bn (BatchNormal (None, 6, 6, 128)    512         conv4_block17_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block17_1_relu (Activatio (None, 6, 6, 128)    0           conv4_block17_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block17_2_conv (Conv2D)   (None, 6, 6, 32)     36864       conv4_block17_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block17_concat (Concatena (None, 6, 6, 800)    0           conv4_block16_concat[0][0]       \n","                                                                 conv4_block17_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block18_0_bn (BatchNormal (None, 6, 6, 800)    3200        conv4_block17_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block18_0_relu (Activatio (None, 6, 6, 800)    0           conv4_block18_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block18_1_conv (Conv2D)   (None, 6, 6, 128)    102400      conv4_block18_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block18_1_bn (BatchNormal (None, 6, 6, 128)    512         conv4_block18_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block18_1_relu (Activatio (None, 6, 6, 128)    0           conv4_block18_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block18_2_conv (Conv2D)   (None, 6, 6, 32)     36864       conv4_block18_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block18_concat (Concatena (None, 6, 6, 832)    0           conv4_block17_concat[0][0]       \n","                                                                 conv4_block18_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block19_0_bn (BatchNormal (None, 6, 6, 832)    3328        conv4_block18_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block19_0_relu (Activatio (None, 6, 6, 832)    0           conv4_block19_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block19_1_conv (Conv2D)   (None, 6, 6, 128)    106496      conv4_block19_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block19_1_bn (BatchNormal (None, 6, 6, 128)    512         conv4_block19_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block19_1_relu (Activatio (None, 6, 6, 128)    0           conv4_block19_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block19_2_conv (Conv2D)   (None, 6, 6, 32)     36864       conv4_block19_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block19_concat (Concatena (None, 6, 6, 864)    0           conv4_block18_concat[0][0]       \n","                                                                 conv4_block19_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block20_0_bn (BatchNormal (None, 6, 6, 864)    3456        conv4_block19_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block20_0_relu (Activatio (None, 6, 6, 864)    0           conv4_block20_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block20_1_conv (Conv2D)   (None, 6, 6, 128)    110592      conv4_block20_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block20_1_bn (BatchNormal (None, 6, 6, 128)    512         conv4_block20_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block20_1_relu (Activatio (None, 6, 6, 128)    0           conv4_block20_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block20_2_conv (Conv2D)   (None, 6, 6, 32)     36864       conv4_block20_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block20_concat (Concatena (None, 6, 6, 896)    0           conv4_block19_concat[0][0]       \n","                                                                 conv4_block20_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block21_0_bn (BatchNormal (None, 6, 6, 896)    3584        conv4_block20_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block21_0_relu (Activatio (None, 6, 6, 896)    0           conv4_block21_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block21_1_conv (Conv2D)   (None, 6, 6, 128)    114688      conv4_block21_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block21_1_bn (BatchNormal (None, 6, 6, 128)    512         conv4_block21_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block21_1_relu (Activatio (None, 6, 6, 128)    0           conv4_block21_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block21_2_conv (Conv2D)   (None, 6, 6, 32)     36864       conv4_block21_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block21_concat (Concatena (None, 6, 6, 928)    0           conv4_block20_concat[0][0]       \n","                                                                 conv4_block21_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block22_0_bn (BatchNormal (None, 6, 6, 928)    3712        conv4_block21_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block22_0_relu (Activatio (None, 6, 6, 928)    0           conv4_block22_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block22_1_conv (Conv2D)   (None, 6, 6, 128)    118784      conv4_block22_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block22_1_bn (BatchNormal (None, 6, 6, 128)    512         conv4_block22_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block22_1_relu (Activatio (None, 6, 6, 128)    0           conv4_block22_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block22_2_conv (Conv2D)   (None, 6, 6, 32)     36864       conv4_block22_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block22_concat (Concatena (None, 6, 6, 960)    0           conv4_block21_concat[0][0]       \n","                                                                 conv4_block22_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block23_0_bn (BatchNormal (None, 6, 6, 960)    3840        conv4_block22_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block23_0_relu (Activatio (None, 6, 6, 960)    0           conv4_block23_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block23_1_conv (Conv2D)   (None, 6, 6, 128)    122880      conv4_block23_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block23_1_bn (BatchNormal (None, 6, 6, 128)    512         conv4_block23_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block23_1_relu (Activatio (None, 6, 6, 128)    0           conv4_block23_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block23_2_conv (Conv2D)   (None, 6, 6, 32)     36864       conv4_block23_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block23_concat (Concatena (None, 6, 6, 992)    0           conv4_block22_concat[0][0]       \n","                                                                 conv4_block23_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block24_0_bn (BatchNormal (None, 6, 6, 992)    3968        conv4_block23_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block24_0_relu (Activatio (None, 6, 6, 992)    0           conv4_block24_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block24_1_conv (Conv2D)   (None, 6, 6, 128)    126976      conv4_block24_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block24_1_bn (BatchNormal (None, 6, 6, 128)    512         conv4_block24_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block24_1_relu (Activatio (None, 6, 6, 128)    0           conv4_block24_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block24_2_conv (Conv2D)   (None, 6, 6, 32)     36864       conv4_block24_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block24_concat (Concatena (None, 6, 6, 1024)   0           conv4_block23_concat[0][0]       \n","                                                                 conv4_block24_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","pool4_bn (BatchNormalization)   (None, 6, 6, 1024)   4096        conv4_block24_concat[0][0]       \n","__________________________________________________________________________________________________\n","pool4_relu (Activation)         (None, 6, 6, 1024)   0           pool4_bn[0][0]                   \n","__________________________________________________________________________________________________\n","pool4_conv (Conv2D)             (None, 6, 6, 512)    524288      pool4_relu[0][0]                 \n","__________________________________________________________________________________________________\n","pool4_pool (AveragePooling2D)   (None, 3, 3, 512)    0           pool4_conv[0][0]                 \n","__________________________________________________________________________________________________\n","conv5_block1_0_bn (BatchNormali (None, 3, 3, 512)    2048        pool4_pool[0][0]                 \n","__________________________________________________________________________________________________\n","conv5_block1_0_relu (Activation (None, 3, 3, 512)    0           conv5_block1_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block1_1_conv (Conv2D)    (None, 3, 3, 128)    65536       conv5_block1_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block1_1_bn (BatchNormali (None, 3, 3, 128)    512         conv5_block1_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block1_1_relu (Activation (None, 3, 3, 128)    0           conv5_block1_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block1_2_conv (Conv2D)    (None, 3, 3, 32)     36864       conv5_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block1_concat (Concatenat (None, 3, 3, 544)    0           pool4_pool[0][0]                 \n","                                                                 conv5_block1_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block2_0_bn (BatchNormali (None, 3, 3, 544)    2176        conv5_block1_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block2_0_relu (Activation (None, 3, 3, 544)    0           conv5_block2_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block2_1_conv (Conv2D)    (None, 3, 3, 128)    69632       conv5_block2_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block2_1_bn (BatchNormali (None, 3, 3, 128)    512         conv5_block2_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block2_1_relu (Activation (None, 3, 3, 128)    0           conv5_block2_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block2_2_conv (Conv2D)    (None, 3, 3, 32)     36864       conv5_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block2_concat (Concatenat (None, 3, 3, 576)    0           conv5_block1_concat[0][0]        \n","                                                                 conv5_block2_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block3_0_bn (BatchNormali (None, 3, 3, 576)    2304        conv5_block2_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block3_0_relu (Activation (None, 3, 3, 576)    0           conv5_block3_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block3_1_conv (Conv2D)    (None, 3, 3, 128)    73728       conv5_block3_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block3_1_bn (BatchNormali (None, 3, 3, 128)    512         conv5_block3_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block3_1_relu (Activation (None, 3, 3, 128)    0           conv5_block3_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block3_2_conv (Conv2D)    (None, 3, 3, 32)     36864       conv5_block3_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block3_concat (Concatenat (None, 3, 3, 608)    0           conv5_block2_concat[0][0]        \n","                                                                 conv5_block3_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block4_0_bn (BatchNormali (None, 3, 3, 608)    2432        conv5_block3_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block4_0_relu (Activation (None, 3, 3, 608)    0           conv5_block4_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block4_1_conv (Conv2D)    (None, 3, 3, 128)    77824       conv5_block4_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block4_1_bn (BatchNormali (None, 3, 3, 128)    512         conv5_block4_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block4_1_relu (Activation (None, 3, 3, 128)    0           conv5_block4_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block4_2_conv (Conv2D)    (None, 3, 3, 32)     36864       conv5_block4_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block4_concat (Concatenat (None, 3, 3, 640)    0           conv5_block3_concat[0][0]        \n","                                                                 conv5_block4_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block5_0_bn (BatchNormali (None, 3, 3, 640)    2560        conv5_block4_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block5_0_relu (Activation (None, 3, 3, 640)    0           conv5_block5_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block5_1_conv (Conv2D)    (None, 3, 3, 128)    81920       conv5_block5_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block5_1_bn (BatchNormali (None, 3, 3, 128)    512         conv5_block5_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block5_1_relu (Activation (None, 3, 3, 128)    0           conv5_block5_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block5_2_conv (Conv2D)    (None, 3, 3, 32)     36864       conv5_block5_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block5_concat (Concatenat (None, 3, 3, 672)    0           conv5_block4_concat[0][0]        \n","                                                                 conv5_block5_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block6_0_bn (BatchNormali (None, 3, 3, 672)    2688        conv5_block5_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block6_0_relu (Activation (None, 3, 3, 672)    0           conv5_block6_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block6_1_conv (Conv2D)    (None, 3, 3, 128)    86016       conv5_block6_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block6_1_bn (BatchNormali (None, 3, 3, 128)    512         conv5_block6_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block6_1_relu (Activation (None, 3, 3, 128)    0           conv5_block6_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block6_2_conv (Conv2D)    (None, 3, 3, 32)     36864       conv5_block6_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block6_concat (Concatenat (None, 3, 3, 704)    0           conv5_block5_concat[0][0]        \n","                                                                 conv5_block6_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block7_0_bn (BatchNormali (None, 3, 3, 704)    2816        conv5_block6_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block7_0_relu (Activation (None, 3, 3, 704)    0           conv5_block7_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block7_1_conv (Conv2D)    (None, 3, 3, 128)    90112       conv5_block7_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block7_1_bn (BatchNormali (None, 3, 3, 128)    512         conv5_block7_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block7_1_relu (Activation (None, 3, 3, 128)    0           conv5_block7_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block7_2_conv (Conv2D)    (None, 3, 3, 32)     36864       conv5_block7_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block7_concat (Concatenat (None, 3, 3, 736)    0           conv5_block6_concat[0][0]        \n","                                                                 conv5_block7_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block8_0_bn (BatchNormali (None, 3, 3, 736)    2944        conv5_block7_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block8_0_relu (Activation (None, 3, 3, 736)    0           conv5_block8_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block8_1_conv (Conv2D)    (None, 3, 3, 128)    94208       conv5_block8_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block8_1_bn (BatchNormali (None, 3, 3, 128)    512         conv5_block8_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block8_1_relu (Activation (None, 3, 3, 128)    0           conv5_block8_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block8_2_conv (Conv2D)    (None, 3, 3, 32)     36864       conv5_block8_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block8_concat (Concatenat (None, 3, 3, 768)    0           conv5_block7_concat[0][0]        \n","                                                                 conv5_block8_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block9_0_bn (BatchNormali (None, 3, 3, 768)    3072        conv5_block8_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block9_0_relu (Activation (None, 3, 3, 768)    0           conv5_block9_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block9_1_conv (Conv2D)    (None, 3, 3, 128)    98304       conv5_block9_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block9_1_bn (BatchNormali (None, 3, 3, 128)    512         conv5_block9_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block9_1_relu (Activation (None, 3, 3, 128)    0           conv5_block9_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block9_2_conv (Conv2D)    (None, 3, 3, 32)     36864       conv5_block9_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block9_concat (Concatenat (None, 3, 3, 800)    0           conv5_block8_concat[0][0]        \n","                                                                 conv5_block9_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block10_0_bn (BatchNormal (None, 3, 3, 800)    3200        conv5_block9_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block10_0_relu (Activatio (None, 3, 3, 800)    0           conv5_block10_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv5_block10_1_conv (Conv2D)   (None, 3, 3, 128)    102400      conv5_block10_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block10_1_bn (BatchNormal (None, 3, 3, 128)    512         conv5_block10_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block10_1_relu (Activatio (None, 3, 3, 128)    0           conv5_block10_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv5_block10_2_conv (Conv2D)   (None, 3, 3, 32)     36864       conv5_block10_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block10_concat (Concatena (None, 3, 3, 832)    0           conv5_block9_concat[0][0]        \n","                                                                 conv5_block10_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block11_0_bn (BatchNormal (None, 3, 3, 832)    3328        conv5_block10_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block11_0_relu (Activatio (None, 3, 3, 832)    0           conv5_block11_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv5_block11_1_conv (Conv2D)   (None, 3, 3, 128)    106496      conv5_block11_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block11_1_bn (BatchNormal (None, 3, 3, 128)    512         conv5_block11_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block11_1_relu (Activatio (None, 3, 3, 128)    0           conv5_block11_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv5_block11_2_conv (Conv2D)   (None, 3, 3, 32)     36864       conv5_block11_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block11_concat (Concatena (None, 3, 3, 864)    0           conv5_block10_concat[0][0]       \n","                                                                 conv5_block11_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block12_0_bn (BatchNormal (None, 3, 3, 864)    3456        conv5_block11_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block12_0_relu (Activatio (None, 3, 3, 864)    0           conv5_block12_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv5_block12_1_conv (Conv2D)   (None, 3, 3, 128)    110592      conv5_block12_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block12_1_bn (BatchNormal (None, 3, 3, 128)    512         conv5_block12_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block12_1_relu (Activatio (None, 3, 3, 128)    0           conv5_block12_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv5_block12_2_conv (Conv2D)   (None, 3, 3, 32)     36864       conv5_block12_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block12_concat (Concatena (None, 3, 3, 896)    0           conv5_block11_concat[0][0]       \n","                                                                 conv5_block12_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block13_0_bn (BatchNormal (None, 3, 3, 896)    3584        conv5_block12_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block13_0_relu (Activatio (None, 3, 3, 896)    0           conv5_block13_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv5_block13_1_conv (Conv2D)   (None, 3, 3, 128)    114688      conv5_block13_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block13_1_bn (BatchNormal (None, 3, 3, 128)    512         conv5_block13_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block13_1_relu (Activatio (None, 3, 3, 128)    0           conv5_block13_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv5_block13_2_conv (Conv2D)   (None, 3, 3, 32)     36864       conv5_block13_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block13_concat (Concatena (None, 3, 3, 928)    0           conv5_block12_concat[0][0]       \n","                                                                 conv5_block13_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block14_0_bn (BatchNormal (None, 3, 3, 928)    3712        conv5_block13_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block14_0_relu (Activatio (None, 3, 3, 928)    0           conv5_block14_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv5_block14_1_conv (Conv2D)   (None, 3, 3, 128)    118784      conv5_block14_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block14_1_bn (BatchNormal (None, 3, 3, 128)    512         conv5_block14_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block14_1_relu (Activatio (None, 3, 3, 128)    0           conv5_block14_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv5_block14_2_conv (Conv2D)   (None, 3, 3, 32)     36864       conv5_block14_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block14_concat (Concatena (None, 3, 3, 960)    0           conv5_block13_concat[0][0]       \n","                                                                 conv5_block14_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block15_0_bn (BatchNormal (None, 3, 3, 960)    3840        conv5_block14_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block15_0_relu (Activatio (None, 3, 3, 960)    0           conv5_block15_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv5_block15_1_conv (Conv2D)   (None, 3, 3, 128)    122880      conv5_block15_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block15_1_bn (BatchNormal (None, 3, 3, 128)    512         conv5_block15_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block15_1_relu (Activatio (None, 3, 3, 128)    0           conv5_block15_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv5_block15_2_conv (Conv2D)   (None, 3, 3, 32)     36864       conv5_block15_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block15_concat (Concatena (None, 3, 3, 992)    0           conv5_block14_concat[0][0]       \n","                                                                 conv5_block15_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block16_0_bn (BatchNormal (None, 3, 3, 992)    3968        conv5_block15_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block16_0_relu (Activatio (None, 3, 3, 992)    0           conv5_block16_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv5_block16_1_conv (Conv2D)   (None, 3, 3, 128)    126976      conv5_block16_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block16_1_bn (BatchNormal (None, 3, 3, 128)    512         conv5_block16_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block16_1_relu (Activatio (None, 3, 3, 128)    0           conv5_block16_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv5_block16_2_conv (Conv2D)   (None, 3, 3, 32)     36864       conv5_block16_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block16_concat (Concatena (None, 3, 3, 1024)   0           conv5_block15_concat[0][0]       \n","                                                                 conv5_block16_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","bn (BatchNormalization)         (None, 3, 3, 1024)   4096        conv5_block16_concat[0][0]       \n","__________________________________________________________________________________________________\n","relu (Activation)               (None, 3, 3, 1024)   0           bn[0][0]                         \n","==================================================================================================\n","Total params: 7,037,504\n","Trainable params: 745,984\n","Non-trainable params: 6,291,520\n","__________________________________________________________________________________________________\n","Model: \"DenseNet121_ADModel\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","tensor (InputLayer)          [(None, 100, 100, 3)]     0         \n","_________________________________________________________________\n","densenet121 (Functional)     (None, 3, 3, 1024)        7037504   \n","_________________________________________________________________\n","flatten (Flatten)            (None, 9216)              0         \n","_________________________________________________________________\n","dropout (Dropout)            (None, 9216)              0         \n","_________________________________________________________________\n","dense (Dense)                (None, 32)                294944    \n","_________________________________________________________________\n","batch_normalization (BatchNo (None, 32)                128       \n","_________________________________________________________________\n","leaky_re_lu (LeakyReLU)      (None, 32)                0         \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 32)                0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 4)                 132       \n","=================================================================\n","Total params: 7,332,708\n","Trainable params: 1,041,124\n","Non-trainable params: 6,291,584\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MZ4jfdUCPsXW","executionInfo":{"status":"ok","timestamp":1618592092264,"user_tz":240,"elapsed":6808657,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"0c7e2bd3-1d71-4c45-cd7d-9bf0645fd7f9"},"source":["# train the model\n","graph_reg_history = graph_reg_model.fit(train_image_dataset, \n","                                        validation_data=test_image_dataset,\n","                                        callbacks = [callback_checkpoints, callback_earlystop],\n","                                        epochs=params.train_epoch,\n","                                        verbose=1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/50\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py:595: UserWarning: Input dict contained keys ['id'] which did not match any model input. They will be ignored by the model.\n","  [n for n in tensors.keys() if n not in ref_input_names])\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/GraphRegularization/graph_loss/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/GraphRegularization/graph_loss/Reshape:0\", shape=(None, 4), dtype=float32), dense_shape=Tensor(\"gradient_tape/GraphRegularization/graph_loss/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"shape. This may consume a large amount of memory.\" % value)\n"],"name":"stderr"},{"output_type":"stream","text":["160/160 [==============================] - 152s 855ms/step - loss: 0.0375 - accuracy: 0.9868 - auc: 0.9996 - f1_score: 0.9867 - scaled_graph_loss: 7.8527e-06 - val_loss: 1.7916 - val_accuracy: 0.6787 - val_auc: 0.8602 - val_f1_score: 0.9518\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.67866, saving model to /content/drive/MyDrive/AD Expriment II/DenseNet_model_checkpoints/densenet_nsl_weights\n","Epoch 2/50\n","160/160 [==============================] - 136s 843ms/step - loss: 0.0354 - accuracy: 0.9877 - auc: 0.9996 - f1_score: 0.9876 - scaled_graph_loss: 8.3765e-06 - val_loss: 2.1548 - val_accuracy: 0.6591 - val_auc: 0.8469 - val_f1_score: 0.6585\n","\n","Epoch 00002: val_accuracy did not improve from 0.67866\n","Epoch 3/50\n","160/160 [==============================] - 136s 843ms/step - loss: 0.0394 - accuracy: 0.9853 - auc: 0.9992 - f1_score: 0.9854 - scaled_graph_loss: 8.6871e-06 - val_loss: 1.9432 - val_accuracy: 0.6654 - val_auc: 0.8628 - val_f1_score: 0.6664\n","\n","Epoch 00003: val_accuracy did not improve from 0.67866\n","Epoch 4/50\n","160/160 [==============================] - 135s 843ms/step - loss: 0.0550 - accuracy: 0.9815 - auc: 0.9985 - f1_score: 0.9816 - scaled_graph_loss: 1.0712e-05 - val_loss: 1.8573 - val_accuracy: 0.6701 - val_auc: 0.8645 - val_f1_score: 0.6695\n","\n","Epoch 00004: val_accuracy did not improve from 0.67866\n","Epoch 5/50\n","160/160 [==============================] - 136s 843ms/step - loss: 0.0365 - accuracy: 0.9881 - auc: 0.9997 - f1_score: 0.9882 - scaled_graph_loss: 7.6446e-06 - val_loss: 2.0336 - val_accuracy: 0.6575 - val_auc: 0.8468 - val_f1_score: 0.6559\n","\n","Epoch 00005: val_accuracy did not improve from 0.67866\n","Epoch 6/50\n","160/160 [==============================] - 135s 843ms/step - loss: 0.0419 - accuracy: 0.9874 - auc: 0.9989 - f1_score: 0.9875 - scaled_graph_loss: 8.3417e-06 - val_loss: 1.9979 - val_accuracy: 0.6513 - val_auc: 0.8505 - val_f1_score: 0.6512\n","\n","Epoch 00006: val_accuracy did not improve from 0.67866\n","Epoch 7/50\n","160/160 [==============================] - 135s 843ms/step - loss: 0.0420 - accuracy: 0.9872 - auc: 0.9992 - f1_score: 0.9871 - scaled_graph_loss: 9.5421e-06 - val_loss: 2.4714 - val_accuracy: 0.6599 - val_auc: 0.8430 - val_f1_score: 0.6593\n","\n","Epoch 00007: val_accuracy did not improve from 0.67866\n","Epoch 8/50\n","160/160 [==============================] - 135s 842ms/step - loss: 0.0531 - accuracy: 0.9831 - auc: 0.9991 - f1_score: 0.9832 - scaled_graph_loss: 1.0583e-05 - val_loss: 4.4842 - val_accuracy: 0.4668 - val_auc: 0.6876 - val_f1_score: 0.4653\n","\n","Epoch 00008: val_accuracy did not improve from 0.67866\n","Epoch 9/50\n","160/160 [==============================] - 135s 842ms/step - loss: 0.0358 - accuracy: 0.9872 - auc: 0.9994 - f1_score: 0.9875 - scaled_graph_loss: 8.0613e-06 - val_loss: 2.4453 - val_accuracy: 0.5895 - val_auc: 0.8075 - val_f1_score: 0.5904\n","\n","Epoch 00009: val_accuracy did not improve from 0.67866\n","Epoch 10/50\n","160/160 [==============================] - 136s 844ms/step - loss: 0.0367 - accuracy: 0.9886 - auc: 0.9994 - f1_score: 0.9888 - scaled_graph_loss: 7.6077e-06 - val_loss: 1.7030 - val_accuracy: 0.6747 - val_auc: 0.8664 - val_f1_score: 0.6732\n","\n","Epoch 00010: val_accuracy did not improve from 0.67866\n","Epoch 11/50\n","160/160 [==============================] - 136s 844ms/step - loss: 0.0258 - accuracy: 0.9912 - auc: 0.9998 - f1_score: 0.9912 - scaled_graph_loss: 5.7446e-06 - val_loss: 2.6047 - val_accuracy: 0.6482 - val_auc: 0.8332 - val_f1_score: 0.6489\n","\n","Epoch 00011: val_accuracy did not improve from 0.67866\n","Epoch 12/50\n","160/160 [==============================] - 136s 844ms/step - loss: 0.0224 - accuracy: 0.9917 - auc: 0.9998 - f1_score: 0.9916 - scaled_graph_loss: 5.1262e-06 - val_loss: 5.1756 - val_accuracy: 0.4206 - val_auc: 0.6528 - val_f1_score: 0.4214\n","\n","Epoch 00012: val_accuracy did not improve from 0.67866\n","Epoch 13/50\n","160/160 [==============================] - 136s 844ms/step - loss: 0.0229 - accuracy: 0.9919 - auc: 0.9999 - f1_score: 0.9919 - scaled_graph_loss: 5.0381e-06 - val_loss: 1.8995 - val_accuracy: 0.6919 - val_auc: 0.8725 - val_f1_score: 0.6920\n","\n","Epoch 00013: val_accuracy improved from 0.67866 to 0.69195, saving model to /content/drive/MyDrive/AD Expriment II/DenseNet_model_checkpoints/densenet_nsl_weights\n","Epoch 14/50\n","160/160 [==============================] - 136s 844ms/step - loss: 0.0382 - accuracy: 0.9872 - auc: 0.9993 - f1_score: 0.9873 - scaled_graph_loss: 8.1346e-06 - val_loss: 2.0061 - val_accuracy: 0.6443 - val_auc: 0.8425 - val_f1_score: 0.6436\n","\n","Epoch 00014: val_accuracy did not improve from 0.69195\n","Epoch 15/50\n","160/160 [==============================] - 136s 844ms/step - loss: 0.0200 - accuracy: 0.9932 - auc: 0.9999 - f1_score: 0.9931 - scaled_graph_loss: 4.4804e-06 - val_loss: 2.5266 - val_accuracy: 0.6661 - val_auc: 0.8421 - val_f1_score: 0.6664\n","\n","Epoch 00015: val_accuracy did not improve from 0.69195\n","Epoch 16/50\n","160/160 [==============================] - 136s 843ms/step - loss: 0.0208 - accuracy: 0.9938 - auc: 0.9997 - f1_score: 0.9938 - scaled_graph_loss: 3.9676e-06 - val_loss: 3.9223 - val_accuracy: 0.5653 - val_auc: 0.7679 - val_f1_score: 0.5659\n","\n","Epoch 00016: val_accuracy did not improve from 0.69195\n","Epoch 17/50\n","160/160 [==============================] - 136s 844ms/step - loss: 0.0365 - accuracy: 0.9881 - auc: 0.9993 - f1_score: 0.9882 - scaled_graph_loss: 8.9564e-06 - val_loss: 1.7026 - val_accuracy: 0.7005 - val_auc: 0.8785 - val_f1_score: 0.7018\n","\n","Epoch 00017: val_accuracy improved from 0.69195 to 0.70055, saving model to /content/drive/MyDrive/AD Expriment II/DenseNet_model_checkpoints/densenet_nsl_weights\n","Epoch 18/50\n","160/160 [==============================] - 136s 843ms/step - loss: 0.0238 - accuracy: 0.9925 - auc: 0.9996 - f1_score: 0.9925 - scaled_graph_loss: 4.6742e-06 - val_loss: 1.6964 - val_accuracy: 0.6919 - val_auc: 0.8777 - val_f1_score: 0.6934\n","\n","Epoch 00018: val_accuracy did not improve from 0.70055\n","Epoch 19/50\n","160/160 [==============================] - 136s 844ms/step - loss: 0.0259 - accuracy: 0.9905 - auc: 0.9997 - f1_score: 0.9907 - scaled_graph_loss: 5.7367e-06 - val_loss: 2.2976 - val_accuracy: 0.6833 - val_auc: 0.8600 - val_f1_score: 0.6821\n","\n","Epoch 00019: val_accuracy did not improve from 0.70055\n","Epoch 20/50\n","160/160 [==============================] - 136s 844ms/step - loss: 0.0219 - accuracy: 0.9933 - auc: 0.9996 - f1_score: 0.9933 - scaled_graph_loss: 5.0357e-06 - val_loss: 3.5378 - val_accuracy: 0.5606 - val_auc: 0.7765 - val_f1_score: 0.5599\n","\n","Epoch 00020: val_accuracy did not improve from 0.70055\n","Epoch 21/50\n","160/160 [==============================] - 136s 844ms/step - loss: 0.0244 - accuracy: 0.9909 - auc: 0.9998 - f1_score: 0.9910 - scaled_graph_loss: 6.0378e-06 - val_loss: 3.8804 - val_accuracy: 0.4621 - val_auc: 0.6999 - val_f1_score: 0.4627\n","\n","Epoch 00021: val_accuracy did not improve from 0.70055\n","Epoch 22/50\n","160/160 [==============================] - 136s 844ms/step - loss: 0.0445 - accuracy: 0.9847 - auc: 0.9991 - f1_score: 0.9844 - scaled_graph_loss: 9.3943e-06 - val_loss: 3.0353 - val_accuracy: 0.5997 - val_auc: 0.8135 - val_f1_score: 0.6006\n","\n","Epoch 00022: val_accuracy did not improve from 0.70055\n","Epoch 23/50\n","160/160 [==============================] - 136s 844ms/step - loss: 0.0176 - accuracy: 0.9946 - auc: 0.9998 - f1_score: 0.9945 - scaled_graph_loss: 4.2005e-06 - val_loss: 2.0265 - val_accuracy: 0.6724 - val_auc: 0.8635 - val_f1_score: 0.6727\n","\n","Epoch 00023: val_accuracy did not improve from 0.70055\n","Epoch 24/50\n","160/160 [==============================] - 136s 844ms/step - loss: 0.0160 - accuracy: 0.9945 - auc: 0.9998 - f1_score: 0.9946 - scaled_graph_loss: 3.7837e-06 - val_loss: 5.6415 - val_accuracy: 0.5012 - val_auc: 0.6999 - val_f1_score: 0.4994\n","\n","Epoch 00024: val_accuracy did not improve from 0.70055\n","Epoch 25/50\n","160/160 [==============================] - 136s 844ms/step - loss: 0.0213 - accuracy: 0.9928 - auc: 0.9998 - f1_score: 0.9927 - scaled_graph_loss: 5.0975e-06 - val_loss: 3.1619 - val_accuracy: 0.6419 - val_auc: 0.8149 - val_f1_score: 0.6422\n","\n","Epoch 00025: val_accuracy did not improve from 0.70055\n","Epoch 26/50\n","160/160 [==============================] - 136s 843ms/step - loss: 0.0393 - accuracy: 0.9879 - auc: 0.9988 - f1_score: 0.9881 - scaled_graph_loss: 7.3741e-06 - val_loss: 2.4968 - val_accuracy: 0.6560 - val_auc: 0.8460 - val_f1_score: 0.6565\n","\n","Epoch 00026: val_accuracy did not improve from 0.70055\n","Epoch 27/50\n","160/160 [==============================] - 135s 843ms/step - loss: 0.0286 - accuracy: 0.9906 - auc: 0.9997 - f1_score: 0.9906 - scaled_graph_loss: 6.1659e-06 - val_loss: 2.8227 - val_accuracy: 0.6466 - val_auc: 0.8274 - val_f1_score: 0.6473\n","\n","Epoch 00027: val_accuracy did not improve from 0.70055\n","Epoch 28/50\n","160/160 [==============================] - 136s 844ms/step - loss: 0.0156 - accuracy: 0.9942 - auc: 0.9999 - f1_score: 0.9942 - scaled_graph_loss: 4.0055e-06 - val_loss: 3.0268 - val_accuracy: 0.6560 - val_auc: 0.8322 - val_f1_score: 0.6555\n","\n","Epoch 00028: val_accuracy did not improve from 0.70055\n","Epoch 29/50\n","160/160 [==============================] - 136s 844ms/step - loss: 0.0128 - accuracy: 0.9963 - auc: 0.9998 - f1_score: 0.9963 - scaled_graph_loss: 2.5728e-06 - val_loss: 2.1397 - val_accuracy: 0.6826 - val_auc: 0.8608 - val_f1_score: 0.6821\n","\n","Epoch 00029: val_accuracy did not improve from 0.70055\n","Epoch 30/50\n","160/160 [==============================] - 136s 844ms/step - loss: 0.0076 - accuracy: 0.9977 - auc: 1.0000 - f1_score: 0.9977 - scaled_graph_loss: 2.2545e-06 - val_loss: 2.0458 - val_accuracy: 0.6904 - val_auc: 0.8676 - val_f1_score: 0.6897\n","\n","Epoch 00030: val_accuracy did not improve from 0.70055\n","Epoch 31/50\n","160/160 [==============================] - 136s 844ms/step - loss: 0.0133 - accuracy: 0.9952 - auc: 0.9999 - f1_score: 0.9954 - scaled_graph_loss: 3.0761e-06 - val_loss: 2.3040 - val_accuracy: 0.6599 - val_auc: 0.8430 - val_f1_score: 0.6599\n","\n","Epoch 00031: val_accuracy did not improve from 0.70055\n","Epoch 32/50\n","160/160 [==============================] - 135s 843ms/step - loss: 0.0400 - accuracy: 0.9862 - auc: 0.9994 - f1_score: 0.9862 - scaled_graph_loss: 9.1672e-06 - val_loss: 2.4635 - val_accuracy: 0.6403 - val_auc: 0.8353 - val_f1_score: 0.6408\n","\n","Epoch 00032: val_accuracy did not improve from 0.70055\n","Epoch 33/50\n","160/160 [==============================] - 136s 843ms/step - loss: 0.0290 - accuracy: 0.9897 - auc: 0.9995 - f1_score: 0.9897 - scaled_graph_loss: 6.4769e-06 - val_loss: 2.1033 - val_accuracy: 0.6747 - val_auc: 0.8587 - val_f1_score: 0.6743\n","\n","Epoch 00033: val_accuracy did not improve from 0.70055\n","Epoch 34/50\n","160/160 [==============================] - 136s 843ms/step - loss: 0.0133 - accuracy: 0.9958 - auc: 1.0000 - f1_score: 0.9958 - scaled_graph_loss: 3.2524e-06 - val_loss: 2.1089 - val_accuracy: 0.6771 - val_auc: 0.8524 - val_f1_score: 0.6792\n","\n","Epoch 00034: val_accuracy did not improve from 0.70055\n","Epoch 35/50\n","160/160 [==============================] - 135s 843ms/step - loss: 0.0154 - accuracy: 0.9951 - auc: 0.9999 - f1_score: 0.9951 - scaled_graph_loss: 3.1643e-06 - val_loss: 2.9907 - val_accuracy: 0.5950 - val_auc: 0.7951 - val_f1_score: 0.5941\n","\n","Epoch 00035: val_accuracy did not improve from 0.70055\n","Epoch 36/50\n","160/160 [==============================] - 136s 843ms/step - loss: 0.0252 - accuracy: 0.9910 - auc: 0.9996 - f1_score: 0.9911 - scaled_graph_loss: 5.6026e-06 - val_loss: 3.9942 - val_accuracy: 0.5911 - val_auc: 0.7889 - val_f1_score: 0.5912\n","\n","Epoch 00036: val_accuracy did not improve from 0.70055\n","Epoch 37/50\n","160/160 [==============================] - 136s 844ms/step - loss: 0.0525 - accuracy: 0.9850 - auc: 0.9986 - f1_score: 0.9849 - scaled_graph_loss: 8.9702e-06 - val_loss: 3.0624 - val_accuracy: 0.6302 - val_auc: 0.8184 - val_f1_score: 0.6291\n","\n","Epoch 00037: val_accuracy did not improve from 0.70055\n","Epoch 38/50\n","160/160 [==============================] - 136s 844ms/step - loss: 0.0096 - accuracy: 0.9975 - auc: 1.0000 - f1_score: 0.9975 - scaled_graph_loss: 2.0821e-06 - val_loss: 1.6922 - val_accuracy: 0.7349 - val_auc: 0.8940 - val_f1_score: 0.7341\n","\n","Epoch 00038: val_accuracy improved from 0.70055 to 0.73495, saving model to /content/drive/MyDrive/AD Expriment II/DenseNet_model_checkpoints/densenet_nsl_weights\n","Epoch 39/50\n","160/160 [==============================] - 136s 844ms/step - loss: 0.0082 - accuracy: 0.9974 - auc: 1.0000 - f1_score: 0.9974 - scaled_graph_loss: 1.9283e-06 - val_loss: 3.0343 - val_accuracy: 0.5801 - val_auc: 0.7854 - val_f1_score: 0.5797\n","\n","Epoch 00039: val_accuracy did not improve from 0.73495\n","Epoch 40/50\n","160/160 [==============================] - 136s 843ms/step - loss: 0.0292 - accuracy: 0.9903 - auc: 0.9996 - f1_score: 0.9902 - scaled_graph_loss: 6.5459e-06 - val_loss: 2.3255 - val_accuracy: 0.6489 - val_auc: 0.8439 - val_f1_score: 0.6486\n","\n","Epoch 00040: val_accuracy did not improve from 0.73495\n","Epoch 41/50\n","160/160 [==============================] - 136s 844ms/step - loss: 0.0118 - accuracy: 0.9968 - auc: 0.9999 - f1_score: 0.9968 - scaled_graph_loss: 2.7580e-06 - val_loss: 2.3850 - val_accuracy: 0.6615 - val_auc: 0.8404 - val_f1_score: 0.6612\n","\n","Epoch 00041: val_accuracy did not improve from 0.73495\n","Epoch 42/50\n","160/160 [==============================] - 136s 844ms/step - loss: 0.0317 - accuracy: 0.9900 - auc: 0.9993 - f1_score: 0.9900 - scaled_graph_loss: 6.3021e-06 - val_loss: 2.6623 - val_accuracy: 0.6630 - val_auc: 0.8355 - val_f1_score: 0.6638\n","\n","Epoch 00042: val_accuracy did not improve from 0.73495\n","Epoch 43/50\n","160/160 [==============================] - 136s 844ms/step - loss: 0.0130 - accuracy: 0.9950 - auc: 1.0000 - f1_score: 0.9950 - scaled_graph_loss: 2.9010e-06 - val_loss: 2.0376 - val_accuracy: 0.6771 - val_auc: 0.8673 - val_f1_score: 0.6777\n","\n","Epoch 00043: val_accuracy did not improve from 0.73495\n","Epoch 44/50\n","160/160 [==============================] - 136s 843ms/step - loss: 0.0154 - accuracy: 0.9941 - auc: 0.9998 - f1_score: 0.9941 - scaled_graph_loss: 3.5064e-06 - val_loss: 3.1994 - val_accuracy: 0.5856 - val_auc: 0.7844 - val_f1_score: 0.5867\n","\n","Epoch 00044: val_accuracy did not improve from 0.73495\n","Epoch 45/50\n","160/160 [==============================] - 136s 843ms/step - loss: 0.0132 - accuracy: 0.9963 - auc: 0.9998 - f1_score: 0.9962 - scaled_graph_loss: 2.5483e-06 - val_loss: 1.8726 - val_accuracy: 0.7131 - val_auc: 0.8787 - val_f1_score: 0.7129\n","\n","Epoch 00045: val_accuracy did not improve from 0.73495\n","Epoch 46/50\n","160/160 [==============================] - 136s 844ms/step - loss: 0.0090 - accuracy: 0.9969 - auc: 1.0000 - f1_score: 0.9969 - scaled_graph_loss: 2.2684e-06 - val_loss: 3.2279 - val_accuracy: 0.6310 - val_auc: 0.8205 - val_f1_score: 0.6307\n","\n","Epoch 00046: val_accuracy did not improve from 0.73495\n","Epoch 47/50\n","160/160 [==============================] - 136s 843ms/step - loss: 0.0103 - accuracy: 0.9957 - auc: 1.0000 - f1_score: 0.9958 - scaled_graph_loss: 2.4637e-06 - val_loss: 2.2080 - val_accuracy: 0.7091 - val_auc: 0.8666 - val_f1_score: 0.7084\n","\n","Epoch 00047: val_accuracy did not improve from 0.73495\n","Epoch 48/50\n","160/160 [==============================] - 136s 844ms/step - loss: 0.0166 - accuracy: 0.9937 - auc: 0.9998 - f1_score: 0.9938 - scaled_graph_loss: 3.5880e-06 - val_loss: 3.2128 - val_accuracy: 0.6388 - val_auc: 0.8243 - val_f1_score: 0.6395\n","\n","Epoch 00048: val_accuracy did not improve from 0.73495\n","Epoch 49/50\n","160/160 [==============================] - 136s 844ms/step - loss: 0.0294 - accuracy: 0.9913 - auc: 0.9993 - f1_score: 0.9911 - scaled_graph_loss: 6.0812e-06 - val_loss: 3.0242 - val_accuracy: 0.6435 - val_auc: 0.8219 - val_f1_score: 0.6445\n","\n","Epoch 00049: val_accuracy did not improve from 0.73495\n","Epoch 50/50\n","160/160 [==============================] - 136s 843ms/step - loss: 0.0191 - accuracy: 0.9935 - auc: 0.9997 - f1_score: 0.9933 - scaled_graph_loss: 3.7100e-06 - val_loss: 2.3824 - val_accuracy: 0.6685 - val_auc: 0.8473 - val_f1_score: 0.6693\n","\n","Epoch 00050: val_accuracy did not improve from 0.73495\n","Early stopping is not triggered, but best model is restored at epoch 38\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CiySckZVg8GJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618838715816,"user_tz":240,"elapsed":40981,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"5a758e99-e12d-4251-a0cb-b5c4bcb5032b"},"source":["'''evalute the test model'''\n","graph_reg_model.evaluate(test_image_dataset)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py:595: UserWarning: Input dict contained keys ['id'] which did not match any model input. They will be ignored by the model.\n","  [n for n in tensors.keys() if n not in ref_input_names])\n"],"name":"stderr"},{"output_type":"stream","text":["20/20 [==============================] - 41s 171ms/step - loss: 1.6862 - accuracy: 0.7479 - auc: 0.8971 - f1_score: 0.7461\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[1.6922053098678589,\n"," 0.7349491715431213,\n"," 0.8940041661262512,\n"," 0.7341175675392151]"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"n1Kudc3XErB-"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pkkMlFWfBTFZ"},"source":["## 3.4 DenseNet_NSL top 10 layers, middle 20 layers and bottom 10 laysers tuning\n","### val_acc: 0.74, val_auc: 0.89, val_f1_score: 0.74"]},{"cell_type":"code","metadata":{"id":"MGAmz0zgZkZZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618853927874,"user_tz":240,"elapsed":9556,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"f00d57c6-c9f5-4604-ede2-7ce701ad5e93"},"source":["'''define params'''\n","params.learning_rate=0.000005\n","params.restore_path= '/content/drive/MyDrive/AD Expriment II/DenseNet_model_checkpoints/densenet_nsl_weights'\n","params.checkpoint_path = '/content/drive/MyDrive/AD Expriment II/DenseNet_model_checkpoints/densenet_nsl_weights'\n","params.early_stop_base_line=0.80\n","params.train_epoch=50\n","params.nsl_multiplier = 0.00005\n","params.nsl_sum_over_axis = -1\n","params.nsl_distance_type = nsl.configs.DistanceType.COSINE\n","\n","'''build a base model with selected trainable layer'''\n","admodel = ADModelBuilder(input_shape=params.ad_base_model_input_shape, base_model='densenet121').setup_DenseNet121(top_layers=10, middle_layers=[190, 210], bottom_layers=10).get_ADModel()\n","\n","'''build NSL model on top of base model'''\n","graph_reg_config = nsl.configs.make_graph_reg_config(neighbor_prefix=params.neighbor_prefix,\n","                                                     neighbor_weight_suffix=params.neighbor_weight_suffix,\n","                                                     max_neighbors= params.max_seed_nbr,\n","                                                     multiplier= params.nsl_multiplier,\n","                                                     distance_type= params.nsl_distance_type,\n","                                                     sum_over_axis= params.nsl_sum_over_axis)\n","graph_reg_model = nsl.keras.GraphRegularization(admodel,graph_reg_config)\n","graph_reg_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=params.learning_rate, amsgrad=True), \n","                        loss=tf.losses.CategoricalCrossentropy(), \n","                        metrics=[\"accuracy\",\"AUC\", tfa.metrics.F1Score(num_classes=4, average=\"micro\", threshold = 0.5)])\n","\n","'''restore the model from last training'''\n","graph_reg_model.load_weights(params.restore_path)"],"execution_count":20,"outputs":[{"output_type":"stream","text":["Note: default DenseNet121 not includes top and has imagenet weights. It is not a trainable model in ADModelBuilder. Please setup trainable layers in setup_DenseNet121 function based on the \"Layer Number\"\n","Model: \"densenet121\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 100, 100, 3) 0                                            \n","__________________________________________________________________________________________________\n","zero_padding2d (ZeroPadding2D)  (None, 106, 106, 3)  0           input_1[0][0]                    \n","__________________________________________________________________________________________________\n","conv1/conv (Conv2D)             (None, 50, 50, 64)   9408        zero_padding2d[0][0]             \n","__________________________________________________________________________________________________\n","conv1/bn (BatchNormalization)   (None, 50, 50, 64)   256         conv1/conv[0][0]                 \n","__________________________________________________________________________________________________\n","conv1/relu (Activation)         (None, 50, 50, 64)   0           conv1/bn[0][0]                   \n","__________________________________________________________________________________________________\n","zero_padding2d_1 (ZeroPadding2D (None, 52, 52, 64)   0           conv1/relu[0][0]                 \n","__________________________________________________________________________________________________\n","pool1 (MaxPooling2D)            (None, 25, 25, 64)   0           zero_padding2d_1[0][0]           \n","__________________________________________________________________________________________________\n","conv2_block1_0_bn (BatchNormali (None, 25, 25, 64)   256         pool1[0][0]                      \n","__________________________________________________________________________________________________\n","conv2_block1_0_relu (Activation (None, 25, 25, 64)   0           conv2_block1_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block1_1_conv (Conv2D)    (None, 25, 25, 128)  8192        conv2_block1_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_1_bn (BatchNormali (None, 25, 25, 128)  512         conv2_block1_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_1_relu (Activation (None, 25, 25, 128)  0           conv2_block1_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block1_2_conv (Conv2D)    (None, 25, 25, 32)   36864       conv2_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_concat (Concatenat (None, 25, 25, 96)   0           pool1[0][0]                      \n","                                                                 conv2_block1_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_0_bn (BatchNormali (None, 25, 25, 96)   384         conv2_block1_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_0_relu (Activation (None, 25, 25, 96)   0           conv2_block2_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block2_1_conv (Conv2D)    (None, 25, 25, 128)  12288       conv2_block2_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_1_bn (BatchNormali (None, 25, 25, 128)  512         conv2_block2_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_1_relu (Activation (None, 25, 25, 128)  0           conv2_block2_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block2_2_conv (Conv2D)    (None, 25, 25, 32)   36864       conv2_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_concat (Concatenat (None, 25, 25, 128)  0           conv2_block1_concat[0][0]        \n","                                                                 conv2_block2_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_0_bn (BatchNormali (None, 25, 25, 128)  512         conv2_block2_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_0_relu (Activation (None, 25, 25, 128)  0           conv2_block3_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block3_1_conv (Conv2D)    (None, 25, 25, 128)  16384       conv2_block3_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_1_bn (BatchNormali (None, 25, 25, 128)  512         conv2_block3_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_1_relu (Activation (None, 25, 25, 128)  0           conv2_block3_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block3_2_conv (Conv2D)    (None, 25, 25, 32)   36864       conv2_block3_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_concat (Concatenat (None, 25, 25, 160)  0           conv2_block2_concat[0][0]        \n","                                                                 conv2_block3_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block4_0_bn (BatchNormali (None, 25, 25, 160)  640         conv2_block3_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block4_0_relu (Activation (None, 25, 25, 160)  0           conv2_block4_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block4_1_conv (Conv2D)    (None, 25, 25, 128)  20480       conv2_block4_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block4_1_bn (BatchNormali (None, 25, 25, 128)  512         conv2_block4_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block4_1_relu (Activation (None, 25, 25, 128)  0           conv2_block4_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block4_2_conv (Conv2D)    (None, 25, 25, 32)   36864       conv2_block4_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block4_concat (Concatenat (None, 25, 25, 192)  0           conv2_block3_concat[0][0]        \n","                                                                 conv2_block4_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block5_0_bn (BatchNormali (None, 25, 25, 192)  768         conv2_block4_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block5_0_relu (Activation (None, 25, 25, 192)  0           conv2_block5_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block5_1_conv (Conv2D)    (None, 25, 25, 128)  24576       conv2_block5_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block5_1_bn (BatchNormali (None, 25, 25, 128)  512         conv2_block5_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block5_1_relu (Activation (None, 25, 25, 128)  0           conv2_block5_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block5_2_conv (Conv2D)    (None, 25, 25, 32)   36864       conv2_block5_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block5_concat (Concatenat (None, 25, 25, 224)  0           conv2_block4_concat[0][0]        \n","                                                                 conv2_block5_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block6_0_bn (BatchNormali (None, 25, 25, 224)  896         conv2_block5_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block6_0_relu (Activation (None, 25, 25, 224)  0           conv2_block6_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block6_1_conv (Conv2D)    (None, 25, 25, 128)  28672       conv2_block6_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block6_1_bn (BatchNormali (None, 25, 25, 128)  512         conv2_block6_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block6_1_relu (Activation (None, 25, 25, 128)  0           conv2_block6_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block6_2_conv (Conv2D)    (None, 25, 25, 32)   36864       conv2_block6_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block6_concat (Concatenat (None, 25, 25, 256)  0           conv2_block5_concat[0][0]        \n","                                                                 conv2_block6_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","pool2_bn (BatchNormalization)   (None, 25, 25, 256)  1024        conv2_block6_concat[0][0]        \n","__________________________________________________________________________________________________\n","pool2_relu (Activation)         (None, 25, 25, 256)  0           pool2_bn[0][0]                   \n","__________________________________________________________________________________________________\n","pool2_conv (Conv2D)             (None, 25, 25, 128)  32768       pool2_relu[0][0]                 \n","__________________________________________________________________________________________________\n","pool2_pool (AveragePooling2D)   (None, 12, 12, 128)  0           pool2_conv[0][0]                 \n","__________________________________________________________________________________________________\n","conv3_block1_0_bn (BatchNormali (None, 12, 12, 128)  512         pool2_pool[0][0]                 \n","__________________________________________________________________________________________________\n","conv3_block1_0_relu (Activation (None, 12, 12, 128)  0           conv3_block1_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block1_1_conv (Conv2D)    (None, 12, 12, 128)  16384       conv3_block1_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_1_bn (BatchNormali (None, 12, 12, 128)  512         conv3_block1_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_1_relu (Activation (None, 12, 12, 128)  0           conv3_block1_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block1_2_conv (Conv2D)    (None, 12, 12, 32)   36864       conv3_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_concat (Concatenat (None, 12, 12, 160)  0           pool2_pool[0][0]                 \n","                                                                 conv3_block1_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_0_bn (BatchNormali (None, 12, 12, 160)  640         conv3_block1_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_0_relu (Activation (None, 12, 12, 160)  0           conv3_block2_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block2_1_conv (Conv2D)    (None, 12, 12, 128)  20480       conv3_block2_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_1_bn (BatchNormali (None, 12, 12, 128)  512         conv3_block2_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_1_relu (Activation (None, 12, 12, 128)  0           conv3_block2_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block2_2_conv (Conv2D)    (None, 12, 12, 32)   36864       conv3_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_concat (Concatenat (None, 12, 12, 192)  0           conv3_block1_concat[0][0]        \n","                                                                 conv3_block2_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_0_bn (BatchNormali (None, 12, 12, 192)  768         conv3_block2_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_0_relu (Activation (None, 12, 12, 192)  0           conv3_block3_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block3_1_conv (Conv2D)    (None, 12, 12, 128)  24576       conv3_block3_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_1_bn (BatchNormali (None, 12, 12, 128)  512         conv3_block3_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_1_relu (Activation (None, 12, 12, 128)  0           conv3_block3_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block3_2_conv (Conv2D)    (None, 12, 12, 32)   36864       conv3_block3_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_concat (Concatenat (None, 12, 12, 224)  0           conv3_block2_concat[0][0]        \n","                                                                 conv3_block3_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_0_bn (BatchNormali (None, 12, 12, 224)  896         conv3_block3_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_0_relu (Activation (None, 12, 12, 224)  0           conv3_block4_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block4_1_conv (Conv2D)    (None, 12, 12, 128)  28672       conv3_block4_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_1_bn (BatchNormali (None, 12, 12, 128)  512         conv3_block4_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_1_relu (Activation (None, 12, 12, 128)  0           conv3_block4_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block4_2_conv (Conv2D)    (None, 12, 12, 32)   36864       conv3_block4_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_concat (Concatenat (None, 12, 12, 256)  0           conv3_block3_concat[0][0]        \n","                                                                 conv3_block4_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block5_0_bn (BatchNormali (None, 12, 12, 256)  1024        conv3_block4_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block5_0_relu (Activation (None, 12, 12, 256)  0           conv3_block5_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block5_1_conv (Conv2D)    (None, 12, 12, 128)  32768       conv3_block5_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block5_1_bn (BatchNormali (None, 12, 12, 128)  512         conv3_block5_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block5_1_relu (Activation (None, 12, 12, 128)  0           conv3_block5_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block5_2_conv (Conv2D)    (None, 12, 12, 32)   36864       conv3_block5_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block5_concat (Concatenat (None, 12, 12, 288)  0           conv3_block4_concat[0][0]        \n","                                                                 conv3_block5_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block6_0_bn (BatchNormali (None, 12, 12, 288)  1152        conv3_block5_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block6_0_relu (Activation (None, 12, 12, 288)  0           conv3_block6_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block6_1_conv (Conv2D)    (None, 12, 12, 128)  36864       conv3_block6_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block6_1_bn (BatchNormali (None, 12, 12, 128)  512         conv3_block6_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block6_1_relu (Activation (None, 12, 12, 128)  0           conv3_block6_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block6_2_conv (Conv2D)    (None, 12, 12, 32)   36864       conv3_block6_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block6_concat (Concatenat (None, 12, 12, 320)  0           conv3_block5_concat[0][0]        \n","                                                                 conv3_block6_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block7_0_bn (BatchNormali (None, 12, 12, 320)  1280        conv3_block6_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block7_0_relu (Activation (None, 12, 12, 320)  0           conv3_block7_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block7_1_conv (Conv2D)    (None, 12, 12, 128)  40960       conv3_block7_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block7_1_bn (BatchNormali (None, 12, 12, 128)  512         conv3_block7_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block7_1_relu (Activation (None, 12, 12, 128)  0           conv3_block7_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block7_2_conv (Conv2D)    (None, 12, 12, 32)   36864       conv3_block7_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block7_concat (Concatenat (None, 12, 12, 352)  0           conv3_block6_concat[0][0]        \n","                                                                 conv3_block7_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block8_0_bn (BatchNormali (None, 12, 12, 352)  1408        conv3_block7_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block8_0_relu (Activation (None, 12, 12, 352)  0           conv3_block8_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block8_1_conv (Conv2D)    (None, 12, 12, 128)  45056       conv3_block8_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block8_1_bn (BatchNormali (None, 12, 12, 128)  512         conv3_block8_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block8_1_relu (Activation (None, 12, 12, 128)  0           conv3_block8_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block8_2_conv (Conv2D)    (None, 12, 12, 32)   36864       conv3_block8_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block8_concat (Concatenat (None, 12, 12, 384)  0           conv3_block7_concat[0][0]        \n","                                                                 conv3_block8_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block9_0_bn (BatchNormali (None, 12, 12, 384)  1536        conv3_block8_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block9_0_relu (Activation (None, 12, 12, 384)  0           conv3_block9_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block9_1_conv (Conv2D)    (None, 12, 12, 128)  49152       conv3_block9_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block9_1_bn (BatchNormali (None, 12, 12, 128)  512         conv3_block9_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block9_1_relu (Activation (None, 12, 12, 128)  0           conv3_block9_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block9_2_conv (Conv2D)    (None, 12, 12, 32)   36864       conv3_block9_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block9_concat (Concatenat (None, 12, 12, 416)  0           conv3_block8_concat[0][0]        \n","                                                                 conv3_block9_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block10_0_bn (BatchNormal (None, 12, 12, 416)  1664        conv3_block9_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block10_0_relu (Activatio (None, 12, 12, 416)  0           conv3_block10_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv3_block10_1_conv (Conv2D)   (None, 12, 12, 128)  53248       conv3_block10_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv3_block10_1_bn (BatchNormal (None, 12, 12, 128)  512         conv3_block10_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv3_block10_1_relu (Activatio (None, 12, 12, 128)  0           conv3_block10_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv3_block10_2_conv (Conv2D)   (None, 12, 12, 32)   36864       conv3_block10_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv3_block10_concat (Concatena (None, 12, 12, 448)  0           conv3_block9_concat[0][0]        \n","                                                                 conv3_block10_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv3_block11_0_bn (BatchNormal (None, 12, 12, 448)  1792        conv3_block10_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv3_block11_0_relu (Activatio (None, 12, 12, 448)  0           conv3_block11_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv3_block11_1_conv (Conv2D)   (None, 12, 12, 128)  57344       conv3_block11_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv3_block11_1_bn (BatchNormal (None, 12, 12, 128)  512         conv3_block11_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv3_block11_1_relu (Activatio (None, 12, 12, 128)  0           conv3_block11_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv3_block11_2_conv (Conv2D)   (None, 12, 12, 32)   36864       conv3_block11_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv3_block11_concat (Concatena (None, 12, 12, 480)  0           conv3_block10_concat[0][0]       \n","                                                                 conv3_block11_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv3_block12_0_bn (BatchNormal (None, 12, 12, 480)  1920        conv3_block11_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv3_block12_0_relu (Activatio (None, 12, 12, 480)  0           conv3_block12_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv3_block12_1_conv (Conv2D)   (None, 12, 12, 128)  61440       conv3_block12_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv3_block12_1_bn (BatchNormal (None, 12, 12, 128)  512         conv3_block12_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv3_block12_1_relu (Activatio (None, 12, 12, 128)  0           conv3_block12_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv3_block12_2_conv (Conv2D)   (None, 12, 12, 32)   36864       conv3_block12_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv3_block12_concat (Concatena (None, 12, 12, 512)  0           conv3_block11_concat[0][0]       \n","                                                                 conv3_block12_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","pool3_bn (BatchNormalization)   (None, 12, 12, 512)  2048        conv3_block12_concat[0][0]       \n","__________________________________________________________________________________________________\n","pool3_relu (Activation)         (None, 12, 12, 512)  0           pool3_bn[0][0]                   \n","__________________________________________________________________________________________________\n","pool3_conv (Conv2D)             (None, 12, 12, 256)  131072      pool3_relu[0][0]                 \n","__________________________________________________________________________________________________\n","pool3_pool (AveragePooling2D)   (None, 6, 6, 256)    0           pool3_conv[0][0]                 \n","__________________________________________________________________________________________________\n","conv4_block1_0_bn (BatchNormali (None, 6, 6, 256)    1024        pool3_pool[0][0]                 \n","__________________________________________________________________________________________________\n","conv4_block1_0_relu (Activation (None, 6, 6, 256)    0           conv4_block1_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block1_1_conv (Conv2D)    (None, 6, 6, 128)    32768       conv4_block1_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_1_bn (BatchNormali (None, 6, 6, 128)    512         conv4_block1_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_1_relu (Activation (None, 6, 6, 128)    0           conv4_block1_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block1_2_conv (Conv2D)    (None, 6, 6, 32)     36864       conv4_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_concat (Concatenat (None, 6, 6, 288)    0           pool3_pool[0][0]                 \n","                                                                 conv4_block1_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_0_bn (BatchNormali (None, 6, 6, 288)    1152        conv4_block1_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_0_relu (Activation (None, 6, 6, 288)    0           conv4_block2_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block2_1_conv (Conv2D)    (None, 6, 6, 128)    36864       conv4_block2_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_1_bn (BatchNormali (None, 6, 6, 128)    512         conv4_block2_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_1_relu (Activation (None, 6, 6, 128)    0           conv4_block2_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block2_2_conv (Conv2D)    (None, 6, 6, 32)     36864       conv4_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_concat (Concatenat (None, 6, 6, 320)    0           conv4_block1_concat[0][0]        \n","                                                                 conv4_block2_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_0_bn (BatchNormali (None, 6, 6, 320)    1280        conv4_block2_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_0_relu (Activation (None, 6, 6, 320)    0           conv4_block3_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block3_1_conv (Conv2D)    (None, 6, 6, 128)    40960       conv4_block3_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_1_bn (BatchNormali (None, 6, 6, 128)    512         conv4_block3_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_1_relu (Activation (None, 6, 6, 128)    0           conv4_block3_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block3_2_conv (Conv2D)    (None, 6, 6, 32)     36864       conv4_block3_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_concat (Concatenat (None, 6, 6, 352)    0           conv4_block2_concat[0][0]        \n","                                                                 conv4_block3_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_0_bn (BatchNormali (None, 6, 6, 352)    1408        conv4_block3_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_0_relu (Activation (None, 6, 6, 352)    0           conv4_block4_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block4_1_conv (Conv2D)    (None, 6, 6, 128)    45056       conv4_block4_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_1_bn (BatchNormali (None, 6, 6, 128)    512         conv4_block4_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_1_relu (Activation (None, 6, 6, 128)    0           conv4_block4_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block4_2_conv (Conv2D)    (None, 6, 6, 32)     36864       conv4_block4_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_concat (Concatenat (None, 6, 6, 384)    0           conv4_block3_concat[0][0]        \n","                                                                 conv4_block4_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_0_bn (BatchNormali (None, 6, 6, 384)    1536        conv4_block4_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_0_relu (Activation (None, 6, 6, 384)    0           conv4_block5_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block5_1_conv (Conv2D)    (None, 6, 6, 128)    49152       conv4_block5_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_1_bn (BatchNormali (None, 6, 6, 128)    512         conv4_block5_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_1_relu (Activation (None, 6, 6, 128)    0           conv4_block5_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block5_2_conv (Conv2D)    (None, 6, 6, 32)     36864       conv4_block5_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_concat (Concatenat (None, 6, 6, 416)    0           conv4_block4_concat[0][0]        \n","                                                                 conv4_block5_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_0_bn (BatchNormali (None, 6, 6, 416)    1664        conv4_block5_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_0_relu (Activation (None, 6, 6, 416)    0           conv4_block6_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block6_1_conv (Conv2D)    (None, 6, 6, 128)    53248       conv4_block6_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_1_bn (BatchNormali (None, 6, 6, 128)    512         conv4_block6_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_1_relu (Activation (None, 6, 6, 128)    0           conv4_block6_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block6_2_conv (Conv2D)    (None, 6, 6, 32)     36864       conv4_block6_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_concat (Concatenat (None, 6, 6, 448)    0           conv4_block5_concat[0][0]        \n","                                                                 conv4_block6_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block7_0_bn (BatchNormali (None, 6, 6, 448)    1792        conv4_block6_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block7_0_relu (Activation (None, 6, 6, 448)    0           conv4_block7_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block7_1_conv (Conv2D)    (None, 6, 6, 128)    57344       conv4_block7_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block7_1_bn (BatchNormali (None, 6, 6, 128)    512         conv4_block7_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block7_1_relu (Activation (None, 6, 6, 128)    0           conv4_block7_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block7_2_conv (Conv2D)    (None, 6, 6, 32)     36864       conv4_block7_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block7_concat (Concatenat (None, 6, 6, 480)    0           conv4_block6_concat[0][0]        \n","                                                                 conv4_block7_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block8_0_bn (BatchNormali (None, 6, 6, 480)    1920        conv4_block7_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block8_0_relu (Activation (None, 6, 6, 480)    0           conv4_block8_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block8_1_conv (Conv2D)    (None, 6, 6, 128)    61440       conv4_block8_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block8_1_bn (BatchNormali (None, 6, 6, 128)    512         conv4_block8_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block8_1_relu (Activation (None, 6, 6, 128)    0           conv4_block8_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block8_2_conv (Conv2D)    (None, 6, 6, 32)     36864       conv4_block8_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block8_concat (Concatenat (None, 6, 6, 512)    0           conv4_block7_concat[0][0]        \n","                                                                 conv4_block8_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block9_0_bn (BatchNormali (None, 6, 6, 512)    2048        conv4_block8_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block9_0_relu (Activation (None, 6, 6, 512)    0           conv4_block9_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block9_1_conv (Conv2D)    (None, 6, 6, 128)    65536       conv4_block9_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block9_1_bn (BatchNormali (None, 6, 6, 128)    512         conv4_block9_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block9_1_relu (Activation (None, 6, 6, 128)    0           conv4_block9_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block9_2_conv (Conv2D)    (None, 6, 6, 32)     36864       conv4_block9_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block9_concat (Concatenat (None, 6, 6, 544)    0           conv4_block8_concat[0][0]        \n","                                                                 conv4_block9_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block10_0_bn (BatchNormal (None, 6, 6, 544)    2176        conv4_block9_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block10_0_relu (Activatio (None, 6, 6, 544)    0           conv4_block10_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block10_1_conv (Conv2D)   (None, 6, 6, 128)    69632       conv4_block10_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block10_1_bn (BatchNormal (None, 6, 6, 128)    512         conv4_block10_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block10_1_relu (Activatio (None, 6, 6, 128)    0           conv4_block10_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block10_2_conv (Conv2D)   (None, 6, 6, 32)     36864       conv4_block10_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block10_concat (Concatena (None, 6, 6, 576)    0           conv4_block9_concat[0][0]        \n","                                                                 conv4_block10_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block11_0_bn (BatchNormal (None, 6, 6, 576)    2304        conv4_block10_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block11_0_relu (Activatio (None, 6, 6, 576)    0           conv4_block11_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block11_1_conv (Conv2D)   (None, 6, 6, 128)    73728       conv4_block11_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block11_1_bn (BatchNormal (None, 6, 6, 128)    512         conv4_block11_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block11_1_relu (Activatio (None, 6, 6, 128)    0           conv4_block11_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block11_2_conv (Conv2D)   (None, 6, 6, 32)     36864       conv4_block11_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block11_concat (Concatena (None, 6, 6, 608)    0           conv4_block10_concat[0][0]       \n","                                                                 conv4_block11_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block12_0_bn (BatchNormal (None, 6, 6, 608)    2432        conv4_block11_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block12_0_relu (Activatio (None, 6, 6, 608)    0           conv4_block12_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block12_1_conv (Conv2D)   (None, 6, 6, 128)    77824       conv4_block12_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block12_1_bn (BatchNormal (None, 6, 6, 128)    512         conv4_block12_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block12_1_relu (Activatio (None, 6, 6, 128)    0           conv4_block12_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block12_2_conv (Conv2D)   (None, 6, 6, 32)     36864       conv4_block12_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block12_concat (Concatena (None, 6, 6, 640)    0           conv4_block11_concat[0][0]       \n","                                                                 conv4_block12_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block13_0_bn (BatchNormal (None, 6, 6, 640)    2560        conv4_block12_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block13_0_relu (Activatio (None, 6, 6, 640)    0           conv4_block13_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block13_1_conv (Conv2D)   (None, 6, 6, 128)    81920       conv4_block13_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block13_1_bn (BatchNormal (None, 6, 6, 128)    512         conv4_block13_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block13_1_relu (Activatio (None, 6, 6, 128)    0           conv4_block13_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block13_2_conv (Conv2D)   (None, 6, 6, 32)     36864       conv4_block13_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block13_concat (Concatena (None, 6, 6, 672)    0           conv4_block12_concat[0][0]       \n","                                                                 conv4_block13_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block14_0_bn (BatchNormal (None, 6, 6, 672)    2688        conv4_block13_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block14_0_relu (Activatio (None, 6, 6, 672)    0           conv4_block14_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block14_1_conv (Conv2D)   (None, 6, 6, 128)    86016       conv4_block14_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block14_1_bn (BatchNormal (None, 6, 6, 128)    512         conv4_block14_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block14_1_relu (Activatio (None, 6, 6, 128)    0           conv4_block14_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block14_2_conv (Conv2D)   (None, 6, 6, 32)     36864       conv4_block14_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block14_concat (Concatena (None, 6, 6, 704)    0           conv4_block13_concat[0][0]       \n","                                                                 conv4_block14_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block15_0_bn (BatchNormal (None, 6, 6, 704)    2816        conv4_block14_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block15_0_relu (Activatio (None, 6, 6, 704)    0           conv4_block15_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block15_1_conv (Conv2D)   (None, 6, 6, 128)    90112       conv4_block15_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block15_1_bn (BatchNormal (None, 6, 6, 128)    512         conv4_block15_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block15_1_relu (Activatio (None, 6, 6, 128)    0           conv4_block15_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block15_2_conv (Conv2D)   (None, 6, 6, 32)     36864       conv4_block15_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block15_concat (Concatena (None, 6, 6, 736)    0           conv4_block14_concat[0][0]       \n","                                                                 conv4_block15_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block16_0_bn (BatchNormal (None, 6, 6, 736)    2944        conv4_block15_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block16_0_relu (Activatio (None, 6, 6, 736)    0           conv4_block16_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block16_1_conv (Conv2D)   (None, 6, 6, 128)    94208       conv4_block16_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block16_1_bn (BatchNormal (None, 6, 6, 128)    512         conv4_block16_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block16_1_relu (Activatio (None, 6, 6, 128)    0           conv4_block16_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block16_2_conv (Conv2D)   (None, 6, 6, 32)     36864       conv4_block16_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block16_concat (Concatena (None, 6, 6, 768)    0           conv4_block15_concat[0][0]       \n","                                                                 conv4_block16_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block17_0_bn (BatchNormal (None, 6, 6, 768)    3072        conv4_block16_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block17_0_relu (Activatio (None, 6, 6, 768)    0           conv4_block17_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block17_1_conv (Conv2D)   (None, 6, 6, 128)    98304       conv4_block17_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block17_1_bn (BatchNormal (None, 6, 6, 128)    512         conv4_block17_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block17_1_relu (Activatio (None, 6, 6, 128)    0           conv4_block17_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block17_2_conv (Conv2D)   (None, 6, 6, 32)     36864       conv4_block17_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block17_concat (Concatena (None, 6, 6, 800)    0           conv4_block16_concat[0][0]       \n","                                                                 conv4_block17_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block18_0_bn (BatchNormal (None, 6, 6, 800)    3200        conv4_block17_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block18_0_relu (Activatio (None, 6, 6, 800)    0           conv4_block18_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block18_1_conv (Conv2D)   (None, 6, 6, 128)    102400      conv4_block18_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block18_1_bn (BatchNormal (None, 6, 6, 128)    512         conv4_block18_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block18_1_relu (Activatio (None, 6, 6, 128)    0           conv4_block18_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block18_2_conv (Conv2D)   (None, 6, 6, 32)     36864       conv4_block18_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block18_concat (Concatena (None, 6, 6, 832)    0           conv4_block17_concat[0][0]       \n","                                                                 conv4_block18_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block19_0_bn (BatchNormal (None, 6, 6, 832)    3328        conv4_block18_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block19_0_relu (Activatio (None, 6, 6, 832)    0           conv4_block19_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block19_1_conv (Conv2D)   (None, 6, 6, 128)    106496      conv4_block19_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block19_1_bn (BatchNormal (None, 6, 6, 128)    512         conv4_block19_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block19_1_relu (Activatio (None, 6, 6, 128)    0           conv4_block19_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block19_2_conv (Conv2D)   (None, 6, 6, 32)     36864       conv4_block19_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block19_concat (Concatena (None, 6, 6, 864)    0           conv4_block18_concat[0][0]       \n","                                                                 conv4_block19_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block20_0_bn (BatchNormal (None, 6, 6, 864)    3456        conv4_block19_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block20_0_relu (Activatio (None, 6, 6, 864)    0           conv4_block20_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block20_1_conv (Conv2D)   (None, 6, 6, 128)    110592      conv4_block20_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block20_1_bn (BatchNormal (None, 6, 6, 128)    512         conv4_block20_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block20_1_relu (Activatio (None, 6, 6, 128)    0           conv4_block20_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block20_2_conv (Conv2D)   (None, 6, 6, 32)     36864       conv4_block20_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block20_concat (Concatena (None, 6, 6, 896)    0           conv4_block19_concat[0][0]       \n","                                                                 conv4_block20_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block21_0_bn (BatchNormal (None, 6, 6, 896)    3584        conv4_block20_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block21_0_relu (Activatio (None, 6, 6, 896)    0           conv4_block21_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block21_1_conv (Conv2D)   (None, 6, 6, 128)    114688      conv4_block21_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block21_1_bn (BatchNormal (None, 6, 6, 128)    512         conv4_block21_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block21_1_relu (Activatio (None, 6, 6, 128)    0           conv4_block21_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block21_2_conv (Conv2D)   (None, 6, 6, 32)     36864       conv4_block21_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block21_concat (Concatena (None, 6, 6, 928)    0           conv4_block20_concat[0][0]       \n","                                                                 conv4_block21_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block22_0_bn (BatchNormal (None, 6, 6, 928)    3712        conv4_block21_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block22_0_relu (Activatio (None, 6, 6, 928)    0           conv4_block22_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block22_1_conv (Conv2D)   (None, 6, 6, 128)    118784      conv4_block22_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block22_1_bn (BatchNormal (None, 6, 6, 128)    512         conv4_block22_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block22_1_relu (Activatio (None, 6, 6, 128)    0           conv4_block22_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block22_2_conv (Conv2D)   (None, 6, 6, 32)     36864       conv4_block22_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block22_concat (Concatena (None, 6, 6, 960)    0           conv4_block21_concat[0][0]       \n","                                                                 conv4_block22_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block23_0_bn (BatchNormal (None, 6, 6, 960)    3840        conv4_block22_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block23_0_relu (Activatio (None, 6, 6, 960)    0           conv4_block23_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block23_1_conv (Conv2D)   (None, 6, 6, 128)    122880      conv4_block23_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block23_1_bn (BatchNormal (None, 6, 6, 128)    512         conv4_block23_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block23_1_relu (Activatio (None, 6, 6, 128)    0           conv4_block23_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block23_2_conv (Conv2D)   (None, 6, 6, 32)     36864       conv4_block23_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block23_concat (Concatena (None, 6, 6, 992)    0           conv4_block22_concat[0][0]       \n","                                                                 conv4_block23_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block24_0_bn (BatchNormal (None, 6, 6, 992)    3968        conv4_block23_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block24_0_relu (Activatio (None, 6, 6, 992)    0           conv4_block24_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block24_1_conv (Conv2D)   (None, 6, 6, 128)    126976      conv4_block24_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block24_1_bn (BatchNormal (None, 6, 6, 128)    512         conv4_block24_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block24_1_relu (Activatio (None, 6, 6, 128)    0           conv4_block24_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block24_2_conv (Conv2D)   (None, 6, 6, 32)     36864       conv4_block24_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block24_concat (Concatena (None, 6, 6, 1024)   0           conv4_block23_concat[0][0]       \n","                                                                 conv4_block24_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","pool4_bn (BatchNormalization)   (None, 6, 6, 1024)   4096        conv4_block24_concat[0][0]       \n","__________________________________________________________________________________________________\n","pool4_relu (Activation)         (None, 6, 6, 1024)   0           pool4_bn[0][0]                   \n","__________________________________________________________________________________________________\n","pool4_conv (Conv2D)             (None, 6, 6, 512)    524288      pool4_relu[0][0]                 \n","__________________________________________________________________________________________________\n","pool4_pool (AveragePooling2D)   (None, 3, 3, 512)    0           pool4_conv[0][0]                 \n","__________________________________________________________________________________________________\n","conv5_block1_0_bn (BatchNormali (None, 3, 3, 512)    2048        pool4_pool[0][0]                 \n","__________________________________________________________________________________________________\n","conv5_block1_0_relu (Activation (None, 3, 3, 512)    0           conv5_block1_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block1_1_conv (Conv2D)    (None, 3, 3, 128)    65536       conv5_block1_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block1_1_bn (BatchNormali (None, 3, 3, 128)    512         conv5_block1_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block1_1_relu (Activation (None, 3, 3, 128)    0           conv5_block1_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block1_2_conv (Conv2D)    (None, 3, 3, 32)     36864       conv5_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block1_concat (Concatenat (None, 3, 3, 544)    0           pool4_pool[0][0]                 \n","                                                                 conv5_block1_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block2_0_bn (BatchNormali (None, 3, 3, 544)    2176        conv5_block1_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block2_0_relu (Activation (None, 3, 3, 544)    0           conv5_block2_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block2_1_conv (Conv2D)    (None, 3, 3, 128)    69632       conv5_block2_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block2_1_bn (BatchNormali (None, 3, 3, 128)    512         conv5_block2_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block2_1_relu (Activation (None, 3, 3, 128)    0           conv5_block2_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block2_2_conv (Conv2D)    (None, 3, 3, 32)     36864       conv5_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block2_concat (Concatenat (None, 3, 3, 576)    0           conv5_block1_concat[0][0]        \n","                                                                 conv5_block2_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block3_0_bn (BatchNormali (None, 3, 3, 576)    2304        conv5_block2_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block3_0_relu (Activation (None, 3, 3, 576)    0           conv5_block3_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block3_1_conv (Conv2D)    (None, 3, 3, 128)    73728       conv5_block3_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block3_1_bn (BatchNormali (None, 3, 3, 128)    512         conv5_block3_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block3_1_relu (Activation (None, 3, 3, 128)    0           conv5_block3_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block3_2_conv (Conv2D)    (None, 3, 3, 32)     36864       conv5_block3_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block3_concat (Concatenat (None, 3, 3, 608)    0           conv5_block2_concat[0][0]        \n","                                                                 conv5_block3_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block4_0_bn (BatchNormali (None, 3, 3, 608)    2432        conv5_block3_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block4_0_relu (Activation (None, 3, 3, 608)    0           conv5_block4_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block4_1_conv (Conv2D)    (None, 3, 3, 128)    77824       conv5_block4_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block4_1_bn (BatchNormali (None, 3, 3, 128)    512         conv5_block4_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block4_1_relu (Activation (None, 3, 3, 128)    0           conv5_block4_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block4_2_conv (Conv2D)    (None, 3, 3, 32)     36864       conv5_block4_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block4_concat (Concatenat (None, 3, 3, 640)    0           conv5_block3_concat[0][0]        \n","                                                                 conv5_block4_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block5_0_bn (BatchNormali (None, 3, 3, 640)    2560        conv5_block4_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block5_0_relu (Activation (None, 3, 3, 640)    0           conv5_block5_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block5_1_conv (Conv2D)    (None, 3, 3, 128)    81920       conv5_block5_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block5_1_bn (BatchNormali (None, 3, 3, 128)    512         conv5_block5_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block5_1_relu (Activation (None, 3, 3, 128)    0           conv5_block5_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block5_2_conv (Conv2D)    (None, 3, 3, 32)     36864       conv5_block5_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block5_concat (Concatenat (None, 3, 3, 672)    0           conv5_block4_concat[0][0]        \n","                                                                 conv5_block5_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block6_0_bn (BatchNormali (None, 3, 3, 672)    2688        conv5_block5_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block6_0_relu (Activation (None, 3, 3, 672)    0           conv5_block6_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block6_1_conv (Conv2D)    (None, 3, 3, 128)    86016       conv5_block6_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block6_1_bn (BatchNormali (None, 3, 3, 128)    512         conv5_block6_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block6_1_relu (Activation (None, 3, 3, 128)    0           conv5_block6_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block6_2_conv (Conv2D)    (None, 3, 3, 32)     36864       conv5_block6_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block6_concat (Concatenat (None, 3, 3, 704)    0           conv5_block5_concat[0][0]        \n","                                                                 conv5_block6_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block7_0_bn (BatchNormali (None, 3, 3, 704)    2816        conv5_block6_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block7_0_relu (Activation (None, 3, 3, 704)    0           conv5_block7_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block7_1_conv (Conv2D)    (None, 3, 3, 128)    90112       conv5_block7_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block7_1_bn (BatchNormali (None, 3, 3, 128)    512         conv5_block7_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block7_1_relu (Activation (None, 3, 3, 128)    0           conv5_block7_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block7_2_conv (Conv2D)    (None, 3, 3, 32)     36864       conv5_block7_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block7_concat (Concatenat (None, 3, 3, 736)    0           conv5_block6_concat[0][0]        \n","                                                                 conv5_block7_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block8_0_bn (BatchNormali (None, 3, 3, 736)    2944        conv5_block7_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block8_0_relu (Activation (None, 3, 3, 736)    0           conv5_block8_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block8_1_conv (Conv2D)    (None, 3, 3, 128)    94208       conv5_block8_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block8_1_bn (BatchNormali (None, 3, 3, 128)    512         conv5_block8_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block8_1_relu (Activation (None, 3, 3, 128)    0           conv5_block8_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block8_2_conv (Conv2D)    (None, 3, 3, 32)     36864       conv5_block8_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block8_concat (Concatenat (None, 3, 3, 768)    0           conv5_block7_concat[0][0]        \n","                                                                 conv5_block8_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block9_0_bn (BatchNormali (None, 3, 3, 768)    3072        conv5_block8_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block9_0_relu (Activation (None, 3, 3, 768)    0           conv5_block9_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block9_1_conv (Conv2D)    (None, 3, 3, 128)    98304       conv5_block9_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block9_1_bn (BatchNormali (None, 3, 3, 128)    512         conv5_block9_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block9_1_relu (Activation (None, 3, 3, 128)    0           conv5_block9_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block9_2_conv (Conv2D)    (None, 3, 3, 32)     36864       conv5_block9_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block9_concat (Concatenat (None, 3, 3, 800)    0           conv5_block8_concat[0][0]        \n","                                                                 conv5_block9_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block10_0_bn (BatchNormal (None, 3, 3, 800)    3200        conv5_block9_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block10_0_relu (Activatio (None, 3, 3, 800)    0           conv5_block10_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv5_block10_1_conv (Conv2D)   (None, 3, 3, 128)    102400      conv5_block10_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block10_1_bn (BatchNormal (None, 3, 3, 128)    512         conv5_block10_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block10_1_relu (Activatio (None, 3, 3, 128)    0           conv5_block10_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv5_block10_2_conv (Conv2D)   (None, 3, 3, 32)     36864       conv5_block10_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block10_concat (Concatena (None, 3, 3, 832)    0           conv5_block9_concat[0][0]        \n","                                                                 conv5_block10_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block11_0_bn (BatchNormal (None, 3, 3, 832)    3328        conv5_block10_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block11_0_relu (Activatio (None, 3, 3, 832)    0           conv5_block11_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv5_block11_1_conv (Conv2D)   (None, 3, 3, 128)    106496      conv5_block11_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block11_1_bn (BatchNormal (None, 3, 3, 128)    512         conv5_block11_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block11_1_relu (Activatio (None, 3, 3, 128)    0           conv5_block11_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv5_block11_2_conv (Conv2D)   (None, 3, 3, 32)     36864       conv5_block11_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block11_concat (Concatena (None, 3, 3, 864)    0           conv5_block10_concat[0][0]       \n","                                                                 conv5_block11_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block12_0_bn (BatchNormal (None, 3, 3, 864)    3456        conv5_block11_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block12_0_relu (Activatio (None, 3, 3, 864)    0           conv5_block12_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv5_block12_1_conv (Conv2D)   (None, 3, 3, 128)    110592      conv5_block12_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block12_1_bn (BatchNormal (None, 3, 3, 128)    512         conv5_block12_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block12_1_relu (Activatio (None, 3, 3, 128)    0           conv5_block12_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv5_block12_2_conv (Conv2D)   (None, 3, 3, 32)     36864       conv5_block12_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block12_concat (Concatena (None, 3, 3, 896)    0           conv5_block11_concat[0][0]       \n","                                                                 conv5_block12_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block13_0_bn (BatchNormal (None, 3, 3, 896)    3584        conv5_block12_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block13_0_relu (Activatio (None, 3, 3, 896)    0           conv5_block13_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv5_block13_1_conv (Conv2D)   (None, 3, 3, 128)    114688      conv5_block13_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block13_1_bn (BatchNormal (None, 3, 3, 128)    512         conv5_block13_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block13_1_relu (Activatio (None, 3, 3, 128)    0           conv5_block13_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv5_block13_2_conv (Conv2D)   (None, 3, 3, 32)     36864       conv5_block13_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block13_concat (Concatena (None, 3, 3, 928)    0           conv5_block12_concat[0][0]       \n","                                                                 conv5_block13_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block14_0_bn (BatchNormal (None, 3, 3, 928)    3712        conv5_block13_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block14_0_relu (Activatio (None, 3, 3, 928)    0           conv5_block14_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv5_block14_1_conv (Conv2D)   (None, 3, 3, 128)    118784      conv5_block14_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block14_1_bn (BatchNormal (None, 3, 3, 128)    512         conv5_block14_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block14_1_relu (Activatio (None, 3, 3, 128)    0           conv5_block14_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv5_block14_2_conv (Conv2D)   (None, 3, 3, 32)     36864       conv5_block14_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block14_concat (Concatena (None, 3, 3, 960)    0           conv5_block13_concat[0][0]       \n","                                                                 conv5_block14_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block15_0_bn (BatchNormal (None, 3, 3, 960)    3840        conv5_block14_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block15_0_relu (Activatio (None, 3, 3, 960)    0           conv5_block15_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv5_block15_1_conv (Conv2D)   (None, 3, 3, 128)    122880      conv5_block15_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block15_1_bn (BatchNormal (None, 3, 3, 128)    512         conv5_block15_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block15_1_relu (Activatio (None, 3, 3, 128)    0           conv5_block15_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv5_block15_2_conv (Conv2D)   (None, 3, 3, 32)     36864       conv5_block15_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block15_concat (Concatena (None, 3, 3, 992)    0           conv5_block14_concat[0][0]       \n","                                                                 conv5_block15_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block16_0_bn (BatchNormal (None, 3, 3, 992)    3968        conv5_block15_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block16_0_relu (Activatio (None, 3, 3, 992)    0           conv5_block16_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv5_block16_1_conv (Conv2D)   (None, 3, 3, 128)    126976      conv5_block16_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block16_1_bn (BatchNormal (None, 3, 3, 128)    512         conv5_block16_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block16_1_relu (Activatio (None, 3, 3, 128)    0           conv5_block16_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv5_block16_2_conv (Conv2D)   (None, 3, 3, 32)     36864       conv5_block16_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block16_concat (Concatena (None, 3, 3, 1024)   0           conv5_block15_concat[0][0]       \n","                                                                 conv5_block16_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","bn (BatchNormalization)         (None, 3, 3, 1024)   4096        conv5_block16_concat[0][0]       \n","__________________________________________________________________________________________________\n","relu (Activation)               (None, 3, 3, 1024)   0           bn[0][0]                         \n","==================================================================================================\n","Total params: 7,037,504\n","Trainable params: 497,024\n","Non-trainable params: 6,540,480\n","__________________________________________________________________________________________________\n","Model: \"DenseNet121_ADModel\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","tensor (InputLayer)          [(None, 100, 100, 3)]     0         \n","_________________________________________________________________\n","densenet121 (Functional)     (None, 3, 3, 1024)        7037504   \n","_________________________________________________________________\n","flatten (Flatten)            (None, 9216)              0         \n","_________________________________________________________________\n","dropout (Dropout)            (None, 9216)              0         \n","_________________________________________________________________\n","dense (Dense)                (None, 32)                294944    \n","_________________________________________________________________\n","batch_normalization (BatchNo (None, 32)                128       \n","_________________________________________________________________\n","leaky_re_lu (LeakyReLU)      (None, 32)                0         \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 32)                0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 4)                 132       \n","=================================================================\n","Total params: 7,332,708\n","Trainable params: 792,164\n","Non-trainable params: 6,540,544\n","_________________________________________________________________\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fe96e133c50>"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yeQw5zEUg8Cw","outputId":"15764c25-a1a0-414b-dc3e-dcf4e7493b10"},"source":["''' NSL model training '''\n","callback_checkpoints = tf.keras.callbacks.ModelCheckpoint(filepath=params.checkpoint_path, monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=True, mode='max',\n","                                                          save_freq='epoch',options=None)\n","\n","callback_earlystop = AccEarlyStop(val_acc_base=params.early_stop_base_line)\n","graph_reg_history = graph_reg_model.fit(train_image_dataset, \n","                                        validation_data=test_image_dataset,\n","                                        callbacks = [callback_checkpoints, callback_earlystop],\n","                                        epochs=params.train_epoch,\n","                                        verbose=1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/50\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py:595: UserWarning: Input dict contained keys ['id'] which did not match any model input. They will be ignored by the model.\n","  [n for n in tensors.keys() if n not in ref_input_names])\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/GraphRegularization/graph_loss/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/GraphRegularization/graph_loss/Reshape:0\", shape=(None, 4), dtype=float32), dense_shape=Tensor(\"gradient_tape/GraphRegularization/graph_loss/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"shape. This may consume a large amount of memory.\" % value)\n"],"name":"stderr"},{"output_type":"stream","text":["160/160 [==============================] - 296s 2s/step - loss: 0.0068 - accuracy: 0.9980 - auc: 1.0000 - f1_score: 0.9980 - scaled_graph_loss: 1.6752e-07 - val_loss: 2.4455 - val_accuracy: 0.6904 - val_auc: 0.8527 - val_f1_score: 0.9642\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.69038, saving model to /content/drive/MyDrive/AD Expriment II/DenseNet_model_checkpoints/densenet_nsl_weights\n","Epoch 2/50\n","160/160 [==============================] - 252s 2s/step - loss: 0.0103 - accuracy: 0.9970 - auc: 0.9999 - f1_score: 0.9969 - scaled_graph_loss: 2.4588e-07 - val_loss: 2.0046 - val_accuracy: 0.7170 - val_auc: 0.8742 - val_f1_score: 0.7173\n","\n","Epoch 00002: val_accuracy improved from 0.69038 to 0.71697, saving model to /content/drive/MyDrive/AD Expriment II/DenseNet_model_checkpoints/densenet_nsl_weights\n","Epoch 3/50\n","160/160 [==============================] - 252s 2s/step - loss: 0.0112 - accuracy: 0.9967 - auc: 0.9998 - f1_score: 0.9967 - scaled_graph_loss: 2.3518e-07 - val_loss: 2.8941 - val_accuracy: 0.6466 - val_auc: 0.8271 - val_f1_score: 0.6474\n","\n","Epoch 00003: val_accuracy did not improve from 0.71697\n","Epoch 4/50\n","160/160 [==============================] - 252s 2s/step - loss: 0.0283 - accuracy: 0.9896 - auc: 0.9997 - f1_score: 0.9895 - scaled_graph_loss: 7.1620e-07 - val_loss: 1.9973 - val_accuracy: 0.7091 - val_auc: 0.8692 - val_f1_score: 0.7093\n","\n","Epoch 00004: val_accuracy did not improve from 0.71697\n","Epoch 5/50\n","160/160 [==============================] - 252s 2s/step - loss: 0.0163 - accuracy: 0.9946 - auc: 0.9999 - f1_score: 0.9948 - scaled_graph_loss: 3.5643e-07 - val_loss: 2.4048 - val_accuracy: 0.6951 - val_auc: 0.8533 - val_f1_score: 0.6946\n","\n","Epoch 00005: val_accuracy did not improve from 0.71697\n","Epoch 6/50\n","160/160 [==============================] - 252s 2s/step - loss: 0.0064 - accuracy: 0.9977 - auc: 1.0000 - f1_score: 0.9979 - scaled_graph_loss: 1.8525e-07 - val_loss: 2.5621 - val_accuracy: 0.7005 - val_auc: 0.8511 - val_f1_score: 0.7016\n","\n","Epoch 00006: val_accuracy did not improve from 0.71697\n","Epoch 7/50\n","160/160 [==============================] - 252s 2s/step - loss: 0.0079 - accuracy: 0.9972 - auc: 1.0000 - f1_score: 0.9974 - scaled_graph_loss: 1.8546e-07 - val_loss: 1.9843 - val_accuracy: 0.7232 - val_auc: 0.8770 - val_f1_score: 0.7218\n","\n","Epoch 00007: val_accuracy improved from 0.71697 to 0.72322, saving model to /content/drive/MyDrive/AD Expriment II/DenseNet_model_checkpoints/densenet_nsl_weights\n","Epoch 8/50\n","160/160 [==============================] - 252s 2s/step - loss: 0.0090 - accuracy: 0.9967 - auc: 1.0000 - f1_score: 0.9967 - scaled_graph_loss: 2.0750e-07 - val_loss: 3.2222 - val_accuracy: 0.6466 - val_auc: 0.8197 - val_f1_score: 0.6463\n","\n","Epoch 00008: val_accuracy did not improve from 0.72322\n","Epoch 9/50\n","160/160 [==============================] - 253s 2s/step - loss: 0.0078 - accuracy: 0.9973 - auc: 1.0000 - f1_score: 0.9973 - scaled_graph_loss: 2.1762e-07 - val_loss: 3.8934 - val_accuracy: 0.6005 - val_auc: 0.7854 - val_f1_score: 0.6002\n","\n","Epoch 00009: val_accuracy did not improve from 0.72322\n","Epoch 10/50\n","160/160 [==============================] - 252s 2s/step - loss: 0.0219 - accuracy: 0.9917 - auc: 0.9997 - f1_score: 0.9917 - scaled_graph_loss: 4.8710e-07 - val_loss: 2.5286 - val_accuracy: 0.6771 - val_auc: 0.8495 - val_f1_score: 0.6776\n","\n","Epoch 00010: val_accuracy did not improve from 0.72322\n","Epoch 11/50\n","160/160 [==============================] - 251s 2s/step - loss: 0.0113 - accuracy: 0.9956 - auc: 1.0000 - f1_score: 0.9954 - scaled_graph_loss: 2.7508e-07 - val_loss: 1.8409 - val_accuracy: 0.7076 - val_auc: 0.8778 - val_f1_score: 0.7067\n","\n","Epoch 00011: val_accuracy did not improve from 0.72322\n","Epoch 12/50\n","160/160 [==============================] - 250s 2s/step - loss: 0.0111 - accuracy: 0.9966 - auc: 0.9999 - f1_score: 0.9963 - scaled_graph_loss: 2.4966e-07 - val_loss: 2.3015 - val_accuracy: 0.6857 - val_auc: 0.8560 - val_f1_score: 0.6849\n","\n","Epoch 00012: val_accuracy did not improve from 0.72322\n","Epoch 13/50\n","160/160 [==============================] - 251s 2s/step - loss: 0.0233 - accuracy: 0.9919 - auc: 0.9997 - f1_score: 0.9919 - scaled_graph_loss: 5.6430e-07 - val_loss: 2.7023 - val_accuracy: 0.6654 - val_auc: 0.8374 - val_f1_score: 0.6638\n","\n","Epoch 00013: val_accuracy did not improve from 0.72322\n","Epoch 14/50\n","160/160 [==============================] - 251s 2s/step - loss: 0.0185 - accuracy: 0.9939 - auc: 0.9997 - f1_score: 0.9943 - scaled_graph_loss: 4.1453e-07 - val_loss: 2.0864 - val_accuracy: 0.7076 - val_auc: 0.8644 - val_f1_score: 0.7065\n","\n","Epoch 00014: val_accuracy did not improve from 0.72322\n","Epoch 15/50\n","160/160 [==============================] - 251s 2s/step - loss: 0.0111 - accuracy: 0.9968 - auc: 1.0000 - f1_score: 0.9968 - scaled_graph_loss: 2.6341e-07 - val_loss: 2.7121 - val_accuracy: 0.6458 - val_auc: 0.8411 - val_f1_score: 0.6432\n","\n","Epoch 00015: val_accuracy did not improve from 0.72322\n","Epoch 16/50\n","160/160 [==============================] - 251s 2s/step - loss: 0.0293 - accuracy: 0.9907 - auc: 0.9991 - f1_score: 0.9907 - scaled_graph_loss: 6.3656e-07 - val_loss: 3.1398 - val_accuracy: 0.5950 - val_auc: 0.7973 - val_f1_score: 0.5957\n","\n","Epoch 00016: val_accuracy did not improve from 0.72322\n","Epoch 17/50\n","160/160 [==============================] - 251s 2s/step - loss: 0.0175 - accuracy: 0.9938 - auc: 0.9998 - f1_score: 0.9937 - scaled_graph_loss: 3.7947e-07 - val_loss: 2.1039 - val_accuracy: 0.7029 - val_auc: 0.8704 - val_f1_score: 0.7019\n","\n","Epoch 00017: val_accuracy did not improve from 0.72322\n","Epoch 18/50\n","160/160 [==============================] - 251s 2s/step - loss: 0.0147 - accuracy: 0.9954 - auc: 0.9999 - f1_score: 0.9953 - scaled_graph_loss: 3.2141e-07 - val_loss: 2.8347 - val_accuracy: 0.6443 - val_auc: 0.8289 - val_f1_score: 0.6448\n","\n","Epoch 00018: val_accuracy did not improve from 0.72322\n","Epoch 19/50\n","160/160 [==============================] - 251s 2s/step - loss: 0.0069 - accuracy: 0.9978 - auc: 1.0000 - f1_score: 0.9978 - scaled_graph_loss: 2.0695e-07 - val_loss: 2.3198 - val_accuracy: 0.7115 - val_auc: 0.8592 - val_f1_score: 0.7109\n","\n","Epoch 00019: val_accuracy did not improve from 0.72322\n","Epoch 20/50\n","135/160 [========================>.....] - ETA: 38s - loss: 0.0038 - accuracy: 0.9988 - auc: 1.0000 - f1_score: 0.9989 - scaled_graph_loss: 8.4310e-08"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HqUg5ceng8E6","executionInfo":{"status":"ok","timestamp":1618851714725,"user_tz":240,"elapsed":3896,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"7f018f21-637e-4dff-e87c-a7726dde8c27"},"source":["'''evalute the test model'''\n","graph_reg_model.evaluate(test_image_dataset)"],"execution_count":12,"outputs":[{"output_type":"stream","text":["20/20 [==============================] - 3s 111ms/step - loss: 1.8784 - accuracy: 0.7193 - auc: 0.8743 - f1_score: 0.7188\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[1.8783780336380005,\n"," 0.7193119525909424,\n"," 0.8742884993553162,\n"," 0.7188110947608948]"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"8IbO8pXDHuoS","executionInfo":{"status":"ok","timestamp":1618851715650,"user_tz":240,"elapsed":4816,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}}},"source":["'''plot confusion mat & calc acc for each label'''\n","test_image_dataset = NSLDataFormat.generate_test_tfr_image_tensor(path_list=test_tfr_list, \n","                                                                  batch_size=4000, \n","                                                                  size=(100,100),\n","                                                                  channels=3,\n","                                                                  shuffle=True)\n","data, data_label = iter(test_image_dataset).get_next()\n","data = data[\"tensor\"]"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":396},"id":"PYyy-pklHOzU","executionInfo":{"status":"ok","timestamp":1618851722869,"user_tz":240,"elapsed":12028,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"8e6470fc-dc1d-4497-a636-1a824336631f"},"source":["ADModelBuilder.plot_confusion_mat(graph_reg_model, data, data_label, title=\"DenseNet121_NSL\")"],"execution_count":14,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x432 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"qQY3nmxy2Va6"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0GWdE1gQKqpF"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KLUpQmqlt3GW"},"source":["#4.Xception & Xception-NSL Model Training"]},{"cell_type":"code","metadata":{"id":"5axk1eIwD6qw"},"source":["'''define hyper params'''\n","params = AD_params()\n","params.max_seed_nbr=5\n","params.batch_size=128\n","params.image_channels =3\n","params.image_size =(100,100)\n","params.ad_base_model_input_shape=(100,100,3)\n","params.graph_path= f'{root_path}AD_graph_aae_kmeans.tsv'\n","params.test_tfr_path =  f'{root_path}test_data.tfr'\n","params.train_tfr_path = f'{root_path}train_data.tfr'\n","\n","'''parse train_data.tfr to train image dataset with batch_size at 128'''\n","train_image_dataset = NSLDataFormat.parse_tfr_to_dataset(file_path_list=[params.train_tfr_path],\n","                                                         batch_size=params.batch_size,\n","                                                         max_neighbor_number=params.max_seed_nbr,\n","                                                         image_size=params.image_size,\n","                                                         image_channels=params.image_channels,\n","                                                         shuffle=True)\n","\n","'''load test data with batch_size at 128 '''\n","test_image_dataset = NSLDataFormat.generate_test_tfr_image_tensor(path_list=tfr_list_test, \n","                                                                  batch_size=params.batch_size, \n","                                                                  size=params.image_size,\n","                                                                  channels=params.image_channels,\n","                                                                  shuffle=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VJqIRkiQ81qg"},"source":["##5.1 Xception Base Model Training\n","### val_acc: 0.901, val_auc: 0.987, val_f1_score: 0.897"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wj2Ei0L1Za0O","executionInfo":{"status":"ok","timestamp":1606257359432,"user_tz":300,"elapsed":7830,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"a70fea5f-21fc-4bf0-f85c-57eaf96c10ac"},"source":["'''define params'''\n","params.learning_rate=0.001\n","params.checkpoint_restore_path='/content/drive/My Drive/Projects/codes/Xception_model_checkpoints/xception_model_new_90'\n","params.checkpoint_path='/content/drive/My Drive/Projects/codes/Xception_model_checkpoints/xception_model_new_90'\n","params.early_stop_base_line=0.90\n","params.train_epoch=50\n","\n","'''build base_model and restore from the last training'''\n","base_model = ADModelBuilder(input_shape=params.ad_base_model_input_shape, base_model='xception').get_ADModel()\n","base_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=params.learning_rate, amsgrad=True), \n","                   loss=tf.losses.CategoricalCrossentropy(), \n","                   metrics=['accuracy', 'AUC',tfa.metrics.F1Score(num_classes=4, average=\"micro\", threshold = 0.5)])\n","base_model.load_weights(params.checkpoint_restore_path)\n","'''set up check point & early stopping'''\n","callback_checkpints = tf.keras.callbacks.ModelCheckpoint(filepath= params.checkpoint_path, monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=True, mode='max',\n","                                                         save_freq='epoch',options=None)\n","callback_earlystop = AccEarlyStop(val_acc_base=params.early_stop_base_line)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Note: default Xception not includes top and has imagenet weights. It is not a trainable model in ADModelBuilder. Please setup trainable layers in setup_Xception function based on the \"Layer Number\"\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n","WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n","Model: \"Xception_ADModel\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","tensor (InputLayer)          [(None, 100, 100, 3)]     0         \n","_________________________________________________________________\n","xception (Functional)        (None, 3, 3, 2048)        20861480  \n","_________________________________________________________________\n","flatten_4 (Flatten)          (None, 18432)             0         \n","_________________________________________________________________\n","dropout_7 (Dropout)          (None, 18432)             0         \n","_________________________________________________________________\n","dense_8 (Dense)              (None, 128)               2359424   \n","_________________________________________________________________\n","batch_normalization_12 (Batc (None, 128)               512       \n","_________________________________________________________________\n","leaky_re_lu_4 (LeakyReLU)    (None, 128)               0         \n","_________________________________________________________________\n","dropout_8 (Dropout)          (None, 128)               0         \n","_________________________________________________________________\n","dense_9 (Dense)              (None, 4)                 516       \n","=================================================================\n","Total params: 23,221,932\n","Trainable params: 2,360,196\n","Non-trainable params: 20,861,736\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jeuKRP8dCAAZ","executionInfo":{"status":"ok","timestamp":1606055078068,"user_tz":300,"elapsed":572218,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"141d59d3-24df-489f-b69d-addea2f5e912"},"source":["'''train base model'''\n","history = base_model.fit(train_image_dataset,\n","                         validation_data= test_image_dataset,\n","                         callbacks = [callback_checkpints, callback_earlystop],\n","                         epochs=params.train_epoch,\n","                         verbose=1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Note: default Xception not includes top and has imagenet weights. It is not a trainable model in ADModelBuilder. Please setup trainable layers in setup_Xception function based on the \"Layer Number\"\n","Model: \"Xception_ADModel\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","tensor (InputLayer)          [(None, 100, 100, 3)]     0         \n","_________________________________________________________________\n","xception (Functional)        (None, 3, 3, 2048)        20861480  \n","_________________________________________________________________\n","flatten_1 (Flatten)          (None, 18432)             0         \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 18432)             0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 128)               2359424   \n","_________________________________________________________________\n","batch_normalization_9 (Batch (None, 128)               512       \n","_________________________________________________________________\n","leaky_re_lu_1 (LeakyReLU)    (None, 128)               0         \n","_________________________________________________________________\n","dropout_3 (Dropout)          (None, 128)               0         \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 4)                 516       \n","=================================================================\n","Total params: 23,221,932\n","Trainable params: 2,360,196\n","Non-trainable params: 20,861,736\n","_________________________________________________________________\n","Epoch 1/50\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py:543: UserWarning: Input dict contained keys ['NL_nbr_0_id', 'NL_nbr_0_tensor', 'NL_nbr_0_weight', 'NL_nbr_1_id', 'NL_nbr_1_tensor', 'NL_nbr_1_weight', 'NL_nbr_2_id', 'NL_nbr_2_tensor', 'NL_nbr_2_weight', 'NL_nbr_3_id', 'NL_nbr_3_tensor', 'NL_nbr_3_weight', 'NL_nbr_4_id', 'NL_nbr_4_tensor', 'NL_nbr_4_weight', 'id'] which did not match any model input. They will be ignored by the model.\n","  [n for n in tensors.keys() if n not in ref_input_names])\n"],"name":"stderr"},{"output_type":"stream","text":["     69/Unknown - 19s 277ms/step - loss: 0.9846 - accuracy: 0.5874 - auc: 0.8402 - f1_score: 0.5660"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py:543: UserWarning: Input dict contained keys ['id'] which did not match any model input. They will be ignored by the model.\n","  [n for n in tensors.keys() if n not in ref_input_names])\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Epoch 00001: val_accuracy improved from -inf to 0.64368, saving model to /content/drive/My Drive/Projects/codes/Xception_model_checkpoints/xception_model_new_90\n","69/69 [==============================] - 29s 417ms/step - loss: 0.9846 - accuracy: 0.5874 - auc: 0.8402 - f1_score: 0.5660 - val_loss: 0.8324 - val_accuracy: 0.6437 - val_auc: 0.8853 - val_f1_score: 0.6391\n","Epoch 2/50\n","69/69 [==============================] - ETA: 0s - loss: 0.7263 - accuracy: 0.6768 - auc: 0.9057 - f1_score: 0.6621\n","Epoch 00002: val_accuracy improved from 0.64368 to 0.69279, saving model to /content/drive/My Drive/Projects/codes/Xception_model_checkpoints/xception_model_new_90\n","69/69 [==============================] - 24s 342ms/step - loss: 0.7263 - accuracy: 0.6768 - auc: 0.9057 - f1_score: 0.6621 - val_loss: 0.6742 - val_accuracy: 0.6928 - val_auc: 0.9195 - val_f1_score: 0.6863\n","Epoch 3/50\n","69/69 [==============================] - ETA: 0s - loss: 0.6480 - accuracy: 0.7086 - auc: 0.9240 - f1_score: 0.6999\n","Epoch 00003: val_accuracy improved from 0.69279 to 0.72309, saving model to /content/drive/My Drive/Projects/codes/Xception_model_checkpoints/xception_model_new_90\n","69/69 [==============================] - 23s 328ms/step - loss: 0.6480 - accuracy: 0.7086 - auc: 0.9240 - f1_score: 0.6999 - val_loss: 0.5882 - val_accuracy: 0.7231 - val_auc: 0.9372 - val_f1_score: 0.7164\n","Epoch 4/50\n","69/69 [==============================] - ETA: 0s - loss: 0.5891 - accuracy: 0.7445 - auc: 0.9373 - f1_score: 0.7311\n","Epoch 00004: val_accuracy did not improve from 0.72309\n","69/69 [==============================] - 22s 320ms/step - loss: 0.5891 - accuracy: 0.7445 - auc: 0.9373 - f1_score: 0.7311 - val_loss: 0.6143 - val_accuracy: 0.7129 - val_auc: 0.9354 - val_f1_score: 0.7178\n","Epoch 5/50\n","69/69 [==============================] - ETA: 0s - loss: 0.5568 - accuracy: 0.7532 - auc: 0.9438 - f1_score: 0.7480\n","Epoch 00005: val_accuracy improved from 0.72309 to 0.77717, saving model to /content/drive/My Drive/Projects/codes/Xception_model_checkpoints/xception_model_new_90\n","69/69 [==============================] - 23s 332ms/step - loss: 0.5568 - accuracy: 0.7532 - auc: 0.9438 - f1_score: 0.7480 - val_loss: 0.5068 - val_accuracy: 0.7772 - val_auc: 0.9548 - val_f1_score: 0.7718\n","Epoch 6/50\n","69/69 [==============================] - ETA: 0s - loss: 0.5257 - accuracy: 0.7709 - auc: 0.9498 - f1_score: 0.7642\n","Epoch 00006: val_accuracy did not improve from 0.77717\n","69/69 [==============================] - 22s 320ms/step - loss: 0.5257 - accuracy: 0.7709 - auc: 0.9498 - f1_score: 0.7642 - val_loss: 0.5394 - val_accuracy: 0.7636 - val_auc: 0.9475 - val_f1_score: 0.7612\n","Epoch 7/50\n","69/69 [==============================] - ETA: 0s - loss: 0.5024 - accuracy: 0.7790 - auc: 0.9540 - f1_score: 0.7728\n","Epoch 00007: val_accuracy did not improve from 0.77717\n","69/69 [==============================] - 22s 319ms/step - loss: 0.5024 - accuracy: 0.7790 - auc: 0.9540 - f1_score: 0.7728 - val_loss: 0.6324 - val_accuracy: 0.7403 - val_auc: 0.9342 - val_f1_score: 0.7394\n","Epoch 8/50\n","69/69 [==============================] - ETA: 0s - loss: 0.4972 - accuracy: 0.7854 - auc: 0.9551 - f1_score: 0.7794\n","Epoch 00008: val_accuracy did not improve from 0.77717\n","69/69 [==============================] - 22s 317ms/step - loss: 0.4972 - accuracy: 0.7854 - auc: 0.9551 - f1_score: 0.7794 - val_loss: 0.6343 - val_accuracy: 0.7095 - val_auc: 0.9295 - val_f1_score: 0.7084\n","Epoch 9/50\n","69/69 [==============================] - ETA: 0s - loss: 0.4834 - accuracy: 0.7911 - auc: 0.9576 - f1_score: 0.7863\n","Epoch 00009: val_accuracy improved from 0.77717 to 0.83229, saving model to /content/drive/My Drive/Projects/codes/Xception_model_checkpoints/xception_model_new_90\n","69/69 [==============================] - 22s 323ms/step - loss: 0.4834 - accuracy: 0.7911 - auc: 0.9576 - f1_score: 0.7863 - val_loss: 0.4077 - val_accuracy: 0.8323 - val_auc: 0.9715 - val_f1_score: 0.8270\n","Epoch 10/50\n","69/69 [==============================] - ETA: 0s - loss: 0.4601 - accuracy: 0.8004 - auc: 0.9614 - f1_score: 0.7964\n","Epoch 00010: val_accuracy improved from 0.83229 to 0.85162, saving model to /content/drive/My Drive/Projects/codes/Xception_model_checkpoints/xception_model_new_90\n","69/69 [==============================] - 23s 332ms/step - loss: 0.4601 - accuracy: 0.8004 - auc: 0.9614 - f1_score: 0.7964 - val_loss: 0.3842 - val_accuracy: 0.8516 - val_auc: 0.9755 - val_f1_score: 0.8499\n","Epoch 11/50\n","69/69 [==============================] - ETA: 0s - loss: 0.4503 - accuracy: 0.8016 - auc: 0.9630 - f1_score: 0.8013\n","Epoch 00011: val_accuracy did not improve from 0.85162\n","69/69 [==============================] - 22s 321ms/step - loss: 0.4503 - accuracy: 0.8016 - auc: 0.9630 - f1_score: 0.8013 - val_loss: 0.4473 - val_accuracy: 0.7939 - val_auc: 0.9629 - val_f1_score: 0.7868\n","Epoch 12/50\n","69/69 [==============================] - ETA: 0s - loss: 0.4281 - accuracy: 0.8192 - auc: 0.9670 - f1_score: 0.8137\n","Epoch 00012: val_accuracy did not improve from 0.85162\n","69/69 [==============================] - 22s 317ms/step - loss: 0.4281 - accuracy: 0.8192 - auc: 0.9670 - f1_score: 0.8137 - val_loss: 0.3788 - val_accuracy: 0.8438 - val_auc: 0.9745 - val_f1_score: 0.8363\n","Epoch 13/50\n","69/69 [==============================] - ETA: 0s - loss: 0.4235 - accuracy: 0.8140 - auc: 0.9672 - f1_score: 0.8112\n","Epoch 00013: val_accuracy improved from 0.85162 to 0.85998, saving model to /content/drive/My Drive/Projects/codes/Xception_model_checkpoints/xception_model_new_90\n","69/69 [==============================] - 23s 330ms/step - loss: 0.4235 - accuracy: 0.8140 - auc: 0.9672 - f1_score: 0.8112 - val_loss: 0.3656 - val_accuracy: 0.8600 - val_auc: 0.9776 - val_f1_score: 0.8547\n","Epoch 14/50\n","69/69 [==============================] - ETA: 0s - loss: 0.4059 - accuracy: 0.8266 - auc: 0.9699 - f1_score: 0.8229\n","Epoch 00014: val_accuracy did not improve from 0.85998\n","69/69 [==============================] - 22s 322ms/step - loss: 0.4059 - accuracy: 0.8266 - auc: 0.9699 - f1_score: 0.8229 - val_loss: 0.4218 - val_accuracy: 0.8302 - val_auc: 0.9677 - val_f1_score: 0.8242\n","Epoch 15/50\n","69/69 [==============================] - ETA: 0s - loss: 0.4157 - accuracy: 0.8197 - auc: 0.9682 - f1_score: 0.8180\n","Epoch 00015: val_accuracy did not improve from 0.85998\n","69/69 [==============================] - 22s 313ms/step - loss: 0.4157 - accuracy: 0.8197 - auc: 0.9682 - f1_score: 0.8180 - val_loss: 0.4569 - val_accuracy: 0.7931 - val_auc: 0.9607 - val_f1_score: 0.7919\n","Epoch 16/50\n","69/69 [==============================] - ETA: 0s - loss: 0.4006 - accuracy: 0.8300 - auc: 0.9707 - f1_score: 0.8266\n","Epoch 00016: val_accuracy improved from 0.85998 to 0.87591, saving model to /content/drive/My Drive/Projects/codes/Xception_model_checkpoints/xception_model_new_90\n","69/69 [==============================] - 22s 324ms/step - loss: 0.4006 - accuracy: 0.8300 - auc: 0.9707 - f1_score: 0.8266 - val_loss: 0.3424 - val_accuracy: 0.8759 - val_auc: 0.9802 - val_f1_score: 0.8705\n","Epoch 17/50\n","69/69 [==============================] - ETA: 0s - loss: 0.3865 - accuracy: 0.8403 - auc: 0.9728 - f1_score: 0.8383\n","Epoch 00017: val_accuracy did not improve from 0.87591\n","69/69 [==============================] - 22s 321ms/step - loss: 0.3865 - accuracy: 0.8403 - auc: 0.9728 - f1_score: 0.8383 - val_loss: 0.3856 - val_accuracy: 0.8331 - val_auc: 0.9728 - val_f1_score: 0.8299\n","Epoch 18/50\n","69/69 [==============================] - ETA: 0s - loss: 0.3990 - accuracy: 0.8274 - auc: 0.9706 - f1_score: 0.8247\n","Epoch 00018: val_accuracy did not improve from 0.87591\n","69/69 [==============================] - 22s 316ms/step - loss: 0.3990 - accuracy: 0.8274 - auc: 0.9706 - f1_score: 0.8247 - val_loss: 0.3577 - val_accuracy: 0.8487 - val_auc: 0.9766 - val_f1_score: 0.8432\n","Epoch 19/50\n","69/69 [==============================] - ETA: 0s - loss: 0.3700 - accuracy: 0.8418 - auc: 0.9749 - f1_score: 0.8409\n","Epoch 00019: val_accuracy did not improve from 0.87591\n","69/69 [==============================] - 22s 313ms/step - loss: 0.3700 - accuracy: 0.8418 - auc: 0.9749 - f1_score: 0.8409 - val_loss: 0.3423 - val_accuracy: 0.8636 - val_auc: 0.9788 - val_f1_score: 0.8621\n","Epoch 20/50\n","69/69 [==============================] - ETA: 0s - loss: 0.3744 - accuracy: 0.8427 - auc: 0.9743 - f1_score: 0.8407\n","Epoch 00020: val_accuracy did not improve from 0.87591\n","69/69 [==============================] - 22s 314ms/step - loss: 0.3744 - accuracy: 0.8427 - auc: 0.9743 - f1_score: 0.8407 - val_loss: 0.3351 - val_accuracy: 0.8715 - val_auc: 0.9802 - val_f1_score: 0.8704\n","Epoch 21/50\n","69/69 [==============================] - ETA: 0s - loss: 0.3678 - accuracy: 0.8447 - auc: 0.9753 - f1_score: 0.8443\n","Epoch 00021: val_accuracy did not improve from 0.87591\n","69/69 [==============================] - 22s 320ms/step - loss: 0.3678 - accuracy: 0.8447 - auc: 0.9753 - f1_score: 0.8443 - val_loss: 0.3393 - val_accuracy: 0.8676 - val_auc: 0.9796 - val_f1_score: 0.8666\n","Epoch 22/50\n","69/69 [==============================] - ETA: 0s - loss: 0.3789 - accuracy: 0.8393 - auc: 0.9737 - f1_score: 0.8379\n","Epoch 00022: val_accuracy improved from 0.87591 to 0.88009, saving model to /content/drive/My Drive/Projects/codes/Xception_model_checkpoints/xception_model_new_90\n","69/69 [==============================] - 23s 331ms/step - loss: 0.3789 - accuracy: 0.8393 - auc: 0.9737 - f1_score: 0.8379 - val_loss: 0.3181 - val_accuracy: 0.8801 - val_auc: 0.9830 - val_f1_score: 0.8788\n","Epoch 23/50\n","69/69 [==============================] - ETA: 0s - loss: 0.3636 - accuracy: 0.8480 - auc: 0.9757 - f1_score: 0.8468\n","Epoch 00023: val_accuracy did not improve from 0.88009\n","69/69 [==============================] - 22s 318ms/step - loss: 0.3636 - accuracy: 0.8480 - auc: 0.9757 - f1_score: 0.8468 - val_loss: 0.3420 - val_accuracy: 0.8668 - val_auc: 0.9791 - val_f1_score: 0.8646\n","Epoch 24/50\n","69/69 [==============================] - ETA: 0s - loss: 0.3503 - accuracy: 0.8555 - auc: 0.9775 - f1_score: 0.8516\n","Epoch 00024: val_accuracy improved from 0.88009 to 0.90125, saving model to /content/drive/My Drive/Projects/codes/Xception_model_checkpoints/xception_model_new_90\n","69/69 [==============================] - 22s 325ms/step - loss: 0.3503 - accuracy: 0.8555 - auc: 0.9775 - f1_score: 0.8516 - val_loss: 0.2796 - val_accuracy: 0.9013 - val_auc: 0.9874 - val_f1_score: 0.8980\n","Epoch 00025: early stopping\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fgKrbn5a9iHy","executionInfo":{"status":"ok","timestamp":1606055083393,"user_tz":300,"elapsed":5297,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"789dba31-dbfd-4b1b-d4f1-c461a6f0ab33"},"source":["\"\"\"evaluate base_model\"\"\"\n","base_model.evaluate(test_image_dataset)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["30/30 [==============================] - 2s 61ms/step - loss: 0.2796 - accuracy: 0.9013 - auc: 0.9874 - f1_score: 0.8980\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[0.27955442667007446,\n"," 0.9012539386749268,\n"," 0.9873639345169067,\n"," 0.8979917764663696]"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":396},"id":"bxUfsjJTxVsb","executionInfo":{"status":"ok","timestamp":1606257460924,"user_tz":300,"elapsed":7208,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"4d5983f5-23a9-48a3-be60-1cc24ba26db0"},"source":["'''plot confusion mat & calc acc for each label'''\n","test_image_dataset = NSLDataFormat.generate_test_tfr_image_tensor(path_list=tfr_list_test, \n","                                                                  batch_size=4000, \n","                                                                  size=(100,100),\n","                                                                  channels=3,\n","                                                                  shuffle=True)\n","data, data_label = iter(test_image_dataset).get_next()\n","data = data[\"tensor\"]\n","ADModelBuilder.plot_confusion_mat(model=base_model, data=data, data_label=data_label, title=\"Xception\", figsize=(6,6))"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x432 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KCUf-aI9GEBL","executionInfo":{"status":"ok","timestamp":1606257464268,"user_tz":300,"elapsed":7998,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"b4387d69-ad66-403e-bd68-5b515c375a3a"},"source":["ADModelBuilder.calc_confu_mat_for_each_label(model=base_model, data=data, data_label=data_label)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["TN: [2704 2708 2838 2856]\n","TP: [890 793 805 962]\n","FN: [101 145 129   3]\n","FP: [133 182  56   7]\n","Acc: [0.93887147 0.9145768  0.95167189 0.99738767]\n","ER(Error rate): [0.06112853 0.0854232  0.04832811 0.00261233]\n","Recall(TP rate): [0.89808274 0.84541578 0.86188437 0.99689119]\n","Specialty(TN rate): [0.95311949 0.93702422 0.98064962 0.99755501]\n","Fall Out(FP rate): [0.04688051 0.06297578 0.01935038 0.00244499]\n","Miss Rate(FN rate): [0.10191726 0.15458422 0.13811563 0.00310881]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JLKaHrGqGEFw"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rTkxi38f9Han"},"source":["##5.2 Xception_NSL Model Training\n","### val_acc: 0.954,val_auc: 0.990,val_f1_score:0.954"]},{"cell_type":"code","metadata":{"id":"8ENVKLvoRFPE"},"source":["'''define hyper params'''\n","params = AD_params()\n","params.max_seed_nbr=5\n","params.batch_size=64\n","params.image_channels =3\n","params.image_size =(100,100)\n","params.ad_base_model_input_shape=(100,100,3)\n","params.train_tfr_path = f'{root_path}train_data.tfr'\n","'''parse train_data.tfr to train image dataset with batch_size at 128'''\n","train_image_dataset = NSLDataFormat.parse_tfr_to_dataset(file_path_list=[params.train_tfr_path],\n","                                                         batch_size=params.batch_size,\n","                                                         max_neighbor_number=params.max_seed_nbr,\n","                                                         image_size=params.image_size,\n","                                                         image_channels=params.image_channels,\n","                                                         shuffle=True)\n","'''load test data with batch_size at 128 '''\n","test_image_dataset = NSLDataFormat.generate_test_tfr_image_tensor(path_list=tfr_list_test, \n","                                                                  batch_size=params.batch_size, \n","                                                                  size=params.image_size,\n","                                                                  channels=params.image_channels,\n","                                                                  shuffle=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H0aFX2Bp9Gnx","executionInfo":{"status":"ok","timestamp":1606056077165,"user_tz":300,"elapsed":540274,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"7f0e0518-073d-4b1d-ad7a-42dc92551e13"},"source":["'''define params'''\n","params.learning_rate=0.00005\n","params.restore_path = '/content/drive/My Drive/Projects/codes/Xception_model_checkpoints/xception_model_new_90'\n","params.checkpoint_path = '/content/drive/My Drive/Projects/codes/Xception_NSL_model_checkpoints/xception_model_95'\n","params.early_stop_base_line=0.95\n","params.train_epoch=50\n","params.nsl_multiplier = 0.1\n","params.nsl_sum_over_axis = -1\n","params.nsl_distance_type = nsl.configs.DistanceType.COSINE\n","'''build base_model and restore from the last training'''\n","base_model = ADModelBuilder(input_shape=params.ad_base_model_input_shape, base_model='xception').setup_Xception(top_layers=10, middle_layers=None, bottom_layers=5).get_ADModel()\n","'''build NSL model on top of base model'''\n","graph_reg_config = nsl.configs.make_graph_reg_config(neighbor_prefix=params.neighbor_prefix,\n","                                                     neighbor_weight_suffix=params.neighbor_weight_suffix,\n","                                                     max_neighbors= params.max_seed_nbr,\n","                                                     multiplier= params.nsl_multiplier,\n","                                                     distance_type= params.nsl_distance_type,\n","                                                     sum_over_axis=params.nsl_sum_over_axis)\n","graph_reg_model = nsl.keras.GraphRegularization(base_model,graph_reg_config)\n","graph_reg_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=params.learning_rate, amsgrad=True),\n","                        loss=tf.losses.CategoricalCrossentropy(),\n","                        metrics=[\"accuracy\",\"AUC\",tfa.metrics.F1Score(num_classes=4, average=\"micro\", threshold = 0.5)])\n","graph_reg_model.load_weights(params.restore_path)\n","'''set up check point & early stopping'''\n","callback_checkpoints = tf.keras.callbacks.ModelCheckpoint(filepath= params.checkpoint_path, monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=True, mode='max',\n","                                                         save_freq='epoch',options=None)\n","callback_earlystop = AccEarlyStop(val_acc_base=params.early_stop_base_line)\n","'''train the nsl model'''\n","graph_reg_history = graph_reg_model.fit(train_image_dataset, \n","                                        validation_data=test_image_dataset,\n","                                        callbacks = [callback_checkpoints, callback_earlystop],\n","                                        epochs=params.train_epoch,\n","                                        verbose=1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Note: default Xception not includes top and has imagenet weights. It is not a trainable model in ADModelBuilder. Please setup trainable layers in setup_Xception function based on the \"Layer Number\"\n","Model: \"xception\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_3 (InputLayer)            [(None, 100, 100, 3) 0                                            \n","__________________________________________________________________________________________________\n","block1_conv1 (Conv2D)           (None, 49, 49, 32)   864         input_3[0][0]                    \n","__________________________________________________________________________________________________\n","block1_conv1_bn (BatchNormaliza (None, 49, 49, 32)   128         block1_conv1[0][0]               \n","__________________________________________________________________________________________________\n","block1_conv1_act (Activation)   (None, 49, 49, 32)   0           block1_conv1_bn[0][0]            \n","__________________________________________________________________________________________________\n","block1_conv2 (Conv2D)           (None, 47, 47, 64)   18432       block1_conv1_act[0][0]           \n","__________________________________________________________________________________________________\n","block1_conv2_bn (BatchNormaliza (None, 47, 47, 64)   256         block1_conv2[0][0]               \n","__________________________________________________________________________________________________\n","block1_conv2_act (Activation)   (None, 47, 47, 64)   0           block1_conv2_bn[0][0]            \n","__________________________________________________________________________________________________\n","block2_sepconv1 (SeparableConv2 (None, 47, 47, 128)  8768        block1_conv2_act[0][0]           \n","__________________________________________________________________________________________________\n","block2_sepconv1_bn (BatchNormal (None, 47, 47, 128)  512         block2_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block2_sepconv2_act (Activation (None, 47, 47, 128)  0           block2_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block2_sepconv2 (SeparableConv2 (None, 47, 47, 128)  17536       block2_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block2_sepconv2_bn (BatchNormal (None, 47, 47, 128)  512         block2_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","conv2d_8 (Conv2D)               (None, 24, 24, 128)  8192        block1_conv2_act[0][0]           \n","__________________________________________________________________________________________________\n","block2_pool (MaxPooling2D)      (None, 24, 24, 128)  0           block2_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","batch_normalization_10 (BatchNo (None, 24, 24, 128)  512         conv2d_8[0][0]                   \n","__________________________________________________________________________________________________\n","add_24 (Add)                    (None, 24, 24, 128)  0           block2_pool[0][0]                \n","                                                                 batch_normalization_10[0][0]     \n","__________________________________________________________________________________________________\n","block3_sepconv1_act (Activation (None, 24, 24, 128)  0           add_24[0][0]                     \n","__________________________________________________________________________________________________\n","block3_sepconv1 (SeparableConv2 (None, 24, 24, 256)  33920       block3_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block3_sepconv1_bn (BatchNormal (None, 24, 24, 256)  1024        block3_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block3_sepconv2_act (Activation (None, 24, 24, 256)  0           block3_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block3_sepconv2 (SeparableConv2 (None, 24, 24, 256)  67840       block3_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block3_sepconv2_bn (BatchNormal (None, 24, 24, 256)  1024        block3_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","conv2d_9 (Conv2D)               (None, 12, 12, 256)  32768       add_24[0][0]                     \n","__________________________________________________________________________________________________\n","block3_pool (MaxPooling2D)      (None, 12, 12, 256)  0           block3_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","batch_normalization_11 (BatchNo (None, 12, 12, 256)  1024        conv2d_9[0][0]                   \n","__________________________________________________________________________________________________\n","add_25 (Add)                    (None, 12, 12, 256)  0           block3_pool[0][0]                \n","                                                                 batch_normalization_11[0][0]     \n","__________________________________________________________________________________________________\n","block4_sepconv1_act (Activation (None, 12, 12, 256)  0           add_25[0][0]                     \n","__________________________________________________________________________________________________\n","block4_sepconv1 (SeparableConv2 (None, 12, 12, 728)  188672      block4_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block4_sepconv1_bn (BatchNormal (None, 12, 12, 728)  2912        block4_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block4_sepconv2_act (Activation (None, 12, 12, 728)  0           block4_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block4_sepconv2 (SeparableConv2 (None, 12, 12, 728)  536536      block4_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block4_sepconv2_bn (BatchNormal (None, 12, 12, 728)  2912        block4_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","conv2d_10 (Conv2D)              (None, 6, 6, 728)    186368      add_25[0][0]                     \n","__________________________________________________________________________________________________\n","block4_pool (MaxPooling2D)      (None, 6, 6, 728)    0           block4_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","batch_normalization_12 (BatchNo (None, 6, 6, 728)    2912        conv2d_10[0][0]                  \n","__________________________________________________________________________________________________\n","add_26 (Add)                    (None, 6, 6, 728)    0           block4_pool[0][0]                \n","                                                                 batch_normalization_12[0][0]     \n","__________________________________________________________________________________________________\n","block5_sepconv1_act (Activation (None, 6, 6, 728)    0           add_26[0][0]                     \n","__________________________________________________________________________________________________\n","block5_sepconv1 (SeparableConv2 (None, 6, 6, 728)    536536      block5_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block5_sepconv1_bn (BatchNormal (None, 6, 6, 728)    2912        block5_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block5_sepconv2_act (Activation (None, 6, 6, 728)    0           block5_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block5_sepconv2 (SeparableConv2 (None, 6, 6, 728)    536536      block5_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block5_sepconv2_bn (BatchNormal (None, 6, 6, 728)    2912        block5_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","block5_sepconv3_act (Activation (None, 6, 6, 728)    0           block5_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","block5_sepconv3 (SeparableConv2 (None, 6, 6, 728)    536536      block5_sepconv3_act[0][0]        \n","__________________________________________________________________________________________________\n","block5_sepconv3_bn (BatchNormal (None, 6, 6, 728)    2912        block5_sepconv3[0][0]            \n","__________________________________________________________________________________________________\n","add_27 (Add)                    (None, 6, 6, 728)    0           block5_sepconv3_bn[0][0]         \n","                                                                 add_26[0][0]                     \n","__________________________________________________________________________________________________\n","block6_sepconv1_act (Activation (None, 6, 6, 728)    0           add_27[0][0]                     \n","__________________________________________________________________________________________________\n","block6_sepconv1 (SeparableConv2 (None, 6, 6, 728)    536536      block6_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block6_sepconv1_bn (BatchNormal (None, 6, 6, 728)    2912        block6_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block6_sepconv2_act (Activation (None, 6, 6, 728)    0           block6_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block6_sepconv2 (SeparableConv2 (None, 6, 6, 728)    536536      block6_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block6_sepconv2_bn (BatchNormal (None, 6, 6, 728)    2912        block6_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","block6_sepconv3_act (Activation (None, 6, 6, 728)    0           block6_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","block6_sepconv3 (SeparableConv2 (None, 6, 6, 728)    536536      block6_sepconv3_act[0][0]        \n","__________________________________________________________________________________________________\n","block6_sepconv3_bn (BatchNormal (None, 6, 6, 728)    2912        block6_sepconv3[0][0]            \n","__________________________________________________________________________________________________\n","add_28 (Add)                    (None, 6, 6, 728)    0           block6_sepconv3_bn[0][0]         \n","                                                                 add_27[0][0]                     \n","__________________________________________________________________________________________________\n","block7_sepconv1_act (Activation (None, 6, 6, 728)    0           add_28[0][0]                     \n","__________________________________________________________________________________________________\n","block7_sepconv1 (SeparableConv2 (None, 6, 6, 728)    536536      block7_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block7_sepconv1_bn (BatchNormal (None, 6, 6, 728)    2912        block7_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block7_sepconv2_act (Activation (None, 6, 6, 728)    0           block7_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block7_sepconv2 (SeparableConv2 (None, 6, 6, 728)    536536      block7_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block7_sepconv2_bn (BatchNormal (None, 6, 6, 728)    2912        block7_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","block7_sepconv3_act (Activation (None, 6, 6, 728)    0           block7_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","block7_sepconv3 (SeparableConv2 (None, 6, 6, 728)    536536      block7_sepconv3_act[0][0]        \n","__________________________________________________________________________________________________\n","block7_sepconv3_bn (BatchNormal (None, 6, 6, 728)    2912        block7_sepconv3[0][0]            \n","__________________________________________________________________________________________________\n","add_29 (Add)                    (None, 6, 6, 728)    0           block7_sepconv3_bn[0][0]         \n","                                                                 add_28[0][0]                     \n","__________________________________________________________________________________________________\n","block8_sepconv1_act (Activation (None, 6, 6, 728)    0           add_29[0][0]                     \n","__________________________________________________________________________________________________\n","block8_sepconv1 (SeparableConv2 (None, 6, 6, 728)    536536      block8_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block8_sepconv1_bn (BatchNormal (None, 6, 6, 728)    2912        block8_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block8_sepconv2_act (Activation (None, 6, 6, 728)    0           block8_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block8_sepconv2 (SeparableConv2 (None, 6, 6, 728)    536536      block8_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block8_sepconv2_bn (BatchNormal (None, 6, 6, 728)    2912        block8_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","block8_sepconv3_act (Activation (None, 6, 6, 728)    0           block8_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","block8_sepconv3 (SeparableConv2 (None, 6, 6, 728)    536536      block8_sepconv3_act[0][0]        \n","__________________________________________________________________________________________________\n","block8_sepconv3_bn (BatchNormal (None, 6, 6, 728)    2912        block8_sepconv3[0][0]            \n","__________________________________________________________________________________________________\n","add_30 (Add)                    (None, 6, 6, 728)    0           block8_sepconv3_bn[0][0]         \n","                                                                 add_29[0][0]                     \n","__________________________________________________________________________________________________\n","block9_sepconv1_act (Activation (None, 6, 6, 728)    0           add_30[0][0]                     \n","__________________________________________________________________________________________________\n","block9_sepconv1 (SeparableConv2 (None, 6, 6, 728)    536536      block9_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block9_sepconv1_bn (BatchNormal (None, 6, 6, 728)    2912        block9_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block9_sepconv2_act (Activation (None, 6, 6, 728)    0           block9_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block9_sepconv2 (SeparableConv2 (None, 6, 6, 728)    536536      block9_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block9_sepconv2_bn (BatchNormal (None, 6, 6, 728)    2912        block9_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","block9_sepconv3_act (Activation (None, 6, 6, 728)    0           block9_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","block9_sepconv3 (SeparableConv2 (None, 6, 6, 728)    536536      block9_sepconv3_act[0][0]        \n","__________________________________________________________________________________________________\n","block9_sepconv3_bn (BatchNormal (None, 6, 6, 728)    2912        block9_sepconv3[0][0]            \n","__________________________________________________________________________________________________\n","add_31 (Add)                    (None, 6, 6, 728)    0           block9_sepconv3_bn[0][0]         \n","                                                                 add_30[0][0]                     \n","__________________________________________________________________________________________________\n","block10_sepconv1_act (Activatio (None, 6, 6, 728)    0           add_31[0][0]                     \n","__________________________________________________________________________________________________\n","block10_sepconv1 (SeparableConv (None, 6, 6, 728)    536536      block10_sepconv1_act[0][0]       \n","__________________________________________________________________________________________________\n","block10_sepconv1_bn (BatchNorma (None, 6, 6, 728)    2912        block10_sepconv1[0][0]           \n","__________________________________________________________________________________________________\n","block10_sepconv2_act (Activatio (None, 6, 6, 728)    0           block10_sepconv1_bn[0][0]        \n","__________________________________________________________________________________________________\n","block10_sepconv2 (SeparableConv (None, 6, 6, 728)    536536      block10_sepconv2_act[0][0]       \n","__________________________________________________________________________________________________\n","block10_sepconv2_bn (BatchNorma (None, 6, 6, 728)    2912        block10_sepconv2[0][0]           \n","__________________________________________________________________________________________________\n","block10_sepconv3_act (Activatio (None, 6, 6, 728)    0           block10_sepconv2_bn[0][0]        \n","__________________________________________________________________________________________________\n","block10_sepconv3 (SeparableConv (None, 6, 6, 728)    536536      block10_sepconv3_act[0][0]       \n","__________________________________________________________________________________________________\n","block10_sepconv3_bn (BatchNorma (None, 6, 6, 728)    2912        block10_sepconv3[0][0]           \n","__________________________________________________________________________________________________\n","add_32 (Add)                    (None, 6, 6, 728)    0           block10_sepconv3_bn[0][0]        \n","                                                                 add_31[0][0]                     \n","__________________________________________________________________________________________________\n","block11_sepconv1_act (Activatio (None, 6, 6, 728)    0           add_32[0][0]                     \n","__________________________________________________________________________________________________\n","block11_sepconv1 (SeparableConv (None, 6, 6, 728)    536536      block11_sepconv1_act[0][0]       \n","__________________________________________________________________________________________________\n","block11_sepconv1_bn (BatchNorma (None, 6, 6, 728)    2912        block11_sepconv1[0][0]           \n","__________________________________________________________________________________________________\n","block11_sepconv2_act (Activatio (None, 6, 6, 728)    0           block11_sepconv1_bn[0][0]        \n","__________________________________________________________________________________________________\n","block11_sepconv2 (SeparableConv (None, 6, 6, 728)    536536      block11_sepconv2_act[0][0]       \n","__________________________________________________________________________________________________\n","block11_sepconv2_bn (BatchNorma (None, 6, 6, 728)    2912        block11_sepconv2[0][0]           \n","__________________________________________________________________________________________________\n","block11_sepconv3_act (Activatio (None, 6, 6, 728)    0           block11_sepconv2_bn[0][0]        \n","__________________________________________________________________________________________________\n","block11_sepconv3 (SeparableConv (None, 6, 6, 728)    536536      block11_sepconv3_act[0][0]       \n","__________________________________________________________________________________________________\n","block11_sepconv3_bn (BatchNorma (None, 6, 6, 728)    2912        block11_sepconv3[0][0]           \n","__________________________________________________________________________________________________\n","add_33 (Add)                    (None, 6, 6, 728)    0           block11_sepconv3_bn[0][0]        \n","                                                                 add_32[0][0]                     \n","__________________________________________________________________________________________________\n","block12_sepconv1_act (Activatio (None, 6, 6, 728)    0           add_33[0][0]                     \n","__________________________________________________________________________________________________\n","block12_sepconv1 (SeparableConv (None, 6, 6, 728)    536536      block12_sepconv1_act[0][0]       \n","__________________________________________________________________________________________________\n","block12_sepconv1_bn (BatchNorma (None, 6, 6, 728)    2912        block12_sepconv1[0][0]           \n","__________________________________________________________________________________________________\n","block12_sepconv2_act (Activatio (None, 6, 6, 728)    0           block12_sepconv1_bn[0][0]        \n","__________________________________________________________________________________________________\n","block12_sepconv2 (SeparableConv (None, 6, 6, 728)    536536      block12_sepconv2_act[0][0]       \n","__________________________________________________________________________________________________\n","block12_sepconv2_bn (BatchNorma (None, 6, 6, 728)    2912        block12_sepconv2[0][0]           \n","__________________________________________________________________________________________________\n","block12_sepconv3_act (Activatio (None, 6, 6, 728)    0           block12_sepconv2_bn[0][0]        \n","__________________________________________________________________________________________________\n","block12_sepconv3 (SeparableConv (None, 6, 6, 728)    536536      block12_sepconv3_act[0][0]       \n","__________________________________________________________________________________________________\n","block12_sepconv3_bn (BatchNorma (None, 6, 6, 728)    2912        block12_sepconv3[0][0]           \n","__________________________________________________________________________________________________\n","add_34 (Add)                    (None, 6, 6, 728)    0           block12_sepconv3_bn[0][0]        \n","                                                                 add_33[0][0]                     \n","__________________________________________________________________________________________________\n","block13_sepconv1_act (Activatio (None, 6, 6, 728)    0           add_34[0][0]                     \n","__________________________________________________________________________________________________\n","block13_sepconv1 (SeparableConv (None, 6, 6, 728)    536536      block13_sepconv1_act[0][0]       \n","__________________________________________________________________________________________________\n","block13_sepconv1_bn (BatchNorma (None, 6, 6, 728)    2912        block13_sepconv1[0][0]           \n","__________________________________________________________________________________________________\n","block13_sepconv2_act (Activatio (None, 6, 6, 728)    0           block13_sepconv1_bn[0][0]        \n","__________________________________________________________________________________________________\n","block13_sepconv2 (SeparableConv (None, 6, 6, 1024)   752024      block13_sepconv2_act[0][0]       \n","__________________________________________________________________________________________________\n","block13_sepconv2_bn (BatchNorma (None, 6, 6, 1024)   4096        block13_sepconv2[0][0]           \n","__________________________________________________________________________________________________\n","conv2d_11 (Conv2D)              (None, 3, 3, 1024)   745472      add_34[0][0]                     \n","__________________________________________________________________________________________________\n","block13_pool (MaxPooling2D)     (None, 3, 3, 1024)   0           block13_sepconv2_bn[0][0]        \n","__________________________________________________________________________________________________\n","batch_normalization_13 (BatchNo (None, 3, 3, 1024)   4096        conv2d_11[0][0]                  \n","__________________________________________________________________________________________________\n","add_35 (Add)                    (None, 3, 3, 1024)   0           block13_pool[0][0]               \n","                                                                 batch_normalization_13[0][0]     \n","__________________________________________________________________________________________________\n","block14_sepconv1 (SeparableConv (None, 3, 3, 1536)   1582080     add_35[0][0]                     \n","__________________________________________________________________________________________________\n","block14_sepconv1_bn (BatchNorma (None, 3, 3, 1536)   6144        block14_sepconv1[0][0]           \n","__________________________________________________________________________________________________\n","block14_sepconv1_act (Activatio (None, 3, 3, 1536)   0           block14_sepconv1_bn[0][0]        \n","__________________________________________________________________________________________________\n","block14_sepconv2 (SeparableConv (None, 3, 3, 2048)   3159552     block14_sepconv1_act[0][0]       \n","__________________________________________________________________________________________________\n","block14_sepconv2_bn (BatchNorma (None, 3, 3, 2048)   8192        block14_sepconv2[0][0]           \n","__________________________________________________________________________________________________\n","block14_sepconv2_act (Activatio (None, 3, 3, 2048)   0           block14_sepconv2_bn[0][0]        \n","==================================================================================================\n","Total params: 20,861,480\n","Trainable params: 3,195,232\n","Non-trainable params: 17,666,248\n","__________________________________________________________________________________________________\n","Model: \"Xception_ADModel\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","tensor (InputLayer)          [(None, 100, 100, 3)]     0         \n","_________________________________________________________________\n","xception (Functional)        (None, 3, 3, 2048)        20861480  \n","_________________________________________________________________\n","flatten_2 (Flatten)          (None, 18432)             0         \n","_________________________________________________________________\n","dropout_4 (Dropout)          (None, 18432)             0         \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 128)               2359424   \n","_________________________________________________________________\n","batch_normalization_14 (Batc (None, 128)               512       \n","_________________________________________________________________\n","leaky_re_lu_2 (LeakyReLU)    (None, 128)               0         \n","_________________________________________________________________\n","dropout_5 (Dropout)          (None, 128)               0         \n","_________________________________________________________________\n","dense_5 (Dense)              (None, 4)                 516       \n","=================================================================\n","Total params: 23,221,932\n","Trainable params: 5,555,428\n","Non-trainable params: 17,666,504\n","_________________________________________________________________\n","Epoch 1/50\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py:543: UserWarning: Input dict contained keys ['id'] which did not match any model input. They will be ignored by the model.\n","  [n for n in tensors.keys() if n not in ref_input_names])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:432: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"],"name":"stderr"},{"output_type":"stream","text":["      2/Unknown - 1s 301ms/step - loss: 3.0072 - accuracy: 0.2500 - auc: 0.5468 - f1_score: 0.2443 - scaled_graph_loss: 0.0239WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2346s vs `on_train_batch_end` time: 0.3666s). Check your callbacks.\n","    137/Unknown - 82s 597ms/step - loss: 0.8293 - accuracy: 0.6618 - auc: 0.8905 - f1_score: 0.6381 - scaled_graph_loss: 0.0105\n","Epoch 00001: val_accuracy improved from -inf to 0.74974, saving model to /content/drive/My Drive/Projects/codes/Xception_NSL_model_checkpoints/xception_model_95\n","137/137 [==============================] - 88s 645ms/step - loss: 0.8293 - accuracy: 0.6618 - auc: 0.8905 - f1_score: 0.6381 - scaled_graph_loss: 0.0105 - val_loss: 0.5496 - val_accuracy: 0.7497 - val_auc: 0.9468 - val_f1_score: 0.6678\n","Epoch 2/50\n","137/137 [==============================] - ETA: 0s - loss: 0.4557 - accuracy: 0.8036 - auc: 0.9631 - f1_score: 0.7962 - scaled_graph_loss: 0.0080\n","Epoch 00002: val_accuracy improved from 0.74974 to 0.83699, saving model to /content/drive/My Drive/Projects/codes/Xception_NSL_model_checkpoints/xception_model_95\n","137/137 [==============================] - 86s 626ms/step - loss: 0.4557 - accuracy: 0.8036 - auc: 0.9631 - f1_score: 0.7962 - scaled_graph_loss: 0.0080 - val_loss: 0.3770 - val_accuracy: 0.8370 - val_auc: 0.9743 - val_f1_score: 0.8360\n","Epoch 3/50\n","137/137 [==============================] - ETA: 0s - loss: 0.3232 - accuracy: 0.8726 - auc: 0.9817 - f1_score: 0.8710 - scaled_graph_loss: 0.0074\n","Epoch 00003: val_accuracy improved from 0.83699 to 0.90543, saving model to /content/drive/My Drive/Projects/codes/Xception_NSL_model_checkpoints/xception_model_95\n","137/137 [==============================] - 85s 623ms/step - loss: 0.3232 - accuracy: 0.8726 - auc: 0.9817 - f1_score: 0.8710 - scaled_graph_loss: 0.0074 - val_loss: 0.2457 - val_accuracy: 0.9054 - val_auc: 0.9892 - val_f1_score: 0.9035\n","Epoch 4/50\n","137/137 [==============================] - ETA: 0s - loss: 0.2171 - accuracy: 0.9191 - auc: 0.9916 - f1_score: 0.9180 - scaled_graph_loss: 0.0060\n","Epoch 00004: val_accuracy improved from 0.90543 to 0.92320, saving model to /content/drive/My Drive/Projects/codes/Xception_NSL_model_checkpoints/xception_model_95\n","137/137 [==============================] - 86s 624ms/step - loss: 0.2171 - accuracy: 0.9191 - auc: 0.9916 - f1_score: 0.9180 - scaled_graph_loss: 0.0060 - val_loss: 0.2039 - val_accuracy: 0.9232 - val_auc: 0.9916 - val_f1_score: 0.9231\n","Epoch 5/50\n","137/137 [==============================] - ETA: 0s - loss: 0.1431 - accuracy: 0.9495 - auc: 0.9963 - f1_score: 0.9510 - scaled_graph_loss: 0.0045\n","Epoch 00005: val_accuracy improved from 0.92320 to 0.93835, saving model to /content/drive/My Drive/Projects/codes/Xception_NSL_model_checkpoints/xception_model_95\n","137/137 [==============================] - 86s 626ms/step - loss: 0.1431 - accuracy: 0.9495 - auc: 0.9963 - f1_score: 0.9510 - scaled_graph_loss: 0.0045 - val_loss: 0.1686 - val_accuracy: 0.9383 - val_auc: 0.9938 - val_f1_score: 0.9393\n","Epoch 6/50\n","137/137 [==============================] - ETA: 0s - loss: 0.0973 - accuracy: 0.9681 - auc: 0.9983 - f1_score: 0.9678 - scaled_graph_loss: 0.0033\n","Epoch 00006: val_accuracy improved from 0.93835 to 0.95089, saving model to /content/drive/My Drive/Projects/codes/Xception_NSL_model_checkpoints/xception_model_95\n","137/137 [==============================] - 85s 622ms/step - loss: 0.0973 - accuracy: 0.9681 - auc: 0.9983 - f1_score: 0.9678 - scaled_graph_loss: 0.0033 - val_loss: 0.1488 - val_accuracy: 0.9509 - val_auc: 0.9944 - val_f1_score: 0.9505\n","Epoch 00007: early stopping\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZixNdkut9Gpr"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QBplEqmx1pm1"},"source":["##5.3 Xception_NSL Model top 10 and bottom 5 layers tunning\n","### val_acc: 0.972, val_auc: 0.996, val_f1_score: 0.971"]},{"cell_type":"code","metadata":{"id":"RQfQgpa29Grs"},"source":["'''define hyper params'''\n","params = AD_params()\n","params.max_seed_nbr=5\n","params.batch_size=64\n","params.image_channels =3\n","params.image_size =(100,100)\n","params.ad_base_model_input_shape=(100,100,3)\n","params.train_tfr_path = f'{root_path}train_data.tfr'\n","\n","'''parse train_data.tfr to train image dataset with batch_size at 128'''\n","train_image_dataset = NSLDataFormat.parse_tfr_to_dataset(file_path_list=[params.train_tfr_path],\n","                                                         batch_size=params.batch_size,\n","                                                         max_neighbor_number=params.max_seed_nbr,\n","                                                         image_size=params.image_size,\n","                                                         image_channels=params.image_channels,\n","                                                         shuffle=True)\n","'''load test data with batch_size at 128 '''\n","test_image_dataset = NSLDataFormat.generate_test_tfr_image_tensor(path_list=tfr_list_test, \n","                                                                  batch_size=params.batch_size, \n","                                                                  size=params.image_size,\n","                                                                  channels=params.image_channels,\n","                                                                  shuffle=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qn_OeO8Pag-J","executionInfo":{"status":"ok","timestamp":1606257657532,"user_tz":300,"elapsed":6991,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"df2ecf16-59aa-4ce0-f837-a5ac632d9ec7"},"source":["'''define params'''\n","params.learning_rate=0.00001\n","params.restore_path = '/content/drive/My Drive/Projects/codes/Xception_NSL_model_checkpoints/xception_model_95'\n","params.checkpoint_path = '/content/drive/My Drive/Projects/codes/Xception_NSL_model_checkpoints/xception_model_new_98'\n","params.early_stop_base_line=0.98\n","params.train_epoch=50\n","params.nsl_multiplier = 0.1\n","params.nsl_sum_over_axis = -1\n","params.nsl_distance_type = nsl.configs.DistanceType.COSINE\n","'''build base_model and restore from the last training'''\n","base_model = ADModelBuilder(input_shape=params.ad_base_model_input_shape, base_model='xception').setup_Xception(top_layers=10, middle_layers=None, bottom_layers=5).get_ADModel()\n","'''build NSL model on top of base model'''\n","graph_reg_config = nsl.configs.make_graph_reg_config(neighbor_prefix=params.neighbor_prefix,\n","                                                     neighbor_weight_suffix=params.neighbor_weight_suffix,\n","                                                     max_neighbors= params.max_seed_nbr,\n","                                                     multiplier= params.nsl_multiplier,\n","                                                     distance_type= params.nsl_distance_type,\n","                                                     sum_over_axis=params.nsl_sum_over_axis)\n","graph_reg_model = nsl.keras.GraphRegularization(base_model,graph_reg_config)\n","graph_reg_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=params.learning_rate, amsgrad=True),\n","                        loss=tf.losses.CategoricalCrossentropy(),\n","                        metrics=[\"accuracy\",\"AUC\",tfa.metrics.F1Score(num_classes=4, average=\"micro\", threshold = 0.5)])\n","graph_reg_model.load_weights(params.restore_path)\n","'''set up check point & early stopping'''\n","callback_checkpoints = tf.keras.callbacks.ModelCheckpoint(filepath= params.checkpoint_path, monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=True, mode='max',\n","                                                         save_freq='epoch',options=None)\n","callback_earlystop = AccEarlyStop(val_acc_base=params.early_stop_base_line)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Note: default Xception not includes top and has imagenet weights. It is not a trainable model in ADModelBuilder. Please setup trainable layers in setup_Xception function based on the \"Layer Number\"\n","Model: \"xception\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_7 (InputLayer)            [(None, 100, 100, 3) 0                                            \n","__________________________________________________________________________________________________\n","block1_conv1 (Conv2D)           (None, 49, 49, 32)   864         input_7[0][0]                    \n","__________________________________________________________________________________________________\n","block1_conv1_bn (BatchNormaliza (None, 49, 49, 32)   128         block1_conv1[0][0]               \n","__________________________________________________________________________________________________\n","block1_conv1_act (Activation)   (None, 49, 49, 32)   0           block1_conv1_bn[0][0]            \n","__________________________________________________________________________________________________\n","block1_conv2 (Conv2D)           (None, 47, 47, 64)   18432       block1_conv1_act[0][0]           \n","__________________________________________________________________________________________________\n","block1_conv2_bn (BatchNormaliza (None, 47, 47, 64)   256         block1_conv2[0][0]               \n","__________________________________________________________________________________________________\n","block1_conv2_act (Activation)   (None, 47, 47, 64)   0           block1_conv2_bn[0][0]            \n","__________________________________________________________________________________________________\n","block2_sepconv1 (SeparableConv2 (None, 47, 47, 128)  8768        block1_conv2_act[0][0]           \n","__________________________________________________________________________________________________\n","block2_sepconv1_bn (BatchNormal (None, 47, 47, 128)  512         block2_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block2_sepconv2_act (Activation (None, 47, 47, 128)  0           block2_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block2_sepconv2 (SeparableConv2 (None, 47, 47, 128)  17536       block2_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block2_sepconv2_bn (BatchNormal (None, 47, 47, 128)  512         block2_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","conv2d_12 (Conv2D)              (None, 24, 24, 128)  8192        block1_conv2_act[0][0]           \n","__________________________________________________________________________________________________\n","block2_pool (MaxPooling2D)      (None, 24, 24, 128)  0           block2_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","batch_normalization_18 (BatchNo (None, 24, 24, 128)  512         conv2d_12[0][0]                  \n","__________________________________________________________________________________________________\n","add_36 (Add)                    (None, 24, 24, 128)  0           block2_pool[0][0]                \n","                                                                 batch_normalization_18[0][0]     \n","__________________________________________________________________________________________________\n","block3_sepconv1_act (Activation (None, 24, 24, 128)  0           add_36[0][0]                     \n","__________________________________________________________________________________________________\n","block3_sepconv1 (SeparableConv2 (None, 24, 24, 256)  33920       block3_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block3_sepconv1_bn (BatchNormal (None, 24, 24, 256)  1024        block3_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block3_sepconv2_act (Activation (None, 24, 24, 256)  0           block3_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block3_sepconv2 (SeparableConv2 (None, 24, 24, 256)  67840       block3_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block3_sepconv2_bn (BatchNormal (None, 24, 24, 256)  1024        block3_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","conv2d_13 (Conv2D)              (None, 12, 12, 256)  32768       add_36[0][0]                     \n","__________________________________________________________________________________________________\n","block3_pool (MaxPooling2D)      (None, 12, 12, 256)  0           block3_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","batch_normalization_19 (BatchNo (None, 12, 12, 256)  1024        conv2d_13[0][0]                  \n","__________________________________________________________________________________________________\n","add_37 (Add)                    (None, 12, 12, 256)  0           block3_pool[0][0]                \n","                                                                 batch_normalization_19[0][0]     \n","__________________________________________________________________________________________________\n","block4_sepconv1_act (Activation (None, 12, 12, 256)  0           add_37[0][0]                     \n","__________________________________________________________________________________________________\n","block4_sepconv1 (SeparableConv2 (None, 12, 12, 728)  188672      block4_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block4_sepconv1_bn (BatchNormal (None, 12, 12, 728)  2912        block4_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block4_sepconv2_act (Activation (None, 12, 12, 728)  0           block4_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block4_sepconv2 (SeparableConv2 (None, 12, 12, 728)  536536      block4_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block4_sepconv2_bn (BatchNormal (None, 12, 12, 728)  2912        block4_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","conv2d_14 (Conv2D)              (None, 6, 6, 728)    186368      add_37[0][0]                     \n","__________________________________________________________________________________________________\n","block4_pool (MaxPooling2D)      (None, 6, 6, 728)    0           block4_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","batch_normalization_20 (BatchNo (None, 6, 6, 728)    2912        conv2d_14[0][0]                  \n","__________________________________________________________________________________________________\n","add_38 (Add)                    (None, 6, 6, 728)    0           block4_pool[0][0]                \n","                                                                 batch_normalization_20[0][0]     \n","__________________________________________________________________________________________________\n","block5_sepconv1_act (Activation (None, 6, 6, 728)    0           add_38[0][0]                     \n","__________________________________________________________________________________________________\n","block5_sepconv1 (SeparableConv2 (None, 6, 6, 728)    536536      block5_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block5_sepconv1_bn (BatchNormal (None, 6, 6, 728)    2912        block5_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block5_sepconv2_act (Activation (None, 6, 6, 728)    0           block5_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block5_sepconv2 (SeparableConv2 (None, 6, 6, 728)    536536      block5_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block5_sepconv2_bn (BatchNormal (None, 6, 6, 728)    2912        block5_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","block5_sepconv3_act (Activation (None, 6, 6, 728)    0           block5_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","block5_sepconv3 (SeparableConv2 (None, 6, 6, 728)    536536      block5_sepconv3_act[0][0]        \n","__________________________________________________________________________________________________\n","block5_sepconv3_bn (BatchNormal (None, 6, 6, 728)    2912        block5_sepconv3[0][0]            \n","__________________________________________________________________________________________________\n","add_39 (Add)                    (None, 6, 6, 728)    0           block5_sepconv3_bn[0][0]         \n","                                                                 add_38[0][0]                     \n","__________________________________________________________________________________________________\n","block6_sepconv1_act (Activation (None, 6, 6, 728)    0           add_39[0][0]                     \n","__________________________________________________________________________________________________\n","block6_sepconv1 (SeparableConv2 (None, 6, 6, 728)    536536      block6_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block6_sepconv1_bn (BatchNormal (None, 6, 6, 728)    2912        block6_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block6_sepconv2_act (Activation (None, 6, 6, 728)    0           block6_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block6_sepconv2 (SeparableConv2 (None, 6, 6, 728)    536536      block6_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block6_sepconv2_bn (BatchNormal (None, 6, 6, 728)    2912        block6_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","block6_sepconv3_act (Activation (None, 6, 6, 728)    0           block6_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","block6_sepconv3 (SeparableConv2 (None, 6, 6, 728)    536536      block6_sepconv3_act[0][0]        \n","__________________________________________________________________________________________________\n","block6_sepconv3_bn (BatchNormal (None, 6, 6, 728)    2912        block6_sepconv3[0][0]            \n","__________________________________________________________________________________________________\n","add_40 (Add)                    (None, 6, 6, 728)    0           block6_sepconv3_bn[0][0]         \n","                                                                 add_39[0][0]                     \n","__________________________________________________________________________________________________\n","block7_sepconv1_act (Activation (None, 6, 6, 728)    0           add_40[0][0]                     \n","__________________________________________________________________________________________________\n","block7_sepconv1 (SeparableConv2 (None, 6, 6, 728)    536536      block7_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block7_sepconv1_bn (BatchNormal (None, 6, 6, 728)    2912        block7_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block7_sepconv2_act (Activation (None, 6, 6, 728)    0           block7_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block7_sepconv2 (SeparableConv2 (None, 6, 6, 728)    536536      block7_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block7_sepconv2_bn (BatchNormal (None, 6, 6, 728)    2912        block7_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","block7_sepconv3_act (Activation (None, 6, 6, 728)    0           block7_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","block7_sepconv3 (SeparableConv2 (None, 6, 6, 728)    536536      block7_sepconv3_act[0][0]        \n","__________________________________________________________________________________________________\n","block7_sepconv3_bn (BatchNormal (None, 6, 6, 728)    2912        block7_sepconv3[0][0]            \n","__________________________________________________________________________________________________\n","add_41 (Add)                    (None, 6, 6, 728)    0           block7_sepconv3_bn[0][0]         \n","                                                                 add_40[0][0]                     \n","__________________________________________________________________________________________________\n","block8_sepconv1_act (Activation (None, 6, 6, 728)    0           add_41[0][0]                     \n","__________________________________________________________________________________________________\n","block8_sepconv1 (SeparableConv2 (None, 6, 6, 728)    536536      block8_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block8_sepconv1_bn (BatchNormal (None, 6, 6, 728)    2912        block8_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block8_sepconv2_act (Activation (None, 6, 6, 728)    0           block8_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block8_sepconv2 (SeparableConv2 (None, 6, 6, 728)    536536      block8_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block8_sepconv2_bn (BatchNormal (None, 6, 6, 728)    2912        block8_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","block8_sepconv3_act (Activation (None, 6, 6, 728)    0           block8_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","block8_sepconv3 (SeparableConv2 (None, 6, 6, 728)    536536      block8_sepconv3_act[0][0]        \n","__________________________________________________________________________________________________\n","block8_sepconv3_bn (BatchNormal (None, 6, 6, 728)    2912        block8_sepconv3[0][0]            \n","__________________________________________________________________________________________________\n","add_42 (Add)                    (None, 6, 6, 728)    0           block8_sepconv3_bn[0][0]         \n","                                                                 add_41[0][0]                     \n","__________________________________________________________________________________________________\n","block9_sepconv1_act (Activation (None, 6, 6, 728)    0           add_42[0][0]                     \n","__________________________________________________________________________________________________\n","block9_sepconv1 (SeparableConv2 (None, 6, 6, 728)    536536      block9_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block9_sepconv1_bn (BatchNormal (None, 6, 6, 728)    2912        block9_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block9_sepconv2_act (Activation (None, 6, 6, 728)    0           block9_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block9_sepconv2 (SeparableConv2 (None, 6, 6, 728)    536536      block9_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block9_sepconv2_bn (BatchNormal (None, 6, 6, 728)    2912        block9_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","block9_sepconv3_act (Activation (None, 6, 6, 728)    0           block9_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","block9_sepconv3 (SeparableConv2 (None, 6, 6, 728)    536536      block9_sepconv3_act[0][0]        \n","__________________________________________________________________________________________________\n","block9_sepconv3_bn (BatchNormal (None, 6, 6, 728)    2912        block9_sepconv3[0][0]            \n","__________________________________________________________________________________________________\n","add_43 (Add)                    (None, 6, 6, 728)    0           block9_sepconv3_bn[0][0]         \n","                                                                 add_42[0][0]                     \n","__________________________________________________________________________________________________\n","block10_sepconv1_act (Activatio (None, 6, 6, 728)    0           add_43[0][0]                     \n","__________________________________________________________________________________________________\n","block10_sepconv1 (SeparableConv (None, 6, 6, 728)    536536      block10_sepconv1_act[0][0]       \n","__________________________________________________________________________________________________\n","block10_sepconv1_bn (BatchNorma (None, 6, 6, 728)    2912        block10_sepconv1[0][0]           \n","__________________________________________________________________________________________________\n","block10_sepconv2_act (Activatio (None, 6, 6, 728)    0           block10_sepconv1_bn[0][0]        \n","__________________________________________________________________________________________________\n","block10_sepconv2 (SeparableConv (None, 6, 6, 728)    536536      block10_sepconv2_act[0][0]       \n","__________________________________________________________________________________________________\n","block10_sepconv2_bn (BatchNorma (None, 6, 6, 728)    2912        block10_sepconv2[0][0]           \n","__________________________________________________________________________________________________\n","block10_sepconv3_act (Activatio (None, 6, 6, 728)    0           block10_sepconv2_bn[0][0]        \n","__________________________________________________________________________________________________\n","block10_sepconv3 (SeparableConv (None, 6, 6, 728)    536536      block10_sepconv3_act[0][0]       \n","__________________________________________________________________________________________________\n","block10_sepconv3_bn (BatchNorma (None, 6, 6, 728)    2912        block10_sepconv3[0][0]           \n","__________________________________________________________________________________________________\n","add_44 (Add)                    (None, 6, 6, 728)    0           block10_sepconv3_bn[0][0]        \n","                                                                 add_43[0][0]                     \n","__________________________________________________________________________________________________\n","block11_sepconv1_act (Activatio (None, 6, 6, 728)    0           add_44[0][0]                     \n","__________________________________________________________________________________________________\n","block11_sepconv1 (SeparableConv (None, 6, 6, 728)    536536      block11_sepconv1_act[0][0]       \n","__________________________________________________________________________________________________\n","block11_sepconv1_bn (BatchNorma (None, 6, 6, 728)    2912        block11_sepconv1[0][0]           \n","__________________________________________________________________________________________________\n","block11_sepconv2_act (Activatio (None, 6, 6, 728)    0           block11_sepconv1_bn[0][0]        \n","__________________________________________________________________________________________________\n","block11_sepconv2 (SeparableConv (None, 6, 6, 728)    536536      block11_sepconv2_act[0][0]       \n","__________________________________________________________________________________________________\n","block11_sepconv2_bn (BatchNorma (None, 6, 6, 728)    2912        block11_sepconv2[0][0]           \n","__________________________________________________________________________________________________\n","block11_sepconv3_act (Activatio (None, 6, 6, 728)    0           block11_sepconv2_bn[0][0]        \n","__________________________________________________________________________________________________\n","block11_sepconv3 (SeparableConv (None, 6, 6, 728)    536536      block11_sepconv3_act[0][0]       \n","__________________________________________________________________________________________________\n","block11_sepconv3_bn (BatchNorma (None, 6, 6, 728)    2912        block11_sepconv3[0][0]           \n","__________________________________________________________________________________________________\n","add_45 (Add)                    (None, 6, 6, 728)    0           block11_sepconv3_bn[0][0]        \n","                                                                 add_44[0][0]                     \n","__________________________________________________________________________________________________\n","block12_sepconv1_act (Activatio (None, 6, 6, 728)    0           add_45[0][0]                     \n","__________________________________________________________________________________________________\n","block12_sepconv1 (SeparableConv (None, 6, 6, 728)    536536      block12_sepconv1_act[0][0]       \n","__________________________________________________________________________________________________\n","block12_sepconv1_bn (BatchNorma (None, 6, 6, 728)    2912        block12_sepconv1[0][0]           \n","__________________________________________________________________________________________________\n","block12_sepconv2_act (Activatio (None, 6, 6, 728)    0           block12_sepconv1_bn[0][0]        \n","__________________________________________________________________________________________________\n","block12_sepconv2 (SeparableConv (None, 6, 6, 728)    536536      block12_sepconv2_act[0][0]       \n","__________________________________________________________________________________________________\n","block12_sepconv2_bn (BatchNorma (None, 6, 6, 728)    2912        block12_sepconv2[0][0]           \n","__________________________________________________________________________________________________\n","block12_sepconv3_act (Activatio (None, 6, 6, 728)    0           block12_sepconv2_bn[0][0]        \n","__________________________________________________________________________________________________\n","block12_sepconv3 (SeparableConv (None, 6, 6, 728)    536536      block12_sepconv3_act[0][0]       \n","__________________________________________________________________________________________________\n","block12_sepconv3_bn (BatchNorma (None, 6, 6, 728)    2912        block12_sepconv3[0][0]           \n","__________________________________________________________________________________________________\n","add_46 (Add)                    (None, 6, 6, 728)    0           block12_sepconv3_bn[0][0]        \n","                                                                 add_45[0][0]                     \n","__________________________________________________________________________________________________\n","block13_sepconv1_act (Activatio (None, 6, 6, 728)    0           add_46[0][0]                     \n","__________________________________________________________________________________________________\n","block13_sepconv1 (SeparableConv (None, 6, 6, 728)    536536      block13_sepconv1_act[0][0]       \n","__________________________________________________________________________________________________\n","block13_sepconv1_bn (BatchNorma (None, 6, 6, 728)    2912        block13_sepconv1[0][0]           \n","__________________________________________________________________________________________________\n","block13_sepconv2_act (Activatio (None, 6, 6, 728)    0           block13_sepconv1_bn[0][0]        \n","__________________________________________________________________________________________________\n","block13_sepconv2 (SeparableConv (None, 6, 6, 1024)   752024      block13_sepconv2_act[0][0]       \n","__________________________________________________________________________________________________\n","block13_sepconv2_bn (BatchNorma (None, 6, 6, 1024)   4096        block13_sepconv2[0][0]           \n","__________________________________________________________________________________________________\n","conv2d_15 (Conv2D)              (None, 3, 3, 1024)   745472      add_46[0][0]                     \n","__________________________________________________________________________________________________\n","block13_pool (MaxPooling2D)     (None, 3, 3, 1024)   0           block13_sepconv2_bn[0][0]        \n","__________________________________________________________________________________________________\n","batch_normalization_21 (BatchNo (None, 3, 3, 1024)   4096        conv2d_15[0][0]                  \n","__________________________________________________________________________________________________\n","add_47 (Add)                    (None, 3, 3, 1024)   0           block13_pool[0][0]               \n","                                                                 batch_normalization_21[0][0]     \n","__________________________________________________________________________________________________\n","block14_sepconv1 (SeparableConv (None, 3, 3, 1536)   1582080     add_47[0][0]                     \n","__________________________________________________________________________________________________\n","block14_sepconv1_bn (BatchNorma (None, 3, 3, 1536)   6144        block14_sepconv1[0][0]           \n","__________________________________________________________________________________________________\n","block14_sepconv1_act (Activatio (None, 3, 3, 1536)   0           block14_sepconv1_bn[0][0]        \n","__________________________________________________________________________________________________\n","block14_sepconv2 (SeparableConv (None, 3, 3, 2048)   3159552     block14_sepconv1_act[0][0]       \n","__________________________________________________________________________________________________\n","block14_sepconv2_bn (BatchNorma (None, 3, 3, 2048)   8192        block14_sepconv2[0][0]           \n","__________________________________________________________________________________________________\n","block14_sepconv2_act (Activatio (None, 3, 3, 2048)   0           block14_sepconv2_bn[0][0]        \n","==================================================================================================\n","Total params: 20,861,480\n","Trainable params: 3,195,232\n","Non-trainable params: 17,666,248\n","__________________________________________________________________________________________________\n","Model: \"Xception_ADModel\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","tensor (InputLayer)          [(None, 100, 100, 3)]     0         \n","_________________________________________________________________\n","xception (Functional)        (None, 3, 3, 2048)        20861480  \n","_________________________________________________________________\n","flatten_6 (Flatten)          (None, 18432)             0         \n","_________________________________________________________________\n","dropout_11 (Dropout)         (None, 18432)             0         \n","_________________________________________________________________\n","dense_12 (Dense)             (None, 128)               2359424   \n","_________________________________________________________________\n","batch_normalization_22 (Batc (None, 128)               512       \n","_________________________________________________________________\n","leaky_re_lu_6 (LeakyReLU)    (None, 128)               0         \n","_________________________________________________________________\n","dropout_12 (Dropout)         (None, 128)               0         \n","_________________________________________________________________\n","dense_13 (Dense)             (None, 4)                 516       \n","=================================================================\n","Total params: 23,221,932\n","Trainable params: 5,555,428\n","Non-trainable params: 17,666,504\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TVbtWj9t1oqo","executionInfo":{"status":"ok","timestamp":1606057680269,"user_tz":300,"elapsed":1050510,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"89ff8458-fbd8-453a-8009-544a9cbed844"},"source":["'''train the nsl model'''\n","graph_reg_history = graph_reg_model.fit(train_image_dataset, \n","                                        validation_data=test_image_dataset,\n","                                        callbacks = [callback_checkpoints, callback_earlystop],\n","                                        epochs=params.train_epoch,\n","                                        verbose=1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Note: default Xception not includes top and has imagenet weights. It is not a trainable model in ADModelBuilder. Please setup trainable layers in setup_Xception function based on the \"Layer Number\"\n","Model: \"xception\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_4 (InputLayer)            [(None, 100, 100, 3) 0                                            \n","__________________________________________________________________________________________________\n","block1_conv1 (Conv2D)           (None, 49, 49, 32)   864         input_4[0][0]                    \n","__________________________________________________________________________________________________\n","block1_conv1_bn (BatchNormaliza (None, 49, 49, 32)   128         block1_conv1[0][0]               \n","__________________________________________________________________________________________________\n","block1_conv1_act (Activation)   (None, 49, 49, 32)   0           block1_conv1_bn[0][0]            \n","__________________________________________________________________________________________________\n","block1_conv2 (Conv2D)           (None, 47, 47, 64)   18432       block1_conv1_act[0][0]           \n","__________________________________________________________________________________________________\n","block1_conv2_bn (BatchNormaliza (None, 47, 47, 64)   256         block1_conv2[0][0]               \n","__________________________________________________________________________________________________\n","block1_conv2_act (Activation)   (None, 47, 47, 64)   0           block1_conv2_bn[0][0]            \n","__________________________________________________________________________________________________\n","block2_sepconv1 (SeparableConv2 (None, 47, 47, 128)  8768        block1_conv2_act[0][0]           \n","__________________________________________________________________________________________________\n","block2_sepconv1_bn (BatchNormal (None, 47, 47, 128)  512         block2_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block2_sepconv2_act (Activation (None, 47, 47, 128)  0           block2_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block2_sepconv2 (SeparableConv2 (None, 47, 47, 128)  17536       block2_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block2_sepconv2_bn (BatchNormal (None, 47, 47, 128)  512         block2_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","conv2d_12 (Conv2D)              (None, 24, 24, 128)  8192        block1_conv2_act[0][0]           \n","__________________________________________________________________________________________________\n","block2_pool (MaxPooling2D)      (None, 24, 24, 128)  0           block2_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","batch_normalization_15 (BatchNo (None, 24, 24, 128)  512         conv2d_12[0][0]                  \n","__________________________________________________________________________________________________\n","add_36 (Add)                    (None, 24, 24, 128)  0           block2_pool[0][0]                \n","                                                                 batch_normalization_15[0][0]     \n","__________________________________________________________________________________________________\n","block3_sepconv1_act (Activation (None, 24, 24, 128)  0           add_36[0][0]                     \n","__________________________________________________________________________________________________\n","block3_sepconv1 (SeparableConv2 (None, 24, 24, 256)  33920       block3_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block3_sepconv1_bn (BatchNormal (None, 24, 24, 256)  1024        block3_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block3_sepconv2_act (Activation (None, 24, 24, 256)  0           block3_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block3_sepconv2 (SeparableConv2 (None, 24, 24, 256)  67840       block3_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block3_sepconv2_bn (BatchNormal (None, 24, 24, 256)  1024        block3_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","conv2d_13 (Conv2D)              (None, 12, 12, 256)  32768       add_36[0][0]                     \n","__________________________________________________________________________________________________\n","block3_pool (MaxPooling2D)      (None, 12, 12, 256)  0           block3_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","batch_normalization_16 (BatchNo (None, 12, 12, 256)  1024        conv2d_13[0][0]                  \n","__________________________________________________________________________________________________\n","add_37 (Add)                    (None, 12, 12, 256)  0           block3_pool[0][0]                \n","                                                                 batch_normalization_16[0][0]     \n","__________________________________________________________________________________________________\n","block4_sepconv1_act (Activation (None, 12, 12, 256)  0           add_37[0][0]                     \n","__________________________________________________________________________________________________\n","block4_sepconv1 (SeparableConv2 (None, 12, 12, 728)  188672      block4_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block4_sepconv1_bn (BatchNormal (None, 12, 12, 728)  2912        block4_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block4_sepconv2_act (Activation (None, 12, 12, 728)  0           block4_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block4_sepconv2 (SeparableConv2 (None, 12, 12, 728)  536536      block4_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block4_sepconv2_bn (BatchNormal (None, 12, 12, 728)  2912        block4_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","conv2d_14 (Conv2D)              (None, 6, 6, 728)    186368      add_37[0][0]                     \n","__________________________________________________________________________________________________\n","block4_pool (MaxPooling2D)      (None, 6, 6, 728)    0           block4_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","batch_normalization_17 (BatchNo (None, 6, 6, 728)    2912        conv2d_14[0][0]                  \n","__________________________________________________________________________________________________\n","add_38 (Add)                    (None, 6, 6, 728)    0           block4_pool[0][0]                \n","                                                                 batch_normalization_17[0][0]     \n","__________________________________________________________________________________________________\n","block5_sepconv1_act (Activation (None, 6, 6, 728)    0           add_38[0][0]                     \n","__________________________________________________________________________________________________\n","block5_sepconv1 (SeparableConv2 (None, 6, 6, 728)    536536      block5_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block5_sepconv1_bn (BatchNormal (None, 6, 6, 728)    2912        block5_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block5_sepconv2_act (Activation (None, 6, 6, 728)    0           block5_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block5_sepconv2 (SeparableConv2 (None, 6, 6, 728)    536536      block5_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block5_sepconv2_bn (BatchNormal (None, 6, 6, 728)    2912        block5_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","block5_sepconv3_act (Activation (None, 6, 6, 728)    0           block5_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","block5_sepconv3 (SeparableConv2 (None, 6, 6, 728)    536536      block5_sepconv3_act[0][0]        \n","__________________________________________________________________________________________________\n","block5_sepconv3_bn (BatchNormal (None, 6, 6, 728)    2912        block5_sepconv3[0][0]            \n","__________________________________________________________________________________________________\n","add_39 (Add)                    (None, 6, 6, 728)    0           block5_sepconv3_bn[0][0]         \n","                                                                 add_38[0][0]                     \n","__________________________________________________________________________________________________\n","block6_sepconv1_act (Activation (None, 6, 6, 728)    0           add_39[0][0]                     \n","__________________________________________________________________________________________________\n","block6_sepconv1 (SeparableConv2 (None, 6, 6, 728)    536536      block6_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block6_sepconv1_bn (BatchNormal (None, 6, 6, 728)    2912        block6_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block6_sepconv2_act (Activation (None, 6, 6, 728)    0           block6_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block6_sepconv2 (SeparableConv2 (None, 6, 6, 728)    536536      block6_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block6_sepconv2_bn (BatchNormal (None, 6, 6, 728)    2912        block6_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","block6_sepconv3_act (Activation (None, 6, 6, 728)    0           block6_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","block6_sepconv3 (SeparableConv2 (None, 6, 6, 728)    536536      block6_sepconv3_act[0][0]        \n","__________________________________________________________________________________________________\n","block6_sepconv3_bn (BatchNormal (None, 6, 6, 728)    2912        block6_sepconv3[0][0]            \n","__________________________________________________________________________________________________\n","add_40 (Add)                    (None, 6, 6, 728)    0           block6_sepconv3_bn[0][0]         \n","                                                                 add_39[0][0]                     \n","__________________________________________________________________________________________________\n","block7_sepconv1_act (Activation (None, 6, 6, 728)    0           add_40[0][0]                     \n","__________________________________________________________________________________________________\n","block7_sepconv1 (SeparableConv2 (None, 6, 6, 728)    536536      block7_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block7_sepconv1_bn (BatchNormal (None, 6, 6, 728)    2912        block7_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block7_sepconv2_act (Activation (None, 6, 6, 728)    0           block7_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block7_sepconv2 (SeparableConv2 (None, 6, 6, 728)    536536      block7_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block7_sepconv2_bn (BatchNormal (None, 6, 6, 728)    2912        block7_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","block7_sepconv3_act (Activation (None, 6, 6, 728)    0           block7_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","block7_sepconv3 (SeparableConv2 (None, 6, 6, 728)    536536      block7_sepconv3_act[0][0]        \n","__________________________________________________________________________________________________\n","block7_sepconv3_bn (BatchNormal (None, 6, 6, 728)    2912        block7_sepconv3[0][0]            \n","__________________________________________________________________________________________________\n","add_41 (Add)                    (None, 6, 6, 728)    0           block7_sepconv3_bn[0][0]         \n","                                                                 add_40[0][0]                     \n","__________________________________________________________________________________________________\n","block8_sepconv1_act (Activation (None, 6, 6, 728)    0           add_41[0][0]                     \n","__________________________________________________________________________________________________\n","block8_sepconv1 (SeparableConv2 (None, 6, 6, 728)    536536      block8_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block8_sepconv1_bn (BatchNormal (None, 6, 6, 728)    2912        block8_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block8_sepconv2_act (Activation (None, 6, 6, 728)    0           block8_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block8_sepconv2 (SeparableConv2 (None, 6, 6, 728)    536536      block8_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block8_sepconv2_bn (BatchNormal (None, 6, 6, 728)    2912        block8_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","block8_sepconv3_act (Activation (None, 6, 6, 728)    0           block8_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","block8_sepconv3 (SeparableConv2 (None, 6, 6, 728)    536536      block8_sepconv3_act[0][0]        \n","__________________________________________________________________________________________________\n","block8_sepconv3_bn (BatchNormal (None, 6, 6, 728)    2912        block8_sepconv3[0][0]            \n","__________________________________________________________________________________________________\n","add_42 (Add)                    (None, 6, 6, 728)    0           block8_sepconv3_bn[0][0]         \n","                                                                 add_41[0][0]                     \n","__________________________________________________________________________________________________\n","block9_sepconv1_act (Activation (None, 6, 6, 728)    0           add_42[0][0]                     \n","__________________________________________________________________________________________________\n","block9_sepconv1 (SeparableConv2 (None, 6, 6, 728)    536536      block9_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block9_sepconv1_bn (BatchNormal (None, 6, 6, 728)    2912        block9_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block9_sepconv2_act (Activation (None, 6, 6, 728)    0           block9_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block9_sepconv2 (SeparableConv2 (None, 6, 6, 728)    536536      block9_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block9_sepconv2_bn (BatchNormal (None, 6, 6, 728)    2912        block9_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","block9_sepconv3_act (Activation (None, 6, 6, 728)    0           block9_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","block9_sepconv3 (SeparableConv2 (None, 6, 6, 728)    536536      block9_sepconv3_act[0][0]        \n","__________________________________________________________________________________________________\n","block9_sepconv3_bn (BatchNormal (None, 6, 6, 728)    2912        block9_sepconv3[0][0]            \n","__________________________________________________________________________________________________\n","add_43 (Add)                    (None, 6, 6, 728)    0           block9_sepconv3_bn[0][0]         \n","                                                                 add_42[0][0]                     \n","__________________________________________________________________________________________________\n","block10_sepconv1_act (Activatio (None, 6, 6, 728)    0           add_43[0][0]                     \n","__________________________________________________________________________________________________\n","block10_sepconv1 (SeparableConv (None, 6, 6, 728)    536536      block10_sepconv1_act[0][0]       \n","__________________________________________________________________________________________________\n","block10_sepconv1_bn (BatchNorma (None, 6, 6, 728)    2912        block10_sepconv1[0][0]           \n","__________________________________________________________________________________________________\n","block10_sepconv2_act (Activatio (None, 6, 6, 728)    0           block10_sepconv1_bn[0][0]        \n","__________________________________________________________________________________________________\n","block10_sepconv2 (SeparableConv (None, 6, 6, 728)    536536      block10_sepconv2_act[0][0]       \n","__________________________________________________________________________________________________\n","block10_sepconv2_bn (BatchNorma (None, 6, 6, 728)    2912        block10_sepconv2[0][0]           \n","__________________________________________________________________________________________________\n","block10_sepconv3_act (Activatio (None, 6, 6, 728)    0           block10_sepconv2_bn[0][0]        \n","__________________________________________________________________________________________________\n","block10_sepconv3 (SeparableConv (None, 6, 6, 728)    536536      block10_sepconv3_act[0][0]       \n","__________________________________________________________________________________________________\n","block10_sepconv3_bn (BatchNorma (None, 6, 6, 728)    2912        block10_sepconv3[0][0]           \n","__________________________________________________________________________________________________\n","add_44 (Add)                    (None, 6, 6, 728)    0           block10_sepconv3_bn[0][0]        \n","                                                                 add_43[0][0]                     \n","__________________________________________________________________________________________________\n","block11_sepconv1_act (Activatio (None, 6, 6, 728)    0           add_44[0][0]                     \n","__________________________________________________________________________________________________\n","block11_sepconv1 (SeparableConv (None, 6, 6, 728)    536536      block11_sepconv1_act[0][0]       \n","__________________________________________________________________________________________________\n","block11_sepconv1_bn (BatchNorma (None, 6, 6, 728)    2912        block11_sepconv1[0][0]           \n","__________________________________________________________________________________________________\n","block11_sepconv2_act (Activatio (None, 6, 6, 728)    0           block11_sepconv1_bn[0][0]        \n","__________________________________________________________________________________________________\n","block11_sepconv2 (SeparableConv (None, 6, 6, 728)    536536      block11_sepconv2_act[0][0]       \n","__________________________________________________________________________________________________\n","block11_sepconv2_bn (BatchNorma (None, 6, 6, 728)    2912        block11_sepconv2[0][0]           \n","__________________________________________________________________________________________________\n","block11_sepconv3_act (Activatio (None, 6, 6, 728)    0           block11_sepconv2_bn[0][0]        \n","__________________________________________________________________________________________________\n","block11_sepconv3 (SeparableConv (None, 6, 6, 728)    536536      block11_sepconv3_act[0][0]       \n","__________________________________________________________________________________________________\n","block11_sepconv3_bn (BatchNorma (None, 6, 6, 728)    2912        block11_sepconv3[0][0]           \n","__________________________________________________________________________________________________\n","add_45 (Add)                    (None, 6, 6, 728)    0           block11_sepconv3_bn[0][0]        \n","                                                                 add_44[0][0]                     \n","__________________________________________________________________________________________________\n","block12_sepconv1_act (Activatio (None, 6, 6, 728)    0           add_45[0][0]                     \n","__________________________________________________________________________________________________\n","block12_sepconv1 (SeparableConv (None, 6, 6, 728)    536536      block12_sepconv1_act[0][0]       \n","__________________________________________________________________________________________________\n","block12_sepconv1_bn (BatchNorma (None, 6, 6, 728)    2912        block12_sepconv1[0][0]           \n","__________________________________________________________________________________________________\n","block12_sepconv2_act (Activatio (None, 6, 6, 728)    0           block12_sepconv1_bn[0][0]        \n","__________________________________________________________________________________________________\n","block12_sepconv2 (SeparableConv (None, 6, 6, 728)    536536      block12_sepconv2_act[0][0]       \n","__________________________________________________________________________________________________\n","block12_sepconv2_bn (BatchNorma (None, 6, 6, 728)    2912        block12_sepconv2[0][0]           \n","__________________________________________________________________________________________________\n","block12_sepconv3_act (Activatio (None, 6, 6, 728)    0           block12_sepconv2_bn[0][0]        \n","__________________________________________________________________________________________________\n","block12_sepconv3 (SeparableConv (None, 6, 6, 728)    536536      block12_sepconv3_act[0][0]       \n","__________________________________________________________________________________________________\n","block12_sepconv3_bn (BatchNorma (None, 6, 6, 728)    2912        block12_sepconv3[0][0]           \n","__________________________________________________________________________________________________\n","add_46 (Add)                    (None, 6, 6, 728)    0           block12_sepconv3_bn[0][0]        \n","                                                                 add_45[0][0]                     \n","__________________________________________________________________________________________________\n","block13_sepconv1_act (Activatio (None, 6, 6, 728)    0           add_46[0][0]                     \n","__________________________________________________________________________________________________\n","block13_sepconv1 (SeparableConv (None, 6, 6, 728)    536536      block13_sepconv1_act[0][0]       \n","__________________________________________________________________________________________________\n","block13_sepconv1_bn (BatchNorma (None, 6, 6, 728)    2912        block13_sepconv1[0][0]           \n","__________________________________________________________________________________________________\n","block13_sepconv2_act (Activatio (None, 6, 6, 728)    0           block13_sepconv1_bn[0][0]        \n","__________________________________________________________________________________________________\n","block13_sepconv2 (SeparableConv (None, 6, 6, 1024)   752024      block13_sepconv2_act[0][0]       \n","__________________________________________________________________________________________________\n","block13_sepconv2_bn (BatchNorma (None, 6, 6, 1024)   4096        block13_sepconv2[0][0]           \n","__________________________________________________________________________________________________\n","conv2d_15 (Conv2D)              (None, 3, 3, 1024)   745472      add_46[0][0]                     \n","__________________________________________________________________________________________________\n","block13_pool (MaxPooling2D)     (None, 3, 3, 1024)   0           block13_sepconv2_bn[0][0]        \n","__________________________________________________________________________________________________\n","batch_normalization_18 (BatchNo (None, 3, 3, 1024)   4096        conv2d_15[0][0]                  \n","__________________________________________________________________________________________________\n","add_47 (Add)                    (None, 3, 3, 1024)   0           block13_pool[0][0]               \n","                                                                 batch_normalization_18[0][0]     \n","__________________________________________________________________________________________________\n","block14_sepconv1 (SeparableConv (None, 3, 3, 1536)   1582080     add_47[0][0]                     \n","__________________________________________________________________________________________________\n","block14_sepconv1_bn (BatchNorma (None, 3, 3, 1536)   6144        block14_sepconv1[0][0]           \n","__________________________________________________________________________________________________\n","block14_sepconv1_act (Activatio (None, 3, 3, 1536)   0           block14_sepconv1_bn[0][0]        \n","__________________________________________________________________________________________________\n","block14_sepconv2 (SeparableConv (None, 3, 3, 2048)   3159552     block14_sepconv1_act[0][0]       \n","__________________________________________________________________________________________________\n","block14_sepconv2_bn (BatchNorma (None, 3, 3, 2048)   8192        block14_sepconv2[0][0]           \n","__________________________________________________________________________________________________\n","block14_sepconv2_act (Activatio (None, 3, 3, 2048)   0           block14_sepconv2_bn[0][0]        \n","==================================================================================================\n","Total params: 20,861,480\n","Trainable params: 3,195,232\n","Non-trainable params: 17,666,248\n","__________________________________________________________________________________________________\n","Model: \"Xception_ADModel\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","tensor (InputLayer)          [(None, 100, 100, 3)]     0         \n","_________________________________________________________________\n","xception (Functional)        (None, 3, 3, 2048)        20861480  \n","_________________________________________________________________\n","flatten_3 (Flatten)          (None, 18432)             0         \n","_________________________________________________________________\n","dropout_6 (Dropout)          (None, 18432)             0         \n","_________________________________________________________________\n","dense_6 (Dense)              (None, 128)               2359424   \n","_________________________________________________________________\n","batch_normalization_19 (Batc (None, 128)               512       \n","_________________________________________________________________\n","leaky_re_lu_3 (LeakyReLU)    (None, 128)               0         \n","_________________________________________________________________\n","dropout_7 (Dropout)          (None, 128)               0         \n","_________________________________________________________________\n","dense_7 (Dense)              (None, 4)                 516       \n","=================================================================\n","Total params: 23,221,932\n","Trainable params: 5,555,428\n","Non-trainable params: 17,666,504\n","_________________________________________________________________\n","Epoch 1/50\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py:543: UserWarning: Input dict contained keys ['id'] which did not match any model input. They will be ignored by the model.\n","  [n for n in tensors.keys() if n not in ref_input_names])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:432: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"],"name":"stderr"},{"output_type":"stream","text":["      2/Unknown - 1s 297ms/step - loss: 0.0806 - accuracy: 0.9766 - auc: 0.9992 - f1_score: 0.9725 - scaled_graph_loss: 0.0031WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2242s vs `on_train_batch_end` time: 0.3688s). Check your callbacks.\n","    137/Unknown - 80s 587ms/step - loss: 0.0793 - accuracy: 0.9744 - auc: 0.9987 - f1_score: 0.9745 - scaled_graph_loss: 0.0028\n","Epoch 00001: val_accuracy improved from -inf to 0.95690, saving model to /content/drive/My Drive/Projects/codes/Xception_NSL_model_checkpoints/xception_model_new_98\n","137/137 [==============================] - 87s 635ms/step - loss: 0.0793 - accuracy: 0.9744 - auc: 0.9987 - f1_score: 0.9745 - scaled_graph_loss: 0.0028 - val_loss: 0.1284 - val_accuracy: 0.9569 - val_auc: 0.9962 - val_f1_score: 0.9694\n","Epoch 2/50\n","137/137 [==============================] - ETA: 0s - loss: 0.0607 - accuracy: 0.9817 - auc: 0.9991 - f1_score: 0.9816 - scaled_graph_loss: 0.0022\n","Epoch 00002: val_accuracy did not improve from 0.95690\n","137/137 [==============================] - 85s 617ms/step - loss: 0.0607 - accuracy: 0.9817 - auc: 0.9991 - f1_score: 0.9816 - scaled_graph_loss: 0.0022 - val_loss: 0.1722 - val_accuracy: 0.9420 - val_auc: 0.9935 - val_f1_score: 0.9422\n","Epoch 3/50\n","137/137 [==============================] - ETA: 0s - loss: 0.0487 - accuracy: 0.9830 - auc: 0.9996 - f1_score: 0.9831 - scaled_graph_loss: 0.0018\n","Epoch 00003: val_accuracy improved from 0.95690 to 0.97048, saving model to /content/drive/My Drive/Projects/codes/Xception_NSL_model_checkpoints/xception_model_new_98\n","137/137 [==============================] - 86s 625ms/step - loss: 0.0487 - accuracy: 0.9830 - auc: 0.9996 - f1_score: 0.9831 - scaled_graph_loss: 0.0018 - val_loss: 0.0989 - val_accuracy: 0.9705 - val_auc: 0.9969 - val_f1_score: 0.9706\n","Epoch 4/50\n","137/137 [==============================] - ETA: 0s - loss: 0.0364 - accuracy: 0.9889 - auc: 0.9998 - f1_score: 0.9889 - scaled_graph_loss: 0.0013\n","Epoch 00004: val_accuracy did not improve from 0.97048\n","137/137 [==============================] - 85s 617ms/step - loss: 0.0364 - accuracy: 0.9889 - auc: 0.9998 - f1_score: 0.9889 - scaled_graph_loss: 0.0013 - val_loss: 0.1047 - val_accuracy: 0.9687 - val_auc: 0.9966 - val_f1_score: 0.9693\n","Epoch 5/50\n","137/137 [==============================] - ETA: 0s - loss: 0.0245 - accuracy: 0.9926 - auc: 0.9998 - f1_score: 0.9927 - scaled_graph_loss: 9.2308e-04\n","Epoch 00005: val_accuracy did not improve from 0.97048\n","137/137 [==============================] - 84s 617ms/step - loss: 0.0245 - accuracy: 0.9926 - auc: 0.9998 - f1_score: 0.9927 - scaled_graph_loss: 9.2308e-04 - val_loss: 0.0981 - val_accuracy: 0.9702 - val_auc: 0.9965 - val_f1_score: 0.9701\n","Epoch 6/50\n","137/137 [==============================] - ETA: 0s - loss: 0.0237 - accuracy: 0.9924 - auc: 0.9999 - f1_score: 0.9921 - scaled_graph_loss: 8.9044e-04\n","Epoch 00006: val_accuracy improved from 0.97048 to 0.97466, saving model to /content/drive/My Drive/Projects/codes/Xception_NSL_model_checkpoints/xception_model_new_98\n","137/137 [==============================] - 85s 624ms/step - loss: 0.0237 - accuracy: 0.9924 - auc: 0.9999 - f1_score: 0.9921 - scaled_graph_loss: 8.9044e-04 - val_loss: 0.0839 - val_accuracy: 0.9747 - val_auc: 0.9972 - val_f1_score: 0.9750\n","Epoch 7/50\n","137/137 [==============================] - ETA: 0s - loss: 0.0160 - accuracy: 0.9960 - auc: 1.0000 - f1_score: 0.9961 - scaled_graph_loss: 6.6281e-04\n","Epoch 00007: val_accuracy improved from 0.97466 to 0.97571, saving model to /content/drive/My Drive/Projects/codes/Xception_NSL_model_checkpoints/xception_model_new_98\n","137/137 [==============================] - 86s 626ms/step - loss: 0.0160 - accuracy: 0.9960 - auc: 1.0000 - f1_score: 0.9961 - scaled_graph_loss: 6.6281e-04 - val_loss: 0.0918 - val_accuracy: 0.9757 - val_auc: 0.9966 - val_f1_score: 0.9756\n","Epoch 8/50\n","137/137 [==============================] - ETA: 0s - loss: 0.0221 - accuracy: 0.9935 - auc: 0.9998 - f1_score: 0.9935 - scaled_graph_loss: 7.9495e-04\n","Epoch 00008: val_accuracy did not improve from 0.97571\n","137/137 [==============================] - 84s 616ms/step - loss: 0.0221 - accuracy: 0.9935 - auc: 0.9998 - f1_score: 0.9935 - scaled_graph_loss: 7.9495e-04 - val_loss: 0.0923 - val_accuracy: 0.9747 - val_auc: 0.9960 - val_f1_score: 0.9742\n","Epoch 9/50\n","137/137 [==============================] - ETA: 0s - loss: 0.0213 - accuracy: 0.9929 - auc: 0.9999 - f1_score: 0.9929 - scaled_graph_loss: 8.2664e-04\n","Epoch 00009: val_accuracy did not improve from 0.97571\n","137/137 [==============================] - 85s 618ms/step - loss: 0.0213 - accuracy: 0.9929 - auc: 0.9999 - f1_score: 0.9929 - scaled_graph_loss: 8.2664e-04 - val_loss: 0.0948 - val_accuracy: 0.9741 - val_auc: 0.9965 - val_f1_score: 0.9741\n","Epoch 10/50\n","137/137 [==============================] - ETA: 0s - loss: 0.0250 - accuracy: 0.9919 - auc: 0.9997 - f1_score: 0.9919 - scaled_graph_loss: 9.2941e-04\n","Epoch 00010: val_accuracy did not improve from 0.97571\n","137/137 [==============================] - 84s 616ms/step - loss: 0.0250 - accuracy: 0.9919 - auc: 0.9997 - f1_score: 0.9919 - scaled_graph_loss: 9.2941e-04 - val_loss: 0.0962 - val_accuracy: 0.9734 - val_auc: 0.9961 - val_f1_score: 0.9733\n","Epoch 11/50\n","137/137 [==============================] - ETA: 0s - loss: 0.0326 - accuracy: 0.9887 - auc: 0.9997 - f1_score: 0.9888 - scaled_graph_loss: 0.0012\n","Epoch 00011: val_accuracy did not improve from 0.97571\n","137/137 [==============================] - 84s 616ms/step - loss: 0.0326 - accuracy: 0.9887 - auc: 0.9997 - f1_score: 0.9888 - scaled_graph_loss: 0.0012 - val_loss: 0.1056 - val_accuracy: 0.9702 - val_auc: 0.9958 - val_f1_score: 0.9698\n","Epoch 12/50\n","137/137 [==============================] - ETA: 0s - loss: 0.0202 - accuracy: 0.9942 - auc: 0.9997 - f1_score: 0.9942 - scaled_graph_loss: 7.1435e-04\n","Epoch 00012: val_accuracy improved from 0.97571 to 0.98250, saving model to /content/drive/My Drive/Projects/codes/Xception_NSL_model_checkpoints/xception_model_new_98\n","137/137 [==============================] - 85s 623ms/step - loss: 0.0202 - accuracy: 0.9942 - auc: 0.9997 - f1_score: 0.9942 - scaled_graph_loss: 7.1435e-04 - val_loss: 0.0692 - val_accuracy: 0.9825 - val_auc: 0.9970 - val_f1_score: 0.9824\n","Epoch 00013: early stopping\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oy7GjSCq9Gtw","executionInfo":{"status":"ok","timestamp":1606057683877,"user_tz":300,"elapsed":1042122,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"59009e08-e54b-40d6-8ed8-ceff3424664c"},"source":["'''evaluate the model'''\n","graph_reg_model.evaluate(test_image_dataset)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["60/60 [==============================] - 2s 34ms/step - loss: 0.0692 - accuracy: 0.9825 - auc: 0.9970 - f1_score: 0.9824\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[0.06918579339981079,\n"," 0.9824973940849304,\n"," 0.9970408082008362,\n"," 0.9823644757270813]"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"HYv6Ly9Y9GwB"},"source":["'''plot confusion mat & calc acc for each label'''\n","test_image_dataset = NSLDataFormat.generate_test_tfr_image_tensor(path_list=tfr_list_test, \n","                                                                  batch_size=4000, \n","                                                                  size=(100,100),\n","                                                                  channels=3,\n","                                                                  shuffle=True)\n","data, data_label = iter(test_image_dataset).get_next()\n","data = data[\"tensor\"]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":518},"id":"i82NDBcl9GyF","executionInfo":{"status":"ok","timestamp":1606257703694,"user_tz":300,"elapsed":4985,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"b6d11f58-2807-46c8-d4e4-04fbbdaf2a8a"},"source":["ADModelBuilder.plot_confusion_mat(model=graph_reg_model, data=data, data_label=data_label, title=\"Xception_NSL\", figsize=(6,6))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n","WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x432 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1gb6XWrr9G0B","executionInfo":{"status":"ok","timestamp":1606257706976,"user_tz":300,"elapsed":7678,"user":{"displayName":"Kuo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64","userId":"09688876434688467229"}},"outputId":"c7d3fd72-f0c9-4dae-e36a-8bc829fcb8b1"},"source":["ADModelBuilder.calc_confu_mat_for_each_label(model=graph_reg_model, data=data, data_label=data_label)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["TN: [2817 2864 2874 2862]\n","TP: [971 901 924 965]\n","FN: [20 37 10  0]\n","FP: [20 26 20  1]\n","Acc: [0.98955068 0.98354232 0.99216301 0.99973877]\n","ER(Error rate): [0.01044932 0.01645768 0.00783699 0.00026123]\n","Recall(TP rate): [0.97981837 0.96055437 0.98929336 1.        ]\n","Specialty(TN rate): [0.9929503  0.99100346 0.99308915 0.99965072]\n","Fall Out(FP rate): [0.0070497  0.00899654 0.00691085 0.00034928]\n","Miss Rate(FN rate): [0.02018163 0.03944563 0.01070664 0.        ]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vdqXEIl89G4K"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eZvjZITyuaMt"},"source":[""],"execution_count":null,"outputs":[]}]}