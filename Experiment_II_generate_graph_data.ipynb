{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Data Generation (Done on Google Collab)\n",
    "### Load Packages (Mout Driver At First)\n",
    "### Define Data Path (Path is based on the google collab drive path, not local fs path)\n",
    "### Compress Train Data With AAE\n",
    "### Cluster Train Representation Data With KMeans Cluster\n",
    "### Generate Complete Graph Data\n",
    "### Map Train Data With Complete Graph Data For Final Training Data (train.tfr for final model training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20697,
     "status": "ok",
     "timestamp": 1617291657113,
     "user": {
      "displayName": "Kuo Yang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64",
      "userId": "09688876434688467229"
     },
     "user_tz": 240
    },
    "id": "nl8hmi8WF8nV",
    "outputId": "102817bf-cc7f-49d3-a8a1-407860ccbf41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4SKyLeTAFB7z"
   },
   "source": [
    "###1.Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3675,
     "status": "ok",
     "timestamp": 1617291572086,
     "user": {
      "displayName": "Kuo Yang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64",
      "userId": "09688876434688467229"
     },
     "user_tz": 240
    },
    "id": "jfUc2G4uFYIv",
    "outputId": "b7c00ff9-1eb6-4ec5-f5a8-f3a9bea6eba9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting neural_structured_learning\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8a/23/179e6b7555000de51d9a317e9e47db84cda0180c941cfbf14775925af611/neural_structured_learning-1.3.1-py2.py3-none-any.whl (120kB)\n",
      "\r",
      "\u001b[K     |██▊                             | 10kB 25.1MB/s eta 0:00:01\r",
      "\u001b[K     |█████▍                          | 20kB 31.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████▏                       | 30kB 18.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▉                     | 40kB 21.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▋                  | 51kB 24.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▎               | 61kB 27.1MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████             | 71kB 18.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▊          | 81kB 19.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▌       | 92kB 18.6MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▏    | 102kB 18.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████  | 112kB 18.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 122kB 18.8MB/s \n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.7/dist-packages (from neural_structured_learning) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: absl-py in /usr/local/lib/python3.7/dist-packages (from neural_structured_learning) (0.12.0)\n",
      "Requirement already satisfied, skipping upgrade: attrs in /usr/local/lib/python3.7/dist-packages (from neural_structured_learning) (20.3.0)\n",
      "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.7/dist-packages (from neural_structured_learning) (1.4.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy->neural_structured_learning) (1.19.5)\n",
      "Installing collected packages: neural-structured-learning\n",
      "Successfully installed neural-structured-learning-1.3.1\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Install NSL package\"\"\"\n",
    "!pip install --upgrade neural_structured_learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "executionInfo": {
     "elapsed": 259,
     "status": "error",
     "timestamp": 1617291662582,
     "user": {
      "displayName": "Kuo Yang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhvhHpgVc10_WkXJdd-l8czxL6YthTSeY7jzmZM=s64",
      "userId": "09688876434688467229"
     },
     "user_tz": 240
    },
    "id": "Ptp279xsFB7z",
    "outputId": "898fbc04-a2f6-4308-870d-65dbba373ad2"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-367c2420707b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpython_files\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_data_processing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGraphDataProcess\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpython_files\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAAE_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAAE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpython_files\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnsl_data_processing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGenerateTrainTestDict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNSLDataFormat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpython_files\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKmeans\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKMeansModels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'python_files'",
      "",
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from python_files.graph_data_processing import GraphDataProcess\n",
    "from python_files.AAE_model import AAE\n",
    "from python_files.nsl_data_processing import GenerateTrainTestDict, NSLDataFormat\n",
    "from python_files.Kmeans import KMeans, KMeansModels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-uA0ZmmQFB70"
   },
   "source": [
    "###2.Define Data Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "daeKh-MqFB70"
   },
   "outputs": [],
   "source": [
    "''' label definition: NonDemented - 0, VeryMildDemented - 1, MildDemented -2, ModerateDemented -3 '''\n",
    "label_list = ['NonDemented', 'VeryMildDemented', 'MildDemented', 'ModerateDemented']\n",
    "root_path = './project_dataset/graph_images/'\n",
    "train_root_path = f'{root_path}train/'\n",
    "test_root_path = f'{root_path}test/'\n",
    "\n",
    "train_path_list = [f'{train_root_path}{label}/' for label in label_list]\n",
    "train_tfr_list = [f'{train_root_path}{label}.tfr' for label in label_list]\n",
    "\n",
    "test_path_list = [f'{test_root_path}{label}/' for label in label_list]\n",
    "test_tfr_list = [f'{test_root_path}{label}.tfr' for label in label_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6jYnHd81FB75"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JzJksejGGcE1"
   },
   "source": [
    "###3.Compress TRAIN data with AAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q65VjmzvFB75"
   },
   "outputs": [],
   "source": [
    "'''Generate AAE represents'''\n",
    "latent_dim = 128\n",
    "learning_rate = 0.0001\n",
    "channels = 3\n",
    "real_mean = 0\n",
    "real_std = 1\n",
    "batch = 1\n",
    "size=(100, 100)\n",
    "epochs= 400\n",
    "checkpoint_path = '/content/drive/MyDrive/AD Expriment II/AAE_model_checkpoints/aae_model_checkpoints'\n",
    "image_dataset = GraphDataProcess.parse_tfr_to_image_tensor(path_list=train_tfr_list, \n",
    "                                                           batch_size=batch, \n",
    "                                                           size= size, \n",
    "                                                           channels= channels, \n",
    "                                                           shuffle=True)\n",
    "aae = AAE(latent_dim=latent_dim, \n",
    "          image_channels=channels,\n",
    "          aae_optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate, amsgrad=True))\n",
    "# aae.load_weights(checkpoint_path)           # NOTE: checkpoints are too big to uploaded to the git repo, so this line could be commented out in the first run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cQMpRINhFB75"
   },
   "outputs": [],
   "source": [
    "# aae.fit(image_dataset=image_dataset,\n",
    "#         checkpoints_path=checkpoint_path,\n",
    "#         batch_size=1,\n",
    "#         real_mean=real_mean,\n",
    "#         real_std=real_std,\n",
    "#         epochs=epochs,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o5EKTCSBG6ZE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QooPa8wTFB75"
   },
   "outputs": [],
   "source": [
    "'''Plot real images vs reconstructed images'''\n",
    "tfr_list = [f'{root_path}{label}.tfr' for label in label_list]\n",
    "image_dataset = GraphDataProcess.parse_tfr_to_image_tensor(path_list=train_tfr_list, \n",
    "                                                           batch_size=10, \n",
    "                                                           size=(100,100),\n",
    "                                                           channels=3,\n",
    "                                                           shuffle=True)\n",
    "data = iter(image_dataset).get_next()\n",
    "plt.figure(figsize=(40,50))\n",
    "for img_index, img_tensor in enumerate(data['image_tensor']):\n",
    "    plt.subplot(1, 10, img_index + 1)\n",
    "    plt.imshow(img_tensor)\n",
    "    plt.title(label_list[data['label'].numpy()[img_index]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q3wOgjA7FB76"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40,50))\n",
    "for img_index, img_tensor in enumerate(data['image_tensor']):\n",
    "    img_tensor = tf.expand_dims(img_tensor, axis=0)\n",
    "    _m, _l, rep = aae.encoder(img_tensor)\n",
    "    img_new = aae.decoder(rep)\n",
    "    img_new = tf.squeeze(img_new, axis=0)\n",
    "    plt.subplot(1, 10, img_index + 1)\n",
    "    plt.imshow(tf.abs(img_new))\n",
    "    plt.title('AAE-'+label_list[data['label'].numpy()[img_index]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LaKVbrbnFB76"
   },
   "outputs": [],
   "source": [
    "'''generate TRAIN image represents tfr files'''\n",
    "img_data_list = [ GraphDataProcess.parse_tfr_to_image_tensor(path_list=[tfr_path], batch_size=1, size=(100,100), channels=3, shuffle=False) for tfr_path in tfr_list]\n",
    "print(*img_data_list,sep='\\n')\n",
    "# GraphDataProcess.generate_tfr_aae_represent(image_dataset_list=img_data_list, aae_model=aae, tfr_rep_path=tfr_rep_list)         # NOTE: AAE rep tfr files are uploaded to git repo, so could be comment out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OL31KwkrFB76"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vTTVTNvpHNRm"
   },
   "source": [
    "###4.Cluster AAE Represents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aeRBmv4yFB76"
   },
   "outputs": [],
   "source": [
    "\"\"\"generate K_means models for each label data\"\"\"\n",
    "batch= 5000\n",
    "rep_dim= 128\n",
    "K_value_list = [10,10, 10, 10] # for both train and test data\n",
    "epoch= 50\n",
    "Kmeans_model_list = KMeansModels.generate_model_list(path_list = tfr_rep_list, rep_dim=rep_dim, K_list=K_value_list, epoch=epoch, batch=batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vqEXjcENFB76"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Qhg5o2AHYbk"
   },
   "source": [
    "###5.Generate TRAIN Graph data based on clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AI8D3QeSHXv4"
   },
   "outputs": [],
   "source": [
    "'''generate the complete graph with clustering for TRAIN data only'''\n",
    "threshold = 0.90\n",
    "complete_graph = GraphDataProcess.generate_complete_graph_with_cluster_kmeans(tfr_rep_path_list= tfr_rep_list,\n",
    "                                                                              prefix_list= [0,1,2,3], \n",
    "                                                                              model_list= Kmeans_model_list, \n",
    "                                                                              represent_dim= 128, \n",
    "                                                                              file_output_path= f'{root_path}AD_graph_AAE_KMeans.tsv',\n",
    "                                                                              similarity_threshold=threshold)\n",
    "complete_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "auyUgwRtHj0C"
   },
   "outputs": [],
   "source": [
    "\"\"\"count seed node number for each label\"\"\"\n",
    "seed_count={}\n",
    "for key in complete_graph.keys():\n",
    "    split_content = key.split('_')[0]\n",
    "    if 'c' not in split_content: \n",
    "        index=int(split_content)\n",
    "        if index in [0,1,2,3] and (index in seed_count):\n",
    "            seed_count[index] +=1\n",
    "        elif index in [0,1,2,3] and (index not in seed_count):\n",
    "            seed_count[index] =1\n",
    "print(seed_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KpSuqcNvHj21"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iohtlt-QIMpw"
   },
   "source": [
    "###6.Generate NSL compatible training data (train.tfr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Y-WzBCuHj52"
   },
   "outputs": [],
   "source": [
    "'''Generate the TRAIN dictionary with shuffled MRI images'''\n",
    "train_examples, _ = GenerateTrainTestDict.get_train_test_dict(path_list=path_list, train_percentage=1)\n",
    "print('train examples: ', len(train_examples.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_UppRn03Hj83"
   },
   "outputs": [],
   "source": [
    "'''generate \"train_data.tfr\" by merging TRAIN examples with the complete AAE graph'''\n",
    "# nsl_train= NSLDataFormat(seed_dict_examples= train_examples,\n",
    "#                          rem_dict_examples= _, \n",
    "#                          graph= nsl.tools.read_tsv_graph(f'{root_path}AD_graph_AAE_KMeans.tsv'), \n",
    "#                          max_nbrs= 5)\n",
    "# nsl_train.generate_node_nbrs_tfr(output_file_path=train_tfr_path)              #NOTE: train_data.tfr is uploaded to git repo, so this cell could be commented out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uvq0ExUaHj_L"
   },
   "outputs": [],
   "source": [
    "'''parse train_graph_examples with clusters'''\n",
    "parsed_image_size=(100,100)\n",
    "parsed_image_channel=3\n",
    "batch=1\n",
    "max_seed_node_neighbours=5\n",
    "train_image_dataset = NSLDataFormat.parse_tfr_to_dataset(file_path_list=[train_tfr_path],\n",
    "                                                   batch_size=batch,\n",
    "                                                   max_neighbor_number= max_seed_node_neighbours,\n",
    "                                                   image_size=parsed_image_size,\n",
    "                                                   image_channels=parsed_image_channel,\n",
    "                                                   shuffle=True)\n",
    "data_sample = iter(train_image_dataset).get_next()\n",
    "\n",
    "'''plot parsed train_graph examples with clusters'''\n",
    "label =  tf.argmax(data_sample[1], axis=0)\n",
    "sample = data_sample[0]\n",
    "img_index=0\n",
    "plt.figure(figsize=(30,10))\n",
    "for key, value in sample.items():\n",
    "    if key.split('_')[-1]=='tensor':\n",
    "        plt.subplot(1,max_seed_node_neighbours+1,img_index + 1)\n",
    "        img_tensor = tf.reshape(value, shape=value.shape[1:])\n",
    "        plt.imshow(img_tensor)\n",
    "        plt.title(f'{label_list[label.numpy()[0]]}:{key}')\n",
    "        img_index +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qd-29xzxIjHS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9w7sliQdIjKX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bFLkX1WKIjM6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tzBPtbsXIjQA"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Experiment_II_generate_graph_data.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
